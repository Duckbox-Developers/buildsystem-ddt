Index: linux-3.2/include/linux/fs.h
===================================================================
--- linux-3.2.orig/include/linux/fs.h
+++ linux-3.2/include/linux/fs.h
@@ -2224,8 +2224,12 @@ extern int check_disk_change(struct bloc
 extern int __invalidate_device(struct block_device *, bool);
 extern int invalidate_partition(struct gendisk *, int);
 #endif
-unsigned long invalidate_mapping_pages(struct address_space *mapping,
-					pgoff_t start, pgoff_t end);
+
+#define invalidate_mapping_pages(__mapping, __start, __end)	\
+		__invalidate_mapping_pages(__mapping, __start, __end, true)
+unsigned long __invalidate_mapping_pages(struct address_space *mapping,
+					pgoff_t start, pgoff_t end,
+					bool invalidate);
 
 static inline void invalidate_remote_inode(struct inode *inode)
 {
Index: linux-3.2/mm/fadvise.c
===================================================================
--- linux-3.2.orig/mm/fadvise.c
+++ linux-3.2/mm/fadvise.c
@@ -107,7 +107,7 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, lof
 		nrpages = end_index - start_index + 1;
 		if (!nrpages)
 			nrpages = ~0UL;
-		
+
 		ret = force_page_cache_readahead(mapping, file,
 				start_index,
 				nrpages);
@@ -124,9 +124,16 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, lof
 		start_index = (offset+(PAGE_CACHE_SIZE-1)) >> PAGE_CACHE_SHIFT;
 		end_index = (endbyte >> PAGE_CACHE_SHIFT);
 
+		/*
+		 * Reduce cache eligibility.
+		 *
+		 * This does not guarantee that pages are always dropped from
+		 * page cache: active pages will be moved to the tail of the
+		 * inactive list; inactive pages will be dropped if possible.
+		 */
 		if (end_index >= start_index) {
-			unsigned long count = invalidate_mapping_pages(mapping,
-						start_index, end_index);
+			unsigned long count = __invalidate_mapping_pages(mapping,
+						start_index, end_index, false);
 
 			/*
 			 * If fewer pages were invalidated than expected then
@@ -136,8 +143,8 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, lof
 			 */
 			if (count < (end_index - start_index + 1)) {
 				lru_add_drain_all();
-				invalidate_mapping_pages(mapping, start_index,
-						end_index);
+				__invalidate_mapping_pages(mapping, start_index,
+						end_index, false);
 			}
 		}
 		break;
Index: linux-3.2/mm/swap.c
===================================================================
--- linux-3.2.orig/mm/swap.c
+++ linux-3.2/mm/swap.c
@@ -436,7 +436,7 @@ void add_page_to_unevictable_list(struct
  * 2. active, dirty/writeback page -> inactive, head, PG_reclaim
  * 3. inactive, mapped page -> none
  * 4. inactive, dirty/writeback page -> inactive, head, PG_reclaim
- * 5. inactive, clean -> inactive, tail
+ * 5. [in]active, clean -> inactive, tail
  * 6. Others -> none
  *
  * In 4, why it moves inactive's head, the VM expects the page would
Index: linux-3.2/mm/truncate.c
===================================================================
--- linux-3.2.orig/mm/truncate.c
+++ linux-3.2/mm/truncate.c
@@ -315,20 +315,27 @@ void truncate_inode_pages(struct address
 EXPORT_SYMBOL(truncate_inode_pages);
 
 /**
- * invalidate_mapping_pages - Invalidate all the unlocked pages of one inode
+ * __invalidate_mapping_pages - Invalidate all the unlocked pages of one inode
  * @mapping: the address_space which holds the pages to invalidate
  * @start: the offset 'from' which to invalidate
  * @end: the offset 'to' which to invalidate (inclusive)
+ * @invalidate: aggressive cache invalidation when true
  *
  * This function only removes the unlocked pages, if you want to
  * remove all the pages of one inode, you must call truncate_inode_pages.
  *
- * invalidate_mapping_pages() will not block on IO activity. It will not
- * invalidate pages which are dirty, locked, under writeback or mapped into
- * pagetables.
+ * The @invalidate parameter can be used to apply a more aggressive policy
+ * (when true) that will always drop pages from page cache when possible, or to
+ * just reduce cache eligibility (when false). In the last case active pages
+ * will be moved to the tail of the inactive list by deactivate_page();
+ * inactive pages will be dropped in both cases.
+ *
+ * __invalidate_mapping_pages() will not block on IO activity. It will not
+ * invalidate pages which are dirty, locked, under writeback, mapped into
+ * pagetables, or on active lru when @invalidate is false.
  */
-unsigned long invalidate_mapping_pages(struct address_space *mapping,
-		pgoff_t start, pgoff_t end)
+unsigned long __invalidate_mapping_pages(struct address_space *mapping,
+		pgoff_t start, pgoff_t end, bool invalidate)
 {
 	struct pagevec pvec;
 	pgoff_t index = start;
@@ -359,12 +366,26 @@ unsigned long invalidate_mapping_pages(s
 			if (!trylock_page(page))
 				continue;
 			WARN_ON(page->index != index);
-			ret = invalidate_inode_page(page);
-			unlock_page(page);
 			/*
-			 * Invalidation is a hint that the page is no longer
-			 * of interest and try to speed up its reclaim.
+			 * Invalidation of active page is rather aggressive as
+			 * we can't make sure it's not a working set of other
+			 * processes.
+			 *
+			 * When "invalidate" is false, deactivate_page() would
+			 * move active page into inactive's tail so the page
+			 * will have a chance to activate again if other
+			 * processes touch it.
 			 */
+			if (!invalidate && PageActive(page))
+				ret = 0;
+			else
+				ret = invalidate_inode_page(page);
+			unlock_page(page);
+			/*
+			 * Invalidation of an inactive page (or any page when
+			 * invalidate is true) is a hint that the page is no
+			 * longer of interest and try to speed up its reclaim.
+ 			 */
 			if (!ret)
 				deactivate_page(page);
 			count += ret;
@@ -376,7 +397,7 @@ unsigned long invalidate_mapping_pages(s
 	}
 	return count;
 }
-EXPORT_SYMBOL(invalidate_mapping_pages);
+EXPORT_SYMBOL(__invalidate_mapping_pages);
 
 /*
  * This is like invalidate_complete_page(), except it ignores the page's
