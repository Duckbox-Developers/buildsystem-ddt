--- linux-sh4/include/linux/ata.h.org	2012-03-10 00:25:22.000000000 -0800
+++ linux-sh4/include/linux/ata.h	2012-01-15 06:30:14.000000000 -0800
@@ -29,10 +29,7 @@
 #ifndef __LINUX_ATA_H__
 #define __LINUX_ATA_H__
 
-#include <linux/kernel.h>
-#include <linux/string.h>
 #include <linux/types.h>
-#include <asm/byteorder.h>
 
 /* defines only for the constants which don't work well as enums */
 #define ATA_DMA_BOUNDARY	0xffffUL
@@ -46,55 +43,20 @@
 	ATA_MAX_SECTORS_128	= 128,
 	ATA_MAX_SECTORS		= 256,
 	ATA_MAX_SECTORS_LBA48	= 65535,/* TODO: 65536? */
-	ATA_MAX_SECTORS_TAPE	= 65535,
 
 	ATA_ID_WORDS		= 256,
-	ATA_ID_CONFIG		= 0,
-	ATA_ID_CYLS		= 1,
-	ATA_ID_HEADS		= 3,
-	ATA_ID_SECTORS		= 6,
 	ATA_ID_SERNO		= 10,
-	ATA_ID_BUF_SIZE		= 21,
 	ATA_ID_FW_REV		= 23,
 	ATA_ID_PROD		= 27,
-	ATA_ID_MAX_MULTSECT	= 47,
-	ATA_ID_DWORD_IO		= 48,
-	ATA_ID_CAPABILITY	= 49,
 	ATA_ID_OLD_PIO_MODES	= 51,
-	ATA_ID_OLD_DMA_MODES	= 52,
 	ATA_ID_FIELD_VALID	= 53,
-	ATA_ID_CUR_CYLS		= 54,
-	ATA_ID_CUR_HEADS	= 55,
-	ATA_ID_CUR_SECTORS	= 56,
-	ATA_ID_MULTSECT		= 59,
-	ATA_ID_LBA_CAPACITY	= 60,
-	ATA_ID_SWDMA_MODES	= 62,
 	ATA_ID_MWDMA_MODES	= 63,
 	ATA_ID_PIO_MODES	= 64,
 	ATA_ID_EIDE_DMA_MIN	= 65,
-	ATA_ID_EIDE_DMA_TIME	= 66,
 	ATA_ID_EIDE_PIO		= 67,
 	ATA_ID_EIDE_PIO_IORDY	= 68,
-	ATA_ID_QUEUE_DEPTH	= 75,
-	ATA_ID_MAJOR_VER	= 80,
-	ATA_ID_COMMAND_SET_1	= 82,
-	ATA_ID_COMMAND_SET_2	= 83,
-	ATA_ID_CFSSE		= 84,
-	ATA_ID_CFS_ENABLE_1	= 85,
-	ATA_ID_CFS_ENABLE_2	= 86,
-	ATA_ID_CSF_DEFAULT	= 87,
 	ATA_ID_UDMA_MODES	= 88,
-	ATA_ID_HW_CONFIG	= 93,
-	ATA_ID_SPG		= 98,
-	ATA_ID_LBA_CAPACITY_2	= 100,
-	ATA_ID_LAST_LUN		= 126,
-	ATA_ID_DLF		= 128,
-	ATA_ID_CSFO		= 129,
-	ATA_ID_CFA_POWER	= 160,
-	ATA_ID_CFA_KEY_MGMT	= 162,
-	ATA_ID_CFA_MODES	= 163,
-	ATA_ID_DATA_SET_MGMT	= 169,
-	ATA_ID_ROT_SPEED	= 217,
+	ATA_ID_MAJOR_VER	= 80,
 	ATA_ID_PIO4		= (1 << 1),
 
 	ATA_ID_SERNO_LEN	= 20,
@@ -111,8 +73,6 @@
 	ATA_PIO5		= ATA_PIO4 | (1 << 5),
 	ATA_PIO6		= ATA_PIO5 | (1 << 6),
 
-	ATA_PIO4_ONLY		= (1 << 4),
-
 	ATA_SWDMA0		= (1 << 0),
 	ATA_SWDMA1		= ATA_SWDMA0 | (1 << 1),
 	ATA_SWDMA2		= ATA_SWDMA1 | (1 << 2),
@@ -122,8 +82,6 @@
 	ATA_MWDMA0		= (1 << 0),
 	ATA_MWDMA1		= ATA_MWDMA0 | (1 << 1),
 	ATA_MWDMA2		= ATA_MWDMA1 | (1 << 2),
-	ATA_MWDMA3		= ATA_MWDMA2 | (1 << 3),
-	ATA_MWDMA4		= ATA_MWDMA3 | (1 << 4),
 
 	ATA_MWDMA12_ONLY	= (1 << 1) | (1 << 2),
 	ATA_MWDMA2_ONLY		= (1 << 2),
@@ -138,8 +96,6 @@
 	ATA_UDMA7		= ATA_UDMA6 | (1 << 7),
 	/* ATA_UDMA7 is just for completeness... doesn't exist (yet?).  */
 
-	ATA_UDMA24_ONLY		= (1 << 2) | (1 << 4),
-
 	ATA_UDMA_MASK_40C	= ATA_UDMA2,	/* udma0-2 */
 
 	/* DMA-related */
@@ -166,26 +122,13 @@
 	ATA_BUSY		= (1 << 7),	/* BSY status bit */
 	ATA_DRDY		= (1 << 6),	/* device ready */
 	ATA_DF			= (1 << 5),	/* device fault */
-	ATA_DSC			= (1 << 4),	/* drive seek complete */
 	ATA_DRQ			= (1 << 3),	/* data request i/o */
-	ATA_CORR		= (1 << 2),	/* corrected data error */
-	ATA_IDX			= (1 << 1),	/* index */
 	ATA_ERR			= (1 << 0),	/* have an error */
 	ATA_SRST		= (1 << 2),	/* software reset */
 	ATA_ICRC		= (1 << 7),	/* interface CRC error */
-	ATA_BBK			= ATA_ICRC,	/* pre-EIDE: block marked bad */
 	ATA_UNC			= (1 << 6),	/* uncorrectable media error */
-	ATA_MC			= (1 << 5),	/* media changed */
 	ATA_IDNF		= (1 << 4),	/* ID not found */
-	ATA_MCR			= (1 << 3),	/* media change requested */
 	ATA_ABORTED		= (1 << 2),	/* command aborted */
-	ATA_TRK0NF		= (1 << 1),	/* track 0 not found */
-	ATA_AMNF		= (1 << 0),	/* address mark not found */
-	ATAPI_LFS		= 0xF0,		/* last failed sense */
-	ATAPI_EOM		= ATA_TRK0NF,	/* end of media */
-	ATAPI_ILI		= ATA_AMNF,	/* illegal length indication */
-	ATAPI_IO		= (1 << 1),
-	ATAPI_COD		= (1 << 0),
 
 	/* ATA command block registers */
 	ATA_REG_DATA		= 0x00,
@@ -210,25 +153,15 @@
 	ATA_CMD_STANDBY		= 0xE2, /* place in standby power mode */
 	ATA_CMD_IDLE		= 0xE3, /* place in idle power mode */
 	ATA_CMD_EDD		= 0x90,	/* execute device diagnostic */
-	ATA_CMD_DOWNLOAD_MICRO  = 0x92,
-	ATA_CMD_NOP		= 0x00,
 	ATA_CMD_FLUSH		= 0xE7,
 	ATA_CMD_FLUSH_EXT	= 0xEA,
 	ATA_CMD_ID_ATA		= 0xEC,
 	ATA_CMD_ID_ATAPI	= 0xA1,
-	ATA_CMD_SERVICE		= 0xA2,
 	ATA_CMD_READ		= 0xC8,
 	ATA_CMD_READ_EXT	= 0x25,
-	ATA_CMD_READ_QUEUED	= 0x26,
-	ATA_CMD_READ_STREAM_EXT	= 0x2B,
-	ATA_CMD_READ_STREAM_DMA_EXT = 0x2A,
 	ATA_CMD_WRITE		= 0xCA,
 	ATA_CMD_WRITE_EXT	= 0x35,
-	ATA_CMD_WRITE_QUEUED	= 0x36,
-	ATA_CMD_WRITE_STREAM_EXT = 0x3B,
-	ATA_CMD_WRITE_STREAM_DMA_EXT = 0x3A,
 	ATA_CMD_WRITE_FUA_EXT	= 0x3D,
-	ATA_CMD_WRITE_QUEUED_FUA_EXT = 0x3E,
 	ATA_CMD_FPDMA_READ	= 0x60,
 	ATA_CMD_FPDMA_WRITE	= 0x61,
 	ATA_CMD_PIO_READ	= 0x20,
@@ -245,45 +178,16 @@
 	ATA_CMD_PACKET		= 0xA0,
 	ATA_CMD_VERIFY		= 0x40,
 	ATA_CMD_VERIFY_EXT	= 0x42,
-	ATA_CMD_WRITE_UNCORR_EXT = 0x45,
-	ATA_CMD_STANDBYNOW1	= 0xE0,
-	ATA_CMD_IDLEIMMEDIATE	= 0xE1,
-	ATA_CMD_SLEEP		= 0xE6,
+ 	ATA_CMD_STANDBYNOW1	= 0xE0,
+ 	ATA_CMD_IDLEIMMEDIATE	= 0xE1,
 	ATA_CMD_INIT_DEV_PARAMS	= 0x91,
 	ATA_CMD_READ_NATIVE_MAX	= 0xF8,
 	ATA_CMD_READ_NATIVE_MAX_EXT = 0x27,
 	ATA_CMD_SET_MAX		= 0xF9,
 	ATA_CMD_SET_MAX_EXT	= 0x37,
-	ATA_CMD_READ_LOG_EXT	= 0x2F,
-	ATA_CMD_WRITE_LOG_EXT	= 0x3F,
-	ATA_CMD_READ_LOG_DMA_EXT = 0x47,
-	ATA_CMD_WRITE_LOG_DMA_EXT = 0x57,
-	ATA_CMD_TRUSTED_RCV	= 0x5C,
-	ATA_CMD_TRUSTED_RCV_DMA = 0x5D,
-	ATA_CMD_TRUSTED_SND	= 0x5E,
-	ATA_CMD_TRUSTED_SND_DMA = 0x5F,
+	ATA_CMD_READ_LOG_EXT	= 0x2f,
 	ATA_CMD_PMP_READ	= 0xE4,
 	ATA_CMD_PMP_WRITE	= 0xE8,
-	ATA_CMD_CONF_OVERLAY	= 0xB1,
-	ATA_CMD_SEC_SET_PASS	= 0xF1,
-	ATA_CMD_SEC_UNLOCK	= 0xF2,
-	ATA_CMD_SEC_ERASE_PREP	= 0xF3,
-	ATA_CMD_SEC_ERASE_UNIT	= 0xF4,
-	ATA_CMD_SEC_FREEZE_LOCK	= 0xF5,
-	ATA_CMD_SEC_DISABLE_PASS = 0xF6,
-	ATA_CMD_CONFIG_STREAM	= 0x51,
-	ATA_CMD_SMART		= 0xB0,
-	ATA_CMD_MEDIA_LOCK	= 0xDE,
-	ATA_CMD_MEDIA_UNLOCK	= 0xDF,
-	ATA_CMD_DSM		= 0x06,
-	ATA_CMD_CHK_MED_CRD_TYP = 0xD1,
-	ATA_CMD_CFA_REQ_EXT_ERR = 0x03,
-	ATA_CMD_CFA_WRITE_NE	= 0x38,
-	ATA_CMD_CFA_TRANS_SECT	= 0x87,
-	ATA_CMD_CFA_ERASE	= 0xC0,
-	ATA_CMD_CFA_WRITE_MULT_NE = 0xCD,
-	/* marked obsolete in the ATA/ATAPI-7 spec */
-	ATA_CMD_RESTORE		= 0x10,
 
 	/* READ_LOG_EXT pages */
 	ATA_LOG_SATA_NCQ	= 0x10,
@@ -293,6 +197,8 @@
 	ATA_CMD_READ_LONG_ONCE	= 0x23,
 	ATA_CMD_WRITE_LONG	= 0x32,
 	ATA_CMD_WRITE_LONG_ONCE	= 0x33,
+	
+	ATA_CMD_SMART		= 0xB0,
 
 	/* SETFEATURES stuff */
 	SETFEATURES_XFER	= 0x03,
@@ -324,48 +230,8 @@
 	SETFEATURES_WC_ON	= 0x02, /* Enable write cache */
 	SETFEATURES_WC_OFF	= 0x82, /* Disable write cache */
 
-	/* Enable/Disable Automatic Acoustic Management */
-	SETFEATURES_AAM_ON	= 0x42,
-	SETFEATURES_AAM_OFF	= 0xC2,
-
 	SETFEATURES_SPINUP	= 0x07, /* Spin-up drive */
 
-	SETFEATURES_SATA_ENABLE = 0x10, /* Enable use of SATA feature */
-	SETFEATURES_SATA_DISABLE = 0x90, /* Disable use of SATA feature */
-
-	/* SETFEATURE Sector counts for SATA features */
-	SATA_FPDMA_OFFSET	= 0x01,	/* FPDMA non-zero buffer offsets */
-	SATA_FPDMA_AA		= 0x02, /* FPDMA Setup FIS Auto-Activate */
-	SATA_DIPM		= 0x03,	/* Device Initiated Power Management */
-	SATA_FPDMA_IN_ORDER	= 0x04,	/* FPDMA in-order data delivery */
-	SATA_AN			= 0x05,	/* Asynchronous Notification */
-	SATA_SSP		= 0x06,	/* Software Settings Preservation */
-
-	/* feature values for SET_MAX */
-	ATA_SET_MAX_ADDR	= 0x00,
-	ATA_SET_MAX_PASSWD	= 0x01,
-	ATA_SET_MAX_LOCK	= 0x02,
-	ATA_SET_MAX_UNLOCK	= 0x03,
-	ATA_SET_MAX_FREEZE_LOCK	= 0x04,
-
-	/* feature values for DEVICE CONFIGURATION OVERLAY */
-	ATA_DCO_RESTORE		= 0xC0,
-	ATA_DCO_FREEZE_LOCK	= 0xC1,
-	ATA_DCO_IDENTIFY	= 0xC2,
-	ATA_DCO_SET		= 0xC3,
-
-	/* feature values for SMART */
-	ATA_SMART_ENABLE	= 0xD8,
-	ATA_SMART_READ_VALUES	= 0xD0,
-	ATA_SMART_READ_THRESHOLDS = 0xD1,
-
-	/* feature values for Data Set Management */
-	ATA_DSM_TRIM		= 0x01,
-
-	/* password used in LBA Mid / LBA High for executing SMART commands */
-	ATA_SMART_LBAM_PASS	= 0x4F,
-	ATA_SMART_LBAH_PASS	= 0xC2,
-
 	/* ATAPI stuff */
 	ATAPI_PKT_DMA		= (1 << 0),
 	ATAPI_DMADIR		= (1 << 2),	/* ATAPI data dir:
@@ -398,10 +264,9 @@
 	ATA_CBL_NONE		= 0,
 	ATA_CBL_PATA40		= 1,
 	ATA_CBL_PATA80		= 2,
-	ATA_CBL_PATA40_SHORT	= 3,	/* 40 wire cable to high UDMA spec */
-	ATA_CBL_PATA_UNK	= 4,	/* don't know, maybe 80c? */
-	ATA_CBL_PATA_IGN	= 5,	/* don't know, ignore cable handling */
-	ATA_CBL_SATA		= 6,
+	ATA_CBL_PATA40_SHORT	= 3,		/* 40 wire cable to high UDMA spec */
+	ATA_CBL_PATA_UNK	= 4,
+	ATA_CBL_SATA		= 5,
 
 	/* SATA Status and Control Registers */
 	SCR_STATUS		= 0,
@@ -418,15 +283,6 @@
 	SERR_PROTOCOL		= (1 << 10), /* protocol violation */
 	SERR_INTERNAL		= (1 << 11), /* host internal error */
 	SERR_PHYRDY_CHG		= (1 << 16), /* PHY RDY changed */
-	SERR_PHY_INT_ERR	= (1 << 17), /* PHY internal error */
-	SERR_COMM_WAKE		= (1 << 18), /* Comm wake */
-	SERR_10B_8B_ERR		= (1 << 19), /* 10b to 8b decode error */
-	SERR_DISPARITY		= (1 << 20), /* Disparity */
-	SERR_CRC		= (1 << 21), /* CRC error */
-	SERR_HANDSHAKE		= (1 << 22), /* Handshake error */
-	SERR_LINK_SEQ_ERR	= (1 << 23), /* Link sequence error */
-	SERR_TRANS_ST_ERROR	= (1 << 24), /* Transport state trans. error */
-	SERR_UNRECOG_FIS	= (1 << 25), /* Unrecognized FIS */
 	SERR_DEV_XCHG		= (1 << 26), /* device exchanged */
 
 	/* struct ata_taskfile flags */
@@ -437,13 +293,6 @@
 	ATA_TFLAG_LBA		= (1 << 4), /* enable LBA */
 	ATA_TFLAG_FUA		= (1 << 5), /* enable FUA */
 	ATA_TFLAG_POLLING	= (1 << 6), /* set nIEN to 1 and use polling */
-
-	/* protocol flags */
-	ATA_PROT_FLAG_PIO	= (1 << 0), /* is PIO */
-	ATA_PROT_FLAG_DMA	= (1 << 1), /* is DMA */
-	ATA_PROT_FLAG_DATA	= ATA_PROT_FLAG_PIO | ATA_PROT_FLAG_DMA,
-	ATA_PROT_FLAG_NCQ	= (1 << 2), /* is NCQ */
-	ATA_PROT_FLAG_ATAPI	= (1 << 3), /* is ATAPI */
 };
 
 enum ata_tf_protocols {
@@ -453,9 +302,9 @@
 	ATA_PROT_PIO,		/* PIO data xfer */
 	ATA_PROT_DMA,		/* DMA */
 	ATA_PROT_NCQ,		/* NCQ */
-	ATAPI_PROT_NODATA,	/* packet command, no data */
-	ATAPI_PROT_PIO,		/* packet command, PIO data xfer*/
-	ATAPI_PROT_DMA,		/* packet command with special DMA sauce */
+	ATA_PROT_ATAPI,		/* packet command, PIO data xfer*/
+	ATA_PROT_ATAPI_NODATA,	/* packet command, no data */
+	ATA_PROT_ATAPI_DMA,	/* packet command with special DMA sauce */
 };
 
 enum ata_ioctls {
@@ -466,8 +315,8 @@
 /* core structures */
 
 struct ata_prd {
-	__le32			addr;
-	__le32			flags_len;
+	u32			addr;
+	u32			flags_len;
 };
 
 struct ata_taskfile {
@@ -493,77 +342,25 @@
 	u8			command;	/* IO operation */
 };
 
-/*
- * protocol tests
- */
-static inline unsigned int ata_prot_flags(u8 prot)
-{
-	switch (prot) {
-	case ATA_PROT_NODATA:
-		return 0;
-	case ATA_PROT_PIO:
-		return ATA_PROT_FLAG_PIO;
-	case ATA_PROT_DMA:
-		return ATA_PROT_FLAG_DMA;
-	case ATA_PROT_NCQ:
-		return ATA_PROT_FLAG_DMA | ATA_PROT_FLAG_NCQ;
-	case ATAPI_PROT_NODATA:
-		return ATA_PROT_FLAG_ATAPI;
-	case ATAPI_PROT_PIO:
-		return ATA_PROT_FLAG_ATAPI | ATA_PROT_FLAG_PIO;
-	case ATAPI_PROT_DMA:
-		return ATA_PROT_FLAG_ATAPI | ATA_PROT_FLAG_DMA;
-	}
-	return 0;
-}
-
-static inline int ata_is_atapi(u8 prot)
-{
-	return ata_prot_flags(prot) & ATA_PROT_FLAG_ATAPI;
-}
-
-static inline int ata_is_nodata(u8 prot)
-{
-	return !(ata_prot_flags(prot) & ATA_PROT_FLAG_DATA);
-}
-
-static inline int ata_is_pio(u8 prot)
-{
-	return ata_prot_flags(prot) & ATA_PROT_FLAG_PIO;
-}
-
-static inline int ata_is_dma(u8 prot)
-{
-	return ata_prot_flags(prot) & ATA_PROT_FLAG_DMA;
-}
-
-static inline int ata_is_ncq(u8 prot)
-{
-	return ata_prot_flags(prot) & ATA_PROT_FLAG_NCQ;
-}
-
-static inline int ata_is_data(u8 prot)
-{
-	return ata_prot_flags(prot) & ATA_PROT_FLAG_DATA;
-}
-
-/*
- * id tests
- */
-#define ata_id_is_ata(id)	(((id)[ATA_ID_CONFIG] & (1 << 15)) == 0)
-#define ata_id_has_lba(id)	((id)[ATA_ID_CAPABILITY] & (1 << 9))
-#define ata_id_has_dma(id)	((id)[ATA_ID_CAPABILITY] & (1 << 8))
+#define ata_id_is_ata(id)	(((id)[0] & (1 << 15)) == 0)
+#define ata_id_rahead_enabled(id) ((id)[85] & (1 << 6))
+#define ata_id_wcache_enabled(id) ((id)[85] & (1 << 5))
+#define ata_id_hpa_enabled(id)	((id)[85] & (1 << 10))
+#define ata_id_has_fua(id)	((id)[84] & (1 << 6))
+#define ata_id_has_flush(id)	((id)[83] & (1 << 12))
+#define ata_id_has_flush_ext(id) ((id)[83] & (1 << 13))
+#define ata_id_has_lba48(id)	((id)[83] & (1 << 10))
+#define ata_id_has_hpa(id)	((id)[82] & (1 << 10))
+#define ata_id_has_wcache(id)	((id)[82] & (1 << 5))
+#define ata_id_has_pm(id)	((id)[82] & (1 << 3))
+#define ata_id_has_lba(id)	((id)[49] & (1 << 9))
+#define ata_id_has_dma(id)	((id)[49] & (1 << 8))
 #define ata_id_has_ncq(id)	((id)[76] & (1 << 8))
-#define ata_id_queue_depth(id)	(((id)[ATA_ID_QUEUE_DEPTH] & 0x1f) + 1)
-#define ata_id_removeable(id)	((id)[ATA_ID_CONFIG] & (1 << 7))
-#define ata_id_has_atapi_AN(id)	\
-	( (((id)[76] != 0x0000) && ((id)[76] != 0xffff)) && \
-	  ((id)[78] & (1 << 5)) )
-#define ata_id_has_fpdma_aa(id)	\
-	( (((id)[76] != 0x0000) && ((id)[76] != 0xffff)) && \
-	  ((id)[78] & (1 << 2)) )
-#define ata_id_iordy_disable(id) ((id)[ATA_ID_CAPABILITY] & (1 << 10))
-#define ata_id_has_iordy(id) ((id)[ATA_ID_CAPABILITY] & (1 << 11))
+#define ata_id_queue_depth(id)	(((id)[75] & 0x1f) + 1)
+#define ata_id_removeable(id)	((id)[0] & (1 << 7))
+#define ata_id_has_dword_io(id)	((id)[50] & (1 << 0))
+#define ata_id_iordy_disable(id) ((id)[49] & (1 << 10))
+#define ata_id_has_iordy(id) ((id)[49] & (1 << 9))
 #define ata_id_u32(id,n)	\
 	(((u32) (id)[(n) + 1] << 16) | ((u32) (id)[(n)]))
 #define ata_id_u64(id,n)	\
@@ -572,145 +369,7 @@
 	  ((u64) (id)[(n) + 1] << 16) |	\
 	  ((u64) (id)[(n) + 0]) )
 
-#define ata_id_cdb_intr(id)	(((id)[ATA_ID_CONFIG] & 0x60) == 0x20)
-
-static inline bool ata_id_has_hipm(const u16 *id)
-{
-	u16 val = id[76];
-
-	if (val == 0 || val == 0xffff)
-		return false;
-
-	return val & (1 << 9);
-}
-
-static inline bool ata_id_has_dipm(const u16 *id)
-{
-	u16 val = id[78];
-
-	if (val == 0 || val == 0xffff)
-		return false;
-
-	return val & (1 << 3);
-}
-
-
-static inline int ata_id_has_fua(const u16 *id)
-{
-	if ((id[ATA_ID_CFSSE] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_CFSSE] & (1 << 6);
-}
-
-static inline int ata_id_has_flush(const u16 *id)
-{
-	if ((id[ATA_ID_COMMAND_SET_2] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_COMMAND_SET_2] & (1 << 12);
-}
-
-static inline int ata_id_flush_enabled(const u16 *id)
-{
-	if (ata_id_has_flush(id) == 0)
-		return 0;
-	if ((id[ATA_ID_CSF_DEFAULT] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_CFS_ENABLE_2] & (1 << 12);
-}
-
-static inline int ata_id_has_flush_ext(const u16 *id)
-{
-	if ((id[ATA_ID_COMMAND_SET_2] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_COMMAND_SET_2] & (1 << 13);
-}
-
-static inline int ata_id_flush_ext_enabled(const u16 *id)
-{
-	if (ata_id_has_flush_ext(id) == 0)
-		return 0;
-	if ((id[ATA_ID_CSF_DEFAULT] & 0xC000) != 0x4000)
-		return 0;
-	/*
-	 * some Maxtor disks have bit 13 defined incorrectly
-	 * so check bit 10 too
-	 */
-	return (id[ATA_ID_CFS_ENABLE_2] & 0x2400) == 0x2400;
-}
-
-static inline int ata_id_has_lba48(const u16 *id)
-{
-	if ((id[ATA_ID_COMMAND_SET_2] & 0xC000) != 0x4000)
-		return 0;
-	if (!ata_id_u64(id, ATA_ID_LBA_CAPACITY_2))
-		return 0;
-	return id[ATA_ID_COMMAND_SET_2] & (1 << 10);
-}
-
-static inline int ata_id_lba48_enabled(const u16 *id)
-{
-	if (ata_id_has_lba48(id) == 0)
-		return 0;
-	if ((id[ATA_ID_CSF_DEFAULT] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_CFS_ENABLE_2] & (1 << 10);
-}
-
-static inline int ata_id_hpa_enabled(const u16 *id)
-{
-	/* Yes children, word 83 valid bits cover word 82 data */
-	if ((id[ATA_ID_COMMAND_SET_2] & 0xC000) != 0x4000)
-		return 0;
-	/* And 87 covers 85-87 */
-	if ((id[ATA_ID_CSF_DEFAULT] & 0xC000) != 0x4000)
-		return 0;
-	/* Check command sets enabled as well as supported */
-	if ((id[ATA_ID_CFS_ENABLE_1] & (1 << 10)) == 0)
-		return 0;
-	return id[ATA_ID_COMMAND_SET_1] & (1 << 10);
-}
-
-static inline int ata_id_has_wcache(const u16 *id)
-{
-	/* Yes children, word 83 valid bits cover word 82 data */
-	if ((id[ATA_ID_COMMAND_SET_2] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_COMMAND_SET_1] & (1 << 5);
-}
-
-static inline int ata_id_has_pm(const u16 *id)
-{
-	if ((id[ATA_ID_COMMAND_SET_2] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_COMMAND_SET_1] & (1 << 3);
-}
-
-static inline int ata_id_rahead_enabled(const u16 *id)
-{
-	if ((id[ATA_ID_CSF_DEFAULT] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_CFS_ENABLE_1] & (1 << 6);
-}
-
-static inline int ata_id_wcache_enabled(const u16 *id)
-{
-	if ((id[ATA_ID_CSF_DEFAULT] & 0xC000) != 0x4000)
-		return 0;
-	return id[ATA_ID_CFS_ENABLE_1] & (1 << 5);
-}
-
-/**
- *	ata_id_major_version	-	get ATA level of drive
- *	@id: Identify data
- *
- *	Caveats:
- *		ATA-1 considers identify optional
- *		ATA-2 introduces mandatory identify
- *		ATA-3 introduces word 80 and accurate reporting
- *
- *	The practical impact of this is that ata_id_major_version cannot
- *	reliably report on drives below ATA3.
- */
+#define ata_id_cdb_intr(id)	(((id)[0] & 0x60) == 0x20)
 
 static inline unsigned int ata_id_major_version(const u16 *id)
 {
@@ -727,126 +386,29 @@
 
 static inline int ata_id_is_sata(const u16 *id)
 {
-	/*
-	 * See if word 93 is 0 AND drive is at least ATA-5 compatible
-	 * verifying that word 80 by casting it to a signed type --
-	 * this trick allows us to filter out the reserved values of
-	 * 0x0000 and 0xffff along with the earlier ATA revisions...
-	 */
-	if (id[ATA_ID_HW_CONFIG] == 0 && (short)id[ATA_ID_MAJOR_VER] >= 0x0020)
-		return 1;
-	return 0;
-}
-
-static inline int ata_id_has_tpm(const u16 *id)
-{
-	/* The TPM bits are only valid on ATA8 */
-	if (ata_id_major_version(id) < 8)
-		return 0;
-	if ((id[48] & 0xC000) != 0x4000)
-		return 0;
-	return id[48] & (1 << 0);
-}
-
-static inline int ata_id_has_dword_io(const u16 *id)
-{
-	/* ATA 8 reuses this flag for "trusted" computing */
-	if (ata_id_major_version(id) > 7)
-		return 0;
-	if (id[ATA_ID_DWORD_IO] & (1 << 0))
-		return 1;
-	return 0;
-}
-
-static inline int ata_id_has_unload(const u16 *id)
-{
-	if (ata_id_major_version(id) >= 7 &&
-	    (id[ATA_ID_CFSSE] & 0xC000) == 0x4000 &&
-	    id[ATA_ID_CFSSE] & (1 << 13))
-		return 1;
-	return 0;
-}
-
-static inline int ata_id_form_factor(const u16 *id)
-{
-	u16 val = id[168];
-
-	if (ata_id_major_version(id) < 7 || val == 0 || val == 0xffff)
-		return 0;
-
-	val &= 0xf;
-
-	if (val > 5)
-		return 0;
-
-	return val;
-}
-
-static inline int ata_id_rotation_rate(const u16 *id)
-{
-	u16 val = id[217];
-
-	if (ata_id_major_version(id) < 7 || val == 0 || val == 0xffff)
-		return 0;
-
-	if (val > 1 && val < 0x401)
-		return 0;
-
-	return val;
-}
-
-static inline int ata_id_has_trim(const u16 *id)
-{
-	if (ata_id_major_version(id) >= 7 &&
-	    (id[ATA_ID_DATA_SET_MGMT] & 1))
-		return 1;
-	return 0;
+	return ata_id_major_version(id) >= 5 && id[93] == 0;
 }
 
 static inline int ata_id_current_chs_valid(const u16 *id)
 {
 	/* For ATA-1 devices, if the INITIALIZE DEVICE PARAMETERS command
 	   has not been issued to the device then the values of
-	   id[ATA_ID_CUR_CYLS] to id[ATA_ID_CUR_SECTORS] are vendor specific. */
-	return (id[ATA_ID_FIELD_VALID] & 1) && /* Current translation valid */
-		id[ATA_ID_CUR_CYLS] &&  /* cylinders in current translation */
-		id[ATA_ID_CUR_HEADS] &&  /* heads in current translation */
-		id[ATA_ID_CUR_HEADS] <= 16 &&
-		id[ATA_ID_CUR_SECTORS];    /* sectors in current translation */
+	   id[54] to id[56] are vendor specific. */
+	return (id[53] & 0x01) && /* Current translation valid */
+		id[54] &&  /* cylinders in current translation */
+		id[55] &&  /* heads in current translation */
+		id[55] <= 16 &&
+		id[56];    /* sectors in current translation */
 }
 
 static inline int ata_id_is_cfa(const u16 *id)
 {
-	if (id[ATA_ID_CONFIG] == 0x848A)	/* Traditional CF */
+	u16 v = id[0];
+	if (v == 0x848A)	/* Standard CF */
 		return 1;
-	/*
-	 * CF specs don't require specific value in the word 0 anymore and yet
-	 * they forbid to report the ATA version in the word 80 and require the
-	 * CFA feature set support to be indicated in the word 83 in this case.
-	 * Unfortunately, some cards only follow either of this requirements,
-	 * and while those that don't indicate CFA feature support need some
-	 * sort of quirk list, it seems impractical for the ones that do...
-	 */
-	if ((id[ATA_ID_COMMAND_SET_2] & 0xC004) == 0x4004)
-		return 1;
-	return 0;
-}
-
-static inline int ata_id_is_ssd(const u16 *id)
-{
-	return id[ATA_ID_ROT_SPEED] == 0x01;
-}
-
-static inline int ata_id_pio_need_iordy(const u16 *id, const u8 pio)
-{
-	/* CF spec. r4.1 Table 22 says no IORDY on PIO5 and PIO6. */
-	if (pio > 4 && ata_id_is_cfa(id))
-		return 0;
-	/* For PIO3 and higher it is mandatory. */
-	if (pio > 2)
-		return 1;
-	/* Turn it on when possible. */
-	if (ata_id_has_iordy(id))
+	/* Could be CF hiding as standard ATA */
+	if (ata_id_major_version(id) >= 3 &&  id[82] != 0xFFFF &&
+			(id[82] & ( 1 << 2)))
 		return 1;
 	return 0;
 }
@@ -855,21 +417,14 @@
 {
 	if (ata_id_is_sata(dev_id))
 		return 0;	/* SATA */
-	if ((dev_id[ATA_ID_HW_CONFIG] & 0xE000) == 0x6000)
-		return 0;	/* 80 wire */
-	return 1;
-}
-
-static inline int ata_drive_40wire_relaxed(const u16 *dev_id)
-{
-	if ((dev_id[ATA_ID_HW_CONFIG] & 0x2000) == 0x2000)
+	if ((dev_id[93] & 0xE000) == 0x6000)
 		return 0;	/* 80 wire */
 	return 1;
 }
 
 static inline int atapi_cdb_len(const u16 *dev_id)
 {
-	u16 tmp = dev_id[ATA_ID_CONFIG] & 0x3;
+	u16 tmp = dev_id[0] & 0x3;
 	switch (tmp) {
 	case 0:		return 12;
 	case 1:		return 16;
@@ -877,110 +432,11 @@
 	}
 }
 
-static inline int atapi_command_packet_set(const u16 *dev_id)
+static inline int is_atapi_taskfile(const struct ata_taskfile *tf)
 {
-	return (dev_id[ATA_ID_CONFIG] >> 8) & 0x1f;
-}
-
-static inline int atapi_id_dmadir(const u16 *dev_id)
-{
-	return ata_id_major_version(dev_id) >= 7 && (dev_id[62] & 0x8000);
-}
-
-/*
- * ata_id_is_lba_capacity_ok() performs a sanity check on
- * the claimed LBA capacity value for the device.
- *
- * Returns 1 if LBA capacity looks sensible, 0 otherwise.
- *
- * It is called only once for each device.
- */
-static inline int ata_id_is_lba_capacity_ok(u16 *id)
-{
-	unsigned long lba_sects, chs_sects, head, tail;
-
-	/* No non-LBA info .. so valid! */
-	if (id[ATA_ID_CYLS] == 0)
-		return 1;
-
-	lba_sects = ata_id_u32(id, ATA_ID_LBA_CAPACITY);
-
-	/*
-	 * The ATA spec tells large drives to return
-	 * C/H/S = 16383/16/63 independent of their size.
-	 * Some drives can be jumpered to use 15 heads instead of 16.
-	 * Some drives can be jumpered to use 4092 cyls instead of 16383.
-	 */
-	if ((id[ATA_ID_CYLS] == 16383 ||
-	     (id[ATA_ID_CYLS] == 4092 && id[ATA_ID_CUR_CYLS] == 16383)) &&
-	    id[ATA_ID_SECTORS] == 63 &&
-	    (id[ATA_ID_HEADS] == 15 || id[ATA_ID_HEADS] == 16) &&
-	    (lba_sects >= 16383 * 63 * id[ATA_ID_HEADS]))
-		return 1;
-
-	chs_sects = id[ATA_ID_CYLS] * id[ATA_ID_HEADS] * id[ATA_ID_SECTORS];
-
-	/* perform a rough sanity check on lba_sects: within 10% is OK */
-	if (lba_sects - chs_sects < chs_sects/10)
-		return 1;
-
-	/* some drives have the word order reversed */
-	head = (lba_sects >> 16) & 0xffff;
-	tail = lba_sects & 0xffff;
-	lba_sects = head | (tail << 16);
-
-	if (lba_sects - chs_sects < chs_sects/10) {
-		*(__le32 *)&id[ATA_ID_LBA_CAPACITY] = __cpu_to_le32(lba_sects);
-		return 1;	/* LBA capacity is (now) good */
-	}
-
-	return 0;	/* LBA capacity value may be bad */
-}
-
-static inline void ata_id_to_hd_driveid(u16 *id)
-{
-#ifdef __BIG_ENDIAN
-	/* accessed in struct hd_driveid as 8-bit values */
-	id[ATA_ID_MAX_MULTSECT]	 = __cpu_to_le16(id[ATA_ID_MAX_MULTSECT]);
-	id[ATA_ID_CAPABILITY]	 = __cpu_to_le16(id[ATA_ID_CAPABILITY]);
-	id[ATA_ID_OLD_PIO_MODES] = __cpu_to_le16(id[ATA_ID_OLD_PIO_MODES]);
-	id[ATA_ID_OLD_DMA_MODES] = __cpu_to_le16(id[ATA_ID_OLD_DMA_MODES]);
-	id[ATA_ID_MULTSECT]	 = __cpu_to_le16(id[ATA_ID_MULTSECT]);
-
-	/* as 32-bit values */
-	*(u32 *)&id[ATA_ID_LBA_CAPACITY] = ata_id_u32(id, ATA_ID_LBA_CAPACITY);
-	*(u32 *)&id[ATA_ID_SPG]		 = ata_id_u32(id, ATA_ID_SPG);
-
-	/* as 64-bit value */
-	*(u64 *)&id[ATA_ID_LBA_CAPACITY_2] =
-		ata_id_u64(id, ATA_ID_LBA_CAPACITY_2);
-#endif
-}
-
-/*
- * Write up to 'max' LBA Range Entries to the buffer that will cover the
- * extent from sector to sector + count.  This is used for TRIM and for
- * ADD LBA(S) TO NV CACHE PINNED SET.
- */
-static inline unsigned ata_set_lba_range_entries(void *_buffer, unsigned max,
-						u64 sector, unsigned long count)
-{
-	__le64 *buffer = _buffer;
-	unsigned i = 0;
-
-	while (i < max) {
-		u64 entry = sector |
-			((u64)(count > 0xffff ? 0xffff : count) << 48);
-		buffer[i++] = __cpu_to_le64(entry);
-		if (count <= 0xffff)
-			break;
-		count -= 0xffff;
-		sector += 0xffff;
-	}
-
-	max = ALIGN(i * 8, 512);
-	memset(buffer + i, 0, max - i * 8);
-	return max;
+	return (tf->protocol == ATA_PROT_ATAPI) ||
+	       (tf->protocol == ATA_PROT_ATAPI_NODATA) ||
+	       (tf->protocol == ATA_PROT_ATAPI_DMA);
 }
 
 static inline int is_multi_taskfile(struct ata_taskfile *tf)
@@ -1000,8 +456,8 @@
 
 static inline int lba_28_ok(u64 block, u32 n_block)
 {
-	/* check the ending block number: must be LESS THAN 0x0fffffff */
-	return ((block + n_block) < ((1 << 28) - 1)) && (n_block <= 256);
+	/* check the ending block number */
+	return ((block + n_block - 1) < ((u64)1 << 28)) && (n_block <= 256);
 }
 
 static inline int lba_48_ok(u64 block, u32 n_block)
@@ -1015,4 +471,32 @@
 #define sata_pmp_gscr_rev(gscr)		(((gscr)[SATA_PMP_GSCR_REV] >> 8) & 0xff)
 #define sata_pmp_gscr_ports(gscr)	((gscr)[SATA_PMP_GSCR_PORT_INFO] & 0xf)
 
+static inline int ata_id_form_factor(const u16 *id)
+{
+	u16 val = id[168];
+
+	if (ata_id_major_version(id) < 7 || val == 0 || val == 0xffff)
+		return 0;
+
+	val &= 0xf;
+
+	if (val > 5)
+		return 0;
+
+	return val;
+}
+
+static inline int ata_id_rotation_rate(const u16 *id)
+{
+	u16 val = id[217];
+
+	if (ata_id_major_version(id) < 7 || val == 0 || val == 0xffff)
+		return 0;
+
+	if (val > 1 && val < 0x401)
+		return 0;
+
+	return val;
+}
+
 #endif /* __LINUX_ATA_H__ */
--- linux-sh4/include/linux/libata.h.org	2012-03-10 00:25:23.000000000 -0800
+++ linux-sh4/include/linux/libata.h	2012-01-15 06:30:14.000000000 -0800
@@ -27,16 +27,15 @@
 #define __LINUX_LIBATA_H__
 
 #include <linux/delay.h>
-#include <linux/jiffies.h>
 #include <linux/interrupt.h>
+#include <linux/pci.h>
 #include <linux/dma-mapping.h>
-#include <linux/scatterlist.h>
+#include <asm/scatterlist.h>
 #include <linux/io.h>
 #include <linux/ata.h>
 #include <linux/workqueue.h>
 #include <scsi/scsi_host.h>
 #include <linux/acpi.h>
-#include <linux/cdrom.h>
 
 /*
  * Define if arch has non-standard setup.  This is a _PCI_ standard
@@ -60,9 +59,9 @@
 
 /* note: prints function name for you */
 #ifdef ATA_DEBUG
-#define DPRINTK(fmt, args...) printk(KERN_ERR "%s: " fmt, __func__, ## args)
+#define DPRINTK(fmt, args...) printk(KERN_ERR "%s: " fmt, __FUNCTION__, ## args)
 #ifdef ATA_VERBOSE_DEBUG
-#define VPRINTK(fmt, args...) printk(KERN_ERR "%s: " fmt, __func__, ## args)
+#define VPRINTK(fmt, args...) printk(KERN_ERR "%s: " fmt, __FUNCTION__, ## args)
 #else
 #define VPRINTK(fmt, args...)
 #endif	/* ATA_VERBOSE_DEBUG */
@@ -71,7 +70,7 @@
 #define VPRINTK(fmt, args...)
 #endif	/* ATA_DEBUG */
 
-#define BPRINTK(fmt, args...) if (ap->flags & ATA_FLAG_DEBUGMSG) printk(KERN_ERR "%s: " fmt, __func__, ## args)
+#define BPRINTK(fmt, args...) if (ap->flags & ATA_FLAG_DEBUGMSG) printk(KERN_ERR "%s: " fmt, __FUNCTION__, ## args)
 
 /* NEW: debug levels */
 #define HAVE_LIBATA_MSG 1
@@ -108,19 +107,24 @@
 /* defines only for the constants which don't work well as enums */
 #define ATA_TAG_POISON		0xfafbfcfdU
 
+/* move to PCI layer? */
+static inline struct device *pci_dev_to_dev(struct pci_dev *pdev)
+{
+	return &pdev->dev;
+}
+
 enum {
 	/* various global constants */
 	LIBATA_MAX_PRD		= ATA_MAX_PRD / 2,
 	LIBATA_DUMB_MAX_PRD	= ATA_MAX_PRD / 4,	/* Worst case */
+	ATA_MAX_PORTS		= 8,
 	ATA_DEF_QUEUE		= 1,
 	/* tag ATA_MAX_QUEUE - 1 is reserved for internal commands */
 	ATA_MAX_QUEUE		= 32,
 	ATA_TAG_INTERNAL	= ATA_MAX_QUEUE - 1,
-	ATA_SHORT_PAUSE		= 16,
-
-	ATAPI_MAX_DRAIN		= 16 << 10,
-
-	ATA_ALL_DEVICES		= (1 << ATA_MAX_DEVICES) - 1,
+	ATA_MAX_BUS		= 2,
+	ATA_DEF_BUSY_WAIT	= 10000,
+	ATA_SHORT_PAUSE		= (HZ >> 6) + 1,
 
 	ATA_SHT_EMULATED	= 1,
 	ATA_SHT_CMD_PER_LUN	= 1,
@@ -135,42 +139,22 @@
 	ATA_DFLAG_FLUSH_EXT	= (1 << 4), /* do FLUSH_EXT instead of FLUSH */
 	ATA_DFLAG_ACPI_PENDING	= (1 << 5), /* ACPI resume action pending */
 	ATA_DFLAG_ACPI_FAILED	= (1 << 6), /* ACPI on devcfg has failed */
-	ATA_DFLAG_AN		= (1 << 7), /* AN configured */
-	ATA_DFLAG_HIPM		= (1 << 8), /* device supports HIPM */
-	ATA_DFLAG_DIPM		= (1 << 9), /* device supports DIPM */
-	ATA_DFLAG_DMADIR	= (1 << 10), /* device requires DMADIR */
-	ATA_DFLAG_CFG_MASK	= (1 << 12) - 1,
-
-	ATA_DFLAG_PIO		= (1 << 12), /* device limited to PIO mode */
-	ATA_DFLAG_NCQ_OFF	= (1 << 13), /* device limited to non-NCQ mode */
-	ATA_DFLAG_SLEEPING	= (1 << 15), /* device is sleeping */
-	ATA_DFLAG_DUBIOUS_XFER	= (1 << 16), /* data transfer not verified */
-	ATA_DFLAG_NO_UNLOAD	= (1 << 17), /* device doesn't support unload */
-	ATA_DFLAG_INIT_MASK	= (1 << 24) - 1,
+	ATA_DFLAG_CFG_MASK	= (1 << 8) - 1,
+
+	ATA_DFLAG_PIO		= (1 << 8), /* device limited to PIO mode */
+	ATA_DFLAG_NCQ_OFF	= (1 << 9), /* device limited to non-NCQ mode */
+	ATA_DFLAG_SPUNDOWN	= (1 << 10), /* XXX: for spindown_compat */
+	ATA_DFLAG_INIT_MASK	= (1 << 16) - 1,
 
-	ATA_DFLAG_DETACH	= (1 << 24),
-	ATA_DFLAG_DETACHED	= (1 << 25),
+	ATA_DFLAG_DETACH	= (1 << 16),
+	ATA_DFLAG_DETACHED	= (1 << 17),
 
 	ATA_DEV_UNKNOWN		= 0,	/* unknown device */
 	ATA_DEV_ATA		= 1,	/* ATA device */
 	ATA_DEV_ATA_UNSUP	= 2,	/* ATA device (unsupported) */
 	ATA_DEV_ATAPI		= 3,	/* ATAPI device */
 	ATA_DEV_ATAPI_UNSUP	= 4,	/* ATAPI device (unsupported) */
-	ATA_DEV_PMP		= 5,	/* SATA port multiplier */
-	ATA_DEV_PMP_UNSUP	= 6,	/* SATA port multiplier (unsupported) */
-	ATA_DEV_SEMB		= 7,	/* SEMB */
-	ATA_DEV_SEMB_UNSUP	= 8,	/* SEMB (unsupported) */
-	ATA_DEV_NONE		= 9,	/* no device */
-
-	/* struct ata_link flags */
-	ATA_LFLAG_NO_HRST	= (1 << 1), /* avoid hardreset */
-	ATA_LFLAG_NO_SRST	= (1 << 2), /* avoid softreset */
-	ATA_LFLAG_ASSUME_ATA	= (1 << 3), /* assume ATA class */
-	ATA_LFLAG_ASSUME_SEMB	= (1 << 4), /* assume SEMB class */
-	ATA_LFLAG_ASSUME_CLASS	= ATA_LFLAG_ASSUME_ATA | ATA_LFLAG_ASSUME_SEMB,
-	ATA_LFLAG_NO_RETRY	= (1 << 5), /* don't retry this link */
-	ATA_LFLAG_DISABLED	= (1 << 6), /* link is disabled */
-	ATA_LFLAG_SW_ACTIVITY	= (1 << 7), /* keep activity stats */
+	ATA_DEV_NONE		= 5,	/* no device */
 
 	/* struct ata_port flags */
 	ATA_FLAG_SLAVE_POSS	= (1 << 0), /* host supports slave dev */
@@ -186,20 +170,15 @@
 	ATA_FLAG_PIO_POLLING	= (1 << 9), /* use polling PIO if LLD
 					     * doesn't handle PIO interrupts */
 	ATA_FLAG_NCQ		= (1 << 10), /* host supports NCQ */
-	ATA_FLAG_NO_POWEROFF_SPINDOWN = (1 << 11), /* don't spindown before poweroff */
-	ATA_FLAG_NO_HIBERNATE_SPINDOWN = (1 << 12), /* don't spindown before hibernation */
+	ATA_FLAG_HRST_TO_RESUME	= (1 << 11), /* hardreset to resume phy */
+	ATA_FLAG_SKIP_D2H_BSY	= (1 << 12), /* can't wait for the first D2H
+					      * Register FIS clearing BSY */
 	ATA_FLAG_DEBUGMSG	= (1 << 13),
-	ATA_FLAG_FPDMA_AA		= (1 << 14), /* driver supports Auto-Activate */
 	ATA_FLAG_IGN_SIMPLEX	= (1 << 15), /* ignore SIMPLEX */
 	ATA_FLAG_NO_IORDY	= (1 << 16), /* controller lacks iordy */
 	ATA_FLAG_ACPI_SATA	= (1 << 17), /* need native SATA ACPI layout */
-	ATA_FLAG_AN		= (1 << 18), /* controller supports AN */
-	ATA_FLAG_PMP		= (1 << 19), /* controller supports PMP */
-	ATA_FLAG_IPM		= (1 << 20), /* driver can handle IPM */
-	ATA_FLAG_EM		= (1 << 21), /* driver supports enclosure
-					      * management */
-	ATA_FLAG_SW_ACTIVITY	= (1 << 22), /* driver supports sw activity
-					      * led */
+	ATA_FLAG_NO_SRST	= (1 << 18),
+	ATA_FLAG_ASSUME_ATA	= (1 << 19),
 
 	/* The following flag belongs to ap->pflags but is kept in
 	 * ap->flags because it's referenced in many LLDs and will be
@@ -209,34 +188,27 @@
 
 	/* bits 24:31 of ap->flags are reserved for LLD specific flags */
 
-
 	/* struct ata_port pflags */
 	ATA_PFLAG_EH_PENDING	= (1 << 0), /* EH pending */
 	ATA_PFLAG_EH_IN_PROGRESS = (1 << 1), /* EH in progress */
 	ATA_PFLAG_FROZEN	= (1 << 2), /* port is frozen */
 	ATA_PFLAG_RECOVERED	= (1 << 3), /* recovery action performed */
 	ATA_PFLAG_LOADING	= (1 << 4), /* boot/loading probe */
+	ATA_PFLAG_UNLOADING	= (1 << 5), /* module is unloading */
 	ATA_PFLAG_SCSI_HOTPLUG	= (1 << 6), /* SCSI hotplug scheduled */
 	ATA_PFLAG_INITIALIZING	= (1 << 7), /* being initialized, don't touch */
-	ATA_PFLAG_RESETTING	= (1 << 8), /* reset in progress */
-	ATA_PFLAG_UNLOADING	= (1 << 9), /* driver is being unloaded */
-	ATA_PFLAG_UNLOADED	= (1 << 10), /* driver is unloaded */
 
 	ATA_PFLAG_SUSPENDED	= (1 << 17), /* port is suspended (power) */
 	ATA_PFLAG_PM_PENDING	= (1 << 18), /* PM operation pending */
-	ATA_PFLAG_INIT_GTM_VALID = (1 << 19), /* initial gtm data valid */
-
-	ATA_PFLAG_PIO32		= (1 << 20),  /* 32bit PIO */
-	ATA_PFLAG_PIO32CHANGE	= (1 << 21),  /* 32bit PIO can be turned on/off */
+	ATA_PFLAG_GTM_VALID	= (1 << 19), /* acpi_gtm data valid */
 
 	/* struct ata_queued_cmd flags */
 	ATA_QCFLAG_ACTIVE	= (1 << 0), /* cmd not yet ack'd to scsi lyer */
-	ATA_QCFLAG_DMAMAP	= (1 << 1), /* SG table is DMA mapped */
+	ATA_QCFLAG_SG		= (1 << 1), /* have s/g table? */
+	ATA_QCFLAG_SINGLE	= (1 << 2), /* no s/g, just a single buffer */
+	ATA_QCFLAG_DMAMAP	= ATA_QCFLAG_SG | ATA_QCFLAG_SINGLE,
 	ATA_QCFLAG_IO		= (1 << 3), /* standard IO command */
 	ATA_QCFLAG_RESULT_TF	= (1 << 4), /* result TF requested */
-	ATA_QCFLAG_CLEAR_EXCL	= (1 << 5), /* clear excl_link on completion */
-	ATA_QCFLAG_QUIET	= (1 << 6), /* don't report device error */
-	ATA_QCFLAG_RETRY	= (1 << 7), /* retry after failure */
 
 	ATA_QCFLAG_FAILED	= (1 << 16), /* cmd failed and is owned by EH */
 	ATA_QCFLAG_SENSE_VALID	= (1 << 17), /* sense data valid */
@@ -245,41 +217,14 @@
 	/* host set flags */
 	ATA_HOST_SIMPLEX	= (1 << 0),	/* Host is simplex, one DMA channel per host only */
 	ATA_HOST_STARTED	= (1 << 1),	/* Host started */
-	ATA_HOST_PARALLEL_SCAN	= (1 << 2),	/* Ports on this host can be scanned in parallel */
 
 	/* bits 24:31 of host->flags are reserved for LLD specific flags */
 
 	/* various lengths of time */
-	ATA_TMOUT_BOOT		= 30000,	/* heuristic */
-	ATA_TMOUT_BOOT_QUICK	=  7000,	/* heuristic */
-	ATA_TMOUT_INTERNAL_QUICK = 5000,
-	ATA_TMOUT_MAX_PARK	= 30000,
-
-	/* FIXME: GoVault needs 2s but we can't afford that without
-	 * parallel probing.  800ms is enough for iVDR disk
-	 * HHD424020F7SV00.  Increase to 2secs when parallel probing
-	 * is in place.
-	 */
-	ATA_TMOUT_FF_WAIT	=  800,
-
-	/* Spec mandates to wait for ">= 2ms" before checking status
-	 * after reset.  We wait 150ms, because that was the magic
-	 * delay used for ATAPI devices in Hale Landis's ATADRVR, for
-	 * the period of time between when the ATA command register is
-	 * written, and then status is checked.  Because waiting for
-	 * "a while" before checking status is fine, post SRST, we
-	 * perform this magic delay here as well.
-	 *
-	 * Old drivers/ide uses the 2mS rule and then waits for ready.
-	 */
-	ATA_WAIT_AFTER_RESET	=  150,
-
-	/* If PMP is supported, we have to do follow-up SRST.  As some
-	 * PMPs don't send D2H Reg FIS after hardreset, LLDs are
-	 * advised to wait only for the following duration before
-	 * doing SRST.
-	 */
-	ATA_TMOUT_PMP_SRST_WAIT	= 5000,
+	ATA_TMOUT_BOOT		= 30 * HZ,	/* heuristic */
+	ATA_TMOUT_BOOT_QUICK	= 7 * HZ,	/* heuristic */
+	ATA_TMOUT_INTERNAL	= 30 * HZ,
+	ATA_TMOUT_INTERNAL_QUICK = 5 * HZ,
 
 	/* ATA bus states */
 	BUS_UNKNOWN		= 0,
@@ -299,47 +244,43 @@
 	PORT_DISABLED		= 2,
 
 	/* encoding various smaller bitmaps into a single
-	 * unsigned long bitmap
+	 * unsigned int bitmap
 	 */
-	ATA_NR_PIO_MODES	= 7,
-	ATA_NR_MWDMA_MODES	= 5,
-	ATA_NR_UDMA_MODES	= 8,
+	ATA_BITS_PIO		= 7,
+	ATA_BITS_MWDMA		= 5,
+	ATA_BITS_UDMA		= 8,
 
 	ATA_SHIFT_PIO		= 0,
-	ATA_SHIFT_MWDMA		= ATA_SHIFT_PIO + ATA_NR_PIO_MODES,
-	ATA_SHIFT_UDMA		= ATA_SHIFT_MWDMA + ATA_NR_MWDMA_MODES,
+	ATA_SHIFT_MWDMA		= ATA_SHIFT_PIO + ATA_BITS_PIO,
+	ATA_SHIFT_UDMA		= ATA_SHIFT_MWDMA + ATA_BITS_MWDMA,
+
+	ATA_MASK_PIO		= ((1 << ATA_BITS_PIO) - 1) << ATA_SHIFT_PIO,
+	ATA_MASK_MWDMA		= ((1 << ATA_BITS_MWDMA) - 1) << ATA_SHIFT_MWDMA,
+	ATA_MASK_UDMA		= ((1 << ATA_BITS_UDMA) - 1) << ATA_SHIFT_UDMA,
 
 	/* size of buffer to pad xfers ending on unaligned boundaries */
 	ATA_DMA_PAD_SZ		= 4,
+	ATA_DMA_PAD_BUF_SZ	= ATA_DMA_PAD_SZ * ATA_MAX_QUEUE,
 
 	/* ering size */
 	ATA_ERING_SIZE		= 32,
 
-	/* return values for ->qc_defer */
-	ATA_DEFER_LINK		= 1,
-	ATA_DEFER_PORT		= 2,
-
 	/* desc_len for ata_eh_info and context */
 	ATA_EH_DESC_LEN		= 80,
 
 	/* reset / recovery action types */
 	ATA_EH_REVALIDATE	= (1 << 0),
-	ATA_EH_SOFTRESET	= (1 << 1), /* meaningful only in ->prereset */
-	ATA_EH_HARDRESET	= (1 << 2), /* meaningful only in ->prereset */
-	ATA_EH_RESET		= ATA_EH_SOFTRESET | ATA_EH_HARDRESET,
-	ATA_EH_ENABLE_LINK	= (1 << 3),
-	ATA_EH_LPM		= (1 << 4),  /* link power management action */
-	ATA_EH_PARK		= (1 << 5), /* unload heads and stop I/O */
-
-	ATA_EH_PERDEV_MASK	= ATA_EH_REVALIDATE | ATA_EH_PARK,
-	ATA_EH_ALL_ACTIONS	= ATA_EH_REVALIDATE | ATA_EH_RESET |
-				  ATA_EH_ENABLE_LINK | ATA_EH_LPM,
+	ATA_EH_SOFTRESET	= (1 << 1),
+	ATA_EH_HARDRESET	= (1 << 2),
+
+	ATA_EH_RESET_MASK	= ATA_EH_SOFTRESET | ATA_EH_HARDRESET,
+	ATA_EH_PERDEV_MASK	= ATA_EH_REVALIDATE,
 
 	/* ata_eh_info->flags */
 	ATA_EHI_HOTPLUGGED	= (1 << 0),  /* could have been hotplugged */
+	ATA_EHI_RESUME_LINK	= (1 << 1),  /* resume link (reset modifier) */
 	ATA_EHI_NO_AUTOPSY	= (1 << 2),  /* no autopsy */
 	ATA_EHI_QUIET		= (1 << 3),  /* be quiet */
-	ATA_EHI_NO_RECOVERY	= (1 << 4),  /* no recovery */
 
 	ATA_EHI_DID_SOFTRESET	= (1 << 16), /* already soft-reset this port */
 	ATA_EHI_DID_HARDRESET	= (1 << 17), /* already soft-reset this port */
@@ -348,28 +289,14 @@
 	ATA_EHI_POST_SETMODE	= (1 << 20), /* revaildating after setmode */
 
 	ATA_EHI_DID_RESET	= ATA_EHI_DID_SOFTRESET | ATA_EHI_DID_HARDRESET,
+	ATA_EHI_RESET_MODIFIER_MASK = ATA_EHI_RESUME_LINK,
 
-	/* mask of flags to transfer *to* the slave link */
-	ATA_EHI_TO_SLAVE_MASK	= ATA_EHI_NO_AUTOPSY | ATA_EHI_QUIET,
-
-	/* max tries if error condition is still set after ->error_handler */
-	ATA_EH_MAX_TRIES	= 5,
-
-	/* sometimes resuming a link requires several retries */
-	ATA_LINK_RESUME_TRIES	= 5,
+	/* max repeat if error condition is still set after ->error_handler */
+	ATA_EH_MAX_REPEAT	= 5,
 
 	/* how hard are we gonna try to probe/recover devices */
 	ATA_PROBE_MAX_TRIES	= 3,
 	ATA_EH_DEV_TRIES	= 3,
-	ATA_EH_PMP_TRIES	= 5,
-	ATA_EH_PMP_LINK_TRIES	= 3,
-
-	SATA_PMP_RW_TIMEOUT	= 3000,		/* PMP read/write timeout */
-
-	/* This should match the actual table size of
-	 * ata_eh_cmd_timeout_table in libata-eh.c.
-	 */
-	ATA_EH_CMD_TIMEOUT_TABLE_SIZE = 5,
 
 	/* Horkage types. May be set by libata or controller on drives
 	   (some horkage may be drive/controller pair dependant */
@@ -379,69 +306,15 @@
 	ATA_HORKAGE_NONCQ	= (1 << 2),	/* Don't use NCQ */
 	ATA_HORKAGE_MAX_SEC_128	= (1 << 3),	/* Limit max sects to 128 */
 	ATA_HORKAGE_BROKEN_HPA	= (1 << 4),	/* Broken HPA */
-	ATA_HORKAGE_DISABLE	= (1 << 5),	/* Disable it */
-	ATA_HORKAGE_HPA_SIZE	= (1 << 6),	/* native size off by one */
-	ATA_HORKAGE_IPM		= (1 << 7),	/* Link PM problems */
-	ATA_HORKAGE_IVB		= (1 << 8),	/* cbl det validity bit bugs */
-	ATA_HORKAGE_STUCK_ERR	= (1 << 9),	/* stuck ERR on next PACKET */
-	ATA_HORKAGE_BRIDGE_OK	= (1 << 10),	/* no bridge limits */
-	ATA_HORKAGE_ATAPI_MOD16_DMA = (1 << 11), /* use ATAPI DMA for commands
-						    not multiple of 16 bytes */
-	ATA_HORKAGE_FIRMWARE_WARN = (1 << 12),	/* firmware update warning */
-	ATA_HORKAGE_1_5_GBPS	= (1 << 13),	/* force 1.5 Gbps */
-	ATA_HORKAGE_NOSETXFER	= (1 << 14),	/* skip SETXFER, SATA only */
-	ATA_HORKAGE_BROKEN_FPDMA_AA	= (1 << 15),	/* skip AA */
-
-	 /* DMA mask for user DMA control: User visible values; DO NOT
-	    renumber */
-	ATA_DMA_MASK_ATA	= (1 << 0),	/* DMA on ATA Disk */
-	ATA_DMA_MASK_ATAPI	= (1 << 1),	/* DMA on ATAPI */
-	ATA_DMA_MASK_CFA	= (1 << 2),	/* DMA on CF Card */
-
-	/* ATAPI command types */
+	
+		/* ATAPI command types */
 	ATAPI_READ		= 0,		/* READs */
 	ATAPI_WRITE		= 1,		/* WRITEs */
 	ATAPI_READ_CD		= 2,		/* READ CD [MSF] */
 	ATAPI_PASS_THRU		= 3,		/* SAT pass-thru */
 	ATAPI_MISC		= 4,		/* the rest */
-
-	/* Timing constants */
-	ATA_TIMING_SETUP	= (1 << 0),
-	ATA_TIMING_ACT8B	= (1 << 1),
-	ATA_TIMING_REC8B	= (1 << 2),
-	ATA_TIMING_CYC8B	= (1 << 3),
-	ATA_TIMING_8BIT		= ATA_TIMING_ACT8B | ATA_TIMING_REC8B |
-				  ATA_TIMING_CYC8B,
-	ATA_TIMING_ACTIVE	= (1 << 4),
-	ATA_TIMING_RECOVER	= (1 << 5),
-	ATA_TIMING_DMACK_HOLD	= (1 << 6),
-	ATA_TIMING_CYCLE	= (1 << 7),
-	ATA_TIMING_UDMA		= (1 << 8),
-	ATA_TIMING_ALL		= ATA_TIMING_SETUP | ATA_TIMING_ACT8B |
-				  ATA_TIMING_REC8B | ATA_TIMING_CYC8B |
-				  ATA_TIMING_ACTIVE | ATA_TIMING_RECOVER |
-				  ATA_TIMING_DMACK_HOLD | ATA_TIMING_CYCLE |
-				  ATA_TIMING_UDMA,
-
-	/* ACPI constants */
-	ATA_ACPI_FILTER_SETXFER	= 1 << 0,
-	ATA_ACPI_FILTER_LOCK	= 1 << 1,
-	ATA_ACPI_FILTER_DIPM	= 1 << 2,
-	ATA_ACPI_FILTER_FPDMA_OFFSET = 1 << 3,	/* FPDMA non-zero offset */
-	ATA_ACPI_FILTER_FPDMA_AA = 1 << 4,	/* FPDMA auto activate */
-
-	ATA_ACPI_FILTER_DEFAULT	= ATA_ACPI_FILTER_SETXFER |
-				  ATA_ACPI_FILTER_LOCK |
-				  ATA_ACPI_FILTER_DIPM,
-};
-
-enum ata_xfer_mask {
-	ATA_MASK_PIO		= ((1LU << ATA_NR_PIO_MODES) - 1)
-					<< ATA_SHIFT_PIO,
-	ATA_MASK_MWDMA		= ((1LU << ATA_NR_MWDMA_MODES) - 1)
-					<< ATA_SHIFT_MWDMA,
-	ATA_MASK_UDMA		= ((1LU << ATA_NR_UDMA_MODES) - 1)
-					<< ATA_SHIFT_UDMA,
+	
+	ATAPI_MAX_DRAIN		= 16 << 10,
 };
 
 enum hsm_task_states {
@@ -471,39 +344,15 @@
 struct scsi_device;
 struct ata_port_operations;
 struct ata_port;
-struct ata_link;
 struct ata_queued_cmd;
 
 /* typedefs */
 typedef void (*ata_qc_cb_t) (struct ata_queued_cmd *qc);
-typedef int (*ata_prereset_fn_t)(struct ata_link *link, unsigned long deadline);
-typedef int (*ata_reset_fn_t)(struct ata_link *link, unsigned int *classes,
+typedef int (*ata_prereset_fn_t)(struct ata_port *ap, unsigned long deadline);
+typedef int (*ata_reset_fn_t)(struct ata_port *ap, unsigned int *classes,
 			      unsigned long deadline);
-typedef void (*ata_postreset_fn_t)(struct ata_link *link, unsigned int *classes);
-
-/*
- * host pm policy: If you alter this, you also need to alter libata-scsi.c
- * (for the ascii descriptions)
- */
-enum link_pm {
-	NOT_AVAILABLE,
-	MIN_POWER,
-	MAX_PERFORMANCE,
-	MEDIUM_POWER,
-};
-extern struct device_attribute dev_attr_link_power_management_policy;
-extern struct device_attribute dev_attr_unload_heads;
-extern struct device_attribute dev_attr_em_message_type;
-extern struct device_attribute dev_attr_em_message;
-extern struct device_attribute dev_attr_sw_activity;
-
-enum sw_activity {
-	OFF,
-	BLINK_ON,
-	BLINK_OFF,
-};
+typedef void (*ata_postreset_fn_t)(struct ata_port *ap, unsigned int *classes);
 
-#ifdef CONFIG_ATA_SFF
 struct ata_ioports {
 	void __iomem		*cmd_addr;
 	void __iomem		*data_addr;
@@ -521,15 +370,16 @@
 	void __iomem		*bmdma_addr;
 	void __iomem		*scr_addr;
 };
-#endif /* CONFIG_ATA_SFF */
 
 struct ata_host {
 	spinlock_t		lock;
 	struct device 		*dev;
+	unsigned long		irq;
+	unsigned long		irq2;
 	void __iomem * const	*iomap;
 	unsigned int		n_ports;
 	void			*private_data;
-	struct ata_port_operations *ops;
+	const struct ata_port_operations *ops;
 	unsigned long		flags;
 #ifdef CONFIG_ATA_ACPI
 	acpi_handle		acpi_handle;
@@ -555,18 +405,21 @@
 
 	int			dma_dir;
 
+	unsigned int		pad_len;
 	unsigned int		sect_size;
 
 	unsigned int		nbytes;
-	unsigned int		extrabytes;
 	unsigned int		curbytes;
 
-	struct scatterlist	*cursg;
+	unsigned int		cursg;
 	unsigned int		cursg_ofs;
 
 	struct scatterlist	sgent;
+	struct scatterlist	pad_sgent;
+	void			*buf_virt;
 
-	struct scatterlist	*sg;
+	/* DO NOT iterate over __sg manually, use ata_for_each_sg() */
+	struct scatterlist	*__sg;
 
 	unsigned int		err_mask;
 	struct ata_taskfile	result_tf;
@@ -583,7 +436,7 @@
 };
 
 struct ata_ering_entry {
-	unsigned int		eflags;
+	int			is_io;
 	unsigned int		err_mask;
 	u64			timestamp;
 };
@@ -594,22 +447,18 @@
 };
 
 struct ata_device {
-	struct ata_link		*link;
+	struct ata_port		*ap;
 	unsigned int		devno;		/* 0 or 1 */
-	unsigned int		horkage;	/* List of broken features */
 	unsigned long		flags;		/* ATA_DFLAG_xxx */
+	unsigned int		horkage;	/* List of broken features */
 	struct scsi_device	*sdev;		/* attached SCSI device */
 #ifdef CONFIG_ATA_ACPI
 	acpi_handle		acpi_handle;
-	union acpi_object	*gtf_cache;
-	unsigned int		gtf_filter;
 #endif
-	/* n_sector is CLEAR_BEGIN, read comment above CLEAR_BEGIN */
+	/* n_sector is used as CLEAR_OFFSET, read comment above CLEAR_OFFSET */
 	u64			n_sectors;	/* size of device, if ATA */
-	u64			n_native_sectors; /* native size, if ATA */
 	unsigned int		class;		/* ATA_DEV_xxx */
-	unsigned long		unpark_deadline;
-
+	u16			id[ATA_ID_WORDS]; /* IDENTIFY xxx DEVICE data */
 	u8			pio_mode;
 	u8			dma_mode;
 	u8			xfer_mode;
@@ -621,31 +470,24 @@
 	unsigned int		cdb_len;
 
 	/* per-dev xfer mask */
-	unsigned long		pio_mask;
-	unsigned long		mwdma_mask;
-	unsigned long		udma_mask;
+	unsigned int		pio_mask;
+	unsigned int		mwdma_mask;
+	unsigned int		udma_mask;
 
 	/* for CHS addressing */
 	u16			cylinders;	/* Number of cylinders */
 	u16			heads;		/* Number of heads */
 	u16			sectors;	/* Number of sectors per track */
 
-	union {
-		u16		id[ATA_ID_WORDS]; /* IDENTIFY xxx DEVICE data */
-		u32		gscr[SATA_PMP_GSCR_DWORDS]; /* PMP GSCR block */
-	};
-
 	/* error history */
-	int			spdn_cnt;
-	/* ering is CLEAR_END, read comment above CLEAR_END */
 	struct ata_ering	ering;
+	int			spdn_cnt;
 };
 
-/* Fields between ATA_DEVICE_CLEAR_BEGIN and ATA_DEVICE_CLEAR_END are
- * cleared to zero on ata_dev_init().
+/* Offset into struct ata_device.  Fields above it are maintained
+ * acress device init.  Fields below are zeroed.
  */
-#define ATA_DEVICE_CLEAR_BEGIN		offsetof(struct ata_device, n_sectors)
-#define ATA_DEVICE_CLEAR_END		offsetof(struct ata_device, ering)
+#define ATA_DEVICE_CLEAR_OFFSET		offsetof(struct ata_device, n_sectors)
 
 struct ata_eh_info {
 	struct ata_device	*dev;		/* offending device */
@@ -664,15 +506,8 @@
 struct ata_eh_context {
 	struct ata_eh_info	i;
 	int			tries[ATA_MAX_DEVICES];
-	int			cmd_timeout_idx[ATA_MAX_DEVICES]
-					       [ATA_EH_CMD_TIMEOUT_TABLE_SIZE];
 	unsigned int		classes[ATA_MAX_DEVICES];
 	unsigned int		did_probe_mask;
-	unsigned int		unloaded_mask;
-	unsigned int		saved_ncq_enabled;
-	u8			saved_xfer_mode[ATA_MAX_DEVICES];
-	/* timestamp for the last reset attempt or success */
-	unsigned long		last_reset;
 };
 
 struct ata_acpi_drive
@@ -686,36 +521,11 @@
 	u32 flags;
 } __packed;
 
-struct ata_link {
-	struct ata_port		*ap;
-	int			pmp;		/* port multiplier port # */
-
-	unsigned int		active_tag;	/* active tag on this link */
-	u32			sactive;	/* active NCQ commands */
-
-	unsigned int		flags;		/* ATA_LFLAG_xxx */
-
-	u32			saved_scontrol;	/* SControl on probe */
-	unsigned int		hw_sata_spd_limit;
-	unsigned int		sata_spd_limit;
-	unsigned int		sata_spd;	/* current SATA PHY speed */
-
-	/* record runtime error info, protected by host_set lock */
-	struct ata_eh_info	eh_info;
-	/* EH context */
-	struct ata_eh_context	eh_context;
-
-	struct ata_device	device[ATA_MAX_DEVICES];
-};
-
 struct ata_port {
 	struct Scsi_Host	*scsi_host; /* our co-allocated scsi host */
-	struct ata_port_operations *ops;
+	const struct ata_port_operations *ops;
 	spinlock_t		*lock;
-	/* Flags owned by the EH context. Only EH should touch these once the
-	   port is active */
 	unsigned long		flags;	/* ATA_FLAG_xxx */
-	/* Flags that change dynamically, protected by ap->lock */
 	unsigned int		pflags; /* ATA_PFLAG_xxx */
 	unsigned int		print_id; /* user visible unique port ID */
 	unsigned int		port_no; /* 0 based port no. inside the host */
@@ -723,9 +533,10 @@
 	struct ata_prd		*prd;	 /* our SG list */
 	dma_addr_t		prd_dma; /* and its DMA mapping */
 
-#ifdef CONFIG_ATA_SFF
+	void			*pad;	/* array of DMA pad buffers */
+	dma_addr_t		pad_dma;
+
 	struct ata_ioports	ioaddr;	/* ATA cmd/ctl/dma register blocks */
-#endif /* CONFIG_ATA_SFF */
 
 	u8			ctl;	/* cache of ATA control register */
 	u8			last_ctl;	/* Cache last written value */
@@ -733,18 +544,23 @@
 	unsigned int		mwdma_mask;
 	unsigned int		udma_mask;
 	unsigned int		cbl;	/* cable type; ATA_CBL_xxx */
+	unsigned int		hw_sata_spd_limit;
+	unsigned int		sata_spd_limit;	/* SATA PHY speed limit */
+	unsigned int		sata_spd;	/* current SATA PHY speed */
+
+	/* record runtime error info, protected by host lock */
+	struct ata_eh_info	eh_info;
+	/* EH context owned by EH */
+	struct ata_eh_context	eh_context;
+
+	struct ata_device	device[ATA_MAX_DEVICES];
 
 	struct ata_queued_cmd	qcmd[ATA_MAX_QUEUE];
 	unsigned long		qc_allocated;
 	unsigned int		qc_active;
-	int			nr_active_links; /* #links with active qcs */
-
-	struct ata_link		link;		/* host default link */
-	struct ata_link		*slave_link;	/* see ata_slave_link_init() */
 
-	int			nr_pmp_links;	/* nr of available PMP links */
-	struct ata_link		*pmp_link;	/* array of PMP links */
-	struct ata_link		*excl_link;	/* for PMP qc exclusion */
+	unsigned int		active_tag;
+	u32			sactive;
 
 	struct ata_port_stats	stats;
 	struct ata_host		*host;
@@ -760,139 +576,97 @@
 	u32			msg_enable;
 	struct list_head	eh_done_q;
 	wait_queue_head_t	eh_wait_q;
-	int			eh_tries;
-	struct completion	park_req_pending;
 
 	pm_message_t		pm_mesg;
 	int			*pm_result;
-	enum link_pm		pm_policy;
 
 	struct timer_list	fastdrain_timer;
 	unsigned long		fastdrain_cnt;
 
-	int			em_message_type;
 	void			*private_data;
 
 #ifdef CONFIG_ATA_ACPI
 	acpi_handle		acpi_handle;
-	struct ata_acpi_gtm	__acpi_init_gtm; /* use ata_acpi_init_gtm() */
+	struct ata_acpi_gtm	acpi_gtm;
 #endif
-	/* owned by EH */
-	u8			sector_buf[ATA_SECT_SIZE] ____cacheline_aligned;
+	u8			sector_buf[ATA_SECT_SIZE]; /* owned by EH */
 };
 
-/* The following initializer overrides a method to NULL whether one of
- * its parent has the method defined or not.  This is equivalent to
- * ERR_PTR(-ENOENT).  Unfortunately, ERR_PTR doesn't render a constant
- * expression and thus can't be used as an initializer.
- */
-#define ATA_OP_NULL		(void *)(unsigned long)(-ENOENT)
-
 struct ata_port_operations {
-	/*
-	 * Command execution
-	 */
-	int  (*qc_defer)(struct ata_queued_cmd *qc);
-	int  (*check_atapi_dma)(struct ata_queued_cmd *qc);
-	void (*qc_prep)(struct ata_queued_cmd *qc);
-	unsigned int (*qc_issue)(struct ata_queued_cmd *qc);
-	bool (*qc_fill_rtf)(struct ata_queued_cmd *qc);
+	void (*port_disable) (struct ata_port *);
 
-	/*
-	 * Configuration and exception handling
-	 */
-	int  (*cable_detect)(struct ata_port *ap);
-	unsigned long (*mode_filter)(struct ata_device *dev, unsigned long xfer_mask);
-	void (*set_piomode)(struct ata_port *ap, struct ata_device *dev);
-	void (*set_dmamode)(struct ata_port *ap, struct ata_device *dev);
-	int  (*set_mode)(struct ata_link *link, struct ata_device **r_failed_dev);
-	unsigned int (*read_id)(struct ata_device *dev, struct ata_taskfile *tf, u16 *id);
-
-	void (*dev_config)(struct ata_device *dev);
-
-	void (*freeze)(struct ata_port *ap);
-	void (*thaw)(struct ata_port *ap);
-	ata_prereset_fn_t	prereset;
-	ata_reset_fn_t		softreset;
-	ata_reset_fn_t		hardreset;
-	ata_postreset_fn_t	postreset;
-	ata_prereset_fn_t	pmp_prereset;
-	ata_reset_fn_t		pmp_softreset;
-	ata_reset_fn_t		pmp_hardreset;
-	ata_postreset_fn_t	pmp_postreset;
-	void (*error_handler)(struct ata_port *ap);
-	void (*lost_interrupt)(struct ata_port *ap);
-	void (*post_internal_cmd)(struct ata_queued_cmd *qc);
+	void (*dev_config) (struct ata_device *);
 
-	/*
-	 * Optional features
-	 */
-	int  (*scr_read)(struct ata_link *link, unsigned int sc_reg, u32 *val);
-	int  (*scr_write)(struct ata_link *link, unsigned int sc_reg, u32 val);
-	void (*pmp_attach)(struct ata_port *ap);
-	void (*pmp_detach)(struct ata_port *ap);
-	int  (*enable_pm)(struct ata_port *ap, enum link_pm policy);
-	void (*disable_pm)(struct ata_port *ap);
+	void (*set_piomode) (struct ata_port *, struct ata_device *);
+	void (*set_dmamode) (struct ata_port *, struct ata_device *);
+	unsigned long (*mode_filter) (struct ata_device *, unsigned long);
 
-	/*
-	 * Start, stop, suspend and resume
-	 */
-	int  (*port_suspend)(struct ata_port *ap, pm_message_t mesg);
-	int  (*port_resume)(struct ata_port *ap);
-	int  (*port_start)(struct ata_port *ap);
-	void (*port_stop)(struct ata_port *ap);
-	void (*host_stop)(struct ata_host *host);
-
-#ifdef CONFIG_ATA_SFF
-	/*
-	 * SFF / taskfile oriented ops
-	 */
-	void (*sff_dev_select)(struct ata_port *ap, unsigned int device);
-	u8   (*sff_check_status)(struct ata_port *ap);
-	u8   (*sff_check_altstatus)(struct ata_port *ap);
-	void (*sff_tf_load)(struct ata_port *ap, const struct ata_taskfile *tf);
-	void (*sff_tf_read)(struct ata_port *ap, struct ata_taskfile *tf);
-	void (*sff_exec_command)(struct ata_port *ap,
-				 const struct ata_taskfile *tf);
-	unsigned int (*sff_data_xfer)(struct ata_device *dev,
-			unsigned char *buf, unsigned int buflen, int rw);
-	u8   (*sff_irq_on)(struct ata_port *);
-	void (*sff_irq_clear)(struct ata_port *);
-
-	void (*bmdma_setup)(struct ata_queued_cmd *qc);
-	void (*bmdma_start)(struct ata_queued_cmd *qc);
-	void (*bmdma_stop)(struct ata_queued_cmd *qc);
-	u8   (*bmdma_status)(struct ata_port *ap);
-
-	void (*drain_fifo)(struct ata_queued_cmd *qc);
-#endif /* CONFIG_ATA_SFF */
-
-	ssize_t (*em_show)(struct ata_port *ap, char *buf);
-	ssize_t (*em_store)(struct ata_port *ap, const char *message,
-			    size_t size);
-	ssize_t (*sw_activity_show)(struct ata_device *dev, char *buf);
-	ssize_t (*sw_activity_store)(struct ata_device *dev,
-				     enum sw_activity val);
-	/*
-	 * Obsolete
-	 */
-	void (*phy_reset)(struct ata_port *ap);
-	void (*eng_timeout)(struct ata_port *ap);
+	void (*tf_load) (struct ata_port *ap, const struct ata_taskfile *tf);
+	void (*tf_read) (struct ata_port *ap, struct ata_taskfile *tf);
+
+	void (*exec_command)(struct ata_port *ap, const struct ata_taskfile *tf);
+	u8   (*check_status)(struct ata_port *ap);
+	u8   (*check_altstatus)(struct ata_port *ap);
+	void (*dev_select)(struct ata_port *ap, unsigned int device);
 
-	/*
-	 * ->inherits must be the last field and all the preceding
-	 * fields must be pointers.
+	void (*phy_reset) (struct ata_port *ap); /* obsolete */
+	int  (*set_mode) (struct ata_port *ap, struct ata_device **r_failed_dev);
+
+	int (*cable_detect) (struct ata_port *ap);
+
+	int  (*check_atapi_dma) (struct ata_queued_cmd *qc);
+
+	void (*bmdma_setup) (struct ata_queued_cmd *qc);
+	void (*bmdma_start) (struct ata_queued_cmd *qc);
+
+	void (*data_xfer) (struct ata_device *, unsigned char *, unsigned int, int);
+
+	void (*qc_prep) (struct ata_queued_cmd *qc);
+	unsigned int (*qc_issue) (struct ata_queued_cmd *qc);
+
+	/* Error handlers.  ->error_handler overrides ->eng_timeout and
+	 * indicates that new-style EH is in place.
 	 */
-	const struct ata_port_operations	*inherits;
+	void (*eng_timeout) (struct ata_port *ap); /* obsolete */
+
+	void (*freeze) (struct ata_port *ap);
+	void (*thaw) (struct ata_port *ap);
+	void (*error_handler) (struct ata_port *ap);
+	void (*post_internal_cmd) (struct ata_queued_cmd *qc);
+
+	irq_handler_t irq_handler;
+	void (*irq_clear) (struct ata_port *);
+	u8 (*irq_on) (struct ata_port *);
+	u8 (*irq_ack) (struct ata_port *ap, unsigned int chk_drq);
+
+	int (*scr_read) (struct ata_port *ap, unsigned int sc_reg, u32 *val);
+	int (*scr_write) (struct ata_port *ap, unsigned int sc_reg, u32 val);
+
+	int (*port_suspend) (struct ata_port *ap, pm_message_t mesg);
+	int (*port_resume) (struct ata_port *ap);
+
+	int (*port_start) (struct ata_port *ap);
+	void (*port_stop) (struct ata_port *ap);
+
+	void (*host_stop) (struct ata_host *host);
+
+	void (*bmdma_stop) (struct ata_queued_cmd *qc);
+	u8   (*bmdma_status) (struct ata_port *ap);
+
+	unsigned char (*readb)(const volatile void __iomem *addr);
+	unsigned short (*readw)(const volatile void __iomem *addr);
+	void (*writeb)(unsigned char b, volatile void __iomem *addr);
+	void (*writew)(unsigned short b, volatile void __iomem *addr);
 };
 
 struct ata_port_info {
+	struct scsi_host_template	*sht;
 	unsigned long		flags;
-	unsigned long		link_flags;
 	unsigned long		pio_mask;
 	unsigned long		mwdma_mask;
 	unsigned long		udma_mask;
-	struct ata_port_operations *port_ops;
+	const struct ata_port_operations *port_ops;
+	irq_handler_t		irq_handler;
 	void 			*private_data;
 };
 
@@ -904,19 +678,17 @@
 	unsigned short cyc8b;		/* t0 for 8-bit I/O */
 	unsigned short active;		/* t2 or tD */
 	unsigned short recover;		/* t2i or tK */
-	unsigned short dmack_hold;	/* tj */
 	unsigned short cycle;		/* t0 */
 	unsigned short udma;		/* t2CYCTYP/2 */
 };
 
-/*
- * Core layer - drivers/ata/libata-core.c
- */
+#define FIT(v,vmin,vmax)	max_t(short,min_t(short,v,vmax),vmin)
+
 extern const unsigned long sata_deb_timing_normal[];
 extern const unsigned long sata_deb_timing_hotplug[];
 extern const unsigned long sata_deb_timing_long[];
 
-extern struct ata_port_operations ata_dummy_port_ops;
+extern const struct ata_port_operations ata_dummy_port_ops;
 extern const struct ata_port_info ata_dummy_port_info;
 
 static inline const unsigned long *
@@ -933,27 +705,93 @@
 	return ap->ops == &ata_dummy_port_ops;
 }
 
+static inline u8 sata_readb(struct ata_port *ap,
+			    const volatile void __iomem *addr)
+{
+	u8 r;
+	if (ap->ops->readb)
+		r = (ap->ops->readb)(addr);
+	else
+		r = readb(addr);
+
+	return r;
+}
+
+static inline u16 sata_readw(struct ata_port *ap,
+			     const volatile void __iomem *addr)
+{
+	u16 r;
+	if (ap->ops->readw)
+		r = (ap->ops->readw)(addr);
+	else
+		r = readw(addr);
+
+	return r;
+}
+
+static inline void sata_writeb(struct ata_port *ap,
+			       u8 b, volatile void __iomem *addr)
+{
+	if (ap->ops->writeb)
+		(ap->ops->writeb)(b, addr);
+	else
+		writeb(b, addr);
+}
+
+static inline void sata_writew(struct ata_port *ap,
+			       u16 b, volatile void __iomem *addr)
+{
+	if (ap->ops->writew)
+		(ap->ops->writew)(b, addr);
+	else
+		writew(b, addr);
+}
+
+#undef readb
+#define readb(a_)	sata_readb(ap, a_)
+#undef writeb
+#define writeb(v_,a_)	sata_writeb(ap, v_, a_)
+#undef readw
+#define readw(a_)	sata_readw(ap, a_)
+#undef writew
+#define writew(v_,a_)	sata_writew(ap, v_, a_)
+
+
+extern void sata_print_link_status(struct ata_port *ap);
 extern void ata_port_probe(struct ata_port *);
-extern int sata_set_spd(struct ata_link *link);
-extern int ata_std_prereset(struct ata_link *link, unsigned long deadline);
-extern int ata_wait_after_reset(struct ata_link *link, unsigned long deadline,
-				int (*check_ready)(struct ata_link *link));
-extern int sata_link_debounce(struct ata_link *link,
-			const unsigned long *params, unsigned long deadline);
-extern int sata_link_resume(struct ata_link *link, const unsigned long *params,
-			    unsigned long deadline);
-extern int sata_link_hardreset(struct ata_link *link,
-			const unsigned long *timing, unsigned long deadline,
-			bool *online, int (*check_ready)(struct ata_link *));
-extern int sata_std_hardreset(struct ata_link *link, unsigned int *class,
+extern void __sata_phy_reset(struct ata_port *ap);
+extern void sata_phy_reset(struct ata_port *ap);
+extern void ata_bus_reset(struct ata_port *ap);
+extern int sata_set_spd(struct ata_port *ap);
+extern int sata_phy_debounce(struct ata_port *ap, const unsigned long *param,
+			     unsigned long deadline);
+extern int sata_phy_resume(struct ata_port *ap, const unsigned long *param,
+			   unsigned long deadline);
+extern int ata_std_prereset(struct ata_port *ap, unsigned long deadline);
+extern int ata_std_softreset(struct ata_port *ap, unsigned int *classes,
+			     unsigned long deadline);
+extern int sata_port_hardreset(struct ata_port *ap, const unsigned long *timing,
+			       unsigned long deadline);
+extern int sata_std_hardreset(struct ata_port *ap, unsigned int *class,
 			      unsigned long deadline);
-extern void ata_std_postreset(struct ata_link *link, unsigned int *classes);
+extern void ata_std_postreset(struct ata_port *ap, unsigned int *classes);
 extern void ata_port_disable(struct ata_port *);
-
+extern void ata_std_ports(struct ata_ioports *ioaddr);
+#ifdef CONFIG_PCI
+extern int ata_pci_init_one (struct pci_dev *pdev,
+			     const struct ata_port_info * const * ppi);
+extern void ata_pci_remove_one (struct pci_dev *pdev);
+#ifdef CONFIG_PM
+extern void ata_pci_device_do_suspend(struct pci_dev *pdev, pm_message_t mesg);
+extern int __must_check ata_pci_device_do_resume(struct pci_dev *pdev);
+extern int ata_pci_device_suspend(struct pci_dev *pdev, pm_message_t mesg);
+extern int ata_pci_device_resume(struct pci_dev *pdev);
+#endif
+extern int ata_pci_clear_simplex(struct pci_dev *pdev);
+#endif /* CONFIG_PCI */
 extern struct ata_host *ata_host_alloc(struct device *dev, int max_ports);
 extern struct ata_host *ata_host_alloc_pinfo(struct device *dev,
 			const struct ata_port_info * const * ppi, int n_ports);
-extern int ata_slave_link_init(struct ata_port *ap);
 extern int ata_host_start(struct ata_host *host);
 extern int ata_host_register(struct ata_host *host,
 			     struct scsi_host_template *sht);
@@ -962,12 +800,10 @@
 			     struct scsi_host_template *sht);
 extern void ata_host_detach(struct ata_host *host);
 extern void ata_host_init(struct ata_host *, struct device *,
-			  unsigned long, struct ata_port_operations *);
+			  unsigned long, const struct ata_port_operations *);
 extern int ata_scsi_detect(struct scsi_host_template *sht);
 extern int ata_scsi_ioctl(struct scsi_device *dev, int cmd, void __user *arg);
 extern int ata_scsi_queuecmd(struct scsi_cmnd *cmd, void (*done)(struct scsi_cmnd *));
-extern int ata_sas_scsi_ioctl(struct ata_port *ap, struct scsi_device *dev,
-			    int cmd, void __user *arg);
 extern void ata_sas_port_destroy(struct ata_port *);
 extern struct ata_port *ata_sas_port_alloc(struct ata_host *,
 					   struct ata_port_info *, struct Scsi_Host *);
@@ -977,36 +813,54 @@
 extern int ata_sas_slave_configure(struct scsi_device *, struct ata_port *);
 extern int ata_sas_queuecmd(struct scsi_cmnd *cmd, void (*done)(struct scsi_cmnd *),
 			    struct ata_port *ap);
-extern int sata_scr_valid(struct ata_link *link);
-extern int sata_scr_read(struct ata_link *link, int reg, u32 *val);
-extern int sata_scr_write(struct ata_link *link, int reg, u32 val);
-extern int sata_scr_write_flush(struct ata_link *link, int reg, u32 val);
-extern bool ata_link_online(struct ata_link *link);
-extern bool ata_link_offline(struct ata_link *link);
+extern unsigned int ata_host_intr(struct ata_port *ap, struct ata_queued_cmd *qc);
+extern int sata_scr_valid(struct ata_port *ap);
+extern int sata_scr_read(struct ata_port *ap, int reg, u32 *val);
+extern int sata_scr_write(struct ata_port *ap, int reg, u32 val);
+extern int sata_scr_write_flush(struct ata_port *ap, int reg, u32 val);
+extern int ata_port_online(struct ata_port *ap);
+extern int ata_port_offline(struct ata_port *ap);
 #ifdef CONFIG_PM
 extern int ata_host_suspend(struct ata_host *host, pm_message_t mesg);
 extern void ata_host_resume(struct ata_host *host);
 #endif
 extern int ata_ratelimit(void);
+extern int ata_busy_sleep(struct ata_port *ap,
+			  unsigned long timeout_pat, unsigned long timeout);
+extern int ata_wait_ready(struct ata_port *ap, unsigned long deadline);
+extern void ata_port_queue_task(struct ata_port *ap, work_func_t fn,
+				void *data, unsigned long delay);
 extern u32 ata_wait_register(void __iomem *reg, u32 mask, u32 val,
-			     unsigned long interval, unsigned long timeout);
-extern int atapi_cmd_type(u8 opcode);
+			     unsigned long interval_msec,
+			     unsigned long timeout_msec);
+extern unsigned int ata_dev_try_classify(struct ata_port *, unsigned int, u8 *);
+
+/*
+ * Default driver ops implementations
+ */
+extern void ata_tf_load(struct ata_port *ap, const struct ata_taskfile *tf);
+extern void ata_tf_read(struct ata_port *ap, struct ata_taskfile *tf);
 extern void ata_tf_to_fis(const struct ata_taskfile *tf,
 			  u8 pmp, int is_cmd, u8 *fis);
 extern void ata_tf_from_fis(const u8 *fis, struct ata_taskfile *tf);
-extern unsigned long ata_pack_xfermask(unsigned long pio_mask,
-			unsigned long mwdma_mask, unsigned long udma_mask);
-extern void ata_unpack_xfermask(unsigned long xfer_mask,
-			unsigned long *pio_mask, unsigned long *mwdma_mask,
-			unsigned long *udma_mask);
-extern u8 ata_xfer_mask2mode(unsigned long xfer_mask);
-extern unsigned long ata_xfer_mode2mask(u8 xfer_mode);
-extern int ata_xfer_mode2shift(unsigned long xfer_mode);
-extern const char *ata_mode_string(unsigned long xfer_mask);
-extern unsigned long ata_id_xfermask(const u16 *id);
-extern int ata_port_start(struct ata_port *ap);
-extern int ata_std_qc_defer(struct ata_queued_cmd *qc);
+extern void ata_noop_dev_select (struct ata_port *ap, unsigned int device);
+extern void ata_std_dev_select (struct ata_port *ap, unsigned int device);
+extern u8 ata_check_status(struct ata_port *ap);
+extern u8 ata_altstatus(struct ata_port *ap);
+extern void ata_exec_command(struct ata_port *ap, const struct ata_taskfile *tf);
+extern int ata_port_start (struct ata_port *ap);
+extern int ata_sff_port_start (struct ata_port *ap);
+extern irqreturn_t ata_interrupt (int irq, void *dev_instance);
+extern void ata_data_xfer(struct ata_device *adev, unsigned char *buf,
+			  unsigned int buflen, int write_data);
+extern void ata_data_xfer_noirq(struct ata_device *adev, unsigned char *buf,
+				unsigned int buflen, int write_data);
+extern void ata_dumb_qc_prep(struct ata_queued_cmd *qc);
+extern void ata_qc_prep(struct ata_queued_cmd *qc);
 extern void ata_noop_qc_prep(struct ata_queued_cmd *qc);
+extern unsigned int ata_qc_issue_prot(struct ata_queued_cmd *qc);
+extern void ata_sg_init_one(struct ata_queued_cmd *qc, void *buf,
+		unsigned int buflen);
 extern void ata_sg_init(struct ata_queued_cmd *qc, struct scatterlist *sg,
 		 unsigned int n_elem);
 extern unsigned int ata_dev_classify(const struct ata_taskfile *tf);
@@ -1015,10 +869,25 @@
 			  unsigned int ofs, unsigned int len);
 extern void ata_id_c_string(const u16 *id, unsigned char *s,
 			    unsigned int ofs, unsigned int len);
-extern unsigned int ata_do_dev_read_id(struct ata_device *dev,
-					struct ata_taskfile *tf, u16 *id);
+extern void ata_id_to_dma_mode(struct ata_device *dev, u8 unknown);
+extern void ata_bmdma_setup (struct ata_queued_cmd *qc);
+extern void ata_bmdma_start (struct ata_queued_cmd *qc);
+extern void ata_bmdma_stop(struct ata_queued_cmd *qc);
+extern u8   ata_bmdma_status(struct ata_port *ap);
+extern void ata_bmdma_irq_clear(struct ata_port *ap);
+extern void ata_bmdma_freeze(struct ata_port *ap);
+extern void ata_bmdma_thaw(struct ata_port *ap);
+extern void ata_bmdma_drive_eh(struct ata_port *ap, ata_prereset_fn_t prereset,
+			       ata_reset_fn_t softreset,
+			       ata_reset_fn_t hardreset,
+			       ata_postreset_fn_t postreset);
+extern void ata_bmdma_error_handler(struct ata_port *ap);
+extern void ata_bmdma_post_internal_cmd(struct ata_queued_cmd *qc);
+extern int ata_hsm_move(struct ata_port *ap, struct ata_queued_cmd *qc,
+			u8 status, int in_wq);
 extern void ata_qc_complete(struct ata_queued_cmd *qc);
-extern int ata_qc_complete_multiple(struct ata_port *ap, u32 qc_active);
+extern int ata_qc_complete_multiple(struct ata_port *ap, u32 qc_active,
+				    void (*finish_qc)(struct ata_queued_cmd *));
 extern void ata_scsi_simulate(struct ata_device *dev, struct scsi_cmnd *cmd,
 			      void (*done)(struct scsi_cmnd *));
 extern int ata_std_bios_param(struct scsi_device *sdev,
@@ -1029,31 +898,47 @@
 extern int ata_scsi_change_queue_depth(struct scsi_device *sdev,
 				       int queue_depth);
 extern struct ata_device *ata_dev_pair(struct ata_device *adev);
-extern int ata_do_set_mode(struct ata_link *link, struct ata_device **r_failed_dev);
+extern int ata_do_set_mode(struct ata_port *ap, struct ata_device **r_failed_dev);
+extern u8 ata_irq_on(struct ata_port *ap);
+extern u8 ata_dummy_irq_on(struct ata_port *ap);
+extern u8 ata_irq_ack(struct ata_port *ap, unsigned int chk_drq);
+extern u8 ata_dummy_irq_ack(struct ata_port *ap, unsigned int chk_drq);
 
 extern int ata_cable_40wire(struct ata_port *ap);
 extern int ata_cable_80wire(struct ata_port *ap);
 extern int ata_cable_sata(struct ata_port *ap);
-extern int ata_cable_ignore(struct ata_port *ap);
 extern int ata_cable_unknown(struct ata_port *ap);
 
-extern void ata_pio_queue_task(struct ata_port *ap, void *data,
-			       unsigned long delay);
+/*
+ * Timing helpers
+ */
 
-/* Timing helpers */
 extern unsigned int ata_pio_need_iordy(const struct ata_device *);
-extern const struct ata_timing *ata_timing_find_mode(u8 xfer_mode);
 extern int ata_timing_compute(struct ata_device *, unsigned short,
 			      struct ata_timing *, int, int);
 extern void ata_timing_merge(const struct ata_timing *,
 			     const struct ata_timing *, struct ata_timing *,
 			     unsigned int);
-extern u8 ata_timing_cycle2mode(unsigned int xfer_shift, int cycle);
 
-/* PCI */
-#ifdef CONFIG_PCI
-struct pci_dev;
+enum {
+	ATA_TIMING_SETUP	= (1 << 0),
+	ATA_TIMING_ACT8B	= (1 << 1),
+	ATA_TIMING_REC8B	= (1 << 2),
+	ATA_TIMING_CYC8B	= (1 << 3),
+	ATA_TIMING_8BIT		= ATA_TIMING_ACT8B | ATA_TIMING_REC8B |
+				  ATA_TIMING_CYC8B,
+	ATA_TIMING_ACTIVE	= (1 << 4),
+	ATA_TIMING_RECOVER	= (1 << 5),
+	ATA_TIMING_CYCLE	= (1 << 6),
+	ATA_TIMING_UDMA		= (1 << 7),
+	ATA_TIMING_ALL		= ATA_TIMING_SETUP | ATA_TIMING_ACT8B |
+				  ATA_TIMING_REC8B | ATA_TIMING_CYC8B |
+				  ATA_TIMING_ACTIVE | ATA_TIMING_RECOVER |
+				  ATA_TIMING_CYCLE | ATA_TIMING_UDMA,
+};
+
 
+#ifdef CONFIG_PCI
 struct pci_bits {
 	unsigned int		reg;	/* PCI config register to read */
 	unsigned int		width;	/* 1 (8 bit), 2 (16 bit), 4 (32 bit) */
@@ -1061,215 +946,103 @@
 	unsigned long		val;
 };
 
+extern int ata_pci_init_sff_host(struct ata_host *host);
+extern int ata_pci_init_bmdma(struct ata_host *host);
+extern int ata_pci_prepare_sff_host(struct pci_dev *pdev,
+				    const struct ata_port_info * const * ppi,
+				    struct ata_host **r_host);
 extern int pci_test_config_bits(struct pci_dev *pdev, const struct pci_bits *bits);
-extern void ata_pci_remove_one(struct pci_dev *pdev);
-
-#ifdef CONFIG_PM
-extern void ata_pci_device_do_suspend(struct pci_dev *pdev, pm_message_t mesg);
-extern int __must_check ata_pci_device_do_resume(struct pci_dev *pdev);
-extern int ata_pci_device_suspend(struct pci_dev *pdev, pm_message_t mesg);
-extern int ata_pci_device_resume(struct pci_dev *pdev);
-#endif /* CONFIG_PM */
+extern unsigned long ata_pci_default_filter(struct ata_device *, unsigned long);
 #endif /* CONFIG_PCI */
 
 /*
- * ACPI - drivers/ata/libata-acpi.c
+ * EH
  */
-#ifdef CONFIG_ATA_ACPI
-static inline const struct ata_acpi_gtm *ata_acpi_init_gtm(struct ata_port *ap)
-{
-	if (ap->pflags & ATA_PFLAG_INIT_GTM_VALID)
-		return &ap->__acpi_init_gtm;
-	return NULL;
-}
-int ata_acpi_stm(struct ata_port *ap, const struct ata_acpi_gtm *stm);
-int ata_acpi_gtm(struct ata_port *ap, struct ata_acpi_gtm *stm);
-unsigned long ata_acpi_gtm_xfermask(struct ata_device *dev,
-				    const struct ata_acpi_gtm *gtm);
-int ata_acpi_cbl_80wire(struct ata_port *ap, const struct ata_acpi_gtm *gtm);
-#else
-static inline const struct ata_acpi_gtm *ata_acpi_init_gtm(struct ata_port *ap)
-{
-	return NULL;
-}
-
-static inline int ata_acpi_stm(const struct ata_port *ap,
-			       struct ata_acpi_gtm *stm)
-{
-	return -ENOSYS;
-}
-
-static inline int ata_acpi_gtm(const struct ata_port *ap,
-			       struct ata_acpi_gtm *stm)
-{
-	return -ENOSYS;
-}
+extern void ata_eng_timeout(struct ata_port *ap);
 
-static inline unsigned int ata_acpi_gtm_xfermask(struct ata_device *dev,
-					const struct ata_acpi_gtm *gtm)
-{
-	return 0;
-}
-
-static inline int ata_acpi_cbl_80wire(struct ata_port *ap,
-				      const struct ata_acpi_gtm *gtm)
-{
-	return 0;
-}
-#endif
-
-/*
- * EH - drivers/ata/libata-eh.c
- */
 extern void ata_port_schedule_eh(struct ata_port *ap);
-extern int ata_link_abort(struct ata_link *link);
 extern int ata_port_abort(struct ata_port *ap);
 extern int ata_port_freeze(struct ata_port *ap);
-extern int sata_async_notification(struct ata_port *ap);
 
 extern void ata_eh_freeze_port(struct ata_port *ap);
 extern void ata_eh_thaw_port(struct ata_port *ap);
 
 extern void ata_eh_qc_complete(struct ata_queued_cmd *qc);
 extern void ata_eh_qc_retry(struct ata_queued_cmd *qc);
-extern void ata_eh_analyze_ncq_error(struct ata_link *link);
 
 extern void ata_do_eh(struct ata_port *ap, ata_prereset_fn_t prereset,
 		      ata_reset_fn_t softreset, ata_reset_fn_t hardreset,
 		      ata_postreset_fn_t postreset);
-extern void ata_std_error_handler(struct ata_port *ap);
 
 /*
- * Base operations to inherit from and initializers for sht
- *
- * Operations
- *
- * base  : Common to all libata drivers.
- * sata  : SATA controllers w/ native interface.
- * pmp   : SATA controllers w/ PMP support.
- * sff   : SFF ATA controllers w/o BMDMA support.
- * bmdma : SFF ATA controllers w/ BMDMA support.
- *
- * sht initializers
- *
- * BASE  : Common to all libata drivers.  The user must set
- *	   sg_tablesize and dma_boundary.
- * PIO   : SFF ATA controllers w/ only PIO support.
- * BMDMA : SFF ATA controllers w/ BMDMA support.  sg_tablesize and
- *	   dma_boundary are set to BMDMA limits.
- * NCQ   : SATA controllers supporting NCQ.  The user must set
- *	   sg_tablesize, dma_boundary and can_queue.
+ * printk helpers
  */
-extern const struct ata_port_operations ata_base_port_ops;
-extern const struct ata_port_operations sata_port_ops;
-extern struct device_attribute *ata_common_sdev_attrs[];
-
-#define ATA_BASE_SHT(drv_name)					\
-	.module			= THIS_MODULE,			\
-	.name			= drv_name,			\
-	.ioctl			= ata_scsi_ioctl,		\
-	.queuecommand		= ata_scsi_queuecmd,		\
-	.can_queue		= ATA_DEF_QUEUE,		\
-	.this_id		= ATA_SHT_THIS_ID,		\
-	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,		\
-	.emulated		= ATA_SHT_EMULATED,		\
-	.use_clustering		= ATA_SHT_USE_CLUSTERING,	\
-	.proc_name		= drv_name,			\
-	.slave_configure	= ata_scsi_slave_config,	\
-	.slave_destroy		= ata_scsi_slave_destroy,	\
-	.bios_param		= ata_std_bios_param,		\
-	.sdev_attrs		= ata_common_sdev_attrs
-
-#define ATA_NCQ_SHT(drv_name)					\
-	ATA_BASE_SHT(drv_name),					\
-	.change_queue_depth	= ata_scsi_change_queue_depth
+#define ata_port_printk(ap, lv, fmt, args...) \
+	printk(lv"ata%u: "fmt, (ap)->print_id , ##args)
+
+#define ata_dev_printk(dev, lv, fmt, args...) \
+	printk(lv"ata%u.%02u: "fmt, (dev)->ap->print_id, (dev)->devno , ##args)
 
 /*
- * PMP helpers
+ * ata_eh_info helpers
  */
-#ifdef CONFIG_SATA_PMP
-static inline bool sata_pmp_supported(struct ata_port *ap)
-{
-	return ap->flags & ATA_FLAG_PMP;
-}
-
-static inline bool sata_pmp_attached(struct ata_port *ap)
-{
-	return ap->nr_pmp_links != 0;
-}
+extern void __ata_ehi_push_desc(struct ata_eh_info *ehi, const char *fmt, ...);
+extern void ata_ehi_push_desc(struct ata_eh_info *ehi, const char *fmt, ...);
+extern void ata_ehi_clear_desc(struct ata_eh_info *ehi);
 
-static inline int ata_is_host_link(const struct ata_link *link)
-{
-	return link == &link->ap->link || link == link->ap->slave_link;
-}
-#else /* CONFIG_SATA_PMP */
-static inline bool sata_pmp_supported(struct ata_port *ap)
+static inline void ata_ehi_schedule_probe(struct ata_eh_info *ehi)
 {
-	return false;
+	ehi->flags |= ATA_EHI_RESUME_LINK;
+	ehi->action |= ATA_EH_SOFTRESET;
+	ehi->probe_mask |= (1 << ATA_MAX_DEVICES) - 1;
 }
 
-static inline bool sata_pmp_attached(struct ata_port *ap)
+static inline void ata_ehi_hotplugged(struct ata_eh_info *ehi)
 {
-	return false;
+	ata_ehi_schedule_probe(ehi);
+	ehi->flags |= ATA_EHI_HOTPLUGGED;
+	ehi->err_mask |= AC_ERR_ATA_BUS;
 }
 
-static inline int ata_is_host_link(const struct ata_link *link)
+/*
+ * qc helpers
+ */
+static inline int
+ata_sg_is_last(struct scatterlist *sg, struct ata_queued_cmd *qc)
 {
-	return 1;
+	if (sg == &qc->pad_sgent)
+		return 1;
+	if (qc->pad_len)
+		return 0;
+	if (((sg - qc->__sg) + 1) == qc->n_elem)
+		return 1;
+	return 0;
 }
-#endif /* CONFIG_SATA_PMP */
 
-static inline int sata_srst_pmp(struct ata_link *link)
+static inline struct scatterlist *
+ata_qc_first_sg(struct ata_queued_cmd *qc)
 {
-	if (sata_pmp_supported(link->ap) && ata_is_host_link(link))
-		return SATA_PMP_CTRL_PORT;
-	return link->pmp;
+	if (qc->n_elem)
+		return qc->__sg;
+	if (qc->pad_len)
+		return &qc->pad_sgent;
+	return NULL;
 }
 
-/*
- * printk helpers
- */
-#define ata_port_printk(ap, lv, fmt, args...) \
-	printk("%sata%u: "fmt, lv, (ap)->print_id , ##args)
-
-#define ata_link_printk(link, lv, fmt, args...) do { \
-	if (sata_pmp_attached((link)->ap) || (link)->ap->slave_link)	\
-		printk("%sata%u.%02u: "fmt, lv, (link)->ap->print_id,	\
-		       (link)->pmp , ##args); \
-	else \
-		printk("%sata%u: "fmt, lv, (link)->ap->print_id , ##args); \
-	} while(0)
-
-#define ata_dev_printk(dev, lv, fmt, args...) \
-	printk("%sata%u.%02u: "fmt, lv, (dev)->link->ap->print_id,	\
-	       (dev)->link->pmp + (dev)->devno , ##args)
-
-/*
- * ata_eh_info helpers
- */
-extern void __ata_ehi_push_desc(struct ata_eh_info *ehi, const char *fmt, ...)
-	__attribute__ ((format (printf, 2, 3)));
-extern void ata_ehi_push_desc(struct ata_eh_info *ehi, const char *fmt, ...)
-	__attribute__ ((format (printf, 2, 3)));
-extern void ata_ehi_clear_desc(struct ata_eh_info *ehi);
-
-static inline void ata_ehi_hotplugged(struct ata_eh_info *ehi)
+static inline struct scatterlist *
+ata_qc_next_sg(struct scatterlist *sg, struct ata_queued_cmd *qc)
 {
-	ehi->probe_mask |= (1 << ATA_MAX_DEVICES) - 1;
-	ehi->flags |= ATA_EHI_HOTPLUGGED;
-	ehi->action |= ATA_EH_RESET | ATA_EH_ENABLE_LINK;
-	ehi->err_mask |= AC_ERR_ATA_BUS;
+	if (sg == &qc->pad_sgent)
+		return NULL;
+	if (++sg - qc->__sg < qc->n_elem)
+		return sg;
+	if (qc->pad_len)
+		return &qc->pad_sgent;
+	return NULL;
 }
 
-/*
- * port description helpers
- */
-extern void ata_port_desc(struct ata_port *ap, const char *fmt, ...)
-	__attribute__ ((format (printf, 2, 3)));
-#ifdef CONFIG_PCI
-extern void ata_port_pbar_desc(struct ata_port *ap, int bar, ssize_t offset,
-			       const char *name);
-#endif
+#define ata_for_each_sg(sg, qc) \
+	for (sg = ata_qc_first_sg(qc); sg; sg = ata_qc_next_sg(sg, qc))
 
 static inline unsigned int ata_tag_valid(unsigned int tag)
 {
@@ -1278,7 +1051,7 @@
 
 static inline unsigned int ata_tag_internal(unsigned int tag)
 {
-	return tag == ATA_TAG_INTERNAL;
+	return tag == ATA_MAX_QUEUE - 1;
 }
 
 /*
@@ -1286,14 +1059,12 @@
  */
 static inline unsigned int ata_class_enabled(unsigned int class)
 {
-	return class == ATA_DEV_ATA || class == ATA_DEV_ATAPI ||
-		class == ATA_DEV_PMP || class == ATA_DEV_SEMB;
+	return class == ATA_DEV_ATA || class == ATA_DEV_ATAPI;
 }
 
 static inline unsigned int ata_class_disabled(unsigned int class)
 {
-	return class == ATA_DEV_ATA_UNSUP || class == ATA_DEV_ATAPI_UNSUP ||
-		class == ATA_DEV_PMP_UNSUP || class == ATA_DEV_SEMB_UNSUP;
+	return class == ATA_DEV_ATA_UNSUP || class == ATA_DEV_ATAPI_UNSUP;
 }
 
 static inline unsigned int ata_class_absent(unsigned int class)
@@ -1317,91 +1088,101 @@
 }
 
 /*
- * link helpers
+ * port helpers
  */
-static inline int ata_link_max_devices(const struct ata_link *link)
+static inline int ata_port_max_devices(const struct ata_port *ap)
 {
-	if (ata_is_host_link(link) && link->ap->flags & ATA_FLAG_SLAVE_POSS)
+	if (ap->flags & ATA_FLAG_SLAVE_POSS)
 		return 2;
 	return 1;
 }
 
-static inline int ata_link_active(struct ata_link *link)
+
+static inline u8 ata_chk_status(struct ata_port *ap)
 {
-	return ata_tag_valid(link->active_tag) || link->sactive;
+	return ap->ops->check_status(ap);
 }
 
-/*
- * Iterators
+/**
+ *	ata_ncq_enabled - Test whether NCQ is enabled
+ *	@dev: ATA device to test for
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
  *
- * ATA_LITER_* constants are used to select link iteration mode and
- * ATA_DITER_* device iteration mode.
+ *	RETURNS:
+ *	1 if NCQ is enabled for @dev, 0 otherwise.
+ */
+static inline int ata_ncq_enabled(struct ata_device *dev)
+{
+	return (dev->flags & (ATA_DFLAG_PIO | ATA_DFLAG_NCQ_OFF |
+			      ATA_DFLAG_NCQ)) == ATA_DFLAG_NCQ;
+}
+
+/**
+ *	ata_pause - Flush writes and pause 400 nanoseconds.
+ *	@ap: Port to wait for.
  *
- * For a custom iteration directly using ata_{link|dev}_next(), if
- * @link or @dev, respectively, is NULL, the first element is
- * returned.  @dev and @link can be any valid device or link and the
- * next element according to the iteration mode will be returned.
- * After the last element, NULL is returned.
+ *	LOCKING:
+ *	Inherited from caller.
  */
-enum ata_link_iter_mode {
-	ATA_LITER_EDGE,		/* if present, PMP links only; otherwise,
-				 * host link.  no slave link */
-	ATA_LITER_HOST_FIRST,	/* host link followed by PMP or slave links */
-	ATA_LITER_PMP_FIRST,	/* PMP links followed by host link,
-				 * slave link still comes after host link */
-};
 
-enum ata_dev_iter_mode {
-	ATA_DITER_ENABLED,
-	ATA_DITER_ENABLED_REVERSE,
-	ATA_DITER_ALL,
-	ATA_DITER_ALL_REVERSE,
-};
+static inline void ata_pause(struct ata_port *ap)
+{
+	ata_altstatus(ap);
+	ndelay(400);
+}
 
-extern struct ata_link *ata_link_next(struct ata_link *link,
-				      struct ata_port *ap,
-				      enum ata_link_iter_mode mode);
-
-extern struct ata_device *ata_dev_next(struct ata_device *dev,
-				       struct ata_link *link,
-				       enum ata_dev_iter_mode mode);
 
-/*
- * Shortcut notation for iterations
+/**
+ *	ata_busy_wait - Wait for a port status register
+ *	@ap: Port to wait for.
+ *	@bits: bits that must be clear
+ *	@max: number of 10uS waits to perform
  *
- * ata_for_each_link() iterates over each link of @ap according to
- * @mode.  @link points to the current link in the loop.  @link is
- * NULL after loop termination.  ata_for_each_dev() works the same way
- * except that it iterates over each device of @link.
+ *	Waits up to max*10 microseconds for the selected bits in the port's
+ *	status register to be cleared.
+ *	Returns final value of status register.
  *
- * Note that the mode prefixes ATA_{L|D}ITER_ shouldn't need to be
- * specified when using the following shorthand notations.  Only the
- * mode itself (EDGE, HOST_FIRST, ENABLED, etc...) should be
- * specified.  This not only increases brevity but also makes it
- * impossible to use ATA_LITER_* for device iteration or vice-versa.
+ *	LOCKING:
+ *	Inherited from caller.
  */
-#define ata_for_each_link(link, ap, mode) \
-	for ((link) = ata_link_next(NULL, (ap), ATA_LITER_##mode); (link); \
-	     (link) = ata_link_next((link), (ap), ATA_LITER_##mode))
-
-#define ata_for_each_dev(dev, link, mode) \
-	for ((dev) = ata_dev_next(NULL, (link), ATA_DITER_##mode); (dev); \
-	     (dev) = ata_dev_next((dev), (link), ATA_DITER_##mode))
+
+static inline u8 ata_busy_wait(struct ata_port *ap, unsigned int bits,
+			       unsigned int max)
+{
+	u8 status;
+
+	do {
+		udelay(10);
+		status = ata_chk_status(ap);
+		max--;
+	} while (status != 0xff && (status & bits) && (max > 0));
+
+	return status;
+}
+
 
 /**
- *	ata_ncq_enabled - Test whether NCQ is enabled
- *	@dev: ATA device to test for
+ *	ata_wait_idle - Wait for a port to be idle.
+ *	@ap: Port to wait for.
  *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
+ *	Waits up to 10ms for port's BUSY and DRQ signals to clear.
+ *	Returns final value of status register.
  *
- *	RETURNS:
- *	1 if NCQ is enabled for @dev, 0 otherwise.
+ *	LOCKING:
+ *	Inherited from caller.
  */
-static inline int ata_ncq_enabled(struct ata_device *dev)
+
+static inline u8 ata_wait_idle(struct ata_port *ap)
 {
-	return (dev->flags & (ATA_DFLAG_PIO | ATA_DFLAG_NCQ_OFF |
-			      ATA_DFLAG_NCQ)) == ATA_DFLAG_NCQ;
+	u8 status = ata_busy_wait(ap, ATA_BUSY | ATA_DRQ, 1000);
+
+	if (status != 0xff && (status & (ATA_BUSY | ATA_DRQ)))
+		DPRINTK("ATA: abnormal status 0x%X on port 0x%p\n",
+			status, ap->ioaddr.status_addr);
+
+	return status;
 }
 
 static inline void ata_qc_set_polling(struct ata_queued_cmd *qc)
@@ -1432,16 +1213,11 @@
 	return NULL;
 }
 
-static inline unsigned int ata_qc_raw_nbytes(struct ata_queued_cmd *qc)
-{
-	return qc->nbytes - min(qc->extrabytes, qc->nbytes);
-}
-
 static inline void ata_tf_init(struct ata_device *dev, struct ata_taskfile *tf)
 {
 	memset(tf, 0, sizeof(*tf));
 
-	tf->ctl = dev->link->ap->ctl;
+	tf->ctl = dev->ap->ctl;
 	if (dev->devno == 0)
 		tf->device = ATA_DEVICE_OBS;
 	else
@@ -1451,13 +1227,13 @@
 static inline void ata_qc_reinit(struct ata_queued_cmd *qc)
 {
 	qc->dma_dir = DMA_NONE;
-	qc->sg = NULL;
+	qc->__sg = NULL;
 	qc->flags = 0;
-	qc->cursg = NULL;
-	qc->cursg_ofs = 0;
-	qc->nbytes = qc->extrabytes = qc->curbytes = 0;
+	qc->cursg = qc->cursg_ofs = 0;
+	qc->nbytes = qc->curbytes = 0;
 	qc->n_elem = 0;
 	qc->err_mask = 0;
+	qc->pad_len = 0;
 	qc->sect_size = ATA_SECT_SIZE;
 
 	ata_tf_init(qc->dev, &qc->tf);
@@ -1491,210 +1267,22 @@
 	return mask;
 }
 
-static inline struct ata_port *ata_shost_to_port(struct Scsi_Host *host)
-{
-	return *(struct ata_port **)&host->hostdata[0];
-}
-
-static inline int ata_check_ready(u8 status)
-{
-	if (!(status & ATA_BUSY))
-		return 1;
-
-	/* 0xff indicates either no device or device not ready */
-	if (status == 0xff)
-		return -ENODEV;
-
-	return 0;
-}
-
-static inline unsigned long ata_deadline(unsigned long from_jiffies,
-					 unsigned long timeout_msecs)
+static inline int ata_pad_alloc(struct ata_port *ap, struct device *dev)
 {
-	return from_jiffies + msecs_to_jiffies(timeout_msecs);
-}
-
-/* Don't open code these in drivers as there are traps. Firstly the range may
-   change in future hardware and specs, secondly 0xFF means 'no DMA' but is
-   > UDMA_0. Dyma ddreigiau */
-
-static inline int ata_using_mwdma(struct ata_device *adev)
-{
-	if (adev->dma_mode >= XFER_MW_DMA_0 && adev->dma_mode <= XFER_MW_DMA_4)
-		return 1;
-	return 0;
-}
-
-static inline int ata_using_udma(struct ata_device *adev)
-{
-	if (adev->dma_mode >= XFER_UDMA_0 && adev->dma_mode <= XFER_UDMA_7)
-		return 1;
-	return 0;
+	ap->pad_dma = 0;
+	ap->pad = dmam_alloc_coherent(dev, ATA_DMA_PAD_BUF_SZ,
+				      &ap->pad_dma, GFP_KERNEL);
+	return (ap->pad == NULL) ? -ENOMEM : 0;
 }
 
-static inline int ata_dma_enabled(struct ata_device *adev)
-{
-	return (adev->dma_mode == 0xFF ? 0 : 1);
-}
-
-/**************************************************************************
- * PMP - drivers/ata/libata-pmp.c
- */
-#ifdef CONFIG_SATA_PMP
-
-extern const struct ata_port_operations sata_pmp_port_ops;
-
-extern int sata_pmp_qc_defer_cmd_switch(struct ata_queued_cmd *qc);
-extern void sata_pmp_error_handler(struct ata_port *ap);
-
-#else /* CONFIG_SATA_PMP */
-
-#define sata_pmp_port_ops		sata_port_ops
-#define sata_pmp_qc_defer_cmd_switch	ata_std_qc_defer
-#define sata_pmp_error_handler		ata_std_error_handler
-
-#endif /* CONFIG_SATA_PMP */
-
-
-/**************************************************************************
- * SFF - drivers/ata/libata-sff.c
- */
-#ifdef CONFIG_ATA_SFF
-
-extern const struct ata_port_operations ata_sff_port_ops;
-extern const struct ata_port_operations ata_bmdma_port_ops;
-extern const struct ata_port_operations ata_bmdma32_port_ops;
-
-/* PIO only, sg_tablesize and dma_boundary limits can be removed */
-#define ATA_PIO_SHT(drv_name)					\
-	ATA_BASE_SHT(drv_name),					\
-	.sg_tablesize		= LIBATA_MAX_PRD,		\
-	.dma_boundary		= ATA_DMA_BOUNDARY
-
-#define ATA_BMDMA_SHT(drv_name)					\
-	ATA_BASE_SHT(drv_name),					\
-	.sg_tablesize		= LIBATA_MAX_PRD,		\
-	.dma_boundary		= ATA_DMA_BOUNDARY
-
-extern void ata_sff_qc_prep(struct ata_queued_cmd *qc);
-extern void ata_sff_dumb_qc_prep(struct ata_queued_cmd *qc);
-extern void ata_sff_dev_select(struct ata_port *ap, unsigned int device);
-extern u8 ata_sff_check_status(struct ata_port *ap);
-extern void ata_sff_pause(struct ata_port *ap);
-extern void ata_sff_dma_pause(struct ata_port *ap);
-extern int ata_sff_busy_sleep(struct ata_port *ap,
-			      unsigned long timeout_pat, unsigned long timeout);
-extern int ata_sff_wait_ready(struct ata_link *link, unsigned long deadline);
-extern void ata_sff_tf_load(struct ata_port *ap, const struct ata_taskfile *tf);
-extern void ata_sff_tf_read(struct ata_port *ap, struct ata_taskfile *tf);
-extern void ata_sff_exec_command(struct ata_port *ap,
-				 const struct ata_taskfile *tf);
-extern unsigned int ata_sff_data_xfer(struct ata_device *dev,
-			unsigned char *buf, unsigned int buflen, int rw);
-extern unsigned int ata_sff_data_xfer32(struct ata_device *dev,
-			unsigned char *buf, unsigned int buflen, int rw);
-extern unsigned int ata_sff_data_xfer_noirq(struct ata_device *dev,
-			unsigned char *buf, unsigned int buflen, int rw);
-extern u8 ata_sff_irq_on(struct ata_port *ap);
-extern void ata_sff_irq_clear(struct ata_port *ap);
-extern int ata_sff_hsm_move(struct ata_port *ap, struct ata_queued_cmd *qc,
-			    u8 status, int in_wq);
-extern unsigned int ata_sff_qc_issue(struct ata_queued_cmd *qc);
-extern bool ata_sff_qc_fill_rtf(struct ata_queued_cmd *qc);
-extern unsigned int ata_sff_host_intr(struct ata_port *ap,
-				      struct ata_queued_cmd *qc);
-extern irqreturn_t ata_sff_interrupt(int irq, void *dev_instance);
-extern void ata_sff_lost_interrupt(struct ata_port *ap);
-extern void ata_sff_freeze(struct ata_port *ap);
-extern void ata_sff_thaw(struct ata_port *ap);
-extern int ata_sff_prereset(struct ata_link *link, unsigned long deadline);
-extern unsigned int ata_sff_dev_classify(struct ata_device *dev, int present,
-					  u8 *r_err);
-extern int ata_sff_wait_after_reset(struct ata_link *link, unsigned int devmask,
-				    unsigned long deadline);
-extern int ata_sff_softreset(struct ata_link *link, unsigned int *classes,
-			     unsigned long deadline);
-extern int sata_sff_hardreset(struct ata_link *link, unsigned int *class,
-			       unsigned long deadline);
-extern void ata_sff_postreset(struct ata_link *link, unsigned int *classes);
-extern void ata_sff_drain_fifo(struct ata_queued_cmd *qc);
-extern void ata_sff_error_handler(struct ata_port *ap);
-extern void ata_sff_post_internal_cmd(struct ata_queued_cmd *qc);
-extern int ata_sff_port_start(struct ata_port *ap);
-extern int ata_sff_port_start32(struct ata_port *ap);
-extern void ata_sff_std_ports(struct ata_ioports *ioaddr);
-extern unsigned long ata_bmdma_mode_filter(struct ata_device *dev,
-					   unsigned long xfer_mask);
-extern void ata_bmdma_setup(struct ata_queued_cmd *qc);
-extern void ata_bmdma_start(struct ata_queued_cmd *qc);
-extern void ata_bmdma_stop(struct ata_queued_cmd *qc);
-extern u8 ata_bmdma_status(struct ata_port *ap);
-extern void ata_bus_reset(struct ata_port *ap);
-
-#ifdef CONFIG_PCI
-extern int ata_pci_bmdma_clear_simplex(struct pci_dev *pdev);
-extern int ata_pci_bmdma_init(struct ata_host *host);
-extern int ata_pci_sff_init_host(struct ata_host *host);
-extern int ata_pci_sff_prepare_host(struct pci_dev *pdev,
-				    const struct ata_port_info * const * ppi,
-				    struct ata_host **r_host);
-extern int ata_pci_sff_activate_host(struct ata_host *host,
-				     irq_handler_t irq_handler,
-				     struct scsi_host_template *sht);
-extern int ata_pci_sff_init_one(struct pci_dev *pdev,
-				const struct ata_port_info * const * ppi,
-				struct scsi_host_template *sht, void *host_priv);
-#endif /* CONFIG_PCI */
-
-/**
- *	ata_sff_busy_wait - Wait for a port status register
- *	@ap: Port to wait for.
- *	@bits: bits that must be clear
- *	@max: number of 10uS waits to perform
- *
- *	Waits up to max*10 microseconds for the selected bits in the port's
- *	status register to be cleared.
- *	Returns final value of status register.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static inline u8 ata_sff_busy_wait(struct ata_port *ap, unsigned int bits,
-				   unsigned int max)
+static inline void ata_pad_free(struct ata_port *ap, struct device *dev)
 {
-	u8 status;
-
-	do {
-		udelay(10);
-		status = ap->ops->sff_check_status(ap);
-		max--;
-	} while (status != 0xff && (status & bits) && (max > 0));
-
-	return status;
+	dmam_free_coherent(dev, ATA_DMA_PAD_BUF_SZ, ap->pad, ap->pad_dma);
 }
 
-/**
- *	ata_wait_idle - Wait for a port to be idle.
- *	@ap: Port to wait for.
- *
- *	Waits up to 10ms for port's BUSY and DRQ signals to clear.
- *	Returns final value of status register.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static inline u8 ata_wait_idle(struct ata_port *ap)
+static inline struct ata_port *ata_shost_to_port(struct Scsi_Host *host)
 {
-	u8 status = ata_sff_busy_wait(ap, ATA_BUSY | ATA_DRQ, 1000);
-
-#ifdef ATA_DEBUG
-	if (status != 0xff && (status & (ATA_BUSY | ATA_DRQ)))
-		ata_port_printk(ap, KERN_DEBUG, "abnormal Status 0x%X\n",
-				status);
-#endif
-
-	return status;
+	return *(struct ata_port **)&host->hostdata[0];
 }
-#endif /* CONFIG_ATA_SFF */
 
 #endif /* __LINUX_LIBATA_H__ */
diff -Nur linux-sh4/drivers/ata.org/ahci.c linux-sh4/drivers/ata/ahci.c
--- linux-sh4/drivers/ata.org/ahci.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/ahci.c	2012-01-15 06:30:14.000000000 -0800
@@ -47,42 +47,15 @@
 #include <linux/libata.h>
 
 #define DRV_NAME	"ahci"
-#define DRV_VERSION	"3.0"
+#define DRV_VERSION	"2.3"
 
-/* Enclosure Management Control */
-#define EM_CTRL_MSG_TYPE              0x000f0000
-
-/* Enclosure Management LED Message Type */
-#define EM_MSG_LED_HBA_PORT           0x0000000f
-#define EM_MSG_LED_PMP_SLOT           0x0000ff00
-#define EM_MSG_LED_VALUE              0xffff0000
-#define EM_MSG_LED_VALUE_ACTIVITY     0x00070000
-#define EM_MSG_LED_VALUE_OFF          0xfff80000
-#define EM_MSG_LED_VALUE_ON           0x00010000
-
-static int ahci_skip_host_reset;
-static int ahci_ignore_sss;
-
-module_param_named(skip_host_reset, ahci_skip_host_reset, int, 0444);
-MODULE_PARM_DESC(skip_host_reset, "skip global host reset (0=don't skip, 1=skip)");
-
-module_param_named(ignore_sss, ahci_ignore_sss, int, 0444);
-MODULE_PARM_DESC(ignore_sss, "Ignore staggered spinup flag (0=don't ignore, 1=ignore)");
-
-static int ahci_enable_alpm(struct ata_port *ap,
-		enum link_pm policy);
-static void ahci_disable_alpm(struct ata_port *ap);
-static ssize_t ahci_led_show(struct ata_port *ap, char *buf);
-static ssize_t ahci_led_store(struct ata_port *ap, const char *buf,
-			      size_t size);
-static ssize_t ahci_transmit_led_message(struct ata_port *ap, u32 state,
-					ssize_t size);
 
 enum {
 	AHCI_PCI_BAR		= 5,
 	AHCI_MAX_PORTS		= 32,
 	AHCI_MAX_SG		= 168, /* hardware max is 64K */
 	AHCI_DMA_BOUNDARY	= 0xffffffff,
+	AHCI_USE_CLUSTERING	= 1,
 	AHCI_MAX_CMDS		= 32,
 	AHCI_CMD_SZ		= 32,
 	AHCI_CMD_SLOT_SZ	= AHCI_MAX_CMDS * AHCI_CMD_SZ,
@@ -105,15 +78,11 @@
 	RX_FIS_UNK		= 0x60, /* offset of Unknown FIS data */
 
 	board_ahci		= 0,
-	board_ahci_vt8251	= 1,
-	board_ahci_ign_iferr	= 2,
-	board_ahci_sb600	= 3,
-	board_ahci_mv		= 4,
-	board_ahci_sb700	= 5, /* for SB700 and SB800 */
-	board_ahci_mcp65	= 6,
-	board_ahci_nopmp	= 7,
-	board_ahci_yesncq	= 8,
-	board_ahci_nosntf	= 9,
+	board_ahci_pi		= 1,
+	board_ahci_vt8251	= 2,
+	board_ahci_ign_iferr	= 3,
+	board_ahci_sb600	= 4,
+	board_ahci_mv		= 5,
 
 	/* global controller registers */
 	HOST_CAP		= 0x00, /* host capabilities */
@@ -121,9 +90,6 @@
 	HOST_IRQ_STAT		= 0x08, /* interrupt status */
 	HOST_PORTS_IMPL		= 0x0c, /* bitmap of implemented ports */
 	HOST_VERSION		= 0x10, /* AHCI spec. version compliancy */
-	HOST_EM_LOC		= 0x1c, /* Enclosure Management location */
-	HOST_EM_CTL		= 0x20, /* Enclosure Management Control */
-	HOST_CAP2		= 0x24, /* host capabilities, extended */
 
 	/* HOST_CTL bits */
 	HOST_RESET		= (1 << 0),  /* reset controller; self-clear */
@@ -131,29 +97,13 @@
 	HOST_AHCI_EN		= (1 << 31), /* AHCI enabled */
 
 	/* HOST_CAP bits */
-	HOST_CAP_SXS		= (1 << 5),  /* Supports External SATA */
-	HOST_CAP_EMS		= (1 << 6),  /* Enclosure Management support */
-	HOST_CAP_CCC		= (1 << 7),  /* Command Completion Coalescing */
-	HOST_CAP_PART		= (1 << 13), /* Partial state capable */
-	HOST_CAP_SSC		= (1 << 14), /* Slumber state capable */
-	HOST_CAP_PIO_MULTI	= (1 << 15), /* PIO multiple DRQ support */
-	HOST_CAP_FBS		= (1 << 16), /* FIS-based switching support */
-	HOST_CAP_PMP		= (1 << 17), /* Port Multiplier support */
-	HOST_CAP_ONLY		= (1 << 18), /* Supports AHCI mode only */
+	HOST_CAP_SSC		= (1 << 14), /* Slumber capable */
 	HOST_CAP_CLO		= (1 << 24), /* Command List Override support */
-	HOST_CAP_LED		= (1 << 25), /* Supports activity LED */
-	HOST_CAP_ALPM		= (1 << 26), /* Aggressive Link PM support */
 	HOST_CAP_SSS		= (1 << 27), /* Staggered Spin-up */
-	HOST_CAP_MPS		= (1 << 28), /* Mechanical presence switch */
 	HOST_CAP_SNTF		= (1 << 29), /* SNotification register */
 	HOST_CAP_NCQ		= (1 << 30), /* Native Command Queueing */
 	HOST_CAP_64		= (1 << 31), /* PCI DAC (64-bit DMA) support */
 
-	/* HOST_CAP2 bits */
-	HOST_CAP2_BOH		= (1 << 0),  /* BIOS/OS handoff supported */
-	HOST_CAP2_NVMHCI	= (1 << 1),  /* NVMHCI supported */
-	HOST_CAP2_APST		= (1 << 2),  /* Automatic partial to slumber */
-
 	/* registers for each SATA port */
 	PORT_LST_ADDR		= 0x00, /* command list DMA addr */
 	PORT_LST_ADDR_HI	= 0x04, /* command list DMA addr hi */
@@ -195,8 +145,7 @@
 				  PORT_IRQ_IF_ERR |
 				  PORT_IRQ_CONNECT |
 				  PORT_IRQ_PHYRDY |
-				  PORT_IRQ_UNK_FIS |
-				  PORT_IRQ_BAD_PMP,
+				  PORT_IRQ_UNK_FIS,
 	PORT_IRQ_ERROR		= PORT_IRQ_FREEZE |
 				  PORT_IRQ_TF_ERR |
 				  PORT_IRQ_HBUS_DATA_ERR,
@@ -205,10 +154,7 @@
 				  PORT_IRQ_PIOS_FIS | PORT_IRQ_D2H_REG_FIS,
 
 	/* PORT_CMD bits */
-	PORT_CMD_ASP		= (1 << 27), /* Aggressive Slumber/Partial */
-	PORT_CMD_ALPE		= (1 << 26), /* Aggressive Link PM enable */
 	PORT_CMD_ATAPI		= (1 << 24), /* Device is ATAPI */
-	PORT_CMD_PMP		= (1 << 17), /* PMP attached */
 	PORT_CMD_LIST_ON	= (1 << 15), /* cmd list DMA engine running */
 	PORT_CMD_FIS_ON		= (1 << 14), /* FIS DMA engine running */
 	PORT_CMD_FIS_RX		= (1 << 4), /* Enable FIS receive DMA engine */
@@ -222,77 +168,44 @@
 	PORT_CMD_ICC_PARTIAL	= (0x2 << 28), /* Put i/f in partial state */
 	PORT_CMD_ICC_SLUMBER	= (0x6 << 28), /* Put i/f in slumber state */
 
-	/* hpriv->flags bits */
-	AHCI_HFLAG_NO_NCQ		= (1 << 0),
-	AHCI_HFLAG_IGN_IRQ_IF_ERR	= (1 << 1), /* ignore IRQ_IF_ERR */
-	AHCI_HFLAG_IGN_SERR_INTERNAL	= (1 << 2), /* ignore SERR_INTERNAL */
-	AHCI_HFLAG_32BIT_ONLY		= (1 << 3), /* force 32bit */
-	AHCI_HFLAG_MV_PATA		= (1 << 4), /* PATA port */
-	AHCI_HFLAG_NO_MSI		= (1 << 5), /* no PCI MSI */
-	AHCI_HFLAG_NO_PMP		= (1 << 6), /* no PMP */
-	AHCI_HFLAG_NO_HOTPLUG		= (1 << 7), /* ignore PxSERR.DIAG.N */
-	AHCI_HFLAG_SECT255		= (1 << 8), /* max 255 sectors */
-	AHCI_HFLAG_YES_NCQ		= (1 << 9), /* force NCQ cap on */
-	AHCI_HFLAG_NO_SUSPEND		= (1 << 10), /* don't suspend */
-	AHCI_HFLAG_SRST_TOUT_IS_OFFLINE	= (1 << 11), /* treat SRST timeout as
-							link offline */
-	AHCI_HFLAG_NO_SNTF		= (1 << 12), /* no sntf */
-
 	/* ap->flags bits */
+	AHCI_FLAG_NO_NCQ		= (1 << 24),
+	AHCI_FLAG_IGN_IRQ_IF_ERR	= (1 << 25), /* ignore IRQ_IF_ERR */
+	AHCI_FLAG_HONOR_PI		= (1 << 26), /* honor PORTS_IMPL */
+	AHCI_FLAG_IGN_SERR_INTERNAL	= (1 << 27), /* ignore SERR_INTERNAL */
+	AHCI_FLAG_32BIT_ONLY		= (1 << 28), /* force 32bit */
+	AHCI_FLAG_MV_PATA		= (1 << 29), /* PATA port */
+	AHCI_FLAG_NO_MSI		= (1 << 30), /* no PCI MSI */
 
 	AHCI_FLAG_COMMON		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
 					  ATA_FLAG_MMIO | ATA_FLAG_PIO_DMA |
-					  ATA_FLAG_ACPI_SATA | ATA_FLAG_AN |
-					  ATA_FLAG_IPM,
-
-	ICH_MAP				= 0x90, /* ICH MAP register */
-
-	/* em constants */
-	EM_MAX_SLOTS			= 8,
-	EM_MAX_RETRY			= 5,
-
-	/* em_ctl bits */
-	EM_CTL_RST			= (1 << 9), /* Reset */
-	EM_CTL_TM			= (1 << 8), /* Transmit Message */
-	EM_CTL_ALHD			= (1 << 26), /* Activity LED */
+					  ATA_FLAG_SKIP_D2H_BSY |
+					  ATA_FLAG_ACPI_SATA,
 };
 
 struct ahci_cmd_hdr {
-	__le32			opts;
-	__le32			status;
-	__le32			tbl_addr;
-	__le32			tbl_addr_hi;
-	__le32			reserved[4];
+	u32			opts;
+	u32			status;
+	u32			tbl_addr;
+	u32			tbl_addr_hi;
+	u32			reserved[4];
 };
 
 struct ahci_sg {
-	__le32			addr;
-	__le32			addr_hi;
-	__le32			reserved;
-	__le32			flags_size;
-};
-
-struct ahci_em_priv {
-	enum sw_activity blink_policy;
-	struct timer_list timer;
-	unsigned long saved_activity;
-	unsigned long activity;
-	unsigned long led_state;
+	u32			addr;
+	u32			addr_hi;
+	u32			reserved;
+	u32			flags_size;
 };
 
 struct ahci_host_priv {
-	unsigned int		flags;		/* AHCI_HFLAG_* */
 	u32			cap;		/* cap to use */
-	u32			cap2;		/* cap2 to use */
 	u32			port_map;	/* port map to use */
 	u32			saved_cap;	/* saved initial cap */
-	u32			saved_cap2;	/* saved initial cap2 */
 	u32			saved_port_map;	/* saved initial port_map */
-	u32 			em_loc; /* enclosure management location */
 };
 
 struct ahci_port_priv {
-	struct ata_link		*active_link;
 	struct ahci_cmd_hdr	*cmd_slot;
 	dma_addr_t		cmd_slot_dma;
 	void			*cmd_tbl;
@@ -303,38 +216,26 @@
 	unsigned int		ncq_saw_d2h:1;
 	unsigned int		ncq_saw_dmas:1;
 	unsigned int		ncq_saw_sdb:1;
-	u32 			intr_mask;	/* interrupts to enable */
-	/* enclosure management info per PM slot */
-	struct ahci_em_priv	em_priv[EM_MAX_SLOTS];
 };
 
-static int ahci_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val);
-static int ahci_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val);
-static int ahci_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
+static int ahci_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val);
+static int ahci_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val);
+static int ahci_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
 static unsigned int ahci_qc_issue(struct ata_queued_cmd *qc);
-static bool ahci_qc_fill_rtf(struct ata_queued_cmd *qc);
+static void ahci_irq_clear(struct ata_port *ap);
 static int ahci_port_start(struct ata_port *ap);
 static void ahci_port_stop(struct ata_port *ap);
+static void ahci_tf_read(struct ata_port *ap, struct ata_taskfile *tf);
 static void ahci_qc_prep(struct ata_queued_cmd *qc);
+static u8 ahci_check_status(struct ata_port *ap);
 static void ahci_freeze(struct ata_port *ap);
 static void ahci_thaw(struct ata_port *ap);
-static void ahci_pmp_attach(struct ata_port *ap);
-static void ahci_pmp_detach(struct ata_port *ap);
-static int ahci_softreset(struct ata_link *link, unsigned int *class,
-			  unsigned long deadline);
-static int ahci_sb600_softreset(struct ata_link *link, unsigned int *class,
-			  unsigned long deadline);
-static int ahci_hardreset(struct ata_link *link, unsigned int *class,
-			  unsigned long deadline);
-static int ahci_vt8251_hardreset(struct ata_link *link, unsigned int *class,
-				 unsigned long deadline);
-static int ahci_p5wdh_hardreset(struct ata_link *link, unsigned int *class,
-				unsigned long deadline);
-static void ahci_postreset(struct ata_link *link, unsigned int *class);
 static void ahci_error_handler(struct ata_port *ap);
+static void ahci_vt8251_error_handler(struct ata_port *ap);
+static void ahci_p5wdh_error_handler(struct ata_port *ap);
 static void ahci_post_internal_cmd(struct ata_queued_cmd *qc);
 static int ahci_port_resume(struct ata_port *ap);
-static void ahci_dev_config(struct ata_device *dev);
+static unsigned int ahci_fill_sg(struct ata_queued_cmd *qc, void *cmd_tbl);
 static void ahci_fill_cmd_slot(struct ahci_port_priv *pp, unsigned int tag,
 			       u32 opts);
 #ifdef CONFIG_PM
@@ -342,187 +243,176 @@
 static int ahci_pci_device_suspend(struct pci_dev *pdev, pm_message_t mesg);
 static int ahci_pci_device_resume(struct pci_dev *pdev);
 #endif
-static ssize_t ahci_activity_show(struct ata_device *dev, char *buf);
-static ssize_t ahci_activity_store(struct ata_device *dev,
-				   enum sw_activity val);
-static void ahci_init_sw_activity(struct ata_link *link);
-
-static ssize_t ahci_show_host_caps(struct device *dev,
-				   struct device_attribute *attr, char *buf);
-static ssize_t ahci_show_host_cap2(struct device *dev,
-				   struct device_attribute *attr, char *buf);
-static ssize_t ahci_show_host_version(struct device *dev,
-				      struct device_attribute *attr, char *buf);
-static ssize_t ahci_show_port_cmd(struct device *dev,
-				  struct device_attribute *attr, char *buf);
-
-DEVICE_ATTR(ahci_host_caps, S_IRUGO, ahci_show_host_caps, NULL);
-DEVICE_ATTR(ahci_host_cap2, S_IRUGO, ahci_show_host_cap2, NULL);
-DEVICE_ATTR(ahci_host_version, S_IRUGO, ahci_show_host_version, NULL);
-DEVICE_ATTR(ahci_port_cmd, S_IRUGO, ahci_show_port_cmd, NULL);
-
-static struct device_attribute *ahci_shost_attrs[] = {
-	&dev_attr_link_power_management_policy,
-	&dev_attr_em_message_type,
-	&dev_attr_em_message,
-	&dev_attr_ahci_host_caps,
-	&dev_attr_ahci_host_cap2,
-	&dev_attr_ahci_host_version,
-	&dev_attr_ahci_port_cmd,
-	NULL
-};
-
-static struct device_attribute *ahci_sdev_attrs[] = {
-	&dev_attr_sw_activity,
-	&dev_attr_unload_heads,
-	NULL
-};
 
 static struct scsi_host_template ahci_sht = {
-	ATA_NCQ_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.change_queue_depth	= ata_scsi_change_queue_depth,
 	.can_queue		= AHCI_MAX_CMDS - 1,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= AHCI_MAX_SG,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= AHCI_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
 	.dma_boundary		= AHCI_DMA_BOUNDARY,
-	.shost_attrs		= ahci_shost_attrs,
-	.sdev_attrs		= ahci_sdev_attrs,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations ahci_ops = {
-	.inherits		= &sata_pmp_port_ops,
+static const struct ata_port_operations ahci_ops = {
+	.port_disable		= ata_port_disable,
+
+	.check_status		= ahci_check_status,
+	.check_altstatus	= ahci_check_status,
+	.dev_select		= ata_noop_dev_select,
+
+	.tf_read		= ahci_tf_read,
 
-	.qc_defer		= sata_pmp_qc_defer_cmd_switch,
 	.qc_prep		= ahci_qc_prep,
 	.qc_issue		= ahci_qc_issue,
-	.qc_fill_rtf		= ahci_qc_fill_rtf,
+
+	.irq_clear		= ahci_irq_clear,
+	.irq_on			= ata_dummy_irq_on,
+	.irq_ack		= ata_dummy_irq_ack,
+
+	.scr_read		= ahci_scr_read,
+	.scr_write		= ahci_scr_write,
 
 	.freeze			= ahci_freeze,
 	.thaw			= ahci_thaw,
-	.softreset		= ahci_softreset,
-	.hardreset		= ahci_hardreset,
-	.postreset		= ahci_postreset,
-	.pmp_softreset		= ahci_softreset,
+
 	.error_handler		= ahci_error_handler,
 	.post_internal_cmd	= ahci_post_internal_cmd,
-	.dev_config		= ahci_dev_config,
+
+#ifdef CONFIG_PM
+	.port_suspend		= ahci_port_suspend,
+	.port_resume		= ahci_port_resume,
+#endif
+
+	.port_start		= ahci_port_start,
+	.port_stop		= ahci_port_stop,
+};
+
+static const struct ata_port_operations ahci_vt8251_ops = {
+	.port_disable		= ata_port_disable,
+
+	.check_status		= ahci_check_status,
+	.check_altstatus	= ahci_check_status,
+	.dev_select		= ata_noop_dev_select,
+
+	.tf_read		= ahci_tf_read,
+
+	.qc_prep		= ahci_qc_prep,
+	.qc_issue		= ahci_qc_issue,
+
+	.irq_clear		= ahci_irq_clear,
+	.irq_on			= ata_dummy_irq_on,
+	.irq_ack		= ata_dummy_irq_ack,
 
 	.scr_read		= ahci_scr_read,
 	.scr_write		= ahci_scr_write,
-	.pmp_attach		= ahci_pmp_attach,
-	.pmp_detach		= ahci_pmp_detach,
 
-	.enable_pm		= ahci_enable_alpm,
-	.disable_pm		= ahci_disable_alpm,
-	.em_show		= ahci_led_show,
-	.em_store		= ahci_led_store,
-	.sw_activity_show	= ahci_activity_show,
-	.sw_activity_store	= ahci_activity_store,
+	.freeze			= ahci_freeze,
+	.thaw			= ahci_thaw,
+
+	.error_handler		= ahci_vt8251_error_handler,
+	.post_internal_cmd	= ahci_post_internal_cmd,
+
 #ifdef CONFIG_PM
 	.port_suspend		= ahci_port_suspend,
 	.port_resume		= ahci_port_resume,
 #endif
+
 	.port_start		= ahci_port_start,
 	.port_stop		= ahci_port_stop,
 };
 
-static struct ata_port_operations ahci_vt8251_ops = {
-	.inherits		= &ahci_ops,
-	.hardreset		= ahci_vt8251_hardreset,
-};
+static const struct ata_port_operations ahci_p5wdh_ops = {
+	.port_disable		= ata_port_disable,
 
-static struct ata_port_operations ahci_p5wdh_ops = {
-	.inherits		= &ahci_ops,
-	.hardreset		= ahci_p5wdh_hardreset,
-};
+	.check_status		= ahci_check_status,
+	.check_altstatus	= ahci_check_status,
+	.dev_select		= ata_noop_dev_select,
 
-static struct ata_port_operations ahci_sb600_ops = {
-	.inherits		= &ahci_ops,
-	.softreset		= ahci_sb600_softreset,
-	.pmp_softreset		= ahci_sb600_softreset,
-};
+	.tf_read		= ahci_tf_read,
+
+	.qc_prep		= ahci_qc_prep,
+	.qc_issue		= ahci_qc_issue,
+
+	.irq_clear		= ahci_irq_clear,
+	.irq_on			= ata_dummy_irq_on,
+	.irq_ack		= ata_dummy_irq_ack,
 
-#define AHCI_HFLAGS(flags)	.private_data	= (void *)(flags)
+	.scr_read		= ahci_scr_read,
+	.scr_write		= ahci_scr_write,
+
+	.freeze			= ahci_freeze,
+	.thaw			= ahci_thaw,
+
+	.error_handler		= ahci_p5wdh_error_handler,
+	.post_internal_cmd	= ahci_post_internal_cmd,
+
+#ifdef CONFIG_PM
+	.port_suspend		= ahci_port_suspend,
+	.port_resume		= ahci_port_resume,
+#endif
+
+	.port_start		= ahci_port_start,
+	.port_stop		= ahci_port_stop,
+};
 
 static const struct ata_port_info ahci_port_info[] = {
-	[board_ahci] =
+	/* board_ahci */
 	{
 		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
+		.pio_mask	= 0x1f, /* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &ahci_ops,
 	},
-	[board_ahci_vt8251] =
-	{
-		AHCI_HFLAGS	(AHCI_HFLAG_NO_NCQ | AHCI_HFLAG_NO_PMP),
-		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
-		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &ahci_vt8251_ops,
-	},
-	[board_ahci_ign_iferr] =
+	/* board_ahci_pi */
 	{
-		AHCI_HFLAGS	(AHCI_HFLAG_IGN_IRQ_IF_ERR),
-		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
+		.flags		= AHCI_FLAG_COMMON | AHCI_FLAG_HONOR_PI,
+		.pio_mask	= 0x1f, /* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &ahci_ops,
 	},
-	[board_ahci_sb600] =
+	/* board_ahci_vt8251 */
 	{
-		AHCI_HFLAGS	(AHCI_HFLAG_IGN_SERR_INTERNAL |
-				 AHCI_HFLAG_NO_MSI | AHCI_HFLAG_SECT255 |
-				 AHCI_HFLAG_32BIT_ONLY),
-		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
+		.flags		= AHCI_FLAG_COMMON | ATA_FLAG_HRST_TO_RESUME |
+				  AHCI_FLAG_NO_NCQ,
+		.pio_mask	= 0x1f, /* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &ahci_sb600_ops,
-	},
-	[board_ahci_mv] =
-	{
-		AHCI_HFLAGS	(AHCI_HFLAG_NO_NCQ | AHCI_HFLAG_NO_MSI |
-				 AHCI_HFLAG_MV_PATA | AHCI_HFLAG_NO_PMP),
-		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
-				  ATA_FLAG_MMIO | ATA_FLAG_PIO_DMA,
-		.pio_mask	= ATA_PIO4,
-		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &ahci_ops,
-	},
-	[board_ahci_sb700] =	/* for SB700 and SB800 */
-	{
-		AHCI_HFLAGS	(AHCI_HFLAG_IGN_SERR_INTERNAL),
-		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
-		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &ahci_sb600_ops,
-	},
-	[board_ahci_mcp65] =
-	{
-		AHCI_HFLAGS	(AHCI_HFLAG_YES_NCQ),
-		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
-		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &ahci_ops,
+		.port_ops	= &ahci_vt8251_ops,
 	},
-	[board_ahci_nopmp] =
+	/* board_ahci_ign_iferr */
 	{
-		AHCI_HFLAGS	(AHCI_HFLAG_NO_PMP),
-		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
+		.flags		= AHCI_FLAG_COMMON | AHCI_FLAG_IGN_IRQ_IF_ERR,
+		.pio_mask	= 0x1f, /* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &ahci_ops,
 	},
-	[board_ahci_yesncq] =
+	/* board_ahci_sb600 */
 	{
-		AHCI_HFLAGS	(AHCI_HFLAG_YES_NCQ),
-		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
+		.flags		= AHCI_FLAG_COMMON |
+				  AHCI_FLAG_IGN_SERR_INTERNAL |
+				  AHCI_FLAG_32BIT_ONLY,
+		.pio_mask	= 0x1f, /* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &ahci_ops,
 	},
-	[board_ahci_nosntf] =
+	/* board_ahci_mv */
 	{
-		AHCI_HFLAGS	(AHCI_HFLAG_NO_SNTF),
-		.flags		= AHCI_FLAG_COMMON,
-		.pio_mask	= ATA_PIO4,
+		.sht		= &ahci_sht,
+		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
+				  ATA_FLAG_MMIO | ATA_FLAG_PIO_DMA |
+				  ATA_FLAG_SKIP_D2H_BSY | AHCI_FLAG_HONOR_PI |
+				  AHCI_FLAG_NO_NCQ | AHCI_FLAG_NO_MSI |
+				  AHCI_FLAG_MV_PATA,
+		.pio_mask	= 0x1f, /* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &ahci_ops,
 	},
@@ -540,47 +430,23 @@
 	{ PCI_VDEVICE(INTEL, 0x2682), board_ahci }, /* ESB2 */
 	{ PCI_VDEVICE(INTEL, 0x2683), board_ahci }, /* ESB2 */
 	{ PCI_VDEVICE(INTEL, 0x27c6), board_ahci }, /* ICH7-M DH */
-	{ PCI_VDEVICE(INTEL, 0x2821), board_ahci }, /* ICH8 */
-	{ PCI_VDEVICE(INTEL, 0x2822), board_ahci_nosntf }, /* ICH8 */
-	{ PCI_VDEVICE(INTEL, 0x2824), board_ahci }, /* ICH8 */
-	{ PCI_VDEVICE(INTEL, 0x2829), board_ahci }, /* ICH8M */
-	{ PCI_VDEVICE(INTEL, 0x282a), board_ahci }, /* ICH8M */
-	{ PCI_VDEVICE(INTEL, 0x2922), board_ahci }, /* ICH9 */
-	{ PCI_VDEVICE(INTEL, 0x2923), board_ahci }, /* ICH9 */
-	{ PCI_VDEVICE(INTEL, 0x2924), board_ahci }, /* ICH9 */
-	{ PCI_VDEVICE(INTEL, 0x2925), board_ahci }, /* ICH9 */
-	{ PCI_VDEVICE(INTEL, 0x2927), board_ahci }, /* ICH9 */
-	{ PCI_VDEVICE(INTEL, 0x2929), board_ahci }, /* ICH9M */
-	{ PCI_VDEVICE(INTEL, 0x292a), board_ahci }, /* ICH9M */
-	{ PCI_VDEVICE(INTEL, 0x292b), board_ahci }, /* ICH9M */
-	{ PCI_VDEVICE(INTEL, 0x292c), board_ahci }, /* ICH9M */
-	{ PCI_VDEVICE(INTEL, 0x292f), board_ahci }, /* ICH9M */
-	{ PCI_VDEVICE(INTEL, 0x294d), board_ahci }, /* ICH9 */
-	{ PCI_VDEVICE(INTEL, 0x294e), board_ahci }, /* ICH9M */
-	{ PCI_VDEVICE(INTEL, 0x502a), board_ahci }, /* Tolapai */
-	{ PCI_VDEVICE(INTEL, 0x502b), board_ahci }, /* Tolapai */
-	{ PCI_VDEVICE(INTEL, 0x3a05), board_ahci }, /* ICH10 */
-	{ PCI_VDEVICE(INTEL, 0x3a22), board_ahci }, /* ICH10 */
-	{ PCI_VDEVICE(INTEL, 0x3a25), board_ahci }, /* ICH10 */
-	{ PCI_VDEVICE(INTEL, 0x3b22), board_ahci }, /* PCH AHCI */
-	{ PCI_VDEVICE(INTEL, 0x3b23), board_ahci }, /* PCH AHCI */
-	{ PCI_VDEVICE(INTEL, 0x3b24), board_ahci }, /* PCH RAID */
-	{ PCI_VDEVICE(INTEL, 0x3b25), board_ahci }, /* PCH RAID */
-	{ PCI_VDEVICE(INTEL, 0x3b29), board_ahci }, /* PCH AHCI */
-	{ PCI_VDEVICE(INTEL, 0x3b2b), board_ahci }, /* PCH RAID */
-	{ PCI_VDEVICE(INTEL, 0x3b2c), board_ahci }, /* PCH RAID */
-	{ PCI_VDEVICE(INTEL, 0x3b2f), board_ahci }, /* PCH AHCI */
-	{ PCI_VDEVICE(INTEL, 0x1c02), board_ahci }, /* CPT AHCI */
-	{ PCI_VDEVICE(INTEL, 0x1c03), board_ahci }, /* CPT AHCI */
-	{ PCI_VDEVICE(INTEL, 0x1c04), board_ahci }, /* CPT RAID */
-	{ PCI_VDEVICE(INTEL, 0x1c05), board_ahci }, /* CPT RAID */
-	{ PCI_VDEVICE(INTEL, 0x1c06), board_ahci }, /* CPT RAID */
-	{ PCI_VDEVICE(INTEL, 0x1c07), board_ahci }, /* CPT RAID */
-	{ PCI_VDEVICE(INTEL, 0x1d02), board_ahci }, /* PBG AHCI */
-	{ PCI_VDEVICE(INTEL, 0x1d04), board_ahci }, /* PBG RAID */
-	{ PCI_VDEVICE(INTEL, 0x1d06), board_ahci }, /* PBG RAID */
-	{ PCI_VDEVICE(INTEL, 0x2826), board_ahci }, /* PBG RAID */
-	{ PCI_VDEVICE(INTEL, 0x2323), board_ahci }, /* DH89xxCC AHCI */
+	{ PCI_VDEVICE(INTEL, 0x2821), board_ahci_pi }, /* ICH8 */
+	{ PCI_VDEVICE(INTEL, 0x2822), board_ahci_pi }, /* ICH8 */
+	{ PCI_VDEVICE(INTEL, 0x2824), board_ahci_pi }, /* ICH8 */
+	{ PCI_VDEVICE(INTEL, 0x2829), board_ahci_pi }, /* ICH8M */
+	{ PCI_VDEVICE(INTEL, 0x282a), board_ahci_pi }, /* ICH8M */
+	{ PCI_VDEVICE(INTEL, 0x2922), board_ahci_pi }, /* ICH9 */
+	{ PCI_VDEVICE(INTEL, 0x2923), board_ahci_pi }, /* ICH9 */
+	{ PCI_VDEVICE(INTEL, 0x2924), board_ahci_pi }, /* ICH9 */
+	{ PCI_VDEVICE(INTEL, 0x2925), board_ahci_pi }, /* ICH9 */
+	{ PCI_VDEVICE(INTEL, 0x2927), board_ahci_pi }, /* ICH9 */
+	{ PCI_VDEVICE(INTEL, 0x2929), board_ahci_pi }, /* ICH9M */
+	{ PCI_VDEVICE(INTEL, 0x292a), board_ahci_pi }, /* ICH9M */
+	{ PCI_VDEVICE(INTEL, 0x292b), board_ahci_pi }, /* ICH9M */
+	{ PCI_VDEVICE(INTEL, 0x292c), board_ahci_pi }, /* ICH9M */
+	{ PCI_VDEVICE(INTEL, 0x292f), board_ahci_pi }, /* ICH9M */
+	{ PCI_VDEVICE(INTEL, 0x294d), board_ahci_pi }, /* ICH9 */
+	{ PCI_VDEVICE(INTEL, 0x294e), board_ahci_pi }, /* ICH9M */
 
 	/* JMicron 360/1/3/5/6, match class to avoid IDE function */
 	{ PCI_VENDOR_ID_JMICRON, PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID,
@@ -588,57 +454,50 @@
 
 	/* ATI */
 	{ PCI_VDEVICE(ATI, 0x4380), board_ahci_sb600 }, /* ATI SB600 */
-	{ PCI_VDEVICE(ATI, 0x4390), board_ahci_sb700 }, /* ATI SB700/800 */
-	{ PCI_VDEVICE(ATI, 0x4391), board_ahci_sb700 }, /* ATI SB700/800 */
-	{ PCI_VDEVICE(ATI, 0x4392), board_ahci_sb700 }, /* ATI SB700/800 */
-	{ PCI_VDEVICE(ATI, 0x4393), board_ahci_sb700 }, /* ATI SB700/800 */
-	{ PCI_VDEVICE(ATI, 0x4394), board_ahci_sb700 }, /* ATI SB700/800 */
-	{ PCI_VDEVICE(ATI, 0x4395), board_ahci_sb700 }, /* ATI SB700/800 */
-
-	/* AMD */
-	{ PCI_VDEVICE(AMD, 0x7800), board_ahci }, /* AMD Hudson-2 */
-	/* AMD is using RAID class only for ahci controllers */
-	{ PCI_VENDOR_ID_AMD, PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID,
-	  PCI_CLASS_STORAGE_RAID << 8, 0xffffff, board_ahci },
+	{ PCI_VDEVICE(ATI, 0x4390), board_ahci_sb600 }, /* ATI SB700/800 */
+	{ PCI_VDEVICE(ATI, 0x4391), board_ahci_sb600 }, /* ATI SB700/800 */
+	{ PCI_VDEVICE(ATI, 0x4392), board_ahci_sb600 }, /* ATI SB700/800 */
+	{ PCI_VDEVICE(ATI, 0x4393), board_ahci_sb600 }, /* ATI SB700/800 */
+	{ PCI_VDEVICE(ATI, 0x4394), board_ahci_sb600 }, /* ATI SB700/800 */
+	{ PCI_VDEVICE(ATI, 0x4395), board_ahci_sb600 }, /* ATI SB700/800 */
 
 	/* VIA */
 	{ PCI_VDEVICE(VIA, 0x3349), board_ahci_vt8251 }, /* VIA VT8251 */
 	{ PCI_VDEVICE(VIA, 0x6287), board_ahci_vt8251 }, /* VIA VT8251 */
 
 	/* NVIDIA */
-	{ PCI_VDEVICE(NVIDIA, 0x044c), board_ahci_mcp65 },	/* MCP65 */
-	{ PCI_VDEVICE(NVIDIA, 0x044d), board_ahci_mcp65 },	/* MCP65 */
-	{ PCI_VDEVICE(NVIDIA, 0x044e), board_ahci_mcp65 },	/* MCP65 */
-	{ PCI_VDEVICE(NVIDIA, 0x044f), board_ahci_mcp65 },	/* MCP65 */
-	{ PCI_VDEVICE(NVIDIA, 0x045c), board_ahci_mcp65 },	/* MCP65 */
-	{ PCI_VDEVICE(NVIDIA, 0x045d), board_ahci_mcp65 },	/* MCP65 */
-	{ PCI_VDEVICE(NVIDIA, 0x045e), board_ahci_mcp65 },	/* MCP65 */
-	{ PCI_VDEVICE(NVIDIA, 0x045f), board_ahci_mcp65 },	/* MCP65 */
-	{ PCI_VDEVICE(NVIDIA, 0x0550), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0551), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0552), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0553), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0554), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0555), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0556), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0557), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0558), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0559), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x055a), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x055b), board_ahci_yesncq },	/* MCP67 */
-	{ PCI_VDEVICE(NVIDIA, 0x0580), board_ahci_yesncq },	/* Linux ID */
-	{ PCI_VDEVICE(NVIDIA, 0x07f0), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f1), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f2), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f3), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f4), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f5), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f6), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f7), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f8), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07f9), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07fa), board_ahci_yesncq },	/* MCP73 */
-	{ PCI_VDEVICE(NVIDIA, 0x07fb), board_ahci_yesncq },	/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x044c), board_ahci },		/* MCP65 */
+	{ PCI_VDEVICE(NVIDIA, 0x044d), board_ahci },		/* MCP65 */
+	{ PCI_VDEVICE(NVIDIA, 0x044e), board_ahci },		/* MCP65 */
+	{ PCI_VDEVICE(NVIDIA, 0x044f), board_ahci },		/* MCP65 */
+	{ PCI_VDEVICE(NVIDIA, 0x045c), board_ahci },		/* MCP65 */
+	{ PCI_VDEVICE(NVIDIA, 0x045d), board_ahci },		/* MCP65 */
+	{ PCI_VDEVICE(NVIDIA, 0x045e), board_ahci },		/* MCP65 */
+	{ PCI_VDEVICE(NVIDIA, 0x045f), board_ahci },		/* MCP65 */
+	{ PCI_VDEVICE(NVIDIA, 0x0550), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0551), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0552), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0553), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0554), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0555), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0556), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0557), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0558), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x0559), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x055a), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x055b), board_ahci },		/* MCP67 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f0), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f1), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f2), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f3), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f4), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f5), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f6), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f7), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f8), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07f9), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07fa), board_ahci },		/* MCP73 */
+	{ PCI_VDEVICE(NVIDIA, 0x07fb), board_ahci },		/* MCP73 */
 	{ PCI_VDEVICE(NVIDIA, 0x0ad0), board_ahci },		/* MCP77 */
 	{ PCI_VDEVICE(NVIDIA, 0x0ad1), board_ahci },		/* MCP77 */
 	{ PCI_VDEVICE(NVIDIA, 0x0ad2), board_ahci },		/* MCP77 */
@@ -651,42 +510,14 @@
 	{ PCI_VDEVICE(NVIDIA, 0x0ad9), board_ahci },		/* MCP77 */
 	{ PCI_VDEVICE(NVIDIA, 0x0ada), board_ahci },		/* MCP77 */
 	{ PCI_VDEVICE(NVIDIA, 0x0adb), board_ahci },		/* MCP77 */
-	{ PCI_VDEVICE(NVIDIA, 0x0ab4), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0ab5), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0ab6), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0ab7), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0ab8), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0ab9), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0aba), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0abb), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0abc), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0abd), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0abe), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0abf), board_ahci },		/* MCP79 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d84), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d85), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d86), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d87), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d88), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d89), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d8a), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d8b), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d8c), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d8d), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d8e), board_ahci },		/* MCP89 */
-	{ PCI_VDEVICE(NVIDIA, 0x0d8f), board_ahci },		/* MCP89 */
 
 	/* SiS */
-	{ PCI_VDEVICE(SI, 0x1184), board_ahci },		/* SiS 966 */
-	{ PCI_VDEVICE(SI, 0x1185), board_ahci },		/* SiS 968 */
-	{ PCI_VDEVICE(SI, 0x0186), board_ahci },		/* SiS 968 */
+	{ PCI_VDEVICE(SI, 0x1184), board_ahci }, /* SiS 966 */
+	{ PCI_VDEVICE(SI, 0x1185), board_ahci }, /* SiS 966 */
+	{ PCI_VDEVICE(SI, 0x0186), board_ahci }, /* SiS 968 */
 
 	/* Marvell */
 	{ PCI_VDEVICE(MARVELL, 0x6145), board_ahci_mv },	/* 6145 */
-	{ PCI_VDEVICE(MARVELL, 0x6121), board_ahci_mv },	/* 6121 */
-
-	/* Promise */
-	{ PCI_VDEVICE(PROMISE, 0x3f20), board_ahci },	/* PDC42819 */
 
 	/* Generic, PCI class code for AHCI */
 	{ PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID,
@@ -707,20 +538,6 @@
 #endif
 };
 
-static int ahci_em_messages = 1;
-module_param(ahci_em_messages, int, 0444);
-/* add other LED protocol types when they become supported */
-MODULE_PARM_DESC(ahci_em_messages,
-	"Set AHCI Enclosure Management Message type (0 = disabled, 1 = LED");
-
-#if defined(CONFIG_PATA_MARVELL) || defined(CONFIG_PATA_MARVELL_MODULE)
-static int marvell_enable;
-#else
-static int marvell_enable = 1;
-#endif
-module_param(marvell_enable, int, 0644);
-MODULE_PARM_DESC(marvell_enable, "Marvell SATA via AHCI (1 = enabled)");
-
 
 static inline int ahci_nr_ports(u32 cap)
 {
@@ -740,74 +557,10 @@
 	return __ahci_port_base(ap->host, ap->port_no);
 }
 
-static void ahci_enable_ahci(void __iomem *mmio)
-{
-	int i;
-	u32 tmp;
-
-	/* turn on AHCI_EN */
-	tmp = readl(mmio + HOST_CTL);
-	if (tmp & HOST_AHCI_EN)
-		return;
-
-	/* Some controllers need AHCI_EN to be written multiple times.
-	 * Try a few times before giving up.
-	 */
-	for (i = 0; i < 5; i++) {
-		tmp |= HOST_AHCI_EN;
-		writel(tmp, mmio + HOST_CTL);
-		tmp = readl(mmio + HOST_CTL);	/* flush && sanity check */
-		if (tmp & HOST_AHCI_EN)
-			return;
-		msleep(10);
-	}
-
-	WARN_ON(1);
-}
-
-static ssize_t ahci_show_host_caps(struct device *dev,
-				   struct device_attribute *attr, char *buf)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-	struct ahci_host_priv *hpriv = ap->host->private_data;
-
-	return sprintf(buf, "%x\n", hpriv->cap);
-}
-
-static ssize_t ahci_show_host_cap2(struct device *dev,
-				   struct device_attribute *attr, char *buf)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-	struct ahci_host_priv *hpriv = ap->host->private_data;
-
-	return sprintf(buf, "%x\n", hpriv->cap2);
-}
-
-static ssize_t ahci_show_host_version(struct device *dev,
-				   struct device_attribute *attr, char *buf)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-	void __iomem *mmio = ap->host->iomap[AHCI_PCI_BAR];
-
-	return sprintf(buf, "%x\n", readl(mmio + HOST_VERSION));
-}
-
-static ssize_t ahci_show_port_cmd(struct device *dev,
-				  struct device_attribute *attr, char *buf)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-	void __iomem *port_mmio = ahci_port_base(ap);
-
-	return sprintf(buf, "%x\n", readl(port_mmio + PORT_CMD));
-}
-
 /**
  *	ahci_save_initial_config - Save and fixup initial config values
  *	@pdev: target PCI device
+ *	@pi: associated ATA port info
  *	@hpriv: host private area to store config values
  *
  *	Some registers containing configuration info might be setup by
@@ -821,15 +574,12 @@
  *	None.
  */
 static void ahci_save_initial_config(struct pci_dev *pdev,
+				     const struct ata_port_info *pi,
 				     struct ahci_host_priv *hpriv)
 {
 	void __iomem *mmio = pcim_iomap_table(pdev)[AHCI_PCI_BAR];
-	u32 cap, cap2, vers, port_map;
+	u32 cap, port_map;
 	int i;
-	int mv;
-
-	/* make sure AHCI mode is enabled before accessing CAP */
-	ahci_enable_ahci(mmio);
 
 	/* Values prefixed with saved_ are written back to host after
 	 * reset.  Values without are used for driver operation.
@@ -837,51 +587,27 @@
 	hpriv->saved_cap = cap = readl(mmio + HOST_CAP);
 	hpriv->saved_port_map = port_map = readl(mmio + HOST_PORTS_IMPL);
 
-	/* CAP2 register is only defined for AHCI 1.2 and later */
-	vers = readl(mmio + HOST_VERSION);
-	if ((vers >> 16) > 1 ||
-	   ((vers >> 16) == 1 && (vers & 0xFFFF) >= 0x200))
-		hpriv->saved_cap2 = cap2 = readl(mmio + HOST_CAP2);
-	else
-		hpriv->saved_cap2 = cap2 = 0;
-
 	/* some chips have errata preventing 64bit use */
-	if ((cap & HOST_CAP_64) && (hpriv->flags & AHCI_HFLAG_32BIT_ONLY)) {
+	if ((cap & HOST_CAP_64) && (pi->flags & AHCI_FLAG_32BIT_ONLY)) {
 		dev_printk(KERN_INFO, &pdev->dev,
 			   "controller can't do 64bit DMA, forcing 32bit\n");
 		cap &= ~HOST_CAP_64;
 	}
 
-	if ((cap & HOST_CAP_NCQ) && (hpriv->flags & AHCI_HFLAG_NO_NCQ)) {
+	if ((cap & HOST_CAP_NCQ) && (pi->flags & AHCI_FLAG_NO_NCQ)) {
 		dev_printk(KERN_INFO, &pdev->dev,
 			   "controller can't do NCQ, turning off CAP_NCQ\n");
 		cap &= ~HOST_CAP_NCQ;
 	}
 
-	if (!(cap & HOST_CAP_NCQ) && (hpriv->flags & AHCI_HFLAG_YES_NCQ)) {
-		dev_printk(KERN_INFO, &pdev->dev,
-			   "controller can do NCQ, turning on CAP_NCQ\n");
-		cap |= HOST_CAP_NCQ;
-	}
-
-	if ((cap & HOST_CAP_PMP) && (hpriv->flags & AHCI_HFLAG_NO_PMP)) {
-		dev_printk(KERN_INFO, &pdev->dev,
-			   "controller can't do PMP, turning off CAP_PMP\n");
-		cap &= ~HOST_CAP_PMP;
-	}
-
-	if ((cap & HOST_CAP_SNTF) && (hpriv->flags & AHCI_HFLAG_NO_SNTF)) {
-		dev_printk(KERN_INFO, &pdev->dev,
-			   "controller can't do SNTF, turning off CAP_SNTF\n");
-		cap &= ~HOST_CAP_SNTF;
-	}
+	/* fixup zero port_map */
+	if (!port_map) {
+		port_map = (1 << ahci_nr_ports(cap)) - 1;
+		dev_printk(KERN_WARNING, &pdev->dev,
+			   "PORTS_IMPL is zero, forcing 0x%x\n", port_map);
 
-	if (pdev->vendor == PCI_VENDOR_ID_JMICRON && pdev->device == 0x2361 &&
-	    port_map != 1) {
-		dev_printk(KERN_INFO, &pdev->dev,
-			   "JMB361 has only one port, port_map 0x%x -> 0x%x\n",
-			   port_map, 1);
-		port_map = 1;
+		/* write the fixed up value to the PI register */
+		hpriv->saved_port_map = port_map;
 	}
 
 	/*
@@ -889,54 +615,42 @@
 	 * is asserted through the standard AHCI port
 	 * presence register, as bit 4 (counting from 0)
 	 */
-	if (hpriv->flags & AHCI_HFLAG_MV_PATA) {
-		if (pdev->device == 0x6121)
-			mv = 0x3;
-		else
-			mv = 0xf;
+	if (pi->flags & AHCI_FLAG_MV_PATA) {
 		dev_printk(KERN_ERR, &pdev->dev,
 			   "MV_AHCI HACK: port_map %x -> %x\n",
-			   port_map,
-			   port_map & mv);
-		dev_printk(KERN_ERR, &pdev->dev,
-			  "Disabling your PATA port. Use the boot option 'ahci.marvell_enable=0' to avoid this.\n");
+			   hpriv->port_map,
+			   hpriv->port_map & 0xf);
 
-		port_map &= mv;
+		port_map &= 0xf;
 	}
 
 	/* cross check port_map and cap.n_ports */
-	if (port_map) {
-		int map_ports = 0;
-
-		for (i = 0; i < AHCI_MAX_PORTS; i++)
-			if (port_map & (1 << i))
-				map_ports++;
+	if (pi->flags & AHCI_FLAG_HONOR_PI) {
+		u32 tmp_port_map = port_map;
+		int n_ports = ahci_nr_ports(cap);
+
+		for (i = 0; i < AHCI_MAX_PORTS && n_ports; i++) {
+			if (tmp_port_map & (1 << i)) {
+				n_ports--;
+				tmp_port_map &= ~(1 << i);
+			}
+		}
 
-		/* If PI has more ports than n_ports, whine, clear
-		 * port_map and let it be generated from n_ports.
+		/* Whine if inconsistent.  No need to update cap.
+		 * port_map is used to determine number of ports.
 		 */
-		if (map_ports > ahci_nr_ports(cap)) {
+		if (n_ports || tmp_port_map)
 			dev_printk(KERN_WARNING, &pdev->dev,
-				   "implemented port map (0x%x) contains more "
-				   "ports than nr_ports (%u), using nr_ports\n",
-				   port_map, ahci_nr_ports(cap));
-			port_map = 0;
-		}
-	}
-
-	/* fabricate port_map from cap.nr_ports */
-	if (!port_map) {
+				   "nr_ports (%u) and implemented port map "
+				   "(0x%x) don't match\n",
+				   ahci_nr_ports(cap), port_map);
+	} else {
+		/* fabricate port_map from cap.nr_ports */
 		port_map = (1 << ahci_nr_ports(cap)) - 1;
-		dev_printk(KERN_WARNING, &pdev->dev,
-			   "forcing PORTS_IMPL to 0x%x\n", port_map);
-
-		/* write the fixed up value to the PI register */
-		hpriv->saved_port_map = port_map;
 	}
 
 	/* record values to use during operation */
 	hpriv->cap = cap;
-	hpriv->cap2 = cap2;
 	hpriv->port_map = port_map;
 }
 
@@ -955,8 +669,6 @@
 	void __iomem *mmio = host->iomap[AHCI_PCI_BAR];
 
 	writel(hpriv->saved_cap, mmio + HOST_CAP);
-	if (hpriv->saved_cap2)
-		writel(hpriv->saved_cap2, mmio + HOST_CAP2);
 	writel(hpriv->saved_port_map, mmio + HOST_PORTS_IMPL);
 	(void) readl(mmio + HOST_PORTS_IMPL);	/* flush */
 }
@@ -978,10 +690,10 @@
 	return 0;
 }
 
-static int ahci_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)
+static int ahci_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
-	void __iomem *port_mmio = ahci_port_base(link->ap);
-	int offset = ahci_scr_offset(link->ap, sc_reg);
+	void __iomem *port_mmio = ahci_port_base(ap);
+	int offset = ahci_scr_offset(ap, sc_reg);
 
 	if (offset) {
 		*val = readl(port_mmio + offset);
@@ -990,10 +702,10 @@
 	return -EINVAL;
 }
 
-static int ahci_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)
+static int ahci_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
-	void __iomem *port_mmio = ahci_port_base(link->ap);
-	int offset = ahci_scr_offset(link->ap, sc_reg);
+	void __iomem *port_mmio = ahci_port_base(ap);
+	int offset = ahci_scr_offset(ap, sc_reg);
 
 	if (offset) {
 		writel(val, port_mmio + offset);
@@ -1031,7 +743,7 @@
 
 	/* wait for engine to stop. This could be as long as 500 msec */
 	tmp = ata_wait_register(port_mmio + PORT_CMD,
-				PORT_CMD_LIST_ON, PORT_CMD_LIST_ON, 1, 500);
+			        PORT_CMD_LIST_ON, PORT_CMD_LIST_ON, 1, 500);
 	if (tmp & PORT_CMD_LIST_ON)
 		return -EIO;
 
@@ -1102,130 +814,6 @@
 	writel(cmd | PORT_CMD_ICC_ACTIVE, port_mmio + PORT_CMD);
 }
 
-static void ahci_disable_alpm(struct ata_port *ap)
-{
-	struct ahci_host_priv *hpriv = ap->host->private_data;
-	void __iomem *port_mmio = ahci_port_base(ap);
-	u32 cmd;
-	struct ahci_port_priv *pp = ap->private_data;
-
-	/* IPM bits should be disabled by libata-core */
-	/* get the existing command bits */
-	cmd = readl(port_mmio + PORT_CMD);
-
-	/* disable ALPM and ASP */
-	cmd &= ~PORT_CMD_ASP;
-	cmd &= ~PORT_CMD_ALPE;
-
-	/* force the interface back to active */
-	cmd |= PORT_CMD_ICC_ACTIVE;
-
-	/* write out new cmd value */
-	writel(cmd, port_mmio + PORT_CMD);
-	cmd = readl(port_mmio + PORT_CMD);
-
-	/* wait 10ms to be sure we've come out of any low power state */
-	msleep(10);
-
-	/* clear out any PhyRdy stuff from interrupt status */
-	writel(PORT_IRQ_PHYRDY, port_mmio + PORT_IRQ_STAT);
-
-	/* go ahead and clean out PhyRdy Change from Serror too */
-	ahci_scr_write(&ap->link, SCR_ERROR, ((1 << 16) | (1 << 18)));
-
-	/*
- 	 * Clear flag to indicate that we should ignore all PhyRdy
- 	 * state changes
- 	 */
-	hpriv->flags &= ~AHCI_HFLAG_NO_HOTPLUG;
-
-	/*
- 	 * Enable interrupts on Phy Ready.
- 	 */
-	pp->intr_mask |= PORT_IRQ_PHYRDY;
-	writel(pp->intr_mask, port_mmio + PORT_IRQ_MASK);
-
-	/*
- 	 * don't change the link pm policy - we can be called
- 	 * just to turn of link pm temporarily
- 	 */
-}
-
-static int ahci_enable_alpm(struct ata_port *ap,
-	enum link_pm policy)
-{
-	struct ahci_host_priv *hpriv = ap->host->private_data;
-	void __iomem *port_mmio = ahci_port_base(ap);
-	u32 cmd;
-	struct ahci_port_priv *pp = ap->private_data;
-	u32 asp;
-
-	/* Make sure the host is capable of link power management */
-	if (!(hpriv->cap & HOST_CAP_ALPM))
-		return -EINVAL;
-
-	switch (policy) {
-	case MAX_PERFORMANCE:
-	case NOT_AVAILABLE:
-		/*
- 		 * if we came here with NOT_AVAILABLE,
- 		 * it just means this is the first time we
- 		 * have tried to enable - default to max performance,
- 		 * and let the user go to lower power modes on request.
- 		 */
-		ahci_disable_alpm(ap);
-		return 0;
-	case MIN_POWER:
-		/* configure HBA to enter SLUMBER */
-		asp = PORT_CMD_ASP;
-		break;
-	case MEDIUM_POWER:
-		/* configure HBA to enter PARTIAL */
-		asp = 0;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	/*
- 	 * Disable interrupts on Phy Ready. This keeps us from
- 	 * getting woken up due to spurious phy ready interrupts
-	 * TBD - Hot plug should be done via polling now, is
-	 * that even supported?
- 	 */
-	pp->intr_mask &= ~PORT_IRQ_PHYRDY;
-	writel(pp->intr_mask, port_mmio + PORT_IRQ_MASK);
-
-	/*
- 	 * Set a flag to indicate that we should ignore all PhyRdy
- 	 * state changes since these can happen now whenever we
- 	 * change link state
- 	 */
-	hpriv->flags |= AHCI_HFLAG_NO_HOTPLUG;
-
-	/* get the existing command bits */
-	cmd = readl(port_mmio + PORT_CMD);
-
-	/*
- 	 * Set ASP based on Policy
- 	 */
-	cmd |= asp;
-
-	/*
- 	 * Setting this bit will instruct the HBA to aggressively
- 	 * enter a lower power link state when it's appropriate and
- 	 * based on the value set above for ASP
- 	 */
-	cmd |= PORT_CMD_ALPE;
-
-	/* write out new cmd value */
-	writel(cmd, port_mmio + PORT_CMD);
-	cmd = readl(port_mmio + PORT_CMD);
-
-	/* IPM bits should be set by libata-core */
-	return 0;
-}
-
 #ifdef CONFIG_PM
 static void ahci_power_down(struct ata_port *ap)
 {
@@ -1250,40 +838,11 @@
 
 static void ahci_start_port(struct ata_port *ap)
 {
-	struct ahci_port_priv *pp = ap->private_data;
-	struct ata_link *link;
-	struct ahci_em_priv *emp;
-	ssize_t rc;
-	int i;
-
 	/* enable FIS reception */
 	ahci_start_fis_rx(ap);
 
 	/* enable DMA */
 	ahci_start_engine(ap);
-
-	/* turn on LEDs */
-	if (ap->flags & ATA_FLAG_EM) {
-		ata_for_each_link(link, ap, EDGE) {
-			emp = &pp->em_priv[link->pmp];
-
-			/* EM Transmit bit maybe busy during init */
-			for (i = 0; i < EM_MAX_RETRY; i++) {
-				rc = ahci_transmit_led_message(ap,
-							       emp->led_state,
-							       4);
-				if (rc == -EBUSY)
-					msleep(1);
-				else
-					break;
-			}
-		}
-	}
-
-	if (ap->flags & ATA_FLAG_SW_ACTIVITY)
-		ata_for_each_link(link, ap, EDGE)
-			ahci_init_sw_activity(link);
-
 }
 
 static int ahci_deinit_port(struct ata_port *ap, const char **emsg)
@@ -1310,290 +869,47 @@
 static int ahci_reset_controller(struct ata_host *host)
 {
 	struct pci_dev *pdev = to_pci_dev(host->dev);
-	struct ahci_host_priv *hpriv = host->private_data;
 	void __iomem *mmio = host->iomap[AHCI_PCI_BAR];
 	u32 tmp;
 
-	/* we must be in AHCI mode, before using anything
-	 * AHCI-specific, such as HOST_RESET.
-	 */
-	ahci_enable_ahci(mmio);
-
 	/* global controller reset */
-	if (!ahci_skip_host_reset) {
-		tmp = readl(mmio + HOST_CTL);
-		if ((tmp & HOST_RESET) == 0) {
-			writel(tmp | HOST_RESET, mmio + HOST_CTL);
-			readl(mmio + HOST_CTL); /* flush */
-		}
+	tmp = readl(mmio + HOST_CTL);
+	if ((tmp & HOST_RESET) == 0) {
+		writel(tmp | HOST_RESET, mmio + HOST_CTL);
+		readl(mmio + HOST_CTL); /* flush */
+	}
 
-		/*
-		 * to perform host reset, OS should set HOST_RESET
-		 * and poll until this bit is read to be "0".
-		 * reset must complete within 1 second, or
-		 * the hardware should be considered fried.
-		 */
-		tmp = ata_wait_register(mmio + HOST_CTL, HOST_RESET,
-					HOST_RESET, 10, 1000);
+	/* reset must complete within 1 second, or
+	 * the hardware should be considered fried.
+	 */
+	ssleep(1);
 
-		if (tmp & HOST_RESET) {
-			dev_printk(KERN_ERR, host->dev,
-				   "controller reset failed (0x%x)\n", tmp);
-			return -EIO;
-		}
+	tmp = readl(mmio + HOST_CTL);
+	if (tmp & HOST_RESET) {
+		dev_printk(KERN_ERR, host->dev,
+			   "controller reset failed (0x%x)\n", tmp);
+		return -EIO;
+	}
 
-		/* turn on AHCI mode */
-		ahci_enable_ahci(mmio);
+	/* turn on AHCI mode */
+	writel(HOST_AHCI_EN, mmio + HOST_CTL);
+	(void) readl(mmio + HOST_CTL);	/* flush */
 
-		/* Some registers might be cleared on reset.  Restore
-		 * initial values.
-		 */
-		ahci_restore_initial_config(host);
-	} else
-		dev_printk(KERN_INFO, host->dev,
-			   "skipping global host reset\n");
+	/* some registers might be cleared on reset.  restore initial values */
+	ahci_restore_initial_config(host);
 
 	if (pdev->vendor == PCI_VENDOR_ID_INTEL) {
 		u16 tmp16;
 
 		/* configure PCS */
 		pci_read_config_word(pdev, 0x92, &tmp16);
-		if ((tmp16 & hpriv->port_map) != hpriv->port_map) {
-			tmp16 |= hpriv->port_map;
-			pci_write_config_word(pdev, 0x92, tmp16);
-		}
-	}
-
-	return 0;
-}
-
-static void ahci_sw_activity(struct ata_link *link)
-{
-	struct ata_port *ap = link->ap;
-	struct ahci_port_priv *pp = ap->private_data;
-	struct ahci_em_priv *emp = &pp->em_priv[link->pmp];
-
-	if (!(link->flags & ATA_LFLAG_SW_ACTIVITY))
-		return;
-
-	emp->activity++;
-	if (!timer_pending(&emp->timer))
-		mod_timer(&emp->timer, jiffies + msecs_to_jiffies(10));
-}
-
-static void ahci_sw_activity_blink(unsigned long arg)
-{
-	struct ata_link *link = (struct ata_link *)arg;
-	struct ata_port *ap = link->ap;
-	struct ahci_port_priv *pp = ap->private_data;
-	struct ahci_em_priv *emp = &pp->em_priv[link->pmp];
-	unsigned long led_message = emp->led_state;
-	u32 activity_led_state;
-	unsigned long flags;
-
-	led_message &= EM_MSG_LED_VALUE;
-	led_message |= ap->port_no | (link->pmp << 8);
-
-	/* check to see if we've had activity.  If so,
-	 * toggle state of LED and reset timer.  If not,
-	 * turn LED to desired idle state.
-	 */
-	spin_lock_irqsave(ap->lock, flags);
-	if (emp->saved_activity != emp->activity) {
-		emp->saved_activity = emp->activity;
-		/* get the current LED state */
-		activity_led_state = led_message & EM_MSG_LED_VALUE_ON;
-
-		if (activity_led_state)
-			activity_led_state = 0;
-		else
-			activity_led_state = 1;
-
-		/* clear old state */
-		led_message &= ~EM_MSG_LED_VALUE_ACTIVITY;
-
-		/* toggle state */
-		led_message |= (activity_led_state << 16);
-		mod_timer(&emp->timer, jiffies + msecs_to_jiffies(100));
-	} else {
-		/* switch to idle */
-		led_message &= ~EM_MSG_LED_VALUE_ACTIVITY;
-		if (emp->blink_policy == BLINK_OFF)
-			led_message |= (1 << 16);
+		tmp16 |= 0xf;
+		pci_write_config_word(pdev, 0x92, tmp16);
 	}
-	spin_unlock_irqrestore(ap->lock, flags);
-	ahci_transmit_led_message(ap, led_message, 4);
-}
-
-static void ahci_init_sw_activity(struct ata_link *link)
-{
-	struct ata_port *ap = link->ap;
-	struct ahci_port_priv *pp = ap->private_data;
-	struct ahci_em_priv *emp = &pp->em_priv[link->pmp];
-
-	/* init activity stats, setup timer */
-	emp->saved_activity = emp->activity = 0;
-	setup_timer(&emp->timer, ahci_sw_activity_blink, (unsigned long)link);
-
-	/* check our blink policy and set flag for link if it's enabled */
-	if (emp->blink_policy)
-		link->flags |= ATA_LFLAG_SW_ACTIVITY;
-}
-
-static int ahci_reset_em(struct ata_host *host)
-{
-	void __iomem *mmio = host->iomap[AHCI_PCI_BAR];
-	u32 em_ctl;
-
-	em_ctl = readl(mmio + HOST_EM_CTL);
-	if ((em_ctl & EM_CTL_TM) || (em_ctl & EM_CTL_RST))
-		return -EINVAL;
 
-	writel(em_ctl | EM_CTL_RST, mmio + HOST_EM_CTL);
 	return 0;
 }
 
-static ssize_t ahci_transmit_led_message(struct ata_port *ap, u32 state,
-					ssize_t size)
-{
-	struct ahci_host_priv *hpriv = ap->host->private_data;
-	struct ahci_port_priv *pp = ap->private_data;
-	void __iomem *mmio = ap->host->iomap[AHCI_PCI_BAR];
-	u32 em_ctl;
-	u32 message[] = {0, 0};
-	unsigned long flags;
-	int pmp;
-	struct ahci_em_priv *emp;
-
-	/* get the slot number from the message */
-	pmp = (state & EM_MSG_LED_PMP_SLOT) >> 8;
-	if (pmp < EM_MAX_SLOTS)
-		emp = &pp->em_priv[pmp];
-	else
-		return -EINVAL;
-
-	spin_lock_irqsave(ap->lock, flags);
-
-	/*
-	 * if we are still busy transmitting a previous message,
-	 * do not allow
-	 */
-	em_ctl = readl(mmio + HOST_EM_CTL);
-	if (em_ctl & EM_CTL_TM) {
-		spin_unlock_irqrestore(ap->lock, flags);
-		return -EBUSY;
-	}
-
-	/*
-	 * create message header - this is all zero except for
-	 * the message size, which is 4 bytes.
-	 */
-	message[0] |= (4 << 8);
-
-	/* ignore 0:4 of byte zero, fill in port info yourself */
-	message[1] = ((state & ~EM_MSG_LED_HBA_PORT) | ap->port_no);
-
-	/* write message to EM_LOC */
-	writel(message[0], mmio + hpriv->em_loc);
-	writel(message[1], mmio + hpriv->em_loc+4);
-
-	/* save off new led state for port/slot */
-	emp->led_state = state;
-
-	/*
-	 * tell hardware to transmit the message
-	 */
-	writel(em_ctl | EM_CTL_TM, mmio + HOST_EM_CTL);
-
-	spin_unlock_irqrestore(ap->lock, flags);
-	return size;
-}
-
-static ssize_t ahci_led_show(struct ata_port *ap, char *buf)
-{
-	struct ahci_port_priv *pp = ap->private_data;
-	struct ata_link *link;
-	struct ahci_em_priv *emp;
-	int rc = 0;
-
-	ata_for_each_link(link, ap, EDGE) {
-		emp = &pp->em_priv[link->pmp];
-		rc += sprintf(buf, "%lx\n", emp->led_state);
-	}
-	return rc;
-}
-
-static ssize_t ahci_led_store(struct ata_port *ap, const char *buf,
-				size_t size)
-{
-	int state;
-	int pmp;
-	struct ahci_port_priv *pp = ap->private_data;
-	struct ahci_em_priv *emp;
-
-	state = simple_strtoul(buf, NULL, 0);
-
-	/* get the slot number from the message */
-	pmp = (state & EM_MSG_LED_PMP_SLOT) >> 8;
-	if (pmp < EM_MAX_SLOTS)
-		emp = &pp->em_priv[pmp];
-	else
-		return -EINVAL;
-
-	/* mask off the activity bits if we are in sw_activity
-	 * mode, user should turn off sw_activity before setting
-	 * activity led through em_message
-	 */
-	if (emp->blink_policy)
-		state &= ~EM_MSG_LED_VALUE_ACTIVITY;
-
-	return ahci_transmit_led_message(ap, state, size);
-}
-
-static ssize_t ahci_activity_store(struct ata_device *dev, enum sw_activity val)
-{
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
-	struct ahci_port_priv *pp = ap->private_data;
-	struct ahci_em_priv *emp = &pp->em_priv[link->pmp];
-	u32 port_led_state = emp->led_state;
-
-	/* save the desired Activity LED behavior */
-	if (val == OFF) {
-		/* clear LFLAG */
-		link->flags &= ~(ATA_LFLAG_SW_ACTIVITY);
-
-		/* set the LED to OFF */
-		port_led_state &= EM_MSG_LED_VALUE_OFF;
-		port_led_state |= (ap->port_no | (link->pmp << 8));
-		ahci_transmit_led_message(ap, port_led_state, 4);
-	} else {
-		link->flags |= ATA_LFLAG_SW_ACTIVITY;
-		if (val == BLINK_OFF) {
-			/* set LED to ON for idle */
-			port_led_state &= EM_MSG_LED_VALUE_OFF;
-			port_led_state |= (ap->port_no | (link->pmp << 8));
-			port_led_state |= EM_MSG_LED_VALUE_ON; /* check this */
-			ahci_transmit_led_message(ap, port_led_state, 4);
-		}
-	}
-	emp->blink_policy = val;
-	return 0;
-}
-
-static ssize_t ahci_activity_show(struct ata_device *dev, char *buf)
-{
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
-	struct ahci_port_priv *pp = ap->private_data;
-	struct ahci_em_priv *emp = &pp->em_priv[link->pmp];
-
-	/* display the saved value of activity behavior for this
-	 * disk.
-	 */
-	return sprintf(buf, "%d\n", emp->blink_policy);
-}
-
 static void ahci_port_init(struct pci_dev *pdev, struct ata_port *ap,
 			   int port_no, void __iomem *mmio,
 			   void __iomem *port_mmio)
@@ -1624,20 +940,14 @@
 
 static void ahci_init_controller(struct ata_host *host)
 {
-	struct ahci_host_priv *hpriv = host->private_data;
 	struct pci_dev *pdev = to_pci_dev(host->dev);
 	void __iomem *mmio = host->iomap[AHCI_PCI_BAR];
 	int i;
 	void __iomem *port_mmio;
 	u32 tmp;
-	int mv;
 
-	if (hpriv->flags & AHCI_HFLAG_MV_PATA) {
-		if (pdev->device == 0x6121)
-			mv = 2;
-		else
-			mv = 4;
-		port_mmio = __ahci_port_base(host, mv);
+	if (host->ports[0]->flags & AHCI_FLAG_MV_PATA) {
+		port_mmio = __ahci_port_base(host, 4);
 
 		writel(0, port_mmio + PORT_IRQ_MASK);
 
@@ -1665,17 +975,6 @@
 	VPRINTK("HOST_CTL 0x%x\n", tmp);
 }
 
-static void ahci_dev_config(struct ata_device *dev)
-{
-	struct ahci_host_priv *hpriv = dev->link->ap->host->private_data;
-
-	if (hpriv->flags & AHCI_HFLAG_SECT255) {
-		dev->max_sectors = 255;
-		ata_dev_printk(dev, KERN_INFO,
-			       "SB600 AHCI: limiting to 255 sectors per cmd\n");
-	}
-}
-
 static unsigned int ahci_dev_classify(struct ata_port *ap)
 {
 	void __iomem *port_mmio = ahci_port_base(ap);
@@ -1704,24 +1003,25 @@
 	pp->cmd_slot[tag].tbl_addr_hi = cpu_to_le32((cmd_tbl_dma >> 16) >> 16);
 }
 
-static int ahci_kick_engine(struct ata_port *ap)
+static int ahci_kick_engine(struct ata_port *ap, int force_restart)
 {
-	void __iomem *port_mmio = ahci_port_base(ap);
+	void __iomem *port_mmio = ap->ioaddr.cmd_addr;
 	struct ahci_host_priv *hpriv = ap->host->private_data;
-	u8 status = readl(port_mmio + PORT_TFDATA) & 0xFF;
 	u32 tmp;
 	int busy, rc;
 
+	/* do we need to kick the port? */
+	busy = ahci_check_status(ap) & (ATA_BUSY | ATA_DRQ);
+	if (!busy && !force_restart)
+		return 0;
+
 	/* stop engine */
 	rc = ahci_stop_engine(ap);
 	if (rc)
 		goto out_restart;
 
-	/* need to do CLO?
-	 * always do CLO if PMP is attached (AHCI-1.3 9.2)
-	 */
-	busy = status & (ATA_BUSY | ATA_DRQ);
-	if (!busy && !sata_pmp_attached(ap)) {
+	/* need to do CLO? */
+	if (!busy) {
 		rc = 0;
 		goto out_restart;
 	}
@@ -1769,7 +1069,7 @@
 		tmp = ata_wait_register(port_mmio + PORT_CMD_ISSUE, 0x1, 0x1,
 					1, timeout_msec);
 		if (tmp & 0x1) {
-			ahci_kick_engine(ap);
+			ahci_kick_engine(ap, 1);
 			return -EBUSY;
 		}
 	} else
@@ -1778,12 +1078,9 @@
 	return 0;
 }
 
-static int ahci_do_softreset(struct ata_link *link, unsigned int *class,
-			     int pmp, unsigned long deadline,
-			     int (*check_ready)(struct ata_link *link))
+static int ahci_do_softreset(struct ata_port *ap, unsigned int *class,
+			     int pmp, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
-	struct ahci_host_priv *hpriv = ap->host->private_data;
 	const char *reason = NULL;
 	unsigned long now, msecs;
 	struct ata_taskfile tf;
@@ -1791,13 +1088,19 @@
 
 	DPRINTK("ENTER\n");
 
+	if (ata_port_offline(ap)) {
+		DPRINTK("PHY reports no device\n");
+		*class = ATA_DEV_NONE;
+		return 0;
+	}
+
 	/* prepare for SRST (AHCI-1.1 10.4.1) */
-	rc = ahci_kick_engine(ap);
-	if (rc && rc != -EOPNOTSUPP)
-		ata_link_printk(link, KERN_WARNING,
-				"failed to reset engine (errno=%d)\n", rc);
+	rc = ahci_kick_engine(ap, 1);
+	if (rc)
+		ata_port_printk(ap, KERN_WARNING,
+				"failed to reset engine (errno=%d)", rc);
 
-	ata_tf_init(link->device, &tf);
+	ata_tf_init(ap->device, &tf);
 
 	/* issue the first D2H Register FIS */
 	msecs = 0;
@@ -1813,115 +1116,51 @@
 		goto fail;
 	}
 
-	/* spec says at least 5us, but be generous and sleep for 1ms */
-	msleep(1);
-
-	/* issue the second D2H Register FIS */
-	tf.ctl &= ~ATA_SRST;
-	ahci_exec_polled_cmd(ap, pmp, &tf, 0, 0, 0);
-
-	/* wait for link to become ready */
-	rc = ata_wait_after_reset(link, deadline, check_ready);
-	if (rc == -EBUSY && hpriv->flags & AHCI_HFLAG_SRST_TOUT_IS_OFFLINE) {
-		/*
-		 * Workaround for cases where link online status can't
-		 * be trusted.  Treat device readiness timeout as link
-		 * offline.
-		 */
-		ata_link_printk(link, KERN_INFO,
-				"device not ready, treating as offline\n");
-		*class = ATA_DEV_NONE;
-	} else if (rc) {
-		/* link occupied, -ENODEV too is an error */
-		reason = "device not ready";
-		goto fail;
-	} else
-		*class = ahci_dev_classify(ap);
-
-	DPRINTK("EXIT, class=%u\n", *class);
-	return 0;
-
- fail:
-	ata_link_printk(link, KERN_ERR, "softreset failed (%s)\n", reason);
-	return rc;
-}
-
-static int ahci_check_ready(struct ata_link *link)
-{
-	void __iomem *port_mmio = ahci_port_base(link->ap);
-	u8 status = readl(port_mmio + PORT_TFDATA) & 0xFF;
-
-	return ata_check_ready(status);
-}
-
-static int ahci_softreset(struct ata_link *link, unsigned int *class,
-			  unsigned long deadline)
-{
-	int pmp = sata_srst_pmp(link);
-
-	DPRINTK("ENTER\n");
-
-	return ahci_do_softreset(link, class, pmp, deadline, ahci_check_ready);
-}
-
-static int ahci_sb600_check_ready(struct ata_link *link)
-{
-	void __iomem *port_mmio = ahci_port_base(link->ap);
-	u8 status = readl(port_mmio + PORT_TFDATA) & 0xFF;
-	u32 irq_status = readl(port_mmio + PORT_IRQ_STAT);
-
-	/*
-	 * There is no need to check TFDATA if BAD PMP is found due to HW bug,
-	 * which can save timeout delay.
-	 */
-	if (irq_status & PORT_IRQ_BAD_PMP)
-		return -EIO;
-
-	return ata_check_ready(status);
-}
-
-static int ahci_sb600_softreset(struct ata_link *link, unsigned int *class,
-				unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	void __iomem *port_mmio = ahci_port_base(ap);
-	int pmp = sata_srst_pmp(link);
-	int rc;
-	u32 irq_sts;
-
-	DPRINTK("ENTER\n");
+	/* spec says at least 5us, but be generous and sleep for 1ms */
+	msleep(1);
 
-	rc = ahci_do_softreset(link, class, pmp, deadline,
-			       ahci_sb600_check_ready);
+	/* issue the second D2H Register FIS */
+	tf.ctl &= ~ATA_SRST;
+	ahci_exec_polled_cmd(ap, pmp, &tf, 0, 0, 0);
 
-	/*
-	 * Soft reset fails on some ATI chips with IPMS set when PMP
-	 * is enabled but SATA HDD/ODD is connected to SATA port,
-	 * do soft reset again to port 0.
+	/* spec mandates ">= 2ms" before checking status.
+	 * We wait 150ms, because that was the magic delay used for
+	 * ATAPI devices in Hale Landis's ATADRVR, for the period of time
+	 * between when the ATA command register is written, and then
+	 * status is checked.  Because waiting for "a while" before
+	 * checking status is fine, post SRST, we perform this magic
+	 * delay here as well.
 	 */
-	if (rc == -EIO) {
-		irq_sts = readl(port_mmio + PORT_IRQ_STAT);
-		if (irq_sts & PORT_IRQ_BAD_PMP) {
-			ata_link_printk(link, KERN_WARNING,
-					"applying SB600 PMP SRST workaround "
-					"and retrying\n");
-			rc = ahci_do_softreset(link, class, 0, deadline,
-					       ahci_check_ready);
-		}
+	msleep(150);
+
+	rc = ata_wait_ready(ap, deadline);
+	/* link occupied, -ENODEV too is an error */
+	if (rc) {
+		reason = "device not ready";
+		goto fail;
 	}
+	*class = ahci_dev_classify(ap);
+
+	DPRINTK("EXIT, class=%u\n", *class);
+	return 0;
 
+ fail:
+	ata_port_printk(ap, KERN_ERR, "softreset failed (%s)\n", reason);
 	return rc;
 }
 
-static int ahci_hardreset(struct ata_link *link, unsigned int *class,
+static int ahci_softreset(struct ata_port *ap, unsigned int *class,
+			  unsigned long deadline)
+{
+	return ahci_do_softreset(ap, class, 0, deadline);
+}
+
+static int ahci_hardreset(struct ata_port *ap, unsigned int *class,
 			  unsigned long deadline)
 {
-	const unsigned long *timing = sata_ehc_deb_timing(&link->eh_context);
-	struct ata_port *ap = link->ap;
 	struct ahci_port_priv *pp = ap->private_data;
 	u8 *d2h_fis = pp->rx_fis + RX_FIS_D2H_REG;
 	struct ata_taskfile tf;
-	bool online;
 	int rc;
 
 	DPRINTK("ENTER\n");
@@ -1929,35 +1168,39 @@
 	ahci_stop_engine(ap);
 
 	/* clear D2H reception area to properly wait for D2H FIS */
-	ata_tf_init(link->device, &tf);
+	ata_tf_init(ap->device, &tf);
 	tf.command = 0x80;
 	ata_tf_to_fis(&tf, 0, 0, d2h_fis);
 
-	rc = sata_link_hardreset(link, timing, deadline, &online,
-				 ahci_check_ready);
+	rc = sata_std_hardreset(ap, class, deadline);
 
 	ahci_start_engine(ap);
 
-	if (online)
+	if (rc == 0 && ata_port_online(ap))
 		*class = ahci_dev_classify(ap);
+	if (*class == ATA_DEV_UNKNOWN)
+		*class = ATA_DEV_NONE;
 
 	DPRINTK("EXIT, rc=%d, class=%u\n", rc, *class);
 	return rc;
 }
 
-static int ahci_vt8251_hardreset(struct ata_link *link, unsigned int *class,
+static int ahci_vt8251_hardreset(struct ata_port *ap, unsigned int *class,
 				 unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
-	bool online;
+	u32 serror;
 	int rc;
 
 	DPRINTK("ENTER\n");
 
 	ahci_stop_engine(ap);
 
-	rc = sata_link_hardreset(link, sata_ehc_deb_timing(&link->eh_context),
-				 deadline, &online, NULL);
+	rc = sata_port_hardreset(ap, sata_ehc_deb_timing(&ap->eh_context),
+				 deadline);
+
+	/* vt8251 needs SError cleared for the port to operate */
+	ahci_scr_read(ap, SCR_ERROR, &serror);
+	ahci_scr_write(ap, SCR_ERROR, serror);
 
 	ahci_start_engine(ap);
 
@@ -1966,31 +1209,35 @@
 	/* vt8251 doesn't clear BSY on signature FIS reception,
 	 * request follow-up softreset.
 	 */
-	return online ? -EAGAIN : rc;
+	return rc ?: -EAGAIN;
 }
 
-static int ahci_p5wdh_hardreset(struct ata_link *link, unsigned int *class,
+static int ahci_p5wdh_hardreset(struct ata_port *ap, unsigned int *class,
 				unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct ahci_port_priv *pp = ap->private_data;
 	u8 *d2h_fis = pp->rx_fis + RX_FIS_D2H_REG;
 	struct ata_taskfile tf;
-	bool online;
 	int rc;
 
 	ahci_stop_engine(ap);
 
 	/* clear D2H reception area to properly wait for D2H FIS */
-	ata_tf_init(link->device, &tf);
+	ata_tf_init(ap->device, &tf);
 	tf.command = 0x80;
 	ata_tf_to_fis(&tf, 0, 0, d2h_fis);
 
-	rc = sata_link_hardreset(link, sata_ehc_deb_timing(&link->eh_context),
-				 deadline, &online, NULL);
+	rc = sata_port_hardreset(ap, sata_ehc_deb_timing(&ap->eh_context),
+				 deadline);
 
 	ahci_start_engine(ap);
 
+	if (rc || ata_port_offline(ap))
+		return rc;
+
+	/* spec mandates ">= 2ms" before checking status */
+	msleep(150);
+
 	/* The pseudo configuration device on SIMG4726 attached to
 	 * ASUS P5W-DH Deluxe doesn't send signature FIS after
 	 * hardreset if no device is attached to the first downstream
@@ -2004,22 +1251,19 @@
 	 * have to be reset again.  For most cases, this should
 	 * suffice while making probing snappish enough.
 	 */
-	if (online) {
-		rc = ata_wait_after_reset(link, jiffies + 2 * HZ,
-					  ahci_check_ready);
-		if (rc)
-			ahci_kick_engine(ap);
-	}
-	return rc;
+	rc = ata_wait_ready(ap, jiffies + 2 * HZ);
+	if (rc)
+		ahci_kick_engine(ap, 0);
+
+	return 0;
 }
 
-static void ahci_postreset(struct ata_link *link, unsigned int *class)
+static void ahci_postreset(struct ata_port *ap, unsigned int *class)
 {
-	struct ata_port *ap = link->ap;
 	void __iomem *port_mmio = ahci_port_base(ap);
 	u32 new_tmp, tmp;
 
-	ata_std_postreset(link, class);
+	ata_std_postreset(ap, class);
 
 	/* Make sure port's ATAPI bit is set appropriately */
 	new_tmp = tmp = readl(port_mmio + PORT_CMD);
@@ -2033,34 +1277,53 @@
 	}
 }
 
+static u8 ahci_check_status(struct ata_port *ap)
+{
+	void __iomem *mmio = ap->ioaddr.cmd_addr;
+
+	return readl(mmio + PORT_TFDATA) & 0xFF;
+}
+
+static void ahci_tf_read(struct ata_port *ap, struct ata_taskfile *tf)
+{
+	struct ahci_port_priv *pp = ap->private_data;
+	u8 *d2h_fis = pp->rx_fis + RX_FIS_D2H_REG;
+
+	ata_tf_from_fis(d2h_fis, tf);
+}
+
 static unsigned int ahci_fill_sg(struct ata_queued_cmd *qc, void *cmd_tbl)
 {
 	struct scatterlist *sg;
-	struct ahci_sg *ahci_sg = cmd_tbl + AHCI_CMD_TBL_HDR_SZ;
-	unsigned int si;
+	struct ahci_sg *ahci_sg;
+	unsigned int n_sg = 0;
 
 	VPRINTK("ENTER\n");
 
 	/*
 	 * Next, the S/G list.
 	 */
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
+	ahci_sg = cmd_tbl + AHCI_CMD_TBL_HDR_SZ;
+	ata_for_each_sg(sg, qc) {
 		dma_addr_t addr = sg_dma_address(sg);
 		u32 sg_len = sg_dma_len(sg);
 
-		ahci_sg[si].addr = cpu_to_le32(addr & 0xffffffff);
-		ahci_sg[si].addr_hi = cpu_to_le32((addr >> 16) >> 16);
-		ahci_sg[si].flags_size = cpu_to_le32(sg_len - 1);
+		ahci_sg->addr = cpu_to_le32(addr & 0xffffffff);
+		ahci_sg->addr_hi = cpu_to_le32((addr >> 16) >> 16);
+		ahci_sg->flags_size = cpu_to_le32(sg_len - 1);
+
+		ahci_sg++;
+		n_sg++;
 	}
 
-	return si;
+	return n_sg;
 }
 
 static void ahci_qc_prep(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ahci_port_priv *pp = ap->private_data;
-	int is_atapi = ata_is_atapi(qc->tf.protocol);
+	int is_atapi = is_atapi_taskfile(&qc->tf);
 	void *cmd_tbl;
 	u32 opts;
 	const u32 cmd_fis_len = 5; /* five dwords */
@@ -2072,7 +1335,7 @@
 	 */
 	cmd_tbl = pp->cmd_tbl + qc->tag * AHCI_CMD_TBL_SZ;
 
-	ata_tf_to_fis(&qc->tf, qc->dev->link->pmp, 1, cmd_tbl);
+	ata_tf_to_fis(&qc->tf, 0, 1, cmd_tbl);
 	if (is_atapi) {
 		memset(cmd_tbl + AHCI_CMD_TBL_CDB, 0, 32);
 		memcpy(cmd_tbl + AHCI_CMD_TBL_CDB, qc->cdb, qc->dev->cdb_len);
@@ -2085,7 +1348,7 @@
 	/*
 	 * Fill in command slot information.
 	 */
-	opts = cmd_fis_len | n_elem << 16 | (qc->dev->link->pmp << 12);
+	opts = cmd_fis_len | n_elem << 16;
 	if (qc->tf.flags & ATA_TFLAG_WRITE)
 		opts |= AHCI_CMD_WRITE;
 	if (is_atapi)
@@ -2096,87 +1359,66 @@
 
 static void ahci_error_intr(struct ata_port *ap, u32 irq_stat)
 {
-	struct ahci_host_priv *hpriv = ap->host->private_data;
 	struct ahci_port_priv *pp = ap->private_data;
-	struct ata_eh_info *host_ehi = &ap->link.eh_info;
-	struct ata_link *link = NULL;
-	struct ata_queued_cmd *active_qc;
-	struct ata_eh_info *active_ehi;
+	struct ata_eh_info *ehi = &ap->eh_info;
+	unsigned int err_mask = 0, action = 0;
+	struct ata_queued_cmd *qc;
 	u32 serror;
 
-	/* determine active link */
-	ata_for_each_link(link, ap, EDGE)
-		if (ata_link_active(link))
-			break;
-	if (!link)
-		link = &ap->link;
-
-	active_qc = ata_qc_from_tag(ap, link->active_tag);
-	active_ehi = &link->eh_info;
-
-	/* record irq stat */
-	ata_ehi_clear_desc(host_ehi);
-	ata_ehi_push_desc(host_ehi, "irq_stat 0x%08x", irq_stat);
+	ata_ehi_clear_desc(ehi);
 
 	/* AHCI needs SError cleared; otherwise, it might lock up */
-	ahci_scr_read(&ap->link, SCR_ERROR, &serror);
-	ahci_scr_write(&ap->link, SCR_ERROR, serror);
-	host_ehi->serror |= serror;
+	ahci_scr_read(ap, SCR_ERROR, &serror);
+	ahci_scr_write(ap, SCR_ERROR, serror);
+
+	/* analyze @irq_stat */
+	ata_ehi_push_desc(ehi, "irq_stat 0x%08x", irq_stat);
 
 	/* some controllers set IRQ_IF_ERR on device errors, ignore it */
-	if (hpriv->flags & AHCI_HFLAG_IGN_IRQ_IF_ERR)
+	if (ap->flags & AHCI_FLAG_IGN_IRQ_IF_ERR)
 		irq_stat &= ~PORT_IRQ_IF_ERR;
 
 	if (irq_stat & PORT_IRQ_TF_ERR) {
-		/* If qc is active, charge it; otherwise, the active
-		 * link.  There's no active qc on NCQ errors.  It will
-		 * be determined by EH by reading log page 10h.
-		 */
-		if (active_qc)
-			active_qc->err_mask |= AC_ERR_DEV;
-		else
-			active_ehi->err_mask |= AC_ERR_DEV;
-
-		if (hpriv->flags & AHCI_HFLAG_IGN_SERR_INTERNAL)
-			host_ehi->serror &= ~SERR_INTERNAL;
-	}
-
-	if (irq_stat & PORT_IRQ_UNK_FIS) {
-		u32 *unk = (u32 *)(pp->rx_fis + RX_FIS_UNK);
-
-		active_ehi->err_mask |= AC_ERR_HSM;
-		active_ehi->action |= ATA_EH_RESET;
-		ata_ehi_push_desc(active_ehi,
-				  "unknown FIS %08x %08x %08x %08x" ,
-				  unk[0], unk[1], unk[2], unk[3]);
-	}
-
-	if (sata_pmp_attached(ap) && (irq_stat & PORT_IRQ_BAD_PMP)) {
-		active_ehi->err_mask |= AC_ERR_HSM;
-		active_ehi->action |= ATA_EH_RESET;
-		ata_ehi_push_desc(active_ehi, "incorrect PMP");
+		err_mask |= AC_ERR_DEV;
+		if (ap->flags & AHCI_FLAG_IGN_SERR_INTERNAL)
+			serror &= ~SERR_INTERNAL;
 	}
 
 	if (irq_stat & (PORT_IRQ_HBUS_ERR | PORT_IRQ_HBUS_DATA_ERR)) {
-		host_ehi->err_mask |= AC_ERR_HOST_BUS;
-		host_ehi->action |= ATA_EH_RESET;
-		ata_ehi_push_desc(host_ehi, "host bus error");
+		err_mask |= AC_ERR_HOST_BUS;
+		action |= ATA_EH_SOFTRESET;
 	}
 
 	if (irq_stat & PORT_IRQ_IF_ERR) {
-		host_ehi->err_mask |= AC_ERR_ATA_BUS;
-		host_ehi->action |= ATA_EH_RESET;
-		ata_ehi_push_desc(host_ehi, "interface fatal error");
+		err_mask |= AC_ERR_ATA_BUS;
+		action |= ATA_EH_SOFTRESET;
+		ata_ehi_push_desc(ehi, "interface fatal error");
 	}
 
 	if (irq_stat & (PORT_IRQ_CONNECT | PORT_IRQ_PHYRDY)) {
-		ata_ehi_hotplugged(host_ehi);
-		ata_ehi_push_desc(host_ehi, "%s",
-			irq_stat & PORT_IRQ_CONNECT ?
+		ata_ehi_hotplugged(ehi);
+		ata_ehi_push_desc(ehi, "%s", irq_stat & PORT_IRQ_CONNECT ?
 			"connection status changed" : "PHY RDY changed");
 	}
 
+	if (irq_stat & PORT_IRQ_UNK_FIS) {
+		u32 *unk = (u32 *)(pp->rx_fis + RX_FIS_UNK);
+
+		err_mask |= AC_ERR_HSM;
+		action |= ATA_EH_SOFTRESET;
+		ata_ehi_push_desc(ehi, "unknown FIS %08x %08x %08x %08x",
+				  unk[0], unk[1], unk[2], unk[3]);
+	}
+
 	/* okay, let's hand over to EH */
+	ehi->serror |= serror;
+	ehi->action |= action;
+
+	qc = ata_qc_from_tag(ap, ap->active_tag);
+	if (qc)
+		qc->err_mask |= err_mask;
+	else
+		ehi->err_mask |= err_mask;
 
 	if (irq_stat & PORT_IRQ_FREEZE)
 		ata_port_freeze(ap);
@@ -2186,85 +1428,45 @@
 
 static void ahci_port_intr(struct ata_port *ap)
 {
-	void __iomem *port_mmio = ahci_port_base(ap);
-	struct ata_eh_info *ehi = &ap->link.eh_info;
+	void __iomem *port_mmio = ap->ioaddr.cmd_addr;
+	struct ata_eh_info *ehi = &ap->eh_info;
 	struct ahci_port_priv *pp = ap->private_data;
-	struct ahci_host_priv *hpriv = ap->host->private_data;
-	int resetting = !!(ap->pflags & ATA_PFLAG_RESETTING);
 	u32 status, qc_active;
 	int rc;
 
 	status = readl(port_mmio + PORT_IRQ_STAT);
 	writel(status, port_mmio + PORT_IRQ_STAT);
 
-	/* ignore BAD_PMP while resetting */
-	if (unlikely(resetting))
-		status &= ~PORT_IRQ_BAD_PMP;
-
-	/* If we are getting PhyRdy, this is
- 	 * just a power state change, we should
- 	 * clear out this, plus the PhyRdy/Comm
- 	 * Wake bits from Serror
- 	 */
-	if ((hpriv->flags & AHCI_HFLAG_NO_HOTPLUG) &&
-		(status & PORT_IRQ_PHYRDY)) {
-		status &= ~PORT_IRQ_PHYRDY;
-		ahci_scr_write(&ap->link, SCR_ERROR, ((1 << 16) | (1 << 18)));
-	}
-
 	if (unlikely(status & PORT_IRQ_ERROR)) {
 		ahci_error_intr(ap, status);
 		return;
 	}
 
-	if (status & PORT_IRQ_SDB_FIS) {
-		/* If SNotification is available, leave notification
-		 * handling to sata_async_notification().  If not,
-		 * emulate it by snooping SDB FIS RX area.
-		 *
-		 * Snooping FIS RX area is probably cheaper than
-		 * poking SNotification but some constrollers which
-		 * implement SNotification, ICH9 for example, don't
-		 * store AN SDB FIS into receive area.
-		 */
-		if (hpriv->cap & HOST_CAP_SNTF)
-			sata_async_notification(ap);
-		else {
-			/* If the 'N' bit in word 0 of the FIS is set,
-			 * we just received asynchronous notification.
-			 * Tell libata about it.
-			 */
-			const __le32 *f = pp->rx_fis + RX_FIS_SDB;
-			u32 f0 = le32_to_cpu(f[0]);
-
-			if (f0 & (1 << 15))
-				sata_async_notification(ap);
-		}
-	}
-
-	/* pp->active_link is valid iff any command is in flight */
-	if (ap->qc_active && pp->active_link->sactive)
+	if (ap->sactive)
 		qc_active = readl(port_mmio + PORT_SCR_ACT);
 	else
 		qc_active = readl(port_mmio + PORT_CMD_ISSUE);
 
-	rc = ata_qc_complete_multiple(ap, qc_active);
-
-	/* while resetting, invalid completions are expected */
-	if (unlikely(rc < 0 && !resetting)) {
+	rc = ata_qc_complete_multiple(ap, qc_active, NULL);
+	if (rc < 0) {
 		ehi->err_mask |= AC_ERR_HSM;
-		ehi->action |= ATA_EH_RESET;
+		ehi->action |= ATA_EH_SOFTRESET;
 		ata_port_freeze(ap);
 	}
 }
 
+static void ahci_irq_clear(struct ata_port *ap)
+{
+	/* TODO */
+}
+
 static irqreturn_t ahci_interrupt(int irq, void *dev_instance)
 {
 	struct ata_host *host = dev_instance;
 	struct ahci_host_priv *hpriv;
 	unsigned int i, handled = 0;
 	void __iomem *mmio;
-	u32 irq_stat, irq_masked;
+	u32 irq_stat, irq_ack = 0;
 
 	VPRINTK("ENTER\n");
 
@@ -2273,17 +1475,16 @@
 
 	/* sigh.  0xffffffff is a valid return from h/w */
 	irq_stat = readl(mmio + HOST_IRQ_STAT);
+	irq_stat &= hpriv->port_map;
 	if (!irq_stat)
 		return IRQ_NONE;
 
-	irq_masked = irq_stat & hpriv->port_map;
+        spin_lock(&host->lock);
 
-	spin_lock(&host->lock);
-
-	for (i = 0; i < host->n_ports; i++) {
+        for (i = 0; i < host->n_ports; i++) {
 		struct ata_port *ap;
 
-		if (!(irq_masked & (1 << i)))
+		if (!(irq_stat & (1 << i)))
 			continue;
 
 		ap = host->ports[i];
@@ -2297,19 +1498,13 @@
 					"interrupt on disabled port %u\n", i);
 		}
 
-		handled = 1;
+		irq_ack |= (1 << i);
 	}
 
-	/* HOST_IRQ_STAT behaves as level triggered latch meaning that
-	 * it should be cleared after all the port events are cleared;
-	 * otherwise, it will raise a spurious interrupt after each
-	 * valid one.  Please read section 10.6.2 of ahci 1.1 for more
-	 * information.
-	 *
-	 * Also, use the unmasked value to clear interrupt as spurious
-	 * pending event on a dummy port might cause screaming IRQ.
-	 */
-	writel(irq_stat, mmio + HOST_IRQ_STAT);
+	if (irq_ack) {
+		writel(irq_ack, mmio + HOST_IRQ_STAT);
+		handled = 1;
+	}
 
 	spin_unlock(&host->lock);
 
@@ -2322,32 +1517,15 @@
 {
 	struct ata_port *ap = qc->ap;
 	void __iomem *port_mmio = ahci_port_base(ap);
-	struct ahci_port_priv *pp = ap->private_data;
-
-	/* Keep track of the currently active link.  It will be used
-	 * in completion path to determine whether NCQ phase is in
-	 * progress.
-	 */
-	pp->active_link = qc->dev->link;
 
 	if (qc->tf.protocol == ATA_PROT_NCQ)
 		writel(1 << qc->tag, port_mmio + PORT_SCR_ACT);
 	writel(1 << qc->tag, port_mmio + PORT_CMD_ISSUE);
-
-	ahci_sw_activity(qc->dev->link);
+	readl(port_mmio + PORT_CMD_ISSUE);	/* flush */
 
 	return 0;
 }
 
-static bool ahci_qc_fill_rtf(struct ata_queued_cmd *qc)
-{
-	struct ahci_port_priv *pp = qc->ap->private_data;
-	u8 *d2h_fis = pp->rx_fis + RX_FIS_D2H_REG;
-
-	ata_tf_from_fis(d2h_fis, &qc->result_tf);
-	return true;
-}
-
 static void ahci_freeze(struct ata_port *ap)
 {
 	void __iomem *port_mmio = ahci_port_base(ap);
@@ -2361,7 +1539,6 @@
 	void __iomem *mmio = ap->host->iomap[AHCI_PCI_BAR];
 	void __iomem *port_mmio = ahci_port_base(ap);
 	u32 tmp;
-	struct ahci_port_priv *pp = ap->private_data;
 
 	/* clear IRQ */
 	tmp = readl(port_mmio + PORT_IRQ_STAT);
@@ -2369,7 +1546,7 @@
 	writel(1 << ap->port_no, mmio + HOST_IRQ_STAT);
 
 	/* turn IRQ back on */
-	writel(pp->intr_mask, port_mmio + PORT_IRQ_MASK);
+	writel(DEF_PORT_IRQ, port_mmio + PORT_IRQ_MASK);
 }
 
 static void ahci_error_handler(struct ata_port *ap)
@@ -2380,44 +1557,44 @@
 		ahci_start_engine(ap);
 	}
 
-	sata_pmp_error_handler(ap);
+	/* perform recovery */
+	ata_do_eh(ap, ata_std_prereset, ahci_softreset, ahci_hardreset,
+		  ahci_postreset);
 }
 
-static void ahci_post_internal_cmd(struct ata_queued_cmd *qc)
+static void ahci_vt8251_error_handler(struct ata_port *ap)
 {
-	struct ata_port *ap = qc->ap;
+	if (!(ap->pflags & ATA_PFLAG_FROZEN)) {
+		/* restart engine */
+		ahci_stop_engine(ap);
+		ahci_start_engine(ap);
+	}
 
-	/* make DMA engine forget about the failed command */
-	if (qc->flags & ATA_QCFLAG_FAILED)
-		ahci_kick_engine(ap);
+	/* perform recovery */
+	ata_do_eh(ap, ata_std_prereset, ahci_softreset, ahci_vt8251_hardreset,
+		  ahci_postreset);
 }
 
-static void ahci_pmp_attach(struct ata_port *ap)
+static void ahci_p5wdh_error_handler(struct ata_port *ap)
 {
-	void __iomem *port_mmio = ahci_port_base(ap);
-	struct ahci_port_priv *pp = ap->private_data;
-	u32 cmd;
-
-	cmd = readl(port_mmio + PORT_CMD);
-	cmd |= PORT_CMD_PMP;
-	writel(cmd, port_mmio + PORT_CMD);
+	if (!(ap->pflags & ATA_PFLAG_FROZEN)) {
+		/* restart engine */
+		ahci_stop_engine(ap);
+		ahci_start_engine(ap);
+	}
 
-	pp->intr_mask |= PORT_IRQ_BAD_PMP;
-	writel(pp->intr_mask, port_mmio + PORT_IRQ_MASK);
+	/* perform recovery */
+	ata_do_eh(ap, ata_std_prereset, ahci_softreset, ahci_p5wdh_hardreset,
+		  ahci_postreset);
 }
 
-static void ahci_pmp_detach(struct ata_port *ap)
+static void ahci_post_internal_cmd(struct ata_queued_cmd *qc)
 {
-	void __iomem *port_mmio = ahci_port_base(ap);
-	struct ahci_port_priv *pp = ap->private_data;
-	u32 cmd;
-
-	cmd = readl(port_mmio + PORT_CMD);
-	cmd &= ~PORT_CMD_PMP;
-	writel(cmd, port_mmio + PORT_CMD);
+	struct ata_port *ap = qc->ap;
 
-	pp->intr_mask &= ~PORT_IRQ_BAD_PMP;
-	writel(pp->intr_mask, port_mmio + PORT_IRQ_MASK);
+	/* make DMA engine forget about the failed command */
+	if (qc->flags & ATA_QCFLAG_FAILED)
+		ahci_kick_engine(ap, 1);
 }
 
 static int ahci_port_resume(struct ata_port *ap)
@@ -2425,11 +1602,6 @@
 	ahci_power_up(ap);
 	ahci_start_port(ap);
 
-	if (sata_pmp_attached(ap))
-		ahci_pmp_attach(ap);
-	else
-		ahci_pmp_detach(ap);
-
 	return 0;
 }
 
@@ -2453,18 +1625,10 @@
 static int ahci_pci_device_suspend(struct pci_dev *pdev, pm_message_t mesg)
 {
 	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	struct ahci_host_priv *hpriv = host->private_data;
 	void __iomem *mmio = host->iomap[AHCI_PCI_BAR];
 	u32 ctl;
 
-	if (mesg.event & PM_EVENT_SUSPEND &&
-	    hpriv->flags & AHCI_HFLAG_NO_SUSPEND) {
-		dev_printk(KERN_ERR, &pdev->dev,
-			   "BIOS update required for suspend/resume\n");
-		return -EIO;
-	}
-
-	if (mesg.event & PM_EVENT_SLEEP) {
+	if (mesg.event == PM_EVENT_SUSPEND) {
 		/* AHCI spec rev1.1 section 8.3.3:
 		 * Software must disable interrupts prior to requesting a
 		 * transition of the HBA to D3 state.
@@ -2507,11 +1671,16 @@
 	struct ahci_port_priv *pp;
 	void *mem;
 	dma_addr_t mem_dma;
+	int rc;
 
 	pp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);
 	if (!pp)
 		return -ENOMEM;
 
+	rc = ata_pad_alloc(ap, dev);
+	if (rc)
+		return rc;
+
 	mem = dmam_alloc_coherent(dev, AHCI_PORT_PRIV_DMA_SZ, &mem_dma,
 				  GFP_KERNEL);
 	if (!mem)
@@ -2544,12 +1713,6 @@
 	pp->cmd_tbl = mem;
 	pp->cmd_tbl_dma = mem_dma;
 
-	/*
-	 * Save off initial list of interrupts to be enabled.
-	 * This could be changed later
-	 */
-	pp->intr_mask = DEF_PORT_IRQ;
-
 	ap->private_data = pp;
 
 	/* engage engines, captain */
@@ -2572,10 +1735,10 @@
 	int rc;
 
 	if (using_dac &&
-	    !pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {
-		rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
+	    !pci_set_dma_mask(pdev, DMA_64BIT_MASK)) {
+		rc = pci_set_consistent_dma_mask(pdev, DMA_64BIT_MASK);
 		if (rc) {
-			rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+			rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 			if (rc) {
 				dev_printk(KERN_ERR, &pdev->dev,
 					   "64-bit DMA enable failed\n");
@@ -2583,13 +1746,13 @@
 			}
 		}
 	} else {
-		rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
+		rc = pci_set_dma_mask(pdev, DMA_32BIT_MASK);
 		if (rc) {
 			dev_printk(KERN_ERR, &pdev->dev,
 				   "32-bit DMA enable failed\n");
 			return rc;
 		}
-		rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+		rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 		if (rc) {
 			dev_printk(KERN_ERR, &pdev->dev,
 				   "32-bit consistent DMA enable failed\n");
@@ -2604,14 +1767,13 @@
 	struct ahci_host_priv *hpriv = host->private_data;
 	struct pci_dev *pdev = to_pci_dev(host->dev);
 	void __iomem *mmio = host->iomap[AHCI_PCI_BAR];
-	u32 vers, cap, cap2, impl, speed;
+	u32 vers, cap, impl, speed;
 	const char *speed_s;
 	u16 cc;
 	const char *scc_s;
 
 	vers = readl(mmio + HOST_VERSION);
 	cap = hpriv->cap;
-	cap2 = hpriv->cap2;
 	impl = hpriv->port_map;
 
 	speed = (cap >> 20) & 0xf;
@@ -2619,8 +1781,6 @@
 		speed_s = "1.5";
 	else if (speed == 2)
 		speed_s = "3";
-	else if (speed == 3)
-		speed_s = "6";
 	else
 		speed_s = "?";
 
@@ -2637,12 +1797,12 @@
 	dev_printk(KERN_INFO, &pdev->dev,
 		"AHCI %02x%02x.%02x%02x "
 		"%u slots %u ports %s Gbps 0x%x impl %s mode\n"
-		,
+	       	,
 
-		(vers >> 24) & 0xff,
-		(vers >> 16) & 0xff,
-		(vers >> 8) & 0xff,
-		vers & 0xff,
+	       	(vers >> 24) & 0xff,
+	       	(vers >> 16) & 0xff,
+	       	(vers >> 8) & 0xff,
+	       	vers & 0xff,
 
 		((cap >> 8) & 0x1f) + 1,
 		(cap & 0x1f) + 1,
@@ -2653,30 +1813,24 @@
 	dev_printk(KERN_INFO, &pdev->dev,
 		"flags: "
 		"%s%s%s%s%s%s%s"
-		"%s%s%s%s%s%s%s"
-		"%s%s%s%s%s%s\n"
-		,
+		"%s%s%s%s%s%s%s\n"
+	       	,
 
-		cap & HOST_CAP_64 ? "64bit " : "",
-		cap & HOST_CAP_NCQ ? "ncq " : "",
-		cap & HOST_CAP_SNTF ? "sntf " : "",
-		cap & HOST_CAP_MPS ? "ilck " : "",
-		cap & HOST_CAP_SSS ? "stag " : "",
-		cap & HOST_CAP_ALPM ? "pm " : "",
-		cap & HOST_CAP_LED ? "led " : "",
-		cap & HOST_CAP_CLO ? "clo " : "",
-		cap & HOST_CAP_ONLY ? "only " : "",
-		cap & HOST_CAP_PMP ? "pmp " : "",
-		cap & HOST_CAP_FBS ? "fbs " : "",
-		cap & HOST_CAP_PIO_MULTI ? "pio " : "",
-		cap & HOST_CAP_SSC ? "slum " : "",
-		cap & HOST_CAP_PART ? "part " : "",
-		cap & HOST_CAP_CCC ? "ccc " : "",
-		cap & HOST_CAP_EMS ? "ems " : "",
-		cap & HOST_CAP_SXS ? "sxs " : "",
-		cap2 & HOST_CAP2_APST ? "apst " : "",
-		cap2 & HOST_CAP2_NVMHCI ? "nvmp " : "",
-		cap2 & HOST_CAP2_BOH ? "boh " : ""
+		cap & (1 << 31) ? "64bit " : "",
+		cap & (1 << 30) ? "ncq " : "",
+		cap & (1 << 29) ? "sntf " : "",
+		cap & (1 << 28) ? "ilck " : "",
+		cap & (1 << 27) ? "stag " : "",
+		cap & (1 << 26) ? "pm " : "",
+		cap & (1 << 25) ? "led " : "",
+
+		cap & (1 << 24) ? "clo " : "",
+		cap & (1 << 19) ? "nz " : "",
+		cap & (1 << 18) ? "only " : "",
+		cap & (1 << 17) ? "pmp " : "",
+		cap & (1 << 15) ? "pio " : "",
+		cap & (1 << 14) ? "slum " : "",
+		cap & (1 << 13) ? "part " : ""
 		);
 }
 
@@ -2721,313 +1875,19 @@
 			   "Deluxe on-board SIMG4726 workaround\n");
 
 		ap->ops = &ahci_p5wdh_ops;
-		ap->link.flags |= ATA_LFLAG_NO_SRST | ATA_LFLAG_ASSUME_ATA;
-	}
-}
-
-/* only some SB600 ahci controllers can do 64bit DMA */
-static bool ahci_sb600_enable_64bit(struct pci_dev *pdev)
-{
-	static const struct dmi_system_id sysids[] = {
-		/*
-		 * The oldest version known to be broken is 0901 and
-		 * working is 1501 which was released on 2007-10-26.
-		 * Enable 64bit DMA on 1501 and anything newer.
-		 *
-		 * Please read bko#9412 for more info.
-		 */
-		{
-			.ident = "ASUS M2A-VM",
-			.matches = {
-				DMI_MATCH(DMI_BOARD_VENDOR,
-					  "ASUSTeK Computer INC."),
-				DMI_MATCH(DMI_BOARD_NAME, "M2A-VM"),
-			},
-			.driver_data = "20071026",	/* yyyymmdd */
-		},
-		/*
-		 * All BIOS versions for the MSI K9A2 Platinum (MS-7376)
-		 * support 64bit DMA.
-		 *
-		 * BIOS versions earlier than 1.5 had the Manufacturer DMI
-		 * fields as "MICRO-STAR INTERANTIONAL CO.,LTD".
-		 * This spelling mistake was fixed in BIOS version 1.5, so
-		 * 1.5 and later have the Manufacturer as
-		 * "MICRO-STAR INTERNATIONAL CO.,LTD".
-		 * So try to match on DMI_BOARD_VENDOR of "MICRO-STAR INTER".
-		 *
-		 * BIOS versions earlier than 1.9 had a Board Product Name
-		 * DMI field of "MS-7376". This was changed to be
-		 * "K9A2 Platinum (MS-7376)" in version 1.9, but we can still
-		 * match on DMI_BOARD_NAME of "MS-7376".
-		 */
-		{
-			.ident = "MSI K9A2 Platinum",
-			.matches = {
-				DMI_MATCH(DMI_BOARD_VENDOR,
-					  "MICRO-STAR INTER"),
-				DMI_MATCH(DMI_BOARD_NAME, "MS-7376"),
-			},
-		},
-		{ }
-	};
-	const struct dmi_system_id *match;
-	int year, month, date;
-	char buf[9];
-
-	match = dmi_first_match(sysids);
-	if (pdev->bus->number != 0 || pdev->devfn != PCI_DEVFN(0x12, 0) ||
-	    !match)
-		return false;
-
-	if (!match->driver_data)
-		goto enable_64bit;
-
-	dmi_get_date(DMI_BIOS_DATE, &year, &month, &date);
-	snprintf(buf, sizeof(buf), "%04d%02d%02d", year, month, date);
-
-	if (strcmp(buf, match->driver_data) >= 0)
-		goto enable_64bit;
-	else {
-		dev_printk(KERN_WARNING, &pdev->dev, "%s: BIOS too old, "
-			   "forcing 32bit DMA, update BIOS\n", match->ident);
-		return false;
-	}
-
-enable_64bit:
-	dev_printk(KERN_WARNING, &pdev->dev, "%s: enabling 64bit DMA\n",
-		   match->ident);
-	return true;
-}
-
-static bool ahci_broken_system_poweroff(struct pci_dev *pdev)
-{
-	static const struct dmi_system_id broken_systems[] = {
-		{
-			.ident = "HP Compaq nx6310",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "HP Compaq nx6310"),
-			},
-			/* PCI slot number of the controller */
-			.driver_data = (void *)0x1FUL,
-		},
-		{
-			.ident = "HP Compaq 6720s",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "HP Compaq 6720s"),
-			},
-			/* PCI slot number of the controller */
-			.driver_data = (void *)0x1FUL,
-		},
-
-		{ }	/* terminate list */
-	};
-	const struct dmi_system_id *dmi = dmi_first_match(broken_systems);
-
-	if (dmi) {
-		unsigned long slot = (unsigned long)dmi->driver_data;
-		/* apply the quirk only to on-board controllers */
-		return slot == PCI_SLOT(pdev->devfn);
-	}
-
-	return false;
-}
-
-static bool ahci_broken_suspend(struct pci_dev *pdev)
-{
-	static const struct dmi_system_id sysids[] = {
-		/*
-		 * On HP dv[4-6] and HDX18 with earlier BIOSen, link
-		 * to the harddisk doesn't become online after
-		 * resuming from STR.  Warn and fail suspend.
-		 *
-		 * http://bugzilla.kernel.org/show_bug.cgi?id=12276
-		 *
-		 * Use dates instead of versions to match as HP is
-		 * apparently recycling both product and version
-		 * strings.
-		 *
-		 * http://bugzilla.kernel.org/show_bug.cgi?id=15462
-		 */
-		{
-			.ident = "dv4",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME,
-					  "HP Pavilion dv4 Notebook PC"),
-			},
-			.driver_data = "20090105",	/* F.30 */
-		},
-		{
-			.ident = "dv5",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME,
-					  "HP Pavilion dv5 Notebook PC"),
-			},
-			.driver_data = "20090506",	/* F.16 */
-		},
-		{
-			.ident = "dv6",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME,
-					  "HP Pavilion dv6 Notebook PC"),
-			},
-			.driver_data = "20090423",	/* F.21 */
-		},
-		{
-			.ident = "HDX18",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME,
-					  "HP HDX18 Notebook PC"),
-			},
-			.driver_data = "20090430",	/* F.23 */
-		},
-		/*
-		 * Acer eMachines G725 has the same problem.  BIOS
-		 * V1.03 is known to be broken.  V3.04 is known to
-		 * work.  Inbetween, there are V1.06, V2.06 and V3.03
-		 * that we don't have much idea about.  For now,
-		 * blacklist anything older than V3.04.
-		 *
-		 * http://bugzilla.kernel.org/show_bug.cgi?id=15104
-		 */
-		{
-			.ident = "G725",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "eMachines"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "eMachines G725"),
-			},
-			.driver_data = "20091216",	/* V3.04 */
-		},
-		{ }	/* terminate list */
-	};
-	const struct dmi_system_id *dmi = dmi_first_match(sysids);
-	int year, month, date;
-	char buf[9];
-
-	if (!dmi || pdev->bus->number || pdev->devfn != PCI_DEVFN(0x1f, 2))
-		return false;
-
-	dmi_get_date(DMI_BIOS_DATE, &year, &month, &date);
-	snprintf(buf, sizeof(buf), "%04d%02d%02d", year, month, date);
-
-	return strcmp(buf, dmi->driver_data) < 0;
-}
-
-static bool ahci_broken_online(struct pci_dev *pdev)
-{
-#define ENCODE_BUSDEVFN(bus, slot, func)			\
-	(void *)(unsigned long)(((bus) << 8) | PCI_DEVFN((slot), (func)))
-	static const struct dmi_system_id sysids[] = {
-		/*
-		 * There are several gigabyte boards which use
-		 * SIMG5723s configured as hardware RAID.  Certain
-		 * 5723 firmware revisions shipped there keep the link
-		 * online but fail to answer properly to SRST or
-		 * IDENTIFY when no device is attached downstream
-		 * causing libata to retry quite a few times leading
-		 * to excessive detection delay.
-		 *
-		 * As these firmwares respond to the second reset try
-		 * with invalid device signature, considering unknown
-		 * sig as offline works around the problem acceptably.
-		 */
-		{
-			.ident = "EP45-DQ6",
-			.matches = {
-				DMI_MATCH(DMI_BOARD_VENDOR,
-					  "Gigabyte Technology Co., Ltd."),
-				DMI_MATCH(DMI_BOARD_NAME, "EP45-DQ6"),
-			},
-			.driver_data = ENCODE_BUSDEVFN(0x0a, 0x00, 0),
-		},
-		{
-			.ident = "EP45-DS5",
-			.matches = {
-				DMI_MATCH(DMI_BOARD_VENDOR,
-					  "Gigabyte Technology Co., Ltd."),
-				DMI_MATCH(DMI_BOARD_NAME, "EP45-DS5"),
-			},
-			.driver_data = ENCODE_BUSDEVFN(0x03, 0x00, 0),
-		},
-		{ }	/* terminate list */
-	};
-#undef ENCODE_BUSDEVFN
-	const struct dmi_system_id *dmi = dmi_first_match(sysids);
-	unsigned int val;
-
-	if (!dmi)
-		return false;
-
-	val = (unsigned long)dmi->driver_data;
-
-	return pdev->bus->number == (val >> 8) && pdev->devfn == (val & 0xff);
-}
-
-#ifdef CONFIG_ATA_ACPI
-static void ahci_gtf_filter_workaround(struct ata_host *host)
-{
-	static const struct dmi_system_id sysids[] = {
-		/*
-		 * Aspire 3810T issues a bunch of SATA enable commands
-		 * via _GTF including an invalid one and one which is
-		 * rejected by the device.  Among the successful ones
-		 * is FPDMA non-zero offset enable which when enabled
-		 * only on the drive side leads to NCQ command
-		 * failures.  Filter it out.
-		 */
-		{
-			.ident = "Aspire 3810T",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Acer"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "Aspire 3810T"),
-			},
-			.driver_data = (void *)ATA_ACPI_FILTER_FPDMA_OFFSET,
-		},
-		{ }
-	};
-	const struct dmi_system_id *dmi = dmi_first_match(sysids);
-	unsigned int filter;
-	int i;
-
-	if (!dmi)
-		return;
-
-	filter = (unsigned long)dmi->driver_data;
-	dev_printk(KERN_INFO, host->dev,
-		   "applying extra ACPI _GTF filter 0x%x for %s\n",
-		   filter, dmi->ident);
-
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		struct ata_link *link;
-		struct ata_device *dev;
-
-		ata_for_each_link(link, ap, EDGE)
-			ata_for_each_dev(dev, link, ALL)
-				dev->gtf_filter |= filter;
+		ap->flags |= ATA_FLAG_NO_SRST | ATA_FLAG_ASSUME_ATA;
 	}
 }
-#else
-static inline void ahci_gtf_filter_workaround(struct ata_host *host)
-{}
-#endif
 
 static int ahci_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
-	unsigned int board_id = ent->driver_data;
-	struct ata_port_info pi = ahci_port_info[board_id];
+	struct ata_port_info pi = ahci_port_info[ent->driver_data];
 	const struct ata_port_info *ppi[] = { &pi, NULL };
 	struct device *dev = &pdev->dev;
 	struct ahci_host_priv *hpriv;
 	struct ata_host *host;
-	int n_ports, i, rc;
+	int i, rc;
 
 	VPRINTK("ENTER\n");
 
@@ -3036,174 +1896,53 @@
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
 
-	/* The AHCI driver can only drive the SATA ports, the PATA driver
-	   can drive them all so if both drivers are selected make sure
-	   AHCI stays out of the way */
-	if (pdev->vendor == PCI_VENDOR_ID_MARVELL && !marvell_enable)
-		return -ENODEV;
-
-	/*
-	 * For some reason, MCP89 on MacBook 7,1 doesn't work with
-	 * ahci, use ata_generic instead.
-	 */
-	if (pdev->vendor == PCI_VENDOR_ID_NVIDIA &&
-	    pdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP89_SATA &&
-	    pdev->subsystem_vendor == PCI_VENDOR_ID_APPLE &&
-	    pdev->subsystem_device == 0xcb89)
-		return -ENODEV;
-
 	/* acquire resources */
 	rc = pcim_enable_device(pdev);
 	if (rc)
 		return rc;
 
-	/* AHCI controllers often implement SFF compatible interface.
-	 * Grab all PCI BARs just in case.
-	 */
-	rc = pcim_iomap_regions_request_all(pdev, 1 << AHCI_PCI_BAR, DRV_NAME);
+	rc = pcim_iomap_regions(pdev, 1 << AHCI_PCI_BAR, DRV_NAME);
 	if (rc == -EBUSY)
 		pcim_pin_device(pdev);
 	if (rc)
 		return rc;
 
-	if (pdev->vendor == PCI_VENDOR_ID_INTEL &&
-	    (pdev->device == 0x2652 || pdev->device == 0x2653)) {
-		u8 map;
-
-		/* ICH6s share the same PCI ID for both piix and ahci
-		 * modes.  Enabling ahci mode while MAP indicates
-		 * combined mode is a bad idea.  Yield to ata_piix.
-		 */
-		pci_read_config_byte(pdev, ICH_MAP, &map);
-		if (map & 0x3) {
-			dev_printk(KERN_INFO, &pdev->dev, "controller is in "
-				   "combined mode, can't enable AHCI mode\n");
-			return -ENODEV;
-		}
-	}
+	if ((pi.flags & AHCI_FLAG_NO_MSI) || pci_enable_msi(pdev))
+		pci_intx(pdev, 1);
 
 	hpriv = devm_kzalloc(dev, sizeof(*hpriv), GFP_KERNEL);
 	if (!hpriv)
 		return -ENOMEM;
-	hpriv->flags |= (unsigned long)pi.private_data;
-
-	/* MCP65 revision A1 and A2 can't do MSI */
-	if (board_id == board_ahci_mcp65 &&
-	    (pdev->revision == 0xa1 || pdev->revision == 0xa2))
-		hpriv->flags |= AHCI_HFLAG_NO_MSI;
-
-	/* SB800 does NOT need the workaround to ignore SERR_INTERNAL */
-	if (board_id == board_ahci_sb700 && pdev->revision >= 0x40)
-		hpriv->flags &= ~AHCI_HFLAG_IGN_SERR_INTERNAL;
-
-	/* only some SB600s can do 64bit DMA */
-	if (ahci_sb600_enable_64bit(pdev))
-		hpriv->flags &= ~AHCI_HFLAG_32BIT_ONLY;
-
-	if ((hpriv->flags & AHCI_HFLAG_NO_MSI) || pci_enable_msi(pdev))
-		pci_intx(pdev, 1);
 
 	/* save initial config */
-	ahci_save_initial_config(pdev, hpriv);
+	ahci_save_initial_config(pdev, &pi, hpriv);
 
 	/* prepare host */
-	if (hpriv->cap & HOST_CAP_NCQ) {
+	if (hpriv->cap & HOST_CAP_NCQ)
 		pi.flags |= ATA_FLAG_NCQ;
-		/* Auto-activate optimization is supposed to be supported on
-		   all AHCI controllers indicating NCQ support, but it seems
-		   to be broken at least on some NVIDIA MCP79 chipsets.
-		   Until we get info on which NVIDIA chipsets don't have this
-		   issue, if any, disable AA on all NVIDIA AHCIs. */
-		if (pdev->vendor != PCI_VENDOR_ID_NVIDIA)
-			pi.flags |= ATA_FLAG_FPDMA_AA;
-	}
-
-	if (hpriv->cap & HOST_CAP_PMP)
-		pi.flags |= ATA_FLAG_PMP;
-
-	if (ahci_em_messages && (hpriv->cap & HOST_CAP_EMS)) {
-		u8 messages;
-		void __iomem *mmio = pcim_iomap_table(pdev)[AHCI_PCI_BAR];
-		u32 em_loc = readl(mmio + HOST_EM_LOC);
-		u32 em_ctl = readl(mmio + HOST_EM_CTL);
-
-		messages = (em_ctl & EM_CTRL_MSG_TYPE) >> 16;
-
-		/* we only support LED message type right now */
-		if ((messages & 0x01) && (ahci_em_messages == 1)) {
-			/* store em_loc */
-			hpriv->em_loc = ((em_loc >> 16) * 4);
-			pi.flags |= ATA_FLAG_EM;
-			if (!(em_ctl & EM_CTL_ALHD))
-				pi.flags |= ATA_FLAG_SW_ACTIVITY;
-		}
-	}
-
-	if (ahci_broken_system_poweroff(pdev)) {
-		pi.flags |= ATA_FLAG_NO_POWEROFF_SPINDOWN;
-		dev_info(&pdev->dev,
-			"quirky BIOS, skipping spindown on poweroff\n");
-	}
-
-	if (ahci_broken_suspend(pdev)) {
-		hpriv->flags |= AHCI_HFLAG_NO_SUSPEND;
-		dev_printk(KERN_WARNING, &pdev->dev,
-			   "BIOS update required for suspend/resume\n");
-	}
-
-	if (ahci_broken_online(pdev)) {
-		hpriv->flags |= AHCI_HFLAG_SRST_TOUT_IS_OFFLINE;
-		dev_info(&pdev->dev,
-			 "online status unreliable, applying workaround\n");
-	}
 
-	/* CAP.NP sometimes indicate the index of the last enabled
-	 * port, at other times, that of the last possible port, so
-	 * determining the maximum port number requires looking at
-	 * both CAP.NP and port_map.
-	 */
-	n_ports = max(ahci_nr_ports(hpriv->cap), fls(hpriv->port_map));
-
-	host = ata_host_alloc_pinfo(&pdev->dev, ppi, n_ports);
+	host = ata_host_alloc_pinfo(&pdev->dev, ppi, fls(hpriv->port_map));
 	if (!host)
 		return -ENOMEM;
 	host->iomap = pcim_iomap_table(pdev);
 	host->private_data = hpriv;
 
-	if (!(hpriv->cap & HOST_CAP_SSS) || ahci_ignore_sss)
-		host->flags |= ATA_HOST_PARALLEL_SCAN;
-	else
-		printk(KERN_INFO "ahci: SSS flag set, parallel bus scan disabled\n");
-
-	if (pi.flags & ATA_FLAG_EM)
-		ahci_reset_em(host);
-
 	for (i = 0; i < host->n_ports; i++) {
 		struct ata_port *ap = host->ports[i];
+		void __iomem *port_mmio = ahci_port_base(ap);
 
-		ata_port_pbar_desc(ap, AHCI_PCI_BAR, -1, "abar");
-		ata_port_pbar_desc(ap, AHCI_PCI_BAR,
-				   0x100 + ap->port_no * 0x80, "port");
-
-		/* set initial link pm policy */
-		ap->pm_policy = NOT_AVAILABLE;
-
-		/* set enclosure management message type */
-		if (ap->flags & ATA_FLAG_EM)
-			ap->em_message_type = ahci_em_messages;
-
+		/* standard SATA port setup */
+		if (hpriv->port_map & (1 << i))
+			ap->ioaddr.cmd_addr = port_mmio;
 
 		/* disabled/not-implemented port */
-		if (!(hpriv->port_map & (1 << i)))
+		else
 			ap->ops = &ata_dummy_port_ops;
 	}
 
 	/* apply workaround for ASUS P5W DH Deluxe mainboard */
 	ahci_p5wdh_workaround(host);
 
-	/* apply gtf filter quirk */
-	ahci_gtf_filter_workaround(host);
-
 	/* initialize adapter */
 	rc = ahci_configure_dma_masks(pdev, hpriv->cap & HOST_CAP_64);
 	if (rc)
diff -Nur linux-sh4/drivers/ata.org/ata_generic.c linux-sh4/drivers/ata/ata_generic.c
--- linux-sh4/drivers/ata.org/ata_generic.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/ata_generic.c	2012-01-15 06:30:14.000000000 -0800
@@ -1,6 +1,6 @@
 /*
  *  ata_generic.c - Generic PATA/SATA controller driver.
- *  Copyright 2005 Red Hat Inc, all rights reserved.
+ *  Copyright 2005 Red Hat Inc <alan@redhat.com>, all rights reserved.
  *
  *  Elements from ide/pci/generic.c
  *	    Copyright (C) 2001-2002	Andre Hedrick <andre@linux-ide.org>
@@ -26,20 +26,15 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "ata_generic"
-#define DRV_VERSION "0.2.15"
+#define DRV_VERSION "0.2.13"
 
 /*
  *	A generic parallel ATA driver using libata
  */
 
-enum {
-	ATA_GEN_CLASS_MATCH		= (1 << 0),
-	ATA_GEN_FORCE_DMA		= (1 << 1),
-};
-
 /**
  *	generic_set_mode	-	mode setting
- *	@link: link to set up
+ *	@ap: interface to set up
  *	@unused: returned device on error
  *
  *	Use a non standard set_mode function. We don't want to be tuned.
@@ -48,66 +43,87 @@
  *	and respect them.
  */
 
-static int generic_set_mode(struct ata_link *link, struct ata_device **unused)
+static int generic_set_mode(struct ata_port *ap, struct ata_device **unused)
 {
-	struct ata_port *ap = link->ap;
-	const struct pci_device_id *id = ap->host->private_data;
 	int dma_enabled = 0;
-	struct ata_device *dev;
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	int i;
 
-	if (id->driver_data & ATA_GEN_FORCE_DMA) {
-		dma_enabled = 0xff;
-	} else if (ap->ioaddr.bmdma_addr) {
-		/* Bits 5 and 6 indicate if DMA is active on master/slave */
+	/* Bits 5 and 6 indicate if DMA is active on master/slave */
+	if (ap->ioaddr.bmdma_addr)
 		dma_enabled = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
-	}
-
-	if (pdev->vendor == PCI_VENDOR_ID_CENATEK)
-		dma_enabled = 0xFF;
 
-	ata_for_each_dev(dev, link, ENABLED) {
-		/* We don't really care */
-		dev->pio_mode = XFER_PIO_0;
-		dev->dma_mode = XFER_MW_DMA_0;
-		/* We do need the right mode information for DMA or PIO
-		   and this comes from the current configuration flags */
-		if (dma_enabled & (1 << (5 + dev->devno))) {
-			unsigned int xfer_mask = ata_id_xfermask(dev->id);
-			const char *name;
-
-			if (xfer_mask & (ATA_MASK_MWDMA | ATA_MASK_UDMA))
-				name = ata_mode_string(xfer_mask);
-			else {
-				/* SWDMA perhaps? */
-				name = "DMA";
-				xfer_mask |= ata_xfer_mode2mask(XFER_MW_DMA_0);
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+		if (ata_dev_enabled(dev)) {
+			/* We don't really care */
+			dev->pio_mode = XFER_PIO_0;
+			dev->dma_mode = XFER_MW_DMA_0;
+			/* We do need the right mode information for DMA or PIO
+			   and this comes from the current configuration flags */
+			if (dma_enabled & (1 << (5 + i))) {
+				ata_id_to_dma_mode(dev, XFER_MW_DMA_0);
+				dev->flags &= ~ATA_DFLAG_PIO;
+			} else {
+				ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
+				dev->xfer_mode = XFER_PIO_0;
+				dev->xfer_shift = ATA_SHIFT_PIO;
+				dev->flags |= ATA_DFLAG_PIO;
 			}
-
-			ata_dev_printk(dev, KERN_INFO, "configured for %s\n",
-				       name);
-
-			dev->xfer_mode = ata_xfer_mask2mode(xfer_mask);
-			dev->xfer_shift = ata_xfer_mode2shift(dev->xfer_mode);
-			dev->flags &= ~ATA_DFLAG_PIO;
-		} else {
-			ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
-			dev->xfer_mode = XFER_PIO_0;
-			dev->xfer_shift = ATA_SHIFT_PIO;
-			dev->flags |= ATA_DFLAG_PIO;
 		}
 	}
 	return 0;
 }
 
 static struct scsi_host_template generic_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations generic_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= ata_cable_unknown,
 	.set_mode	= generic_set_mode,
+
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.data_xfer	= ata_data_xfer,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_unknown,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int all_generic_ide;		/* Set to claim all devices */
@@ -126,16 +142,17 @@
 {
 	u16 command;
 	static const struct ata_port_info info = {
+		.sht = &generic_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA5,
 		.port_ops = &generic_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
 
 	/* Don't use the generic entry unless instructed to do so */
-	if ((id->driver_data & ATA_GEN_CLASS_MATCH) && all_generic_ide == 0)
+	if (id->driver_data == 1 && all_generic_ide == 0)
 		return -ENODEV;
 
 	/* Devices that need care */
@@ -156,15 +173,9 @@
 		return -ENODEV;
 
 	if (dev->vendor == PCI_VENDOR_ID_AL)
-		ata_pci_bmdma_clear_simplex(dev);
+	    	ata_pci_clear_simplex(dev);
 
-	if (dev->vendor == PCI_VENDOR_ID_ATI) {
-		int rc = pcim_enable_device(dev);
-		if (rc < 0)
-			return rc;
-		pcim_pin_device(dev);
-	}
-	return ata_pci_sff_init_one(dev, ppi, &generic_sht, (void *)id);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static struct pci_device_id ata_generic[] = {
@@ -176,21 +187,11 @@
 	{ PCI_DEVICE(PCI_VENDOR_ID_HINT,   PCI_DEVICE_ID_HINT_VXPROII_IDE), },
 	{ PCI_DEVICE(PCI_VENDOR_ID_VIA,    PCI_DEVICE_ID_VIA_82C561), },
 	{ PCI_DEVICE(PCI_VENDOR_ID_OPTI,   PCI_DEVICE_ID_OPTI_82C558), },
-	{ PCI_DEVICE(PCI_VENDOR_ID_CENATEK,PCI_DEVICE_ID_CENATEK_IDE),
-	  .driver_data = ATA_GEN_FORCE_DMA },
-	/*
-	 * For some reason, MCP89 on MacBook 7,1 doesn't work with
-	 * ahci, use ata_generic instead.
-	 */
-	{ PCI_VENDOR_ID_NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP89_SATA,
-	  PCI_VENDOR_ID_APPLE, 0xcb89,
-	  .driver_data = ATA_GEN_FORCE_DMA },
 	{ PCI_DEVICE(PCI_VENDOR_ID_TOSHIBA,PCI_DEVICE_ID_TOSHIBA_PICCOLO), },
 	{ PCI_DEVICE(PCI_VENDOR_ID_TOSHIBA,PCI_DEVICE_ID_TOSHIBA_PICCOLO_1), },
 	{ PCI_DEVICE(PCI_VENDOR_ID_TOSHIBA,PCI_DEVICE_ID_TOSHIBA_PICCOLO_2),  },
 	/* Must come last. If you add entries adjust this table appropriately */
-	{ PCI_DEVICE_CLASS(PCI_CLASS_STORAGE_IDE << 8, 0xFFFFFF00UL),
-	  .driver_data = ATA_GEN_CLASS_MATCH },
+	{ PCI_ANY_ID,		PCI_ANY_ID,			   PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_STORAGE_IDE << 8, 0xFFFFFF00UL, 1},
 	{ 0, },
 };
 
diff -Nur linux-sh4/drivers/ata.org/ata_piix.c linux-sh4/drivers/ata/ata_piix.c
--- linux-sh4/drivers/ata.org/ata_piix.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/ata_piix.c	2012-01-15 06:30:14.000000000 -0800
@@ -14,7 +14,7 @@
  *
  *  Copyright (C) 1998-1999 Andrzej Krzysztofowicz, Author and Maintainer
  *  Copyright (C) 1998-2000 Andre Hedrick <andre@linux-ide.org>
- *  Copyright (C) 2003 Red Hat Inc
+ *  Copyright (C) 2003 Red Hat Inc <alan@redhat.com>
  *
  *
  *  This program is free software; you can redistribute it and/or modify
@@ -72,7 +72,6 @@
  *	ICH2    spec c #20	- IDE PRD must not cross a 64K boundary
  *				  and must be dword aligned
  *	ICH2    spec c #24	- UDMA mode 4,5 t85/86 should be 6ns not 3.3
- *	ICH7	errata #16	- MWDMA1 timings are incorrect
  *
  * Should have been BIOS fixed:
  *	450NX:	errata #19	- DMA hangs on old 450NX
@@ -95,26 +94,44 @@
 #include <linux/dmi.h>
 
 #define DRV_NAME	"ata_piix"
-#define DRV_VERSION	"2.13"
+#define DRV_VERSION	"2.12"
 
 enum {
 	PIIX_IOCFG		= 0x54, /* IDE I/O configuration register */
 	ICH5_PMR		= 0x90, /* port mapping register */
 	ICH5_PCS		= 0x92,	/* port control and status */
-	PIIX_SIDPR_BAR		= 5,
-	PIIX_SIDPR_LEN		= 16,
-	PIIX_SIDPR_IDX		= 0,
-	PIIX_SIDPR_DATA		= 4,
+	PIIX_SCC		= 0x0A, /* sub-class code register */
 
+	PIIX_FLAG_SCR		= (1 << 26), /* SCR available */
+	PIIX_FLAG_AHCI		= (1 << 27), /* AHCI possible */
 	PIIX_FLAG_CHECKINTR	= (1 << 28), /* make sure PCI INTx enabled */
-	PIIX_FLAG_SIDPR		= (1 << 29), /* SATA idx/data pair regs */
 
 	PIIX_PATA_FLAGS		= ATA_FLAG_SLAVE_POSS,
 	PIIX_SATA_FLAGS		= ATA_FLAG_SATA | PIIX_FLAG_CHECKINTR,
 
+	/* combined mode.  if set, PATA is channel 0.
+	 * if clear, PATA is channel 1.
+	 */
+	PIIX_PORT_ENABLED	= (1 << 0),
+	PIIX_PORT_PRESENT	= (1 << 4),
+
 	PIIX_80C_PRI		= (1 << 5) | (1 << 4),
 	PIIX_80C_SEC		= (1 << 7) | (1 << 6),
 
+	/* controller IDs */
+	piix_pata_33		= 0,	/* PIIX4 at 33Mhz */
+	ich_pata_33		= 1,	/* ICH up to UDMA 33 only */
+	ich_pata_66		= 2,	/* ICH up to 66 Mhz */
+	ich_pata_100		= 3,	/* ICH up to UDMA 100 */
+	ich_pata_133		= 4,	/* ICH up to UDMA 133 */
+	ich5_sata		= 5,
+	ich6_sata		= 6,
+	ich6_sata_ahci		= 7,
+	ich6m_sata_ahci		= 8,
+	ich8_sata_ahci		= 9,
+	piix_pata_mwdma		= 10,	/* PIIX3 MWDMA only */
+	tolapai_sata_ahci	= 11,
+
 	/* constants for mapping table */
 	P0			= 0,  /* port 0 */
 	P1			= 1,  /* port 1 */
@@ -130,24 +147,6 @@
 	PIIX_HOST_BROKEN_SUSPEND = (1 << 24),
 };
 
-enum piix_controller_ids {
-	/* controller IDs */
-	piix_pata_mwdma,	/* PIIX3 MWDMA only */
-	piix_pata_33,		/* PIIX4 at 33Mhz */
-	ich_pata_33,		/* ICH up to UDMA 33 only */
-	ich_pata_66,		/* ICH up to 66 Mhz */
-	ich_pata_100,		/* ICH up to UDMA 100 */
-	ich_pata_100_nomwdma1,	/* ICH up to UDMA 100 but with no MWDMA1*/
-	ich5_sata,
-	ich6_sata,
-	ich6m_sata,
-	ich8_sata,
-	ich8_2port_sata,
-	ich8m_apple_sata,	/* locks up on second port enable */
-	tolapai_sata,
-	piix_pata_vmw,			/* PIIX4 for VMware, spurious DMA_ERR */
-};
-
 struct piix_map_db {
 	const u32 mask;
 	const u16 port_enable;
@@ -156,24 +155,15 @@
 
 struct piix_host_priv {
 	const int *map;
-	u32 saved_iocfg;
-	spinlock_t sidpr_lock;	/* FIXME: remove once locking in EH is fixed */
-	void __iomem *sidpr;
 };
 
-static int piix_init_one(struct pci_dev *pdev,
-			 const struct pci_device_id *ent);
-static void piix_remove_one(struct pci_dev *pdev);
-static int piix_pata_prereset(struct ata_link *link, unsigned long deadline);
-static void piix_set_piomode(struct ata_port *ap, struct ata_device *adev);
-static void piix_set_dmamode(struct ata_port *ap, struct ata_device *adev);
-static void ich_set_dmamode(struct ata_port *ap, struct ata_device *adev);
+static int piix_init_one (struct pci_dev *pdev,
+				    const struct pci_device_id *ent);
+static void piix_pata_error_handler(struct ata_port *ap);
+static void piix_set_piomode (struct ata_port *ap, struct ata_device *adev);
+static void piix_set_dmamode (struct ata_port *ap, struct ata_device *adev);
+static void ich_set_dmamode (struct ata_port *ap, struct ata_device *adev);
 static int ich_pata_cable_detect(struct ata_port *ap);
-static u8 piix_vmw_bmdma_status(struct ata_port *ap);
-static int piix_sidpr_scr_read(struct ata_link *link,
-			       unsigned int reg, u32 *val);
-static int piix_sidpr_scr_write(struct ata_link *link,
-				unsigned int reg, u32 val);
 #ifdef CONFIG_PM
 static int piix_pci_device_suspend(struct pci_dev *pdev, pm_message_t mesg);
 static int piix_pci_device_resume(struct pci_dev *pdev);
@@ -184,8 +174,6 @@
 static const struct pci_device_id piix_pci_tbl[] = {
 	/* Intel PIIX3 for the 430HX etc */
 	{ 0x8086, 0x7010, PCI_ANY_ID, PCI_ANY_ID, 0, 0, piix_pata_mwdma },
-	/* VMware ICH4 */
-	{ 0x8086, 0x7111, 0x15ad, 0x1976, 0, 0, piix_pata_vmw },
 	/* Intel PIIX4 for the 430TX/440BX/MX chipset: UDMA 33 */
 	/* Also PIIX4E (fn3 rev 2) and PIIX4M (fn3 rev 3) */
 	{ 0x8086, 0x7111, PCI_ANY_ID, PCI_ANY_ID, 0, 0, piix_pata_33 },
@@ -211,7 +199,7 @@
 	{ 0x8086, 0x24CA, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100 },
 	{ 0x8086, 0x24CB, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100 },
 	/* Intel ICH5 */
-	{ 0x8086, 0x24DB, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100 },
+	{ 0x8086, 0x24DB, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_133 },
 	/* C-ICH (i810E2) */
 	{ 0x8086, 0x245B, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100 },
 	/* ESB (855GME/875P + 6300ESB) UDMA 100  */
@@ -219,13 +207,15 @@
 	/* ICH6 (and 6) (i915) UDMA 100 */
 	{ 0x8086, 0x266F, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100 },
 	/* ICH7/7-R (i945, i975) UDMA 100*/
-	{ 0x8086, 0x27DF, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100_nomwdma1 },
-	{ 0x8086, 0x269E, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100_nomwdma1 },
+	{ 0x8086, 0x27DF, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_133 },
+	{ 0x8086, 0x269E, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100 },
 	/* ICH8 Mobile PATA Controller */
 	{ 0x8086, 0x2850, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich_pata_100 },
 
-	/* SATA ports */
-	
+	/* NOTE: The following PCI ids must be kept in sync with the
+	 * list in drivers/pci/quirks.c.
+	 */
+
 	/* 82801EB (ICH5) */
 	{ 0x8086, 0x24d1, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich5_sata },
 	/* 82801EB (ICH5) */
@@ -237,69 +227,36 @@
 	/* 82801FB/FW (ICH6/ICH6W) */
 	{ 0x8086, 0x2651, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6_sata },
 	/* 82801FR/FRW (ICH6R/ICH6RW) */
-	{ 0x8086, 0x2652, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6_sata },
-	/* 82801FBM ICH6M (ICH6R with only port 0 and 2 implemented).
-	 * Attach iff the controller is in IDE mode. */
-	{ 0x8086, 0x2653, PCI_ANY_ID, PCI_ANY_ID,
-	  PCI_CLASS_STORAGE_IDE << 8, 0xffff00, ich6m_sata },
+	{ 0x8086, 0x2652, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6_sata_ahci },
+	/* 82801FBM ICH6M (ICH6R with only port 0 and 2 implemented) */
+	{ 0x8086, 0x2653, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6m_sata_ahci },
 	/* 82801GB/GR/GH (ICH7, identical to ICH6) */
-	{ 0x8086, 0x27c0, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6_sata },
+	{ 0x8086, 0x27c0, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6_sata_ahci },
 	/* 2801GBM/GHM (ICH7M, identical to ICH6M) */
-	{ 0x8086, 0x27c4, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6m_sata },
+	{ 0x8086, 0x27c4, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6m_sata_ahci },
 	/* Enterprise Southbridge 2 (631xESB/632xESB) */
-	{ 0x8086, 0x2680, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6_sata },
+	{ 0x8086, 0x2680, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich6_sata_ahci },
 	/* SATA Controller 1 IDE (ICH8) */
-	{ 0x8086, 0x2820, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
+	{ 0x8086, 0x2820, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* SATA Controller 2 IDE (ICH8) */
-	{ 0x8086, 0x2825, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
-	/* Mobile SATA Controller IDE (ICH8M), Apple */
-	{ 0x8086, 0x2828, 0x106b, 0x00a0, 0, 0, ich8m_apple_sata },
-	{ 0x8086, 0x2828, 0x106b, 0x00a1, 0, 0, ich8m_apple_sata },
-	{ 0x8086, 0x2828, 0x106b, 0x00a3, 0, 0, ich8m_apple_sata },
+	{ 0x8086, 0x2825, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* Mobile SATA Controller IDE (ICH8M) */
-	{ 0x8086, 0x2828, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
+	{ 0x8086, 0x2828, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* SATA Controller IDE (ICH9) */
-	{ 0x8086, 0x2920, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
+	{ 0x8086, 0x2920, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* SATA Controller IDE (ICH9) */
-	{ 0x8086, 0x2921, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
+	{ 0x8086, 0x2921, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* SATA Controller IDE (ICH9) */
-	{ 0x8086, 0x2926, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
+	{ 0x8086, 0x2926, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* SATA Controller IDE (ICH9M) */
-	{ 0x8086, 0x2928, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
+	{ 0x8086, 0x2928, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* SATA Controller IDE (ICH9M) */
-	{ 0x8086, 0x292d, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
+	{ 0x8086, 0x292d, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* SATA Controller IDE (ICH9M) */
-	{ 0x8086, 0x292e, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
+	{ 0x8086, 0x292e, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata_ahci },
 	/* SATA Controller IDE (Tolapai) */
-	{ 0x8086, 0x5028, PCI_ANY_ID, PCI_ANY_ID, 0, 0, tolapai_sata },
-	/* SATA Controller IDE (ICH10) */
-	{ 0x8086, 0x3a00, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
-	/* SATA Controller IDE (ICH10) */
-	{ 0x8086, 0x3a06, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
-	/* SATA Controller IDE (ICH10) */
-	{ 0x8086, 0x3a20, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
-	/* SATA Controller IDE (ICH10) */
-	{ 0x8086, 0x3a26, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
-	/* SATA Controller IDE (PCH) */
-	{ 0x8086, 0x3b20, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
-	/* SATA Controller IDE (PCH) */
-	{ 0x8086, 0x3b21, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
-	/* SATA Controller IDE (PCH) */
-	{ 0x8086, 0x3b26, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
-	/* SATA Controller IDE (PCH) */
-	{ 0x8086, 0x3b28, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
-	/* SATA Controller IDE (PCH) */
-	{ 0x8086, 0x3b2d, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
-	/* SATA Controller IDE (PCH) */
-	{ 0x8086, 0x3b2e, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
-	/* SATA Controller IDE (CPT) */
-	{ 0x8086, 0x1c00, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
-	/* SATA Controller IDE (CPT) */
-	{ 0x8086, 0x1c01, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_sata },
-	/* SATA Controller IDE (CPT) */
-	{ 0x8086, 0x1c08, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
-	/* SATA Controller IDE (CPT) */
-	{ 0x8086, 0x1c09, PCI_ANY_ID, PCI_ANY_ID, 0, 0, ich8_2port_sata },
+	{ 0x8086, 0x5028, PCI_ANY_ID, PCI_ANY_ID, 0, 0, tolapai_sata_ahci },
+
 	{ }	/* terminate list */
 };
 
@@ -307,7 +264,7 @@
 	.name			= DRV_NAME,
 	.id_table		= piix_pci_tbl,
 	.probe			= piix_init_one,
-	.remove			= piix_remove_one,
+	.remove			= ata_pci_remove_one,
 #ifdef CONFIG_PM
 	.suspend		= piix_pci_device_suspend,
 	.resume			= piix_pci_device_resume,
@@ -315,37 +272,119 @@
 };
 
 static struct scsi_host_template piix_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations piix_pata_ops = {
-	.inherits		= &ata_bmdma32_port_ops,
-	.cable_detect		= ata_cable_40wire,
+static const struct ata_port_operations piix_pata_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= piix_set_piomode,
 	.set_dmamode		= piix_set_dmamode,
-	.prereset		= piix_pata_prereset,
-};
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= piix_pata_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ata_cable_40wire,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 
-static struct ata_port_operations piix_vmw_ops = {
-	.inherits		= &piix_pata_ops,
-	.bmdma_status		= piix_vmw_bmdma_status,
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations ich_pata_ops = {
-	.inherits		= &piix_pata_ops,
-	.cable_detect		= ich_pata_cable_detect,
+static const struct ata_port_operations ich_pata_ops = {
+	.port_disable		= ata_port_disable,
+	.set_piomode		= piix_set_piomode,
 	.set_dmamode		= ich_set_dmamode,
-};
+	.mode_filter		= ata_pci_default_filter,
 
-static struct ata_port_operations piix_sata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-};
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= piix_pata_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ich_pata_cable_detect,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
+};
+
+static const struct ata_port_operations piix_sata_ops = {
+	.port_disable		= ata_port_disable,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 
-static struct ata_port_operations piix_sidpr_sata_ops = {
-	.inherits		= &piix_sata_ops,
-	.hardreset		= sata_std_hardreset,
-	.scr_read		= piix_sidpr_scr_read,
-	.scr_write		= piix_sidpr_scr_write,
+	.port_start		= ata_port_start,
 };
 
 static const struct piix_map_db ich5_map_db = {
@@ -395,7 +434,7 @@
 
 static const struct piix_map_db ich8_map_db = {
 	.mask = 0x3,
-	.port_enable = 0xf,
+	.port_enable = 0x3,
 	.map = {
 		/* PM   PS   SM   SS       MAP */
 		{  P0,  P2,  P1,  P3 }, /* 00b (hardwired when in AHCI) */
@@ -405,178 +444,149 @@
 	},
 };
 
-static const struct piix_map_db ich8_2port_map_db = {
-	.mask = 0x3,
-	.port_enable = 0x3,
-	.map = {
-		/* PM   PS   SM   SS       MAP */
-		{  P0,  NA,  P1,  NA }, /* 00b */
-		{  RV,  RV,  RV,  RV }, /* 01b */
-		{  RV,  RV,  RV,  RV }, /* 10b */
-		{  RV,  RV,  RV,  RV },
-	},
-};
-
-static const struct piix_map_db ich8m_apple_map_db = {
-	.mask = 0x3,
-	.port_enable = 0x1,
-	.map = {
-		/* PM   PS   SM   SS       MAP */
-		{  P0,  NA,  NA,  NA }, /* 00b */
-		{  RV,  RV,  RV,  RV },
-		{  P0,  P2, IDE, IDE }, /* 10b */
-		{  RV,  RV,  RV,  RV },
-	},
-};
-
 static const struct piix_map_db tolapai_map_db = {
-	.mask = 0x3,
-	.port_enable = 0x3,
-	.map = {
-		/* PM   PS   SM   SS       MAP */
-		{  P0,  NA,  P1,  NA }, /* 00b */
-		{  RV,  RV,  RV,  RV }, /* 01b */
-		{  RV,  RV,  RV,  RV }, /* 10b */
-		{  RV,  RV,  RV,  RV },
-	},
+        .mask = 0x3,
+        .port_enable = 0x3,
+        .map = {
+                /* PM   PS   SM   SS       MAP */
+                {  P0,  NA,  P1,  NA }, /* 00b */
+                {  RV,  RV,  RV,  RV }, /* 01b */
+                {  RV,  RV,  RV,  RV }, /* 10b */
+                {  RV,  RV,  RV,  RV },
+        },
 };
 
 static const struct piix_map_db *piix_map_db_table[] = {
 	[ich5_sata]		= &ich5_map_db,
 	[ich6_sata]		= &ich6_map_db,
-	[ich6m_sata]		= &ich6m_map_db,
-	[ich8_sata]		= &ich8_map_db,
-	[ich8_2port_sata]	= &ich8_2port_map_db,
-	[ich8m_apple_sata]	= &ich8m_apple_map_db,
-	[tolapai_sata]		= &tolapai_map_db,
+	[ich6_sata_ahci]	= &ich6_map_db,
+	[ich6m_sata_ahci]	= &ich6m_map_db,
+	[ich8_sata_ahci]	= &ich8_map_db,
+	[tolapai_sata_ahci]	= &tolapai_map_db,
 };
 
 static struct ata_port_info piix_port_info[] = {
-	[piix_pata_mwdma] = 	/* PIIX3 MWDMA only */
+	/* piix_pata_33: 0:  PIIX4 at 33MHz */
 	{
+		.sht		= &piix_sht,
 		.flags		= PIIX_PATA_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA12_ONLY, /* mwdma1-2 ?? CHECK 0 should be ok but slow */
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x06, /* mwdma1-2 ?? CHECK 0 should be ok but slow */
+		.udma_mask	= ATA_UDMA_MASK_40C,
 		.port_ops	= &piix_pata_ops,
 	},
 
-	[piix_pata_33] =	/* PIIX4 at 33MHz */
+	/* ich_pata_33: 1 	ICH0 - ICH at 33Mhz*/
 	{
+		.sht		= &piix_sht,
 		.flags		= PIIX_PATA_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA12_ONLY, /* mwdma1-2 ?? CHECK 0 should be ok but slow */
-		.udma_mask	= ATA_UDMA2,
-		.port_ops	= &piix_pata_ops,
-	},
-
-	[ich_pata_33] = 	/* ICH0 - ICH at 33Mhz*/
-	{
-		.flags		= PIIX_PATA_FLAGS,
-		.pio_mask 	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA12_ONLY, /* Check: maybe MWDMA0 is ok  */
-		.udma_mask	= ATA_UDMA2,
+		.pio_mask 	= 0x1f,	/* pio 0-4 */
+		.mwdma_mask	= 0x06, /* Check: maybe 0x07  */
+		.udma_mask	= ATA_UDMA2, /* UDMA33 */
 		.port_ops	= &ich_pata_ops,
 	},
-
-	[ich_pata_66] = 	/* ICH controllers up to 66MHz */
+	/* ich_pata_66: 2 	ICH controllers up to 66MHz */
 	{
+		.sht		= &piix_sht,
 		.flags		= PIIX_PATA_FLAGS,
-		.pio_mask 	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA12_ONLY, /* MWDMA0 is broken on chip */
+		.pio_mask 	= 0x1f,	/* pio 0-4 */
+		.mwdma_mask	= 0x06, /* MWDMA0 is broken on chip */
 		.udma_mask	= ATA_UDMA4,
 		.port_ops	= &ich_pata_ops,
 	},
 
-	[ich_pata_100] =
+	/* ich_pata_100: 3 */
 	{
+		.sht		= &piix_sht,
 		.flags		= PIIX_PATA_FLAGS | PIIX_FLAG_CHECKINTR,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA12_ONLY,
-		.udma_mask	= ATA_UDMA5,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x06, /* mwdma1-2 */
+		.udma_mask	= ATA_UDMA5, /* udma0-5 */
 		.port_ops	= &ich_pata_ops,
 	},
 
-	[ich_pata_100_nomwdma1] =
+	/* ich_pata_133: 4 	ICH with full UDMA6 */
 	{
+		.sht		= &piix_sht,
 		.flags		= PIIX_PATA_FLAGS | PIIX_FLAG_CHECKINTR,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2_ONLY,
-		.udma_mask	= ATA_UDMA5,
+		.pio_mask 	= 0x1f,	/* pio 0-4 */
+		.mwdma_mask	= 0x06, /* Check: maybe 0x07  */
+		.udma_mask	= ATA_UDMA6, /* UDMA133 */
 		.port_ops	= &ich_pata_ops,
 	},
 
-	[ich5_sata] =
+	/* ich5_sata: 5 */
 	{
+		.sht		= &piix_sht,
 		.flags		= PIIX_SATA_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &piix_sata_ops,
 	},
 
-	[ich6_sata] =
+	/* ich6_sata: 6 */
 	{
-		.flags		= PIIX_SATA_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.sht		= &piix_sht,
+		.flags		= PIIX_SATA_FLAGS | PIIX_FLAG_SCR,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &piix_sata_ops,
 	},
 
-	[ich6m_sata] =
+	/* ich6_sata_ahci: 7 */
 	{
-		.flags		= PIIX_SATA_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.sht		= &piix_sht,
+		.flags		= PIIX_SATA_FLAGS | PIIX_FLAG_SCR |
+				  PIIX_FLAG_AHCI,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &piix_sata_ops,
 	},
 
-	[ich8_sata] =
+	/* ich6m_sata_ahci: 8 */
 	{
-		.flags		= PIIX_SATA_FLAGS | PIIX_FLAG_SIDPR,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.sht		= &piix_sht,
+		.flags		= PIIX_SATA_FLAGS | PIIX_FLAG_SCR |
+				  PIIX_FLAG_AHCI,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &piix_sata_ops,
 	},
 
-	[ich8_2port_sata] =
+	/* ich8_sata_ahci: 9 */
 	{
-		.flags		= PIIX_SATA_FLAGS | PIIX_FLAG_SIDPR,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.sht		= &piix_sht,
+		.flags		= PIIX_SATA_FLAGS | PIIX_FLAG_SCR |
+				  PIIX_FLAG_AHCI,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &piix_sata_ops,
 	},
 
-	[tolapai_sata] =
+	/* piix_pata_mwdma: 10:  PIIX3 MWDMA only */
 	{
-		.flags		= PIIX_SATA_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &piix_sata_ops,
+		.sht		= &piix_sht,
+		.flags		= PIIX_PATA_FLAGS,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x06, /* mwdma1-2 ?? CHECK 0 should be ok but slow */
+		.port_ops	= &piix_pata_ops,
 	},
 
-	[ich8m_apple_sata] =
+	/* tolapai_sata_ahci: 11: */
 	{
-		.flags		= PIIX_SATA_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.sht		= &piix_sht,
+		.flags		= PIIX_SATA_FLAGS | PIIX_FLAG_SCR |
+				  PIIX_FLAG_AHCI,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &piix_sata_ops,
 	},
-
-	[piix_pata_vmw] =
-	{
-		.flags		= PIIX_PATA_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA12_ONLY, /* mwdma1-2 ?? CHECK 0 should be ok but slow */
-		.udma_mask	= ATA_UDMA2,
-		.port_ops	= &piix_vmw_ops,
-	},
-
 };
 
 static struct pci_bits piix_enable_bits[] = {
@@ -603,19 +613,9 @@
 static const struct ich_laptop ich_laptop[] = {
 	/* devid, subvendor, subdev */
 	{ 0x27DF, 0x0005, 0x0280 },	/* ICH7 on Acer 5602WLMi */
-	{ 0x27DF, 0x1025, 0x0102 },	/* ICH7 on Acer 5602aWLMi */
 	{ 0x27DF, 0x1025, 0x0110 },	/* ICH7 on Acer 3682WLMi */
-	{ 0x27DF, 0x1028, 0x02b0 },	/* ICH7 on unknown Dell */
 	{ 0x27DF, 0x1043, 0x1267 },	/* ICH7 on Asus W5F */
-	{ 0x27DF, 0x103C, 0x30A1 },	/* ICH7 on HP Compaq nc2400 */
-	{ 0x27DF, 0x103C, 0x361a },	/* ICH7 on unkown HP  */
-	{ 0x27DF, 0x1071, 0xD221 },	/* ICH7 on Hercules EC-900 */
-	{ 0x27DF, 0x152D, 0x0778 },	/* ICH7 on unknown Intel */
 	{ 0x24CA, 0x1025, 0x0061 },	/* ICH4 on ACER Aspire 2023WLMi */
-	{ 0x24CA, 0x1025, 0x003d },	/* ICH4 on ACER TM290 */
-	{ 0x266F, 0x1025, 0x0066 },	/* ICH6 on ACER Aspire 1694WLMi */
-	{ 0x2653, 0x1043, 0x82D8 },	/* ICH6M on Asus Eee 701 */
-	{ 0x27df, 0x104d, 0x900e },	/* ICH7 on Sony TZ-90 */
 	/* end marker */
 	{ 0, }
 };
@@ -634,46 +634,49 @@
 static int ich_pata_cable_detect(struct ata_port *ap)
 {
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	struct piix_host_priv *hpriv = ap->host->private_data;
 	const struct ich_laptop *lap = &ich_laptop[0];
-	u8 mask;
+	u8 tmp, mask;
 
 	/* Check for specials - Acer Aspire 5602WLMi */
 	while (lap->device) {
 		if (lap->device == pdev->device &&
 		    lap->subvendor == pdev->subsystem_vendor &&
-		    lap->subdevice == pdev->subsystem_device)
+		    lap->subdevice == pdev->subsystem_device) {
 			return ATA_CBL_PATA40_SHORT;
-
+		}
 		lap++;
 	}
 
 	/* check BIOS cable detect results */
 	mask = ap->port_no == 0 ? PIIX_80C_PRI : PIIX_80C_SEC;
-	if ((hpriv->saved_iocfg & mask) == 0)
+	pci_read_config_byte(pdev, PIIX_IOCFG, &tmp);
+	if ((tmp & mask) == 0)
 		return ATA_CBL_PATA40;
 	return ATA_CBL_PATA80;
 }
 
 /**
  *	piix_pata_prereset - prereset for PATA host controller
- *	@link: Target link
+ *	@ap: Target port
  *	@deadline: deadline jiffies for the operation
  *
  *	LOCKING:
  *	None (inherited from caller).
  */
-static int piix_pata_prereset(struct ata_link *link, unsigned long deadline)
+static int piix_pata_prereset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	if (!pci_test_config_bits(pdev, &piix_enable_bits[ap->port_no]))
 		return -ENOENT;
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
 }
 
-static DEFINE_SPINLOCK(piix_lock);
+static void piix_pata_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, piix_pata_prereset, ata_std_softreset, NULL,
+			   ata_std_postreset);
+}
 
 /**
  *	piix_set_piomode - Initialize host controller PATA PIO timings
@@ -686,11 +689,10 @@
  *	None (inherited from caller).
  */
 
-static void piix_set_piomode(struct ata_port *ap, struct ata_device *adev)
+static void piix_set_piomode (struct ata_port *ap, struct ata_device *adev)
 {
-	struct pci_dev *dev	= to_pci_dev(ap->host->dev);
-	unsigned long flags;
 	unsigned int pio	= adev->pio_mode - XFER_PIO_0;
+	struct pci_dev *dev	= to_pci_dev(ap->host->dev);
 	unsigned int is_slave	= (adev->devno != 0);
 	unsigned int master_port= ap->port_no ? 0x42 : 0x40;
 	unsigned int slave_port	= 0x44;
@@ -720,8 +722,6 @@
 	if (adev->class == ATA_DEV_ATA)
 		control |= 4;	/* PPE enable */
 
-	spin_lock_irqsave(&piix_lock, flags);
-
 	/* PIO configuration clears DTE unconditionally.  It will be
 	 * programmed in set_dmamode which is guaranteed to be called
 	 * after set_piomode if any DMA mode is available.
@@ -730,7 +730,7 @@
 	if (is_slave) {
 		/* clear TIME1|IE1|PPE1|DTE1 */
 		master_data &= 0xff0f;
-		/* Enable SITRE (separate slave timing register) */
+		/* Enable SITRE (seperate slave timing register) */
 		master_data |= 0x4000;
 		/* enable PPE1, IE1 and TIME1 as needed */
 		master_data |= (control << 4);
@@ -761,14 +761,13 @@
 		udma_enable &= ~(1 << (2 * ap->port_no + adev->devno));
 		pci_write_config_byte(dev, 0x48, udma_enable);
 	}
-
-	spin_unlock_irqrestore(&piix_lock, flags);
 }
 
 /**
  *	do_pata_set_dmamode - Initialize host controller PATA PIO timings
  *	@ap: Port whose timings we are configuring
  *	@adev: Drive in question
+ *	@udma: udma mode, 0 - 6
  *	@isich: set if the chip is an ICH device
  *
  *	Set UDMA mode for device, in host controller PCI config space.
@@ -777,10 +776,9 @@
  *	None (inherited from caller).
  */
 
-static void do_pata_set_dmamode(struct ata_port *ap, struct ata_device *adev, int isich)
+static void do_pata_set_dmamode (struct ata_port *ap, struct ata_device *adev, int isich)
 {
 	struct pci_dev *dev	= to_pci_dev(ap->host->dev);
-	unsigned long flags;
 	u8 master_port		= ap->port_no ? 0x42 : 0x40;
 	u16 master_data;
 	u8 speed		= adev->dma_mode;
@@ -794,8 +792,6 @@
 			    { 2, 1 },
 			    { 2, 3 }, };
 
-	spin_lock_irqsave(&piix_lock, flags);
-
 	pci_read_config_word(dev, master_port, &master_data);
 	if (ap->udma_mask)
 		pci_read_config_byte(dev, 0x48, &udma_enable);
@@ -807,7 +803,7 @@
 		int u_clock, u_speed;
 
 		/*
-		 * UDMA is handled by a combination of clock switching and
+	 	 * UDMA is handled by a combination of clock switching and
 		 * selection of dividers
 		 *
 		 * Handy rule: Odd modes are UDMATIMx 01, even are 02
@@ -878,16 +874,14 @@
 				(timings[pio][1] << 8);
 		}
 
-		if (ap->udma_mask)
+		if (ap->udma_mask) {
 			udma_enable &= ~(1 << devid);
-
-		pci_write_config_word(dev, master_port, master_data);
+			pci_write_config_word(dev, master_port, master_data);
+		}
 	}
 	/* Don't scribble on 0x48 if the controller does not support UDMA */
 	if (ap->udma_mask)
 		pci_write_config_byte(dev, 0x48, udma_enable);
-
-	spin_unlock_irqrestore(&piix_lock, flags);
 }
 
 /**
@@ -901,7 +895,7 @@
  *	None (inherited from caller).
  */
 
-static void piix_set_dmamode(struct ata_port *ap, struct ata_device *adev)
+static void piix_set_dmamode (struct ata_port *ap, struct ata_device *adev)
 {
 	do_pata_set_dmamode(ap, adev, 0);
 }
@@ -917,70 +911,15 @@
  *	None (inherited from caller).
  */
 
-static void ich_set_dmamode(struct ata_port *ap, struct ata_device *adev)
+static void ich_set_dmamode (struct ata_port *ap, struct ata_device *adev)
 {
 	do_pata_set_dmamode(ap, adev, 1);
 }
 
-/*
- * Serial ATA Index/Data Pair Superset Registers access
- *
- * Beginning from ICH8, there's a sane way to access SCRs using index
- * and data register pair located at BAR5 which means that we have
- * separate SCRs for master and slave.  This is handled using libata
- * slave_link facility.
- */
-static const int piix_sidx_map[] = {
-	[SCR_STATUS]	= 0,
-	[SCR_ERROR]	= 2,
-	[SCR_CONTROL]	= 1,
-};
-
-static void piix_sidpr_sel(struct ata_link *link, unsigned int reg)
-{
-	struct ata_port *ap = link->ap;
-	struct piix_host_priv *hpriv = ap->host->private_data;
-
-	iowrite32(((ap->port_no * 2 + link->pmp) << 8) | piix_sidx_map[reg],
-		  hpriv->sidpr + PIIX_SIDPR_IDX);
-}
-
-static int piix_sidpr_scr_read(struct ata_link *link,
-			       unsigned int reg, u32 *val)
-{
-	struct piix_host_priv *hpriv = link->ap->host->private_data;
-	unsigned long flags;
-
-	if (reg >= ARRAY_SIZE(piix_sidx_map))
-		return -EINVAL;
-
-	spin_lock_irqsave(&hpriv->sidpr_lock, flags);
-	piix_sidpr_sel(link, reg);
-	*val = ioread32(hpriv->sidpr + PIIX_SIDPR_DATA);
-	spin_unlock_irqrestore(&hpriv->sidpr_lock, flags);
-	return 0;
-}
-
-static int piix_sidpr_scr_write(struct ata_link *link,
-				unsigned int reg, u32 val)
-{
-	struct piix_host_priv *hpriv = link->ap->host->private_data;
-	unsigned long flags;
-
-	if (reg >= ARRAY_SIZE(piix_sidx_map))
-		return -EINVAL;
-
-	spin_lock_irqsave(&hpriv->sidpr_lock, flags);
-	piix_sidpr_sel(link, reg);
-	iowrite32(val, hpriv->sidpr + PIIX_SIDPR_DATA);
-	spin_unlock_irqrestore(&hpriv->sidpr_lock, flags);
-	return 0;
-}
-
 #ifdef CONFIG_PM
 static int piix_broken_suspend(void)
 {
-	static const struct dmi_system_id sysids[] = {
+	static struct dmi_system_id sysids[] = {
 		{
 			.ident = "TECRA M3",
 			.matches = {
@@ -989,27 +928,6 @@
 			},
 		},
 		{
-			.ident = "TECRA M3",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "Tecra M3"),
-			},
-		},
-		{
-			.ident = "TECRA M4",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "Tecra M4"),
-			},
-		},
-		{
-			.ident = "TECRA M4",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "TECRA M4"),
-			},
-		},
-		{
 			.ident = "TECRA M5",
 			.matches = {
 				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
@@ -1017,13 +935,6 @@
 			},
 		},
 		{
-			.ident = "TECRA M6",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "TECRA M6"),
-			},
-		},
-		{
 			.ident = "TECRA M7",
 			.matches = {
 				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
@@ -1031,27 +942,6 @@
 			},
 		},
 		{
-			.ident = "TECRA A8",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "TECRA A8"),
-			},
-		},
-		{
-			.ident = "Satellite R20",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "Satellite R20"),
-			},
-		},
-		{
-			.ident = "Satellite R25",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "Satellite R25"),
-			},
-		},
-		{
 			.ident = "Satellite U200",
 			.matches = {
 				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
@@ -1059,20 +949,6 @@
 			},
 		},
 		{
-			.ident = "Satellite U200",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "SATELLITE U200"),
-			},
-		},
-		{
-			.ident = "Satellite Pro U200",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "SATELLITE PRO U200"),
-			},
-		},
-		{
 			.ident = "Satellite U205",
 			.matches = {
 				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
@@ -1080,26 +956,12 @@
 			},
 		},
 		{
-			.ident = "SATELLITE U205",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "SATELLITE U205"),
-			},
-		},
-		{
 			.ident = "Portege M500",
 			.matches = {
 				DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
 				DMI_MATCH(DMI_PRODUCT_NAME, "PORTEGE M500"),
 			},
 		},
-		{
-			.ident = "VGN-BX297XP",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Sony Corporation"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "VGN-BX297XP"),
-			},
-		},
 
 		{ }	/* terminate list */
 	};
@@ -1115,21 +977,6 @@
 		if (dmi_find_device(DMI_DEV_TYPE_OEM_STRING, oemstrs[i], NULL))
 			return 1;
 
-	/* TECRA M4 sometimes forgets its identify and reports bogus
-	 * DMI information.  As the bogus information is a bit
-	 * generic, match as many entries as possible.  This manual
-	 * matching is necessary because dmi_system_id.matches is
-	 * limited to four entries.
-	 */
-	if (dmi_match(DMI_SYS_VENDOR, "TOSHIBA") &&
-	    dmi_match(DMI_PRODUCT_NAME, "000000") &&
-	    dmi_match(DMI_PRODUCT_VERSION, "000000") &&
-	    dmi_match(DMI_PRODUCT_SERIAL, "000000") &&
-	    dmi_match(DMI_BOARD_VENDOR, "TOSHIBA") &&
-	    dmi_match(DMI_BOARD_NAME, "Portable PC") &&
-	    dmi_match(DMI_BOARD_VERSION, "Version A0"))
-		return 1;
-
 	return 0;
 }
 
@@ -1148,7 +995,7 @@
 	 * cycles and power trying to do something to the sleeping
 	 * beauty.
 	 */
-	if (piix_broken_suspend() && (mesg.event & PM_EVENT_SLEEP)) {
+	if (piix_broken_suspend() && mesg.event == PM_EVENT_SUSPEND) {
 		pci_save_state(pdev);
 
 		/* mark its power state as "unknown", since we don't
@@ -1200,11 +1047,6 @@
 }
 #endif
 
-static u8 piix_vmw_bmdma_status(struct ata_port *ap)
-{
-	return ata_bmdma_status(ap) & ~ATA_DMA_ERR;
-}
-
 #define AHCI_PCI_BAR 5
 #define AHCI_GLOBAL_CTL 0x04
 #define AHCI_ENABLE (1 << 31)
@@ -1226,12 +1068,12 @@
 	if (!mmio)
 		return -ENOMEM;
 
-	tmp = ioread32(mmio + AHCI_GLOBAL_CTL);
+	tmp = readl(mmio + AHCI_GLOBAL_CTL);
 	if (tmp & AHCI_ENABLE) {
 		tmp &= ~AHCI_ENABLE;
-		iowrite32(tmp, mmio + AHCI_GLOBAL_CTL);
+		writel(tmp, mmio + AHCI_GLOBAL_CTL);
 
-		tmp = ioread32(mmio + AHCI_GLOBAL_CTL);
+		tmp = readl(mmio + AHCI_GLOBAL_CTL);
 		if (tmp & AHCI_ENABLE)
 			rc = -EIO;
 	}
@@ -1254,7 +1096,8 @@
 	u16 cfg;
 	int no_piix_dma = 0;
 
-	while ((pdev = pci_get_device(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_82454NX, pdev)) != NULL) {
+	while((pdev = pci_get_device(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_82454NX, pdev)) != NULL)
+	{
 		/* Look for 450NX PXB. Check for problem configurations
 		   A PCI quirk checks bit 6 already */
 		pci_read_config_word(pdev, 0x41, &cfg);
@@ -1272,10 +1115,10 @@
 	return no_piix_dma;
 }
 
-static void __devinit piix_init_pcs(struct ata_host *host,
+static void __devinit piix_init_pcs(struct pci_dev *pdev,
+				    struct ata_port_info *pinfo,
 				    const struct piix_map_db *map_db)
 {
-	struct pci_dev *pdev = to_pci_dev(host->dev);
 	u16 pcs, new_pcs;
 
 	pci_read_config_word(pdev, ICH5_PCS, &pcs);
@@ -1289,11 +1132,12 @@
 	}
 }
 
-static const int *__devinit piix_init_sata_map(struct pci_dev *pdev,
-					       struct ata_port_info *pinfo,
-					       const struct piix_map_db *map_db)
+static void __devinit piix_init_sata_map(struct pci_dev *pdev,
+					 struct ata_port_info *pinfo,
+					 const struct piix_map_db *map_db)
 {
-	const int *map;
+	struct piix_host_priv *hpriv = pinfo[0].private_data;
+	const unsigned int *map;
 	int i, invalid_map = 0;
 	u8 map_value;
 
@@ -1316,6 +1160,7 @@
 		case IDE:
 			WARN_ON((i & 1) || map[i + 1] != IDE);
 			pinfo[i / 2] = piix_port_info[ich_pata_100];
+			pinfo[i / 2].private_data = hpriv;
 			i++;
 			printk(" IDE IDE");
 			break;
@@ -1333,112 +1178,12 @@
 		dev_printk(KERN_ERR, &pdev->dev,
 			   "invalid MAP value %u\n", map_value);
 
-	return map;
-}
-
-static bool piix_no_sidpr(struct ata_host *host)
-{
-	struct pci_dev *pdev = to_pci_dev(host->dev);
-
-	/*
-	 * Samsung DB-P70 only has three ATA ports exposed and
-	 * curiously the unconnected first port reports link online
-	 * while not responding to SRST protocol causing excessive
-	 * detection delay.
-	 *
-	 * Unfortunately, the system doesn't carry enough DMI
-	 * information to identify the machine but does have subsystem
-	 * vendor and device set.  As it's unclear whether the
-	 * subsystem vendor/device is used only for this specific
-	 * board, the port can't be disabled solely with the
-	 * information; however, turning off SIDPR access works around
-	 * the problem.  Turn it off.
-	 *
-	 * This problem is reported in bnc#441240.
-	 *
-	 * https://bugzilla.novell.com/show_bug.cgi?id=441420
-	 */
-	if (pdev->vendor == PCI_VENDOR_ID_INTEL && pdev->device == 0x2920 &&
-	    pdev->subsystem_vendor == PCI_VENDOR_ID_SAMSUNG &&
-	    pdev->subsystem_device == 0xb049) {
-		dev_printk(KERN_WARNING, host->dev,
-			   "Samsung DB-P70 detected, disabling SIDPR\n");
-		return true;
-	}
-
-	return false;
-}
-
-static int __devinit piix_init_sidpr(struct ata_host *host)
-{
-	struct pci_dev *pdev = to_pci_dev(host->dev);
-	struct piix_host_priv *hpriv = host->private_data;
-	struct ata_link *link0 = &host->ports[0]->link;
-	u32 scontrol;
-	int i, rc;
-
-	/* check for availability */
-	for (i = 0; i < 4; i++)
-		if (hpriv->map[i] == IDE)
-			return 0;
-
-	/* is it blacklisted? */
-	if (piix_no_sidpr(host))
-		return 0;
-
-	if (!(host->ports[0]->flags & PIIX_FLAG_SIDPR))
-		return 0;
-
-	if (pci_resource_start(pdev, PIIX_SIDPR_BAR) == 0 ||
-	    pci_resource_len(pdev, PIIX_SIDPR_BAR) != PIIX_SIDPR_LEN)
-		return 0;
-
-	if (pcim_iomap_regions(pdev, 1 << PIIX_SIDPR_BAR, DRV_NAME))
-		return 0;
-
-	hpriv->sidpr = pcim_iomap_table(pdev)[PIIX_SIDPR_BAR];
-
-	/* SCR access via SIDPR doesn't work on some configurations.
-	 * Give it a test drive by inhibiting power save modes which
-	 * we'll do anyway.
-	 */
-	piix_sidpr_scr_read(link0, SCR_CONTROL, &scontrol);
-
-	/* if IPM is already 3, SCR access is probably working.  Don't
-	 * un-inhibit power save modes as BIOS might have inhibited
-	 * them for a reason.
-	 */
-	if ((scontrol & 0xf00) != 0x300) {
-		scontrol |= 0x300;
-		piix_sidpr_scr_write(link0, SCR_CONTROL, scontrol);
-		piix_sidpr_scr_read(link0, SCR_CONTROL, &scontrol);
-
-		if ((scontrol & 0xf00) != 0x300) {
-			dev_printk(KERN_INFO, host->dev, "SCR access via "
-				   "SIDPR is available but doesn't work\n");
-			return 0;
-		}
-	}
-
-	/* okay, SCRs available, set ops and ask libata for slave_link */
-	for (i = 0; i < 2; i++) {
-		struct ata_port *ap = host->ports[i];
-
-		ap->ops = &piix_sidpr_sata_ops;
-
-		if (ap->flags & ATA_FLAG_SLAVE_POSS) {
-			rc = ata_slave_link_init(ap);
-			if (rc)
-				return rc;
-		}
-	}
-
-	return 0;
+	hpriv->map = map;
 }
 
-static void piix_iocfg_bit18_quirk(struct ata_host *host)
+static void piix_iocfg_bit18_quirk(struct pci_dev *pdev)
 {
-	static const struct dmi_system_id sysids[] = {
+	static struct dmi_system_id sysids[] = {
 		{
 			/* Clevo M570U sets IOCFG bit 18 if the cdrom
 			 * isn't used to boot the system which
@@ -1453,8 +1198,7 @@
 
 		{ }	/* terminate list */
 	};
-	struct pci_dev *pdev = to_pci_dev(host->dev);
-	struct piix_host_priv *hpriv = host->private_data;
+	u32 iocfg;
 
 	if (!dmi_check_system(sysids))
 		return;
@@ -1463,47 +1207,13 @@
 	 * seem to use it to disable a channel.  Clear the bit on the
 	 * affected systems.
 	 */
-	if (hpriv->saved_iocfg & (1 << 18)) {
+	pci_read_config_dword(pdev, PIIX_IOCFG, &iocfg);
+	if (iocfg & (1 << 18)) {
 		dev_printk(KERN_INFO, &pdev->dev,
 			   "applying IOCFG bit18 quirk\n");
-		pci_write_config_dword(pdev, PIIX_IOCFG,
-				       hpriv->saved_iocfg & ~(1 << 18));
-	}
-}
-
-static bool piix_broken_system_poweroff(struct pci_dev *pdev)
-{
-	static const struct dmi_system_id broken_systems[] = {
-		{
-			.ident = "HP Compaq 2510p",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "HP Compaq 2510p"),
-			},
-			/* PCI slot number of the controller */
-			.driver_data = (void *)0x1FUL,
-		},
-		{
-			.ident = "HP Compaq nc6000",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "HP Compaq nc6000"),
-			},
-			/* PCI slot number of the controller */
-			.driver_data = (void *)0x1FUL,
-		},
-
-		{ }	/* terminate list */
-	};
-	const struct dmi_system_id *dmi = dmi_first_match(broken_systems);
-
-	if (dmi) {
-		unsigned long slot = (unsigned long)dmi->driver_data;
-		/* apply the quirk only to on-board controllers */
-		return slot == PCI_SLOT(pdev->devfn);
+		iocfg &= ~(1 << 18);
+		pci_write_config_dword(pdev, PIIX_IOCFG, iocfg);
 	}
-
-	return false;
 }
 
 /**
@@ -1521,86 +1231,54 @@
  *	Zero on success, or -ERRNO value.
  */
 
-static int __devinit piix_init_one(struct pci_dev *pdev,
-				   const struct pci_device_id *ent)
+static int piix_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
 	struct device *dev = &pdev->dev;
 	struct ata_port_info port_info[2];
 	const struct ata_port_info *ppi[] = { &port_info[0], &port_info[1] };
-	unsigned long port_flags;
-	struct ata_host *host;
 	struct piix_host_priv *hpriv;
-	int rc;
+	unsigned long port_flags;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "version " DRV_VERSION "\n");
 
-	/* no hotplugging support for later devices (FIXME) */
-	if (!in_module_init && ent->driver_data >= ich5_sata)
+	/* no hotplugging support (FIXME) */
+	if (!in_module_init)
 		return -ENODEV;
 
-	if (piix_broken_system_poweroff(pdev)) {
-		piix_port_info[ent->driver_data].flags |=
-				ATA_FLAG_NO_POWEROFF_SPINDOWN |
-					ATA_FLAG_NO_HIBERNATE_SPINDOWN;
-		dev_info(&pdev->dev, "quirky BIOS, skipping spindown "
-				"on poweroff and hibernation\n");
-	}
+	hpriv = devm_kzalloc(dev, sizeof(*hpriv), GFP_KERNEL);
+	if (!hpriv)
+		return -ENOMEM;
 
 	port_info[0] = piix_port_info[ent->driver_data];
 	port_info[1] = piix_port_info[ent->driver_data];
+	port_info[0].private_data = hpriv;
+	port_info[1].private_data = hpriv;
 
 	port_flags = port_info[0].flags;
 
-	/* enable device and prepare host */
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
-	hpriv = devm_kzalloc(dev, sizeof(*hpriv), GFP_KERNEL);
-	if (!hpriv)
-		return -ENOMEM;
-	spin_lock_init(&hpriv->sidpr_lock);
-
-	/* Save IOCFG, this will be used for cable detection, quirk
-	 * detection and restoration on detach.  This is necessary
-	 * because some ACPI implementations mess up cable related
-	 * bits on _STM.  Reported on kernel bz#11879.
-	 */
-	pci_read_config_dword(pdev, PIIX_IOCFG, &hpriv->saved_iocfg);
-
-	/* ICH6R may be driven by either ata_piix or ahci driver
-	 * regardless of BIOS configuration.  Make sure AHCI mode is
-	 * off.
-	 */
-	if (pdev->vendor == PCI_VENDOR_ID_INTEL && pdev->device == 0x2652) {
-		rc = piix_disable_ahci(pdev);
-		if (rc)
-			return rc;
+	if (port_flags & PIIX_FLAG_AHCI) {
+		u8 tmp;
+		pci_read_config_byte(pdev, PIIX_SCC, &tmp);
+		if (tmp == PIIX_AHCI_DEVICE) {
+			int rc = piix_disable_ahci(pdev);
+			if (rc)
+				return rc;
+		}
 	}
 
-	/* SATA map init can change port_info, do it before prepping host */
-	if (port_flags & ATA_FLAG_SATA)
-		hpriv->map = piix_init_sata_map(pdev, port_info,
-					piix_map_db_table[ent->driver_data]);
-
-	rc = ata_pci_sff_prepare_host(pdev, ppi, &host);
-	if (rc)
-		return rc;
-	host->private_data = hpriv;
-
-	/* initialize controller */
+	/* Initialize SATA map */
 	if (port_flags & ATA_FLAG_SATA) {
-		piix_init_pcs(host, piix_map_db_table[ent->driver_data]);
-		rc = piix_init_sidpr(host);
-		if (rc)
-			return rc;
+		piix_init_sata_map(pdev, port_info,
+				   piix_map_db_table[ent->driver_data]);
+		piix_init_pcs(pdev, port_info,
+			      piix_map_db_table[ent->driver_data]);
 	}
 
 	/* apply IOCFG bit18 quirk */
-	piix_iocfg_bit18_quirk(host);
+	piix_iocfg_bit18_quirk(pdev);
 
 	/* On ICH5, some BIOSen disable the interrupt using the
 	 * PCI_COMMAND_INTX_DISABLE bit added in PCI 2.3.
@@ -1615,25 +1293,12 @@
 		/* This writes into the master table but it does not
 		   really matter for this errata as we will apply it to
 		   all the PIIX devices on the board */
-		host->ports[0]->mwdma_mask = 0;
-		host->ports[0]->udma_mask = 0;
-		host->ports[1]->mwdma_mask = 0;
-		host->ports[1]->udma_mask = 0;
+		port_info[0].mwdma_mask = 0;
+		port_info[0].udma_mask = 0;
+		port_info[1].mwdma_mask = 0;
+		port_info[1].udma_mask = 0;
 	}
-	host->flags |= ATA_HOST_PARALLEL_SCAN;
-
-	pci_set_master(pdev);
-	return ata_pci_sff_activate_host(host, ata_sff_interrupt, &piix_sht);
-}
-
-static void piix_remove_one(struct pci_dev *pdev)
-{
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	struct piix_host_priv *hpriv = host->private_data;
-
-	pci_write_config_dword(pdev, PIIX_IOCFG, hpriv->saved_iocfg);
-
-	ata_pci_remove_one(pdev);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static int __init piix_init(void)
diff -Nur linux-sh4/drivers/ata.org/Kconfig linux-sh4/drivers/ata/Kconfig
--- linux-sh4/drivers/ata.org/Kconfig	2012-03-10 00:25:26.000000000 -0800
+++ linux-sh4/drivers/ata/Kconfig	2012-01-15 06:30:14.000000000 -0800
@@ -7,6 +7,7 @@
 	depends on HAS_IOMEM
 	depends on BLOCK
 	depends on !(M32R || M68K) || BROKEN
+	depends on !SUN4 || BROKEN
 	select SCSI
 	---help---
 	  If you want to use a ATA hard disk, ATA tape drive, ATA CD-ROM or
@@ -26,21 +27,9 @@
        bool
        default n
 
-config ATA_VERBOSE_ERROR
-	bool "Verbose ATA error reporting"
-	default y
-	help
-	  This option adds parsing of ATA command descriptions and error bits
-	  in libata kernel output, making it easier to interpret.
-	  This option will enlarge the kernel by approx. 6KB. Disable it only
-	  if kernel size is more important than ease of debugging.
-
-	  If unsure, say Y.
-
 config ATA_ACPI
-	bool "ATA ACPI Support"
+	bool
 	depends on ACPI && PCI
-	select ACPI_DOCK
 	default y
 	help
 	  This option adds support for ATA-related ACPI objects.
@@ -51,13 +40,6 @@
 	  You can disable this at kernel boot time by using the
 	  option libata.noacpi=1
 
-config SATA_PMP
-	bool "SATA Port Multiplier support"
-	default y
-	help
-	  This option adds support for SATA Port Multipliers
-	  (the SATA version of an ethernet hub, or SAS expander).
-
 config SATA_AHCI
 	tristate "AHCI SATA support"
 	depends on PCI
@@ -66,43 +48,6 @@
 
 	  If unsure, say N.
 
-config SATA_SIL24
-	tristate "Silicon Image 3124/3132 SATA support"
-	depends on PCI
-	help
-	  This option enables support for Silicon Image 3124/3132 Serial ATA.
-
-	  If unsure, say N.
-
-config SATA_FSL
-	tristate "Freescale 3.0Gbps SATA support"
-	depends on FSL_SOC
-	help
-	  This option enables support for Freescale 3.0Gbps SATA controller.
-	  It can be found on MPC837x and MPC8315.
-
-	  If unsure, say N.
-
-config ATA_SFF
-	bool "ATA SFF support"
-	default y
-	help
-	  This option adds support for ATA controllers with SFF
-	  compliant or similar programming interface.
-
-	  SFF is the legacy IDE interface that has been around since
-	  the dawn of time.  Almost all PATA controllers have an
-	  SFF interface.  Many SATA controllers have an SFF interface
-	  when configured into a legacy compatibility mode.
-
-	  For users with exclusively modern controllers like AHCI,
-	  Silicon Image 3124, or Marvell 6440, you may choose to
-	  disable this unneeded SFF support.
-
-	  If unsure, say Y.
-
-if ATA_SFF
-
 config SATA_SVW
 	tristate "ServerWorks Frodo / Apple K2 SATA support"
 	depends on PCI
@@ -123,11 +68,11 @@
 	  If unsure, say N.
 
 config SATA_MV
-	tristate "Marvell SATA support"
+	tristate "Marvell SATA support (HIGHLY EXPERIMENTAL)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the Marvell Serial ATA family.
-	  Currently supports 88SX[56]0[48][01] PCI(-X) chips,
-	  as well as the newer [67]042 PCI-X/PCIe and SOC devices.
+	  Currently supports 88SX[56]0[48][01] chips.
 
 	  If unsure, say N.
 
@@ -164,7 +109,7 @@
 	  If unsure, say N.
 
 config SATA_SX4
-	tristate "Promise SATA SX4 support (Experimental)"
+	tristate "Promise SATA SX4 support"
 	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for Promise Serial ATA SX4.
@@ -179,6 +124,14 @@
 
 	  If unsure, say N.
 
+config SATA_SIL24
+	tristate "Silicon Image 3124/3132 SATA support"
+	depends on PCI
+	help
+	  This option enables support for Silicon Image 3124/3132 Serial ATA.
+
+	  If unsure, say N.
+
 config SATA_SIS
 	tristate "SiS 964/965/966/180 SATA support"
 	depends on PCI
@@ -224,23 +177,14 @@
 	  If unsure, say N.
 
 config SATA_INIC162X
-	tristate "Initio 162x SATA support"
-	depends on PCI
+	tristate "Initio 162x SATA support (HIGHLY EXPERIMENTAL)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for Initio 162x Serial ATA.
 
-config PATA_ACPI
-	tristate "ACPI firmware driver for PATA"
-	depends on ATA_ACPI
-	help
-	  This option enables an ACPI method driver which drives
-	  motherboard PATA controller interfaces through the ACPI
-	  firmware in the BIOS. This driver can sometimes handle
-	  otherwise unsupported hardware.
-
 config PATA_ALI
-	tristate "ALi PATA support"
-	depends on PCI
+	tristate "ALi PATA support (Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the ALi ATA interfaces
 	  found on the many ALi chipsets.
@@ -257,34 +201,16 @@
 	  If unsure, say N.
 
 config PATA_ARTOP
-	tristate "ARTOP 6210/6260 PATA support"
-	depends on PCI
+	tristate "ARTOP 6210/6260 PATA support (Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for ARTOP PATA controllers.
 
 	  If unsure, say N.
 
-config PATA_ATP867X
-	tristate "ARTOP/Acard ATP867X PATA support"
-	depends on PCI
-	help
-	  This option enables support for ARTOP/Acard ATP867X PATA
-	  controllers.
-
-	  If unsure, say N.
-
-config PATA_AT32
-	tristate "Atmel AVR32 PATA support (Experimental)"
-	depends on AVR32 && PLATFORM_AT32AP && EXPERIMENTAL
-	help
-	  This option enables support for the IDE devices on the
-	  Atmel AT32AP platform.
-
-	  If unsure, say N.
-
 config PATA_ATIIXP
-	tristate "ATI PATA support"
-	depends on PCI
+	tristate "ATI PATA support (Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the ATI ATA interfaces
 	  found on the many ATI chipsets.
@@ -292,7 +218,7 @@
 	  If unsure, say N.
 
 config PATA_CMD640_PCI
-	tristate "CMD640 PCI PATA support (Experimental)"
+	tristate "CMD640 PCI PATA support (Very Experimental)"
 	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the CMD640 PCI IDE
@@ -302,8 +228,8 @@
 	  If unsure, say N.
 
 config PATA_CMD64X
-	tristate "CMD64x PATA support"
-	depends on PCI
+	tristate "CMD64x PATA support (Very Experimental)"
+	depends on PCI&& EXPERIMENTAL
 	help
 	  This option enables support for the CMD64x series chips
 	  except for the CMD640.
@@ -320,8 +246,8 @@
 	  If unsure, say N.
 
 config PATA_CS5530
-	tristate "CS5530 PATA support"
-	depends on PCI
+	tristate "CS5530 PATA support (Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the Cyrix/NatSemi/AMD CS5530
 	  companion chip used with the MediaGX/Geode processor family.
@@ -337,15 +263,6 @@
 
 	  If unsure, say N.
 
-config PATA_CS5536
-	tristate "CS5536 PATA support"
-	depends on PCI && X86 && !X86_64
-	help
-	  This option enables support for the AMD CS5536
-	  companion chip used with the Geode LX processor family.
-
-	  If unsure, say N.
-
 config PATA_CYPRESS
 	tristate "Cypress CY82C693 PATA support (Very Experimental)"
 	depends on PCI && EXPERIMENTAL
@@ -374,8 +291,8 @@
 	  If unsure, say N.
 
 config PATA_HPT366
-	tristate "HPT 366/368 PATA support"
-	depends on PCI
+	tristate "HPT 366/368 PATA support (Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the HPT 366 and 368
 	  PATA controllers via the new ATA layer.
@@ -392,7 +309,7 @@
 	  If unsure, say N.
 
 config PATA_HPT3X2N
-	tristate "HPT 372N/302N PATA support (Experimental)"
+	tristate "HPT 372N/302N PATA support (Very Experimental)"
 	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the N variant HPT PATA
@@ -418,8 +335,8 @@
 	  problems with DMA on this chipset.
 
 config PATA_ISAPNP
-	tristate "ISA Plug and Play PATA support"
-	depends on ISAPNP
+	tristate "ISA Plug and Play PATA support (Experimental)"
+	depends on EXPERIMENTAL && ISAPNP
 	help
 	  This option enables support for ISA plug & play ATA
 	  controllers such as those found on old soundcards.
@@ -476,17 +393,14 @@
 	tristate "Marvell PATA support via legacy mode"
 	depends on PCI
 	help
-	  This option enables limited support for the Marvell 88SE61xx ATA
-	  controllers. If you wish to use only the SATA ports then select
-	  the AHCI driver alone. If you wish to the use the PATA port or
-	  both SATA and PATA include this driver.
+	  This option enables limited support for the Marvell 88SE6145 ATA
+	  controller.
 
 	  If unsure, say N.
 
 config PATA_MPC52xx
 	tristate "Freescale MPC52xx SoC internal IDE"
-	depends on PPC_MPC52xx && PPC_BESTCOMM
-	select PPC_BESTCOMM_ATA
+	depends on PPC_MPC52xx
 	help
 	  This option enables support for integrated IDE controller
 	  of the Freescale MPC52xx SoC.
@@ -518,33 +432,15 @@
 
 	  If unsure, say N.
 
-config PATA_NINJA32
-	tristate "Ninja32/Delkin Cardbus ATA support (Experimental)"
-	depends on PCI && EXPERIMENTAL
-	help
-	  This option enables support for the Ninja32, Delkin and
-	  possibly other brands of Cardbus ATA adapter
-
-	  If unsure, say N.
-
 config PATA_NS87410
-	tristate "Nat Semi NS87410 PATA support"
-	depends on PCI
+	tristate "Nat Semi NS87410 PATA support (Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the National Semiconductor
 	  NS87410 PCI-IDE controller.
 
 	  If unsure, say N.
 
-config PATA_NS87415
-	tristate "Nat Semi NS87415 PATA support"
-	depends on PCI
-	help
-	  This option enables support for the National Semiconductor
-	  NS87415 PCI-IDE controller.
-
-	  If unsure, say N.
-
 config PATA_OPTI
 	tristate "OPTI621/6215 PATA support (Very Experimental)"
 	depends on PCI && EXPERIMENTAL
@@ -564,15 +460,6 @@
 
 	  If unsure, say N.
 
-config PATA_PALMLD
-	tristate "Palm LifeDrive PATA support"
-	depends on MACH_PALMLD
-	help
-	  This option enables support for Palm LifeDrive's internal ATA
-	  port via the new ATA layer.
-
-	  If unsure, say N.
-
 config PATA_PCMCIA
 	tristate "PCMCIA PATA support"
 	depends on PCMCIA
@@ -583,8 +470,8 @@
 	  If unsure, say N.
 
 config PATA_PDC_OLD
-	tristate "Older Promise PATA controller support"
-	depends on PCI
+	tristate "Older Promise PATA controller support (Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the Promise 20246, 20262, 20263,
 	  20265 and 20267 adapters.
@@ -598,7 +485,7 @@
 	  Support for QDI 6500 and 6580 PATA controllers on VESA local bus.
 
 config PATA_RADISYS
-	tristate "RADISYS 82600 PATA support (Experimental)"
+	tristate "RADISYS 82600 PATA support (Very Experimental)"
 	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the RADISYS 82600
@@ -606,25 +493,6 @@
 
 	  If unsure, say N.
 
-config PATA_RB532
-	tristate "RouterBoard 532 PATA CompactFlash support"
-	depends on MIKROTIK_RB532
-	help
-	  This option enables support for the RouterBoard 532
-	  PATA CompactFlash controller.
-
-	  If unsure, say N.
-
-config PATA_RDC
-	tristate "RDC PATA support"
-	depends on PCI
-	help
-	  This option enables basic support for the later RDC PATA controllers
-	  controllers via the new ATA layer. For the RDC 1010, you need to
-	  enable the IT821X driver instead.
-
-	  If unsure, say N.
-
 config PATA_RZ1000
 	tristate "PC Tech RZ1000 PATA support"
 	depends on PCI
@@ -635,8 +503,8 @@
 	  If unsure, say N.
 
 config PATA_SC1200
-	tristate "SC1200 PATA support"
-	depends on PCI
+	tristate "SC1200 PATA support (Very Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for the NatSemi/AMD SC1200 SoC
 	  companion chip used with the Geode processor family.
@@ -669,8 +537,8 @@
 	  If unsure, say N.
 
 config PATA_SIS
-	tristate "SiS PATA support"
-	depends on PCI
+	tristate "SiS PATA support (Experimental)"
+	depends on PCI && EXPERIMENTAL
 	help
 	  This option enables support for SiS PATA controllers
 
@@ -701,41 +569,15 @@
 	  Support for the Winbond W83759A controller on Vesa Local Bus
 	  systems.
 
-config HAVE_PATA_PLATFORM
-	bool
-	help
-	  This is an internal configuration node for any machine that
-	  uses pata-platform driver to enable the relevant driver in the
-	  configuration structure without having to submit endless patches
-	  to update the PATA_PLATFORM entry.
-
 config PATA_PLATFORM
 	tristate "Generic platform device PATA support"
-	depends on EMBEDDED || PPC || HAVE_PATA_PLATFORM
+	depends on EMBEDDED || ARCH_RPC
 	help
 	  This option enables support for generic directly connected ATA
 	  devices commonly found on embedded systems.
 
 	  If unsure, say N.
 
-config PATA_AT91
-	tristate "PATA support for AT91SAM9260"
-	depends on ARM && ARCH_AT91
-	help
-	  This option enables support for IDE devices on the Atmel AT91SAM9260 SoC.
-
-	  If unsure, say N.
-
-config PATA_OF_PLATFORM
-	tristate "OpenFirmware platform device PATA support"
-	depends on PATA_PLATFORM && PPC_OF
-	help
-	  This option enables support for generic directly connected ATA
-	  devices commonly found on embedded systems with OpenFirmware
-	  bindings.
-
-	  If unsure, say N.
-
 config PATA_ICSIDE
 	tristate "Acorn ICS PATA support"
 	depends on ARM && ARCH_ACORN
@@ -754,15 +596,6 @@
 
 	  If unsure, say N.
 
-config PATA_OCTEON_CF
-	tristate "OCTEON Boot Bus Compact Flash support"
-	depends on CPU_CAVIUM_OCTEON
-	help
-	  This option enables a polled compact flash driver for use with
-	  compact flash cards attached to the OCTEON boot bus.
-
-	  If unsure, say N.
-
 config PATA_SCC
 	tristate "Toshiba's Cell Reference Set IDE support"
 	depends on PCI && PPC_CELLEB
@@ -772,23 +605,4 @@
 
 	  If unsure, say N.
 
-config PATA_SCH
-	tristate "Intel SCH PATA support"
-	depends on PCI
-	help
-	  This option enables support for Intel SCH PATA on the Intel
-	  SCH (US15W, US15L, UL11L) series host controllers.
-
-	  If unsure, say N.
-
-config PATA_BF54X
-	tristate "Blackfin 54x ATAPI support"
-	depends on BF542 || BF548 || BF549
-	help
-	  This option enables support for the built-in ATAPI controller on
-	  Blackfin 54x family chips.
-
-	  If unsure, say N.
-
-endif # ATA_SFF
 endif # ATA
diff -Nur linux-sh4/drivers/ata.org/libata-acpi.c linux-sh4/drivers/ata/libata-acpi.c
--- linux-sh4/drivers/ata.org/libata-acpi.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/libata-acpi.c	2012-01-15 06:30:14.000000000 -0800
@@ -6,7 +6,6 @@
  * Copyright (C) 2006 Randy Dunlap
  */
 
-#include <linux/module.h>
 #include <linux/ata.h>
 #include <linux/delay.h>
 #include <linux/device.h>
@@ -15,17 +14,18 @@
 #include <linux/acpi.h>
 #include <linux/libata.h>
 #include <linux/pci.h>
-#include <scsi/scsi_device.h>
 #include "libata.h"
 
 #include <acpi/acpi_bus.h>
-
-unsigned int ata_acpi_gtf_filter = ATA_ACPI_FILTER_DEFAULT;
-module_param_named(acpi_gtf_filter, ata_acpi_gtf_filter, int, 0644);
-MODULE_PARM_DESC(acpi_gtf_filter, "filter mask for ACPI _GTF commands, set to filter out (0x1=set xfermode, 0x2=lock/freeze lock, 0x4=DIPM, 0x8=FPDMA non-zero offset, 0x10=FPDMA DMA Setup FIS auto-activate)");
+#include <acpi/acnames.h>
+#include <acpi/acnamesp.h>
+#include <acpi/acparser.h>
+#include <acpi/acexcep.h>
+#include <acpi/acmacros.h>
+#include <acpi/actypes.h>
 
 #define NO_PORT_MULT		0xffff
-#define SATA_ADR(root, pmp)	(((root) << 16) | (pmp))
+#define SATA_ADR(root,pmp)	(((root) << 16) | (pmp))
 
 #define REGS_PER_GTF		7
 struct ata_acpi_gtf {
@@ -40,46 +40,11 @@
 	return (dev->bus == &pci_bus_type);
 }
 
-static void ata_acpi_clear_gtf(struct ata_device *dev)
-{
-	kfree(dev->gtf_cache);
-	dev->gtf_cache = NULL;
-}
-
-/**
- * ata_acpi_associate_sata_port - associate SATA port with ACPI objects
- * @ap: target SATA port
- *
- * Look up ACPI objects associated with @ap and initialize acpi_handle
- * fields of @ap, the port and devices accordingly.
- *
- * LOCKING:
- * EH context.
- *
- * RETURNS:
- * 0 on success, -errno on failure.
- */
-void ata_acpi_associate_sata_port(struct ata_port *ap)
+static void ata_acpi_associate_sata_port(struct ata_port *ap)
 {
-	WARN_ON(!(ap->flags & ATA_FLAG_ACPI_SATA));
+	acpi_integer adr = SATA_ADR(ap->port_no, NO_PORT_MULT);
 
-	if (!sata_pmp_attached(ap)) {
-		acpi_integer adr = SATA_ADR(ap->port_no, NO_PORT_MULT);
-
-		ap->link.device->acpi_handle =
-			acpi_get_child(ap->host->acpi_handle, adr);
-	} else {
-		struct ata_link *link;
-
-		ap->link.device->acpi_handle = NULL;
-
-		ata_for_each_link(link, ap, EDGE) {
-			acpi_integer adr = SATA_ADR(ap->port_no, link->pmp);
-
-			link->device->acpi_handle =
-				acpi_get_child(ap->host->acpi_handle, adr);
-		}
-	}
+	ap->device->acpi_handle = acpi_get_child(ap->host->acpi_handle, adr);
 }
 
 static void ata_acpi_associate_ide_port(struct ata_port *ap)
@@ -95,145 +60,13 @@
 		max_devices++;
 
 	for (i = 0; i < max_devices; i++) {
-		struct ata_device *dev = &ap->link.device[i];
+		struct ata_device *dev = &ap->device[i];
 
 		dev->acpi_handle = acpi_get_child(ap->acpi_handle, i);
 	}
-
-	if (ata_acpi_gtm(ap, &ap->__acpi_init_gtm) == 0)
-		ap->pflags |= ATA_PFLAG_INIT_GTM_VALID;
-}
-
-/* @ap and @dev are the same as ata_acpi_handle_hotplug() */
-static void ata_acpi_detach_device(struct ata_port *ap, struct ata_device *dev)
-{
-	if (dev)
-		dev->flags |= ATA_DFLAG_DETACH;
-	else {
-		struct ata_link *tlink;
-		struct ata_device *tdev;
-
-		ata_for_each_link(tlink, ap, EDGE)
-			ata_for_each_dev(tdev, tlink, ALL)
-				tdev->flags |= ATA_DFLAG_DETACH;
-	}
-
-	ata_port_schedule_eh(ap);
 }
 
 /**
- * ata_acpi_handle_hotplug - ACPI event handler backend
- * @ap: ATA port ACPI event occurred
- * @dev: ATA device ACPI event occurred (can be NULL)
- * @event: ACPI event which occurred
- *
- * All ACPI bay / device realted events end up in this function.  If
- * the event is port-wide @dev is NULL.  If the event is specific to a
- * device, @dev points to it.
- *
- * Hotplug (as opposed to unplug) notification is always handled as
- * port-wide while unplug only kills the target device on device-wide
- * event.
- *
- * LOCKING:
- * ACPI notify handler context.  May sleep.
- */
-static void ata_acpi_handle_hotplug(struct ata_port *ap, struct ata_device *dev,
-				    u32 event)
-{
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	int wait = 0;
-	unsigned long flags;
-	acpi_handle handle;
-
-	if (dev)
-		handle = dev->acpi_handle;
-	else
-		handle = ap->acpi_handle;
-
-	spin_lock_irqsave(ap->lock, flags);
-	/*
-	 * When dock driver calls into the routine, it will always use
-	 * ACPI_NOTIFY_BUS_CHECK/ACPI_NOTIFY_DEVICE_CHECK for add and
-	 * ACPI_NOTIFY_EJECT_REQUEST for remove
-	 */
-	switch (event) {
-	case ACPI_NOTIFY_BUS_CHECK:
-	case ACPI_NOTIFY_DEVICE_CHECK:
-		ata_ehi_push_desc(ehi, "ACPI event");
-
-		ata_ehi_hotplugged(ehi);
-		ata_port_freeze(ap);
-		break;
-	case ACPI_NOTIFY_EJECT_REQUEST:
-		ata_ehi_push_desc(ehi, "ACPI event");
-
-		ata_acpi_detach_device(ap, dev);
-		wait = 1;
-		break;
-	}
-
-	spin_unlock_irqrestore(ap->lock, flags);
-
-	if (wait)
-		ata_port_wait_eh(ap);
-}
-
-static void ata_acpi_dev_notify_dock(acpi_handle handle, u32 event, void *data)
-{
-	struct ata_device *dev = data;
-
-	ata_acpi_handle_hotplug(dev->link->ap, dev, event);
-}
-
-static void ata_acpi_ap_notify_dock(acpi_handle handle, u32 event, void *data)
-{
-	struct ata_port *ap = data;
-
-	ata_acpi_handle_hotplug(ap, NULL, event);
-}
-
-static void ata_acpi_uevent(struct ata_port *ap, struct ata_device *dev,
-	u32 event)
-{
-	struct kobject *kobj = NULL;
-	char event_string[20];
-	char *envp[] = { event_string, NULL };
-
-	if (dev) {
-		if (dev->sdev)
-			kobj = &dev->sdev->sdev_gendev.kobj;
-	} else
-		kobj = &ap->dev->kobj;
-
-	if (kobj) {
-		snprintf(event_string, 20, "BAY_EVENT=%d", event);
-		kobject_uevent_env(kobj, KOBJ_CHANGE, envp);
-	}
-}
-
-static void ata_acpi_ap_uevent(acpi_handle handle, u32 event, void *data)
-{
-	ata_acpi_uevent(data, NULL, event);
-}
-
-static void ata_acpi_dev_uevent(acpi_handle handle, u32 event, void *data)
-{
-	struct ata_device *dev = data;
-	ata_acpi_uevent(dev->link->ap, dev, event);
-}
-
-static struct acpi_dock_ops ata_acpi_dev_dock_ops = {
-	.handler = ata_acpi_dev_notify_dock,
-	.uevent = ata_acpi_dev_uevent,
-};
-
-static struct acpi_dock_ops ata_acpi_ap_dock_ops = {
-	.handler = ata_acpi_ap_notify_dock,
-	.uevent = ata_acpi_ap_uevent,
-};
-
-/**
  * ata_acpi_associate - associate ATA host with ACPI objects
  * @host: target ATA host
  *
@@ -248,7 +81,7 @@
  */
 void ata_acpi_associate(struct ata_host *host)
 {
-	int i, j;
+	int i;
 
 	if (!is_pci_dev(host->dev) || libata_noacpi)
 		return;
@@ -264,48 +97,6 @@
 			ata_acpi_associate_sata_port(ap);
 		else
 			ata_acpi_associate_ide_port(ap);
-
-		if (ap->acpi_handle) {
-			/* we might be on a docking station */
-			register_hotplug_dock_device(ap->acpi_handle,
-					     &ata_acpi_ap_dock_ops, ap);
-		}
-
-		for (j = 0; j < ata_link_max_devices(&ap->link); j++) {
-			struct ata_device *dev = &ap->link.device[j];
-
-			if (dev->acpi_handle) {
-				/* we might be on a docking station */
-				register_hotplug_dock_device(dev->acpi_handle,
-					     &ata_acpi_dev_dock_ops, dev);
-			}
-		}
-	}
-}
-
-/**
- * ata_acpi_dissociate - dissociate ATA host from ACPI objects
- * @host: target ATA host
- *
- * This function is called during driver detach after the whole host
- * is shut down.
- *
- * LOCKING:
- * EH context.
- */
-void ata_acpi_dissociate(struct ata_host *host)
-{
-	int i;
-
-	/* Restore initial _GTM values so that driver which attaches
-	 * afterward can use them too.
-	 */
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		const struct ata_acpi_gtm *gtm = ata_acpi_init_gtm(ap);
-
-		if (ap->acpi_handle && gtm)
-			ata_acpi_stm(ap, gtm);
 	}
 }
 
@@ -322,7 +113,7 @@
  * RETURNS:
  * 0 on success, -ENOENT if _GTM doesn't exist, -errno on failure.
  */
-int ata_acpi_gtm(struct ata_port *ap, struct ata_acpi_gtm *gtm)
+static int ata_acpi_gtm(const struct ata_port *ap, struct ata_acpi_gtm *gtm)
 {
 	struct acpi_buffer output = { .length = ACPI_ALLOCATE_BUFFER };
 	union acpi_object *out_obj;
@@ -366,8 +157,6 @@
 	return rc;
 }
 
-EXPORT_SYMBOL_GPL(ata_acpi_gtm);
-
 /**
  * ata_acpi_stm - execute _STM
  * @ap: target ATA port
@@ -381,23 +170,22 @@
  * RETURNS:
  * 0 on success, -ENOENT if _STM doesn't exist, -errno on failure.
  */
-int ata_acpi_stm(struct ata_port *ap, const struct ata_acpi_gtm *stm)
+static int ata_acpi_stm(const struct ata_port *ap, struct ata_acpi_gtm *stm)
 {
 	acpi_status status;
-	struct ata_acpi_gtm		stm_buf = *stm;
 	struct acpi_object_list         input;
 	union acpi_object               in_params[3];
 
 	in_params[0].type = ACPI_TYPE_BUFFER;
 	in_params[0].buffer.length = sizeof(struct ata_acpi_gtm);
-	in_params[0].buffer.pointer = (u8 *)&stm_buf;
+	in_params[0].buffer.pointer = (u8 *)stm;
 	/* Buffers for id may need byteswapping ? */
 	in_params[1].type = ACPI_TYPE_BUFFER;
 	in_params[1].buffer.length = 512;
-	in_params[1].buffer.pointer = (u8 *)ap->link.device[0].id;
+	in_params[1].buffer.pointer = (u8 *)ap->device[0].id;
 	in_params[2].type = ACPI_TYPE_BUFFER;
 	in_params[2].buffer.length = 512;
-	in_params[2].buffer.pointer = (u8 *)ap->link.device[1].id;
+	in_params[2].buffer.pointer = (u8 *)ap->device[1].id;
 
 	input.count = 3;
 	input.pointer = in_params;
@@ -414,12 +202,11 @@
 	return 0;
 }
 
-EXPORT_SYMBOL_GPL(ata_acpi_stm);
-
 /**
  * ata_dev_get_GTF - get the drive bootup default taskfile settings
  * @dev: target ATA device
  * @gtf: output parameter for buffer containing _GTF taskfile arrays
+ * @ptr_to_free: pointer which should be freed
  *
  * This applies to both PATA and SATA drives.
  *
@@ -433,41 +220,35 @@
  * EH context.
  *
  * RETURNS:
- * Number of taskfiles on success, 0 if _GTF doesn't exist.  -EINVAL
- * if _GTF is invalid.
+ * Number of taskfiles on success, 0 if _GTF doesn't exist or doesn't
+ * contain valid data.  -errno on other errors.
  */
-static int ata_dev_get_GTF(struct ata_device *dev, struct ata_acpi_gtf **gtf)
+static int ata_dev_get_GTF(struct ata_device *dev, struct ata_acpi_gtf **gtf,
+			   void **ptr_to_free)
 {
-	struct ata_port *ap = dev->link->ap;
+	struct ata_port *ap = dev->ap;
 	acpi_status status;
 	struct acpi_buffer output;
 	union acpi_object *out_obj;
 	int rc = 0;
 
-	/* if _GTF is cached, use the cached value */
-	if (dev->gtf_cache) {
-		out_obj = dev->gtf_cache;
-		goto done;
-	}
-
 	/* set up output buffer */
 	output.length = ACPI_ALLOCATE_BUFFER;
 	output.pointer = NULL;	/* ACPI-CA sets this; save/free it later */
 
 	if (ata_msg_probe(ap))
 		ata_dev_printk(dev, KERN_DEBUG, "%s: ENTER: port#: %d\n",
-			       __func__, ap->port_no);
+			       __FUNCTION__, ap->port_no);
 
 	/* _GTF has no input parameters */
 	status = acpi_evaluate_object(dev->acpi_handle, "_GTF", NULL, &output);
-	out_obj = dev->gtf_cache = output.pointer;
 
 	if (ACPI_FAILURE(status)) {
 		if (status != AE_NOT_FOUND) {
 			ata_dev_printk(dev, KERN_WARNING,
 				       "_GTF evaluation failed (AE 0x%x)\n",
 				       status);
-			rc = -EINVAL;
+			rc = -EIO;
 		}
 		goto out_free;
 	}
@@ -476,13 +257,13 @@
 		if (ata_msg_probe(ap))
 			ata_dev_printk(dev, KERN_DEBUG, "%s: Run _GTF: "
 				"length or ptr is NULL (0x%llx, 0x%p)\n",
-				__func__,
+				__FUNCTION__,
 				(unsigned long long)output.length,
 				output.pointer);
-		rc = -EINVAL;
 		goto out_free;
 	}
 
+	out_obj = output.pointer;
 	if (out_obj->type != ACPI_TYPE_BUFFER) {
 		ata_dev_printk(dev, KERN_WARNING,
 			       "_GTF unexpected object type 0x%x\n",
@@ -499,169 +280,23 @@
 		goto out_free;
 	}
 
- done:
+	*ptr_to_free = out_obj;
+	*gtf = (void *)out_obj->buffer.pointer;
 	rc = out_obj->buffer.length / REGS_PER_GTF;
-	if (gtf) {
-		*gtf = (void *)out_obj->buffer.pointer;
-		if (ata_msg_probe(ap))
-			ata_dev_printk(dev, KERN_DEBUG,
-				       "%s: returning gtf=%p, gtf_count=%d\n",
-				       __func__, *gtf, rc);
-	}
+
+	if (ata_msg_probe(ap))
+		ata_dev_printk(dev, KERN_DEBUG, "%s: returning "
+			"gtf=%p, gtf_count=%d, ptr_to_free=%p\n",
+			__FUNCTION__, *gtf, rc, *ptr_to_free);
 	return rc;
 
  out_free:
-	ata_acpi_clear_gtf(dev);
+	kfree(output.pointer);
 	return rc;
 }
 
 /**
- * ata_acpi_gtm_xfermode - determine xfermode from GTM parameter
- * @dev: target device
- * @gtm: GTM parameter to use
- *
- * Determine xfermask for @dev from @gtm.
- *
- * LOCKING:
- * None.
- *
- * RETURNS:
- * Determined xfermask.
- */
-unsigned long ata_acpi_gtm_xfermask(struct ata_device *dev,
-				    const struct ata_acpi_gtm *gtm)
-{
-	unsigned long xfer_mask = 0;
-	unsigned int type;
-	int unit;
-	u8 mode;
-
-	/* we always use the 0 slot for crap hardware */
-	unit = dev->devno;
-	if (!(gtm->flags & 0x10))
-		unit = 0;
-
-	/* PIO */
-	mode = ata_timing_cycle2mode(ATA_SHIFT_PIO, gtm->drive[unit].pio);
-	xfer_mask |= ata_xfer_mode2mask(mode);
-
-	/* See if we have MWDMA or UDMA data. We don't bother with
-	 * MWDMA if UDMA is available as this means the BIOS set UDMA
-	 * and our error changedown if it works is UDMA to PIO anyway.
-	 */
-	if (!(gtm->flags & (1 << (2 * unit))))
-		type = ATA_SHIFT_MWDMA;
-	else
-		type = ATA_SHIFT_UDMA;
-
-	mode = ata_timing_cycle2mode(type, gtm->drive[unit].dma);
-	xfer_mask |= ata_xfer_mode2mask(mode);
-
-	return xfer_mask;
-}
-EXPORT_SYMBOL_GPL(ata_acpi_gtm_xfermask);
-
-/**
- * ata_acpi_cbl_80wire		-	Check for 80 wire cable
- * @ap: Port to check
- * @gtm: GTM data to use
- *
- * Return 1 if the @gtm indicates the BIOS selected an 80wire mode.
- */
-int ata_acpi_cbl_80wire(struct ata_port *ap, const struct ata_acpi_gtm *gtm)
-{
-	struct ata_device *dev;
-
-	ata_for_each_dev(dev, &ap->link, ENABLED) {
-		unsigned long xfer_mask, udma_mask;
-
-		xfer_mask = ata_acpi_gtm_xfermask(dev, gtm);
-		ata_unpack_xfermask(xfer_mask, NULL, NULL, &udma_mask);
-
-		if (udma_mask & ~ATA_UDMA_MASK_40C)
-			return 1;
-	}
-
-	return 0;
-}
-EXPORT_SYMBOL_GPL(ata_acpi_cbl_80wire);
-
-static void ata_acpi_gtf_to_tf(struct ata_device *dev,
-			       const struct ata_acpi_gtf *gtf,
-			       struct ata_taskfile *tf)
-{
-	ata_tf_init(dev, tf);
-
-	tf->flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;
-	tf->protocol = ATA_PROT_NODATA;
-	tf->feature = gtf->tf[0];	/* 0x1f1 */
-	tf->nsect   = gtf->tf[1];	/* 0x1f2 */
-	tf->lbal    = gtf->tf[2];	/* 0x1f3 */
-	tf->lbam    = gtf->tf[3];	/* 0x1f4 */
-	tf->lbah    = gtf->tf[4];	/* 0x1f5 */
-	tf->device  = gtf->tf[5];	/* 0x1f6 */
-	tf->command = gtf->tf[6];	/* 0x1f7 */
-}
-
-static int ata_acpi_filter_tf(struct ata_device *dev,
-			      const struct ata_taskfile *tf,
-			      const struct ata_taskfile *ptf)
-{
-	if (dev->gtf_filter & ATA_ACPI_FILTER_SETXFER) {
-		/* libata doesn't use ACPI to configure transfer mode.
-		 * It will only confuse device configuration.  Skip.
-		 */
-		if (tf->command == ATA_CMD_SET_FEATURES &&
-		    tf->feature == SETFEATURES_XFER)
-			return 1;
-	}
-
-	if (dev->gtf_filter & ATA_ACPI_FILTER_LOCK) {
-		/* BIOS writers, sorry but we don't wanna lock
-		 * features unless the user explicitly said so.
-		 */
-
-		/* DEVICE CONFIGURATION FREEZE LOCK */
-		if (tf->command == ATA_CMD_CONF_OVERLAY &&
-		    tf->feature == ATA_DCO_FREEZE_LOCK)
-			return 1;
-
-		/* SECURITY FREEZE LOCK */
-		if (tf->command == ATA_CMD_SEC_FREEZE_LOCK)
-			return 1;
-
-		/* SET MAX LOCK and SET MAX FREEZE LOCK */
-		if ((!ptf || ptf->command != ATA_CMD_READ_NATIVE_MAX) &&
-		    tf->command == ATA_CMD_SET_MAX &&
-		    (tf->feature == ATA_SET_MAX_LOCK ||
-		     tf->feature == ATA_SET_MAX_FREEZE_LOCK))
-			return 1;
-	}
-
-	if (tf->command == ATA_CMD_SET_FEATURES &&
-	    tf->feature == SETFEATURES_SATA_ENABLE) {
-		/* inhibit enabling DIPM */
-		if (dev->gtf_filter & ATA_ACPI_FILTER_DIPM &&
-		    tf->nsect == SATA_DIPM)
-			return 1;
-
-		/* inhibit FPDMA non-zero offset */
-		if (dev->gtf_filter & ATA_ACPI_FILTER_FPDMA_OFFSET &&
-		    (tf->nsect == SATA_FPDMA_OFFSET ||
-		     tf->nsect == SATA_FPDMA_IN_ORDER))
-			return 1;
-
-		/* inhibit FPDMA auto activation */
-		if (dev->gtf_filter & ATA_ACPI_FILTER_FPDMA_AA &&
-		    tf->nsect == SATA_FPDMA_AA)
-			return 1;
-	}
-
-	return 0;
-}
-
-/**
- * ata_acpi_run_tf - send taskfile registers to host controller
+ * taskfile_load_raw - send taskfile registers to host controller
  * @dev: target ATA device
  * @gtf: raw ATA taskfile register set (0x1f1 - 0x1f7)
  *
@@ -680,117 +315,95 @@
  * EH context.
  *
  * RETURNS:
- * 1 if command is executed successfully.  0 if ignored, rejected or
- * filtered out, -errno on other errors.
+ * 0 on success, -errno on failure.
  */
-static int ata_acpi_run_tf(struct ata_device *dev,
-			   const struct ata_acpi_gtf *gtf,
-			   const struct ata_acpi_gtf *prev_gtf)
+static int taskfile_load_raw(struct ata_device *dev,
+			      const struct ata_acpi_gtf *gtf)
 {
-	struct ata_taskfile *pptf = NULL;
-	struct ata_taskfile tf, ptf, rtf;
+	struct ata_port *ap = dev->ap;
+	struct ata_taskfile tf, rtf;
 	unsigned int err_mask;
-	const char *level;
-	const char *descr;
-	char msg[60];
-	int rc;
 
 	if ((gtf->tf[0] == 0) && (gtf->tf[1] == 0) && (gtf->tf[2] == 0)
 	    && (gtf->tf[3] == 0) && (gtf->tf[4] == 0) && (gtf->tf[5] == 0)
 	    && (gtf->tf[6] == 0))
 		return 0;
 
-	ata_acpi_gtf_to_tf(dev, gtf, &tf);
-	if (prev_gtf) {
-		ata_acpi_gtf_to_tf(dev, prev_gtf, &ptf);
-		pptf = &ptf;
-	}
+	ata_tf_init(dev, &tf);
 
-	if (!ata_acpi_filter_tf(dev, &tf, pptf)) {
-		rtf = tf;
-		err_mask = ata_exec_internal(dev, &rtf, NULL,
-					     DMA_NONE, NULL, 0, 0);
-
-		switch (err_mask) {
-		case 0:
-			level = KERN_DEBUG;
-			snprintf(msg, sizeof(msg), "succeeded");
-			rc = 1;
-			break;
+	/* convert gtf to tf */
+	tf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE; /* TBD */
+	tf.protocol = ATA_PROT_NODATA;
+	tf.feature = gtf->tf[0];	/* 0x1f1 */
+	tf.nsect   = gtf->tf[1];	/* 0x1f2 */
+	tf.lbal    = gtf->tf[2];	/* 0x1f3 */
+	tf.lbam    = gtf->tf[3];	/* 0x1f4 */
+	tf.lbah    = gtf->tf[4];	/* 0x1f5 */
+	tf.device  = gtf->tf[5];	/* 0x1f6 */
+	tf.command = gtf->tf[6];	/* 0x1f7 */
 
-		case AC_ERR_DEV:
-			level = KERN_INFO;
-			snprintf(msg, sizeof(msg),
-				 "rejected by device (Stat=0x%02x Err=0x%02x)",
-				 rtf.command, rtf.feature);
-			rc = 0;
-			break;
-
-		default:
-			level = KERN_ERR;
-			snprintf(msg, sizeof(msg),
-				 "failed (Emask=0x%x Stat=0x%02x Err=0x%02x)",
-				 err_mask, rtf.command, rtf.feature);
-			rc = -EIO;
-			break;
-		}
-	} else {
-		level = KERN_INFO;
-		snprintf(msg, sizeof(msg), "filtered out");
-		rc = 0;
+	if (ata_msg_probe(ap))
+		ata_dev_printk(dev, KERN_DEBUG, "executing ACPI cmd "
+			       "%02x/%02x:%02x:%02x:%02x:%02x:%02x\n",
+			       tf.command, tf.feature, tf.nsect,
+			       tf.lbal, tf.lbam, tf.lbah, tf.device);
+
+	rtf = tf;
+	err_mask = ata_exec_internal(dev, &rtf, NULL, DMA_NONE, NULL, 0);
+	if (err_mask) {
+		ata_dev_printk(dev, KERN_ERR,
+			"ACPI cmd %02x/%02x:%02x:%02x:%02x:%02x:%02x failed "
+			"(Emask=0x%x Stat=0x%02x Err=0x%02x)\n",
+			tf.command, tf.feature, tf.nsect, tf.lbal, tf.lbam,
+			tf.lbah, tf.device, err_mask, rtf.command, rtf.feature);
+		return -EIO;
 	}
-	descr = ata_get_cmd_descript(tf.command);
-
-	ata_dev_printk(dev, level,
-		       "ACPI cmd %02x/%02x:%02x:%02x:%02x:%02x:%02x (%s) %s\n",
-		       tf.command, tf.feature, tf.nsect, tf.lbal,
-		       tf.lbam, tf.lbah, tf.device,
-		       (descr ? descr : "unknown"), msg);
 
-	return rc;
+	return 0;
 }
 
 /**
  * ata_acpi_exec_tfs - get then write drive taskfile settings
  * @dev: target ATA device
- * @nr_executed: out parameter for the number of executed commands
  *
- * Evaluate _GTF and execute returned taskfiles.
+ * Evaluate _GTF and excute returned taskfiles.
  *
  * LOCKING:
  * EH context.
  *
  * RETURNS:
- * Number of executed taskfiles on success, 0 if _GTF doesn't exist.
- * -errno on other errors.
+ * Number of executed taskfiles on success, 0 if _GTF doesn't exist or
+ * doesn't contain valid data.  -errno on other errors.
  */
-static int ata_acpi_exec_tfs(struct ata_device *dev, int *nr_executed)
+static int ata_acpi_exec_tfs(struct ata_device *dev)
 {
-	struct ata_acpi_gtf *gtf = NULL, *pgtf = NULL;
+	struct ata_acpi_gtf *gtf = NULL;
+	void *ptr_to_free = NULL;
 	int gtf_count, i, rc;
 
 	/* get taskfiles */
-	rc = ata_dev_get_GTF(dev, &gtf);
+	rc = ata_dev_get_GTF(dev, &gtf, &ptr_to_free);
 	if (rc < 0)
 		return rc;
 	gtf_count = rc;
 
 	/* execute them */
-	for (i = 0; i < gtf_count; i++, gtf++) {
-		rc = ata_acpi_run_tf(dev, gtf, pgtf);
-		if (rc < 0)
-			break;
-		if (rc) {
-			(*nr_executed)++;
-			pgtf = gtf;
-		}
+	for (i = 0, rc = 0; i < gtf_count; i++) {
+		int tmp;
+
+		/* ACPI errors are eventually ignored.  Run till the
+		 * end even after errors.
+		 */
+		tmp = taskfile_load_raw(dev, gtf++);
+		if (!rc)
+			rc = tmp;
 	}
 
-	ata_acpi_clear_gtf(dev);
+	kfree(ptr_to_free);
 
-	if (rc < 0)
-		return rc;
-	return 0;
+	if (rc == 0)
+		return gtf_count;
+	return rc;
 }
 
 /**
@@ -811,7 +424,7 @@
  */
 static int ata_acpi_push_id(struct ata_device *dev)
 {
-	struct ata_port *ap = dev->link->ap;
+	struct ata_port *ap = dev->ap;
 	int err;
 	acpi_status status;
 	struct acpi_object_list input;
@@ -819,7 +432,7 @@
 
 	if (ata_msg_probe(ap))
 		ata_dev_printk(dev, KERN_DEBUG, "%s: ix = %d, port#: %d\n",
-			       __func__, dev->devno, ap->port_no);
+			       __FUNCTION__, dev->devno, ap->port_no);
 
 	/* Give the drive Identify data to the drive via the _SDD method */
 	/* _SDD: set up input parameters */
@@ -860,8 +473,27 @@
  */
 int ata_acpi_on_suspend(struct ata_port *ap)
 {
-	/* nada */
-	return 0;
+	unsigned long flags;
+	int rc;
+
+	/* proceed iff per-port acpi_handle is valid */
+	if (!ap->acpi_handle)
+		return 0;
+	BUG_ON(ap->flags & ATA_FLAG_ACPI_SATA);
+
+	/* store timing parameters */
+	rc = ata_acpi_gtm(ap, &ap->acpi_gtm);
+
+	spin_lock_irqsave(ap->lock, flags);
+	if (rc == 0)
+		ap->pflags |= ATA_PFLAG_GTM_VALID;
+	else
+		ap->pflags &= ~ATA_PFLAG_GTM_VALID;
+	spin_unlock_irqrestore(ap->lock, flags);
+
+	if (rc == -ENOENT)
+		rc = 0;
+	return rc;
 }
 
 /**
@@ -876,66 +508,18 @@
  */
 void ata_acpi_on_resume(struct ata_port *ap)
 {
-	const struct ata_acpi_gtm *gtm = ata_acpi_init_gtm(ap);
-	struct ata_device *dev;
+	int i;
 
-	if (ap->acpi_handle && gtm) {
-		/* _GTM valid */
+	if (ap->acpi_handle && (ap->pflags & ATA_PFLAG_GTM_VALID)) {
+		BUG_ON(ap->flags & ATA_FLAG_ACPI_SATA);
 
 		/* restore timing parameters */
-		ata_acpi_stm(ap, gtm);
-
-		/* _GTF should immediately follow _STM so that it can
-		 * use values set by _STM.  Cache _GTF result and
-		 * schedule _GTF.
-		 */
-		ata_for_each_dev(dev, &ap->link, ALL) {
-			ata_acpi_clear_gtf(dev);
-			if (ata_dev_enabled(dev) &&
-			    ata_dev_get_GTF(dev, NULL) >= 0)
-				dev->flags |= ATA_DFLAG_ACPI_PENDING;
-		}
-	} else {
-		/* SATA _GTF needs to be evaulated after _SDD and
-		 * there's no reason to evaluate IDE _GTF early
-		 * without _STM.  Clear cache and schedule _GTF.
-		 */
-		ata_for_each_dev(dev, &ap->link, ALL) {
-			ata_acpi_clear_gtf(dev);
-			if (ata_dev_enabled(dev))
-				dev->flags |= ATA_DFLAG_ACPI_PENDING;
-		}
+		ata_acpi_stm(ap, &ap->acpi_gtm);
 	}
-}
-
-/**
- * ata_acpi_set_state - set the port power state
- * @ap: target ATA port
- * @state: state, on/off
- *
- * This function executes the _PS0/_PS3 ACPI method to set the power state.
- * ACPI spec requires _PS0 when IDE power on and _PS3 when power off
- */
-void ata_acpi_set_state(struct ata_port *ap, pm_message_t state)
-{
-	struct ata_device *dev;
 
-	if (!ap->acpi_handle || (ap->flags & ATA_FLAG_ACPI_SATA))
-		return;
-
-	/* channel first and then drives for power on and vica versa
-	   for power off */
-	if (state.event == PM_EVENT_ON)
-		acpi_bus_set_power(ap->acpi_handle, ACPI_STATE_D0);
-
-	ata_for_each_dev(dev, &ap->link, ENABLED) {
-		if (dev->acpi_handle)
-			acpi_bus_set_power(dev->acpi_handle,
-				state.event == PM_EVENT_ON ?
-					ACPI_STATE_D0 : ACPI_STATE_D3);
-	}
-	if (state.event != PM_EVENT_ON)
-		acpi_bus_set_power(ap->acpi_handle, ACPI_STATE_D3);
+	/* schedule _GTF */
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		ap->device[i].flags |= ATA_DFLAG_ACPI_PENDING;
 }
 
 /**
@@ -954,10 +538,9 @@
  */
 int ata_acpi_on_devcfg(struct ata_device *dev)
 {
-	struct ata_port *ap = dev->link->ap;
-	struct ata_eh_context *ehc = &ap->link.eh_context;
+	struct ata_port *ap = dev->ap;
+	struct ata_eh_context *ehc = &ap->eh_context;
 	int acpi_sata = ap->flags & ATA_FLAG_ACPI_SATA;
-	int nr_executed = 0;
 	int rc;
 
 	if (!dev->acpi_handle)
@@ -976,14 +559,14 @@
 	}
 
 	/* do _GTF */
-	rc = ata_acpi_exec_tfs(dev, &nr_executed);
-	if (rc)
+	rc = ata_acpi_exec_tfs(dev);
+	if (rc < 0)
 		goto acpi_err;
 
 	dev->flags &= ~ATA_DFLAG_ACPI_PENDING;
 
 	/* refresh IDENTIFY page if any _GTF command has been executed */
-	if (nr_executed) {
+	if (rc > 0) {
 		rc = ata_dev_reread_id(dev, 0);
 		if (rc < 0) {
 			ata_dev_printk(dev, KERN_ERR, "failed to IDENTIFY "
@@ -995,39 +578,17 @@
 	return 0;
 
  acpi_err:
-	/* ignore evaluation failure if we can continue safely */
-	if (rc == -EINVAL && !nr_executed && !(ap->pflags & ATA_PFLAG_FROZEN))
-		return 0;
-
-	/* fail and let EH retry once more for unknown IO errors */
-	if (!(dev->flags & ATA_DFLAG_ACPI_FAILED)) {
-		dev->flags |= ATA_DFLAG_ACPI_FAILED;
-		return rc;
-	}
+	/* let EH retry on the first failure, disable ACPI on the second */
+	if (dev->flags & ATA_DFLAG_ACPI_FAILED) {
+		ata_dev_printk(dev, KERN_WARNING, "ACPI on devcfg failed the "
+			       "second time, disabling (errno=%d)\n", rc);
 
-	ata_dev_printk(dev, KERN_WARNING,
-		       "ACPI: failed the second time, disabled\n");
-	dev->acpi_handle = NULL;
-
-	/* We can safely continue if no _GTF command has been executed
-	 * and port is not frozen.
-	 */
-	if (!nr_executed && !(ap->pflags & ATA_PFLAG_FROZEN))
-		return 0;
+		dev->acpi_handle = NULL;
 
+		/* if port is working, request IDENTIFY reload and continue */
+		if (!(ap->pflags & ATA_PFLAG_FROZEN))
+			rc = 1;
+	}
+	dev->flags |= ATA_DFLAG_ACPI_FAILED;
 	return rc;
 }
-
-/**
- * ata_acpi_on_disable - ATA ACPI hook called when a device is disabled
- * @dev: target ATA device
- *
- * This function is called when @dev is about to be disabled.
- *
- * LOCKING:
- * EH context.
- */
-void ata_acpi_on_disable(struct ata_device *dev)
-{
-	ata_acpi_clear_gtf(dev);
-}
diff -Nur linux-sh4/drivers/ata.org/libata-core.c linux-sh4/drivers/ata/libata-core.c
--- linux-sh4/drivers/ata.org/libata-core.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/libata-core.c	2012-01-15 06:30:14.000000000 -0800
@@ -30,14 +30,6 @@
  *  Hardware documentation available from http://www.t13.org/ and
  *  http://www.sata-io.org/
  *
- *  Standards documents from:
- *	http://www.t13.org (ATA standards, PCI DMA IDE spec)
- *	http://www.t10.org (SCSI MMC - for ATAPI MMC)
- *	http://www.sata-io.org (SATA)
- *	http://www.compactflash.org (CF)
- *	http://www.qic.org (QIC157 - Tape and DSC)
- *	http://www.ce-ata.org (CE-ATA: not supported)
- *
  */
 
 #include <linux/kernel.h>
@@ -46,6 +38,7 @@
 #include <linux/init.h>
 #include <linux/list.h>
 #include <linux/mm.h>
+#include <linux/highmem.h>
 #include <linux/spinlock.h>
 #include <linux/blkdev.h>
 #include <linux/delay.h>
@@ -54,43 +47,34 @@
 #include <linux/completion.h>
 #include <linux/suspend.h>
 #include <linux/workqueue.h>
+#include <linux/jiffies.h>
 #include <linux/scatterlist.h>
-#include <linux/io.h>
-#include <linux/async.h>
-#include <linux/log2.h>
 #include <scsi/scsi.h>
 #include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_host.h>
+// #include <linux/libata.h>
+#include <asm/io.h>
+
+
+// Moved from above so that it is after this munging.
 #include <linux/libata.h>
+
+#include <linux/semaphore.h>
 #include <asm/byteorder.h>
-#include <linux/cdrom.h>
 
 #include "libata.h"
 
+#define DRV_VERSION	"2.21"	/* must be exactly four chars */
+
 
 /* debounce timing parameters in msecs { interval, duration, timeout } */
 const unsigned long sata_deb_timing_normal[]		= {   5,  100, 2000 };
 const unsigned long sata_deb_timing_hotplug[]		= {  25,  500, 2000 };
 const unsigned long sata_deb_timing_long[]		= { 100, 2000, 5000 };
 
-const struct ata_port_operations ata_base_port_ops = {
-	.prereset		= ata_std_prereset,
-	.postreset		= ata_std_postreset,
-	.error_handler		= ata_std_error_handler,
-};
-
-const struct ata_port_operations sata_port_ops = {
-	.inherits		= &ata_base_port_ops,
-
-	.qc_defer		= ata_std_qc_defer,
-	.hardreset		= sata_std_hardreset,
-};
-
 static unsigned int ata_dev_init_params(struct ata_device *dev,
 					u16 heads, u16 sectors);
 static unsigned int ata_dev_set_xfermode(struct ata_device *dev);
-static unsigned int ata_dev_set_feature(struct ata_device *dev,
-					u8 enable, u8 feature);
 static void ata_dev_xfermask(struct ata_device *dev);
 static unsigned long ata_dev_blacklisted(const struct ata_device *dev);
 
@@ -99,69 +83,29 @@
 
 struct workqueue_struct *ata_aux_wq;
 
-struct ata_force_param {
-	const char	*name;
-	unsigned int	cbl;
-	int		spd_limit;
-	unsigned long	xfer_mask;
-	unsigned int	horkage_on;
-	unsigned int	horkage_off;
-	unsigned int	lflags;
-};
-
-struct ata_force_ent {
-	int			port;
-	int			device;
-	struct ata_force_param	param;
-};
-
-static struct ata_force_ent *ata_force_tbl;
-static int ata_force_tbl_size;
-
-static char ata_force_param_buf[PAGE_SIZE] __initdata;
-/* param_buf is thrown away after initialization, disallow read */
-module_param_string(force, ata_force_param_buf, sizeof(ata_force_param_buf), 0);
-MODULE_PARM_DESC(force, "Force ATA configurations including cable type, link speed and transfer mode (see Documentation/kernel-parameters.txt for details)");
-
-static int atapi_enabled = 1;
+int atapi_enabled = 1;
 module_param(atapi_enabled, int, 0444);
-MODULE_PARM_DESC(atapi_enabled, "Enable discovery of ATAPI devices (0=off, 1=on [default])");
+MODULE_PARM_DESC(atapi_enabled, "Enable discovery of ATAPI devices (0=off, 1=on)");
 
-static int atapi_dmadir = 0;
+int atapi_dmadir = 0;
 module_param(atapi_dmadir, int, 0444);
-MODULE_PARM_DESC(atapi_dmadir, "Enable ATAPI DMADIR bridge support (0=off [default], 1=on)");
-
-int atapi_passthru16 = 1;
-module_param(atapi_passthru16, int, 0444);
-MODULE_PARM_DESC(atapi_passthru16, "Enable ATA_16 passthru for ATAPI devices (0=off, 1=on [default])");
+MODULE_PARM_DESC(atapi_dmadir, "Enable ATAPI DMADIR bridge support (0=off, 1=on)");
 
 int libata_fua = 0;
 module_param_named(fua, libata_fua, int, 0444);
-MODULE_PARM_DESC(fua, "FUA support (0=off [default], 1=on)");
+MODULE_PARM_DESC(fua, "FUA support (0=off, 1=on)");
 
-static int ata_ignore_hpa;
+static int ata_ignore_hpa = 0;
 module_param_named(ignore_hpa, ata_ignore_hpa, int, 0644);
 MODULE_PARM_DESC(ignore_hpa, "Ignore HPA limit (0=keep BIOS limits, 1=ignore limits, using full disk)");
 
-static int libata_dma_mask = ATA_DMA_MASK_ATA|ATA_DMA_MASK_ATAPI|ATA_DMA_MASK_CFA;
-module_param_named(dma, libata_dma_mask, int, 0444);
-MODULE_PARM_DESC(dma, "DMA enable/disable (0x1==ATA, 0x2==ATAPI, 0x4==CF)");
-
-static int ata_probe_timeout;
+static int ata_probe_timeout = ATA_TMOUT_INTERNAL / HZ;
 module_param(ata_probe_timeout, int, 0444);
 MODULE_PARM_DESC(ata_probe_timeout, "Set ATA probing timeout (seconds)");
 
-int libata_noacpi = 0;
+int libata_noacpi = 1;
 module_param_named(noacpi, libata_noacpi, int, 0444);
-MODULE_PARM_DESC(noacpi, "Disable the use of ACPI in probe/suspend/resume (0=off [default], 1=on)");
-
-int libata_allow_tpm = 0;
-module_param_named(allow_tpm, libata_allow_tpm, int, 0444);
-MODULE_PARM_DESC(allow_tpm, "Permit the use of TPM commands (0=off [default], 1=on)");
-
-static int atapi_an;
-module_param(atapi_an, int, 0444);
-MODULE_PARM_DESC(atapi_an, "Enable ATAPI AN media presence notification (0=0ff [default], 1=on)");
+MODULE_PARM_DESC(noacpi, "Disables the use of ACPI in suspend/resume when set");
 
 MODULE_AUTHOR("Jeff Garzik");
 MODULE_DESCRIPTION("Library module for ATA devices");
@@ -169,369 +113,6 @@
 MODULE_VERSION(DRV_VERSION);
 
 
-static bool ata_sstatus_online(u32 sstatus)
-{
-	return (sstatus & 0xf) == 0x3;
-}
-
-/**
- *	ata_link_next - link iteration helper
- *	@link: the previous link, NULL to start
- *	@ap: ATA port containing links to iterate
- *	@mode: iteration mode, one of ATA_LITER_*
- *
- *	LOCKING:
- *	Host lock or EH context.
- *
- *	RETURNS:
- *	Pointer to the next link.
- */
-struct ata_link *ata_link_next(struct ata_link *link, struct ata_port *ap,
-			       enum ata_link_iter_mode mode)
-{
-	BUG_ON(mode != ATA_LITER_EDGE &&
-	       mode != ATA_LITER_PMP_FIRST && mode != ATA_LITER_HOST_FIRST);
-
-	/* NULL link indicates start of iteration */
-	if (!link)
-		switch (mode) {
-		case ATA_LITER_EDGE:
-		case ATA_LITER_PMP_FIRST:
-			if (sata_pmp_attached(ap))
-				return ap->pmp_link;
-			/* fall through */
-		case ATA_LITER_HOST_FIRST:
-			return &ap->link;
-		}
-
-	/* we just iterated over the host link, what's next? */
-	if (link == &ap->link)
-		switch (mode) {
-		case ATA_LITER_HOST_FIRST:
-			if (sata_pmp_attached(ap))
-				return ap->pmp_link;
-			/* fall through */
-		case ATA_LITER_PMP_FIRST:
-			if (unlikely(ap->slave_link))
-				return ap->slave_link;
-			/* fall through */
-		case ATA_LITER_EDGE:
-			return NULL;
-		}
-
-	/* slave_link excludes PMP */
-	if (unlikely(link == ap->slave_link))
-		return NULL;
-
-	/* we were over a PMP link */
-	if (++link < ap->pmp_link + ap->nr_pmp_links)
-		return link;
-
-	if (mode == ATA_LITER_PMP_FIRST)
-		return &ap->link;
-
-	return NULL;
-}
-
-/**
- *	ata_dev_next - device iteration helper
- *	@dev: the previous device, NULL to start
- *	@link: ATA link containing devices to iterate
- *	@mode: iteration mode, one of ATA_DITER_*
- *
- *	LOCKING:
- *	Host lock or EH context.
- *
- *	RETURNS:
- *	Pointer to the next device.
- */
-struct ata_device *ata_dev_next(struct ata_device *dev, struct ata_link *link,
-				enum ata_dev_iter_mode mode)
-{
-	BUG_ON(mode != ATA_DITER_ENABLED && mode != ATA_DITER_ENABLED_REVERSE &&
-	       mode != ATA_DITER_ALL && mode != ATA_DITER_ALL_REVERSE);
-
-	/* NULL dev indicates start of iteration */
-	if (!dev)
-		switch (mode) {
-		case ATA_DITER_ENABLED:
-		case ATA_DITER_ALL:
-			dev = link->device;
-			goto check;
-		case ATA_DITER_ENABLED_REVERSE:
-		case ATA_DITER_ALL_REVERSE:
-			dev = link->device + ata_link_max_devices(link) - 1;
-			goto check;
-		}
-
- next:
-	/* move to the next one */
-	switch (mode) {
-	case ATA_DITER_ENABLED:
-	case ATA_DITER_ALL:
-		if (++dev < link->device + ata_link_max_devices(link))
-			goto check;
-		return NULL;
-	case ATA_DITER_ENABLED_REVERSE:
-	case ATA_DITER_ALL_REVERSE:
-		if (--dev >= link->device)
-			goto check;
-		return NULL;
-	}
-
- check:
-	if ((mode == ATA_DITER_ENABLED || mode == ATA_DITER_ENABLED_REVERSE) &&
-	    !ata_dev_enabled(dev))
-		goto next;
-	return dev;
-}
-
-/**
- *	ata_dev_phys_link - find physical link for a device
- *	@dev: ATA device to look up physical link for
- *
- *	Look up physical link which @dev is attached to.  Note that
- *	this is different from @dev->link only when @dev is on slave
- *	link.  For all other cases, it's the same as @dev->link.
- *
- *	LOCKING:
- *	Don't care.
- *
- *	RETURNS:
- *	Pointer to the found physical link.
- */
-struct ata_link *ata_dev_phys_link(struct ata_device *dev)
-{
-	struct ata_port *ap = dev->link->ap;
-
-	if (!ap->slave_link)
-		return dev->link;
-	if (!dev->devno)
-		return &ap->link;
-	return ap->slave_link;
-}
-
-/**
- *	ata_force_cbl - force cable type according to libata.force
- *	@ap: ATA port of interest
- *
- *	Force cable type according to libata.force and whine about it.
- *	The last entry which has matching port number is used, so it
- *	can be specified as part of device force parameters.  For
- *	example, both "a:40c,1.00:udma4" and "1.00:40c,udma4" have the
- *	same effect.
- *
- *	LOCKING:
- *	EH context.
- */
-void ata_force_cbl(struct ata_port *ap)
-{
-	int i;
-
-	for (i = ata_force_tbl_size - 1; i >= 0; i--) {
-		const struct ata_force_ent *fe = &ata_force_tbl[i];
-
-		if (fe->port != -1 && fe->port != ap->print_id)
-			continue;
-
-		if (fe->param.cbl == ATA_CBL_NONE)
-			continue;
-
-		ap->cbl = fe->param.cbl;
-		ata_port_printk(ap, KERN_NOTICE,
-				"FORCE: cable set to %s\n", fe->param.name);
-		return;
-	}
-}
-
-/**
- *	ata_force_link_limits - force link limits according to libata.force
- *	@link: ATA link of interest
- *
- *	Force link flags and SATA spd limit according to libata.force
- *	and whine about it.  When only the port part is specified
- *	(e.g. 1:), the limit applies to all links connected to both
- *	the host link and all fan-out ports connected via PMP.  If the
- *	device part is specified as 0 (e.g. 1.00:), it specifies the
- *	first fan-out link not the host link.  Device number 15 always
- *	points to the host link whether PMP is attached or not.  If the
- *	controller has slave link, device number 16 points to it.
- *
- *	LOCKING:
- *	EH context.
- */
-static void ata_force_link_limits(struct ata_link *link)
-{
-	bool did_spd = false;
-	int linkno = link->pmp;
-	int i;
-
-	if (ata_is_host_link(link))
-		linkno += 15;
-
-	for (i = ata_force_tbl_size - 1; i >= 0; i--) {
-		const struct ata_force_ent *fe = &ata_force_tbl[i];
-
-		if (fe->port != -1 && fe->port != link->ap->print_id)
-			continue;
-
-		if (fe->device != -1 && fe->device != linkno)
-			continue;
-
-		/* only honor the first spd limit */
-		if (!did_spd && fe->param.spd_limit) {
-			link->hw_sata_spd_limit = (1 << fe->param.spd_limit) - 1;
-			ata_link_printk(link, KERN_NOTICE,
-					"FORCE: PHY spd limit set to %s\n",
-					fe->param.name);
-			did_spd = true;
-		}
-
-		/* let lflags stack */
-		if (fe->param.lflags) {
-			link->flags |= fe->param.lflags;
-			ata_link_printk(link, KERN_NOTICE,
-					"FORCE: link flag 0x%x forced -> 0x%x\n",
-					fe->param.lflags, link->flags);
-		}
-	}
-}
-
-/**
- *	ata_force_xfermask - force xfermask according to libata.force
- *	@dev: ATA device of interest
- *
- *	Force xfer_mask according to libata.force and whine about it.
- *	For consistency with link selection, device number 15 selects
- *	the first device connected to the host link.
- *
- *	LOCKING:
- *	EH context.
- */
-static void ata_force_xfermask(struct ata_device *dev)
-{
-	int devno = dev->link->pmp + dev->devno;
-	int alt_devno = devno;
-	int i;
-
-	/* allow n.15/16 for devices attached to host port */
-	if (ata_is_host_link(dev->link))
-		alt_devno += 15;
-
-	for (i = ata_force_tbl_size - 1; i >= 0; i--) {
-		const struct ata_force_ent *fe = &ata_force_tbl[i];
-		unsigned long pio_mask, mwdma_mask, udma_mask;
-
-		if (fe->port != -1 && fe->port != dev->link->ap->print_id)
-			continue;
-
-		if (fe->device != -1 && fe->device != devno &&
-		    fe->device != alt_devno)
-			continue;
-
-		if (!fe->param.xfer_mask)
-			continue;
-
-		ata_unpack_xfermask(fe->param.xfer_mask,
-				    &pio_mask, &mwdma_mask, &udma_mask);
-		if (udma_mask)
-			dev->udma_mask = udma_mask;
-		else if (mwdma_mask) {
-			dev->udma_mask = 0;
-			dev->mwdma_mask = mwdma_mask;
-		} else {
-			dev->udma_mask = 0;
-			dev->mwdma_mask = 0;
-			dev->pio_mask = pio_mask;
-		}
-
-		ata_dev_printk(dev, KERN_NOTICE,
-			"FORCE: xfer_mask set to %s\n", fe->param.name);
-		return;
-	}
-}
-
-/**
- *	ata_force_horkage - force horkage according to libata.force
- *	@dev: ATA device of interest
- *
- *	Force horkage according to libata.force and whine about it.
- *	For consistency with link selection, device number 15 selects
- *	the first device connected to the host link.
- *
- *	LOCKING:
- *	EH context.
- */
-static void ata_force_horkage(struct ata_device *dev)
-{
-	int devno = dev->link->pmp + dev->devno;
-	int alt_devno = devno;
-	int i;
-
-	/* allow n.15/16 for devices attached to host port */
-	if (ata_is_host_link(dev->link))
-		alt_devno += 15;
-
-	for (i = 0; i < ata_force_tbl_size; i++) {
-		const struct ata_force_ent *fe = &ata_force_tbl[i];
-
-		if (fe->port != -1 && fe->port != dev->link->ap->print_id)
-			continue;
-
-		if (fe->device != -1 && fe->device != devno &&
-		    fe->device != alt_devno)
-			continue;
-
-		if (!(~dev->horkage & fe->param.horkage_on) &&
-		    !(dev->horkage & fe->param.horkage_off))
-			continue;
-
-		dev->horkage |= fe->param.horkage_on;
-		dev->horkage &= ~fe->param.horkage_off;
-
-		ata_dev_printk(dev, KERN_NOTICE,
-			"FORCE: horkage modified (%s)\n", fe->param.name);
-	}
-}
-
-/**
- *	atapi_cmd_type - Determine ATAPI command type from SCSI opcode
- *	@opcode: SCSI opcode
- *
- *	Determine ATAPI command type from @opcode.
- *
- *	LOCKING:
- *	None.
- *
- *	RETURNS:
- *	ATAPI_{READ|WRITE|READ_CD|PASS_THRU|MISC}
- */
-int atapi_cmd_type(u8 opcode)
-{
-	switch (opcode) {
-	case GPCMD_READ_10:
-	case GPCMD_READ_12:
-		return ATAPI_READ;
-
-	case GPCMD_WRITE_10:
-	case GPCMD_WRITE_12:
-	case GPCMD_WRITE_AND_VERIFY_10:
-		return ATAPI_WRITE;
-
-	case GPCMD_READ_CD:
-	case GPCMD_READ_CD_MSF:
-		return ATAPI_READ_CD;
-
-	case ATA_16:
-	case ATA_12:
-		if (atapi_passthru16)
-			return ATAPI_PASS_THRU;
-		/* fall thru */
-	default:
-		return ATAPI_MISC;
-	}
-}
-
 /**
  *	ata_tf_to_fis - Convert ATA taskfile to SATA FIS structure
  *	@tf: Taskfile to convert
@@ -659,7 +240,7 @@
 	if (dev->flags & ATA_DFLAG_PIO) {
 		tf->protocol = ATA_PROT_PIO;
 		index = dev->multi_count ? 0 : 8;
-	} else if (lba48 && (dev->link->ap->flags & ATA_FLAG_PIO_LBA48)) {
+	} else if (lba48 && (dev->ap->flags & ATA_FLAG_PIO_LBA48)) {
 		/* Unable to use DMA due to host limitation */
 		tf->protocol = ATA_PROT_PIO;
 		index = dev->multi_count ? 0 : 8;
@@ -699,7 +280,7 @@
 		if (tf->flags & ATA_TFLAG_LBA48) {
 			block |= (u64)tf->hob_lbah << 40;
 			block |= (u64)tf->hob_lbam << 32;
-			block |= (u64)tf->hob_lbal << 24;
+			block |= tf->hob_lbal << 24;
 		} else
 			block |= (tf->device & 0xf) << 24;
 
@@ -713,13 +294,7 @@
 		head = tf->device & 0xf;
 		sect = tf->lbal;
 
-		if (!sect) {
-			ata_dev_printk(dev, KERN_WARNING, "device reported "
-				       "invalid CHS sector 0\n");
-			sect = 1; /* oh well */
-		}
-
-		block = (cyl * dev->heads + head) * dev->sectors + sect - 1;
+		block = (cyl * dev->heads + head) * dev->sectors + sect;
 	}
 
 	return block;
@@ -863,9 +438,9 @@
  *	RETURNS:
  *	Packed xfer_mask.
  */
-unsigned long ata_pack_xfermask(unsigned long pio_mask,
-				unsigned long mwdma_mask,
-				unsigned long udma_mask)
+static unsigned int ata_pack_xfermask(unsigned int pio_mask,
+				      unsigned int mwdma_mask,
+				      unsigned int udma_mask)
 {
 	return ((pio_mask << ATA_SHIFT_PIO) & ATA_MASK_PIO) |
 		((mwdma_mask << ATA_SHIFT_MWDMA) & ATA_MASK_MWDMA) |
@@ -882,8 +457,10 @@
  *	Unpack @xfer_mask into @pio_mask, @mwdma_mask and @udma_mask.
  *	Any NULL distination masks will be ignored.
  */
-void ata_unpack_xfermask(unsigned long xfer_mask, unsigned long *pio_mask,
-			 unsigned long *mwdma_mask, unsigned long *udma_mask)
+static void ata_unpack_xfermask(unsigned int xfer_mask,
+				unsigned int *pio_mask,
+				unsigned int *mwdma_mask,
+				unsigned int *udma_mask)
 {
 	if (pio_mask)
 		*pio_mask = (xfer_mask & ATA_MASK_PIO) >> ATA_SHIFT_PIO;
@@ -897,9 +474,9 @@
 	int shift, bits;
 	u8 base;
 } ata_xfer_tbl[] = {
-	{ ATA_SHIFT_PIO, ATA_NR_PIO_MODES, XFER_PIO_0 },
-	{ ATA_SHIFT_MWDMA, ATA_NR_MWDMA_MODES, XFER_MW_DMA_0 },
-	{ ATA_SHIFT_UDMA, ATA_NR_UDMA_MODES, XFER_UDMA_0 },
+	{ ATA_SHIFT_PIO, ATA_BITS_PIO, XFER_PIO_0 },
+	{ ATA_SHIFT_MWDMA, ATA_BITS_MWDMA, XFER_MW_DMA_0 },
+	{ ATA_SHIFT_UDMA, ATA_BITS_UDMA, XFER_UDMA_0 },
 	{ -1, },
 };
 
@@ -914,9 +491,9 @@
  *	None.
  *
  *	RETURNS:
- *	Matching XFER_* value, 0xff if no match found.
+ *	Matching XFER_* value, 0 if no match found.
  */
-u8 ata_xfer_mask2mode(unsigned long xfer_mask)
+static u8 ata_xfer_mask2mode(unsigned int xfer_mask)
 {
 	int highbit = fls(xfer_mask) - 1;
 	const struct ata_xfer_ent *ent;
@@ -924,7 +501,7 @@
 	for (ent = ata_xfer_tbl; ent->shift >= 0; ent++)
 		if (highbit >= ent->shift && highbit < ent->shift + ent->bits)
 			return ent->base + highbit - ent->shift;
-	return 0xff;
+	return 0;
 }
 
 /**
@@ -939,14 +516,13 @@
  *	RETURNS:
  *	Matching xfer_mask, 0 if no match found.
  */
-unsigned long ata_xfer_mode2mask(u8 xfer_mode)
+static unsigned int ata_xfer_mode2mask(u8 xfer_mode)
 {
 	const struct ata_xfer_ent *ent;
 
 	for (ent = ata_xfer_tbl; ent->shift >= 0; ent++)
 		if (xfer_mode >= ent->base && xfer_mode < ent->base + ent->bits)
-			return ((2 << (ent->shift + xfer_mode - ent->base)) - 1)
-				& ~((1 << ent->shift) - 1);
+			return 1 << (ent->shift + xfer_mode - ent->base);
 	return 0;
 }
 
@@ -962,7 +538,7 @@
  *	RETURNS:
  *	Matching xfer_shift, -1 if no match found.
  */
-int ata_xfer_mode2shift(unsigned long xfer_mode)
+static int ata_xfer_mode2shift(unsigned int xfer_mode)
 {
 	const struct ata_xfer_ent *ent;
 
@@ -986,7 +562,7 @@
  *	Constant C string representing highest speed listed in
  *	@mode_mask, or the constant C string "<n/a>".
  */
-const char *ata_mode_string(unsigned long xfer_mask)
+static const char *ata_mode_string(unsigned int xfer_mask)
 {
 	static const char * const xfer_mode_str[] = {
 		"PIO0",
@@ -1023,7 +599,6 @@
 	static const char * const spd_str[] = {
 		"1.5 Gbps",
 		"3.0 Gbps",
-		"6.0 Gbps",
 	};
 
 	if (spd == 0 || (spd - 1) >= ARRAY_SIZE(spd_str))
@@ -1031,181 +606,59 @@
 	return spd_str[spd - 1];
 }
 
-static int ata_dev_set_dipm(struct ata_device *dev, enum link_pm policy)
+void ata_dev_disable(struct ata_device *dev)
 {
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
-	u32 scontrol;
-	unsigned int err_mask;
-	int rc;
-
-	/*
-	 * disallow DIPM for drivers which haven't set
-	 * ATA_FLAG_IPM.  This is because when DIPM is enabled,
-	 * phy ready will be set in the interrupt status on
-	 * state changes, which will cause some drivers to
-	 * think there are errors - additionally drivers will
-	 * need to disable hot plug.
-	 */
-	if (!(ap->flags & ATA_FLAG_IPM) || !ata_dev_enabled(dev)) {
-		ap->pm_policy = NOT_AVAILABLE;
-		return -EINVAL;
-	}
-
-	/*
-	 * For DIPM, we will only enable it for the
-	 * min_power setting.
-	 *
-	 * Why?  Because Disks are too stupid to know that
-	 * If the host rejects a request to go to SLUMBER
-	 * they should retry at PARTIAL, and instead it
-	 * just would give up.  So, for medium_power to
-	 * work at all, we need to only allow HIPM.
-	 */
-	rc = sata_scr_read(link, SCR_CONTROL, &scontrol);
-	if (rc)
-		return rc;
-
-	switch (policy) {
-	case MIN_POWER:
-		/* no restrictions on IPM transitions */
-		scontrol &= ~(0x3 << 8);
-		rc = sata_scr_write(link, SCR_CONTROL, scontrol);
-		if (rc)
-			return rc;
-
-		/* enable DIPM */
-		if (dev->flags & ATA_DFLAG_DIPM)
-			err_mask = ata_dev_set_feature(dev,
-					SETFEATURES_SATA_ENABLE, SATA_DIPM);
-		break;
-	case MEDIUM_POWER:
-		/* allow IPM to PARTIAL */
-		scontrol &= ~(0x1 << 8);
-		scontrol |= (0x2 << 8);
-		rc = sata_scr_write(link, SCR_CONTROL, scontrol);
-		if (rc)
-			return rc;
-
-		/*
-		 * we don't have to disable DIPM since IPM flags
-		 * disallow transitions to SLUMBER, which effectively
-		 * disable DIPM if it does not support PARTIAL
-		 */
-		break;
-	case NOT_AVAILABLE:
-	case MAX_PERFORMANCE:
-		/* disable all IPM transitions */
-		scontrol |= (0x3 << 8);
-		rc = sata_scr_write(link, SCR_CONTROL, scontrol);
-		if (rc)
-			return rc;
-
-		/*
-		 * we don't have to disable DIPM since IPM flags
-		 * disallow all transitions which effectively
-		 * disable DIPM anyway.
-		 */
-		break;
+	if (ata_dev_enabled(dev)) {
+		if (ata_msg_drv(dev->ap))
+			ata_dev_printk(dev, KERN_WARNING, "disabled\n");
+		ata_down_xfermask_limit(dev, ATA_DNXFER_FORCE_PIO0 |
+					     ATA_DNXFER_QUIET);
+		dev->class++;
 	}
-
-	/* FIXME: handle SET FEATURES failure */
-	(void) err_mask;
-
-	return 0;
 }
 
 /**
- *	ata_dev_enable_pm - enable SATA interface power management
- *	@dev:  device to enable power management
- *	@policy: the link power management policy
- *
- *	Enable SATA Interface power management.  This will enable
- *	Device Interface Power Management (DIPM) for min_power
- * 	policy, and then call driver specific callbacks for
- *	enabling Host Initiated Power management.
+ *	ata_devchk - PATA device presence detection
+ *	@ap: ATA channel to examine
+ *	@device: Device to examine (starting at zero)
  *
- *	Locking: Caller.
- *	Returns: -EINVAL if IPM is not supported, 0 otherwise.
- */
-void ata_dev_enable_pm(struct ata_device *dev, enum link_pm policy)
-{
-	int rc = 0;
-	struct ata_port *ap = dev->link->ap;
-
-	/* set HIPM first, then DIPM */
-	if (ap->ops->enable_pm)
-		rc = ap->ops->enable_pm(ap, policy);
-	if (rc)
-		goto enable_pm_out;
-	rc = ata_dev_set_dipm(dev, policy);
-
-enable_pm_out:
-	if (rc)
-		ap->pm_policy = MAX_PERFORMANCE;
-	else
-		ap->pm_policy = policy;
-	return /* rc */;	/* hopefully we can use 'rc' eventually */
-}
-
-#ifdef CONFIG_PM
-/**
- *	ata_dev_disable_pm - disable SATA interface power management
- *	@dev: device to disable power management
+ *	This technique was originally described in
+ *	Hale Landis's ATADRVR (www.ata-atapi.com), and
+ *	later found its way into the ATA/ATAPI spec.
  *
- *	Disable SATA Interface power management.  This will disable
- *	Device Interface Power Management (DIPM) without changing
- * 	policy,  call driver specific callbacks for disabling Host
- * 	Initiated Power management.
+ *	Write a pattern to the ATA shadow registers,
+ *	and if a device is present, it will respond by
+ *	correctly storing and echoing back the
+ *	ATA shadow register contents.
  *
- *	Locking: Caller.
- *	Returns: void
+ *	LOCKING:
+ *	caller.
  */
-static void ata_dev_disable_pm(struct ata_device *dev)
+
+static unsigned int ata_devchk(struct ata_port *ap, unsigned int device)
 {
-	struct ata_port *ap = dev->link->ap;
+	struct ata_ioports *ioaddr = &ap->ioaddr;
+	u8 nsect, lbal;
 
-	ata_dev_set_dipm(dev, MAX_PERFORMANCE);
-	if (ap->ops->disable_pm)
-		ap->ops->disable_pm(ap);
-}
-#endif	/* CONFIG_PM */
+	ap->ops->dev_select(ap, device);
 
-void ata_lpm_schedule(struct ata_port *ap, enum link_pm policy)
-{
-	ap->pm_policy = policy;
-	ap->link.eh_info.action |= ATA_EH_LPM;
-	ap->link.eh_info.flags |= ATA_EHI_NO_AUTOPSY;
-	ata_port_schedule_eh(ap);
-}
+	iowrite8(0x55, ioaddr->nsect_addr);
+	iowrite8(0xaa, ioaddr->lbal_addr);
 
-#ifdef CONFIG_PM
-static void ata_lpm_enable(struct ata_host *host)
-{
-	struct ata_link *link;
-	struct ata_port *ap;
-	struct ata_device *dev;
-	int i;
+	iowrite8(0xaa, ioaddr->nsect_addr);
+	iowrite8(0x55, ioaddr->lbal_addr);
 
-	for (i = 0; i < host->n_ports; i++) {
-		ap = host->ports[i];
-		ata_for_each_link(link, ap, EDGE) {
-			ata_for_each_dev(dev, link, ALL)
-				ata_dev_disable_pm(dev);
-		}
-	}
-}
+	iowrite8(0x55, ioaddr->nsect_addr);
+	iowrite8(0xaa, ioaddr->lbal_addr);
 
-static void ata_lpm_disable(struct ata_host *host)
-{
-	int i;
+	nsect = ioread8(ioaddr->nsect_addr);
+	lbal = ioread8(ioaddr->lbal_addr);
 
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		ata_lpm_schedule(ap, ap->pm_policy);
-	}
+	if ((nsect == 0x55) && (lbal == 0xaa))
+		return 1;	/* we found a device */
+
+	return 0;		/* nothing found */
 }
-#endif	/* CONFIG_PM */
 
 /**
  *	ata_dev_classify - determine device type based on ATA-spec signature
@@ -1219,57 +672,93 @@
  *	None.
  *
  *	RETURNS:
- *	Device type, %ATA_DEV_ATA, %ATA_DEV_ATAPI, %ATA_DEV_PMP or
- *	%ATA_DEV_UNKNOWN the event of failure.
+ *	Device type, %ATA_DEV_ATA, %ATA_DEV_ATAPI, or %ATA_DEV_UNKNOWN
+ *	the event of failure.
  */
+
 unsigned int ata_dev_classify(const struct ata_taskfile *tf)
 {
 	/* Apple's open source Darwin code hints that some devices only
 	 * put a proper signature into the LBA mid/high registers,
 	 * So, we only check those.  It's sufficient for uniqueness.
-	 *
-	 * ATA/ATAPI-7 (d1532v1r1: Feb. 19, 2003) specified separate
-	 * signatures for ATA and ATAPI devices attached on SerialATA,
-	 * 0x3c/0xc3 and 0x69/0x96 respectively.  However, SerialATA
-	 * spec has never mentioned about using different signatures
-	 * for ATA/ATAPI devices.  Then, Serial ATA II: Port
-	 * Multiplier specification began to use 0x69/0x96 to identify
-	 * port multpliers and 0x3c/0xc3 to identify SEMB device.
-	 * ATA/ATAPI-7 dropped descriptions about 0x3c/0xc3 and
-	 * 0x69/0x96 shortly and described them as reserved for
-	 * SerialATA.
-	 *
-	 * We follow the current spec and consider that 0x69/0x96
-	 * identifies a port multiplier and 0x3c/0xc3 a SEMB device.
-	 * Unfortunately, WDC WD1600JS-62MHB5 (a hard drive) reports
-	 * SEMB signature.  This is worked around in
-	 * ata_dev_read_id().
 	 */
-	if ((tf->lbam == 0) && (tf->lbah == 0)) {
+
+	if (((tf->lbam == 0) && (tf->lbah == 0)) ||
+	    ((tf->lbam == 0x3c) && (tf->lbah == 0xc3))) {
 		DPRINTK("found ATA device by sig\n");
 		return ATA_DEV_ATA;
 	}
 
-	if ((tf->lbam == 0x14) && (tf->lbah == 0xeb)) {
+	if (((tf->lbam == 0x14) && (tf->lbah == 0xeb)) ||
+	    ((tf->lbam == 0x69) && (tf->lbah == 0x96))) {
 		DPRINTK("found ATAPI device by sig\n");
 		return ATA_DEV_ATAPI;
 	}
 
-	if ((tf->lbam == 0x69) && (tf->lbah == 0x96)) {
-		DPRINTK("found PMP device by sig\n");
-		return ATA_DEV_PMP;
-	}
-
-	if ((tf->lbam == 0x3c) && (tf->lbah == 0xc3)) {
-		DPRINTK("found SEMB device by sig (could be ATA device)\n");
-		return ATA_DEV_SEMB;
-	}
-
 	DPRINTK("unknown device\n");
 	return ATA_DEV_UNKNOWN;
 }
 
 /**
+ *	ata_dev_try_classify - Parse returned ATA device signature
+ *	@ap: ATA channel to examine
+ *	@device: Device to examine (starting at zero)
+ *	@r_err: Value of error register on completion
+ *
+ *	After an event -- SRST, E.D.D., or SATA COMRESET -- occurs,
+ *	an ATA/ATAPI-defined set of values is placed in the ATA
+ *	shadow registers, indicating the results of device detection
+ *	and diagnostics.
+ *
+ *	Select the ATA device, and read the values from the ATA shadow
+ *	registers.  Then parse according to the Error register value,
+ *	and the spec-defined values examined by ata_dev_classify().
+ *
+ *	LOCKING:
+ *	caller.
+ *
+ *	RETURNS:
+ *	Device type - %ATA_DEV_ATA, %ATA_DEV_ATAPI or %ATA_DEV_NONE.
+ */
+
+unsigned int
+ata_dev_try_classify(struct ata_port *ap, unsigned int device, u8 *r_err)
+{
+	struct ata_taskfile tf;
+	unsigned int class;
+	u8 err;
+
+	ap->ops->dev_select(ap, device);
+
+	memset(&tf, 0, sizeof(tf));
+
+	ap->ops->tf_read(ap, &tf);
+	err = tf.feature;
+	if (r_err)
+		*r_err = err;
+
+	/* see if device passed diags: if master then continue and warn later */
+	if (err == 0 && device == 0)
+		/* diagnostic fail : do nothing _YET_ */
+		ap->device[device].horkage |= ATA_HORKAGE_DIAGNOSTIC;
+	else if (err == 1)
+		/* do nothing */ ;
+	else if ((device == 0) && (err == 0x81))
+		/* do nothing */ ;
+	else
+		return ATA_DEV_NONE;
+
+	/* determine if device is ATA or ATAPI */
+	class = ata_dev_classify(&tf);
+
+	if (class == ATA_DEV_UNKNOWN)
+		return ATA_DEV_NONE;
+	if ((class == ATA_DEV_ATA) && (ata_chk_status(ap) == 0))
+		return ATA_DEV_NONE;
+	return class;
+}
+
+/**
  *	ata_id_string - Convert IDENTIFY DEVICE page into string
  *	@id: IDENTIFY DEVICE results we will examine
  *	@s: string into which data is output
@@ -1289,8 +778,6 @@
 {
 	unsigned int c;
 
-	BUG_ON(len & 1);
-
 	while (len > 0) {
 		c = id[ofs] >> 8;
 		*s = c;
@@ -1324,6 +811,8 @@
 {
 	unsigned char *p;
 
+	WARN_ON(!(len & 1));
+
 	ata_id_string(id, s, ofs, len - 1);
 
 	p = s + strnlen(s, len - 1);
@@ -1332,38 +821,21 @@
 	*p = '\0';
 }
 
-static u64 ata_id_n_sectors(const u16 *id)
-{
-	if (ata_id_has_lba(id)) {
-		if (ata_id_has_lba48(id))
-			return ata_id_u64(id, ATA_ID_LBA_CAPACITY_2);
-		else
-			return ata_id_u32(id, ATA_ID_LBA_CAPACITY);
-	} else {
-		if (ata_id_current_chs_valid(id))
-			return id[ATA_ID_CUR_CYLS] * id[ATA_ID_CUR_HEADS] *
-			       id[ATA_ID_CUR_SECTORS];
-		else
-			return id[ATA_ID_CYLS] * id[ATA_ID_HEADS] *
-			       id[ATA_ID_SECTORS];
-	}
-}
-
-u64 ata_tf_to_lba48(const struct ata_taskfile *tf)
+static u64 ata_tf_to_lba48(struct ata_taskfile *tf)
 {
 	u64 sectors = 0;
 
 	sectors |= ((u64)(tf->hob_lbah & 0xff)) << 40;
 	sectors |= ((u64)(tf->hob_lbam & 0xff)) << 32;
-	sectors |= ((u64)(tf->hob_lbal & 0xff)) << 24;
+	sectors |= (tf->hob_lbal & 0xff) << 24;
 	sectors |= (tf->lbah & 0xff) << 16;
 	sectors |= (tf->lbam & 0xff) << 8;
 	sectors |= (tf->lbal & 0xff);
 
-	return sectors;
+	return ++sectors;
 }
 
-u64 ata_tf_to_lba(const struct ata_taskfile *tf)
+static u64 ata_tf_to_lba(struct ata_taskfile *tf)
 {
 	u64 sectors = 0;
 
@@ -1372,114 +844,133 @@
 	sectors |= (tf->lbam & 0xff) << 8;
 	sectors |= (tf->lbal & 0xff);
 
-	return sectors;
+	return ++sectors;
 }
 
 /**
- *	ata_read_native_max_address - Read native max address
- *	@dev: target device
- *	@max_sectors: out parameter for the result native max address
- *
- *	Perform an LBA48 or LBA28 native size query upon the device in
- *	question.
+ *	ata_read_native_max_address_ext	-	LBA48 native max query
+ *	@dev: Device to query
  *
- *	RETURNS:
- *	0 on success, -EACCES if command is aborted by the drive.
- *	-EIO on other errors.
+ *	Perform an LBA48 size query upon the device in question. Return the
+ *	actual LBA48 size or zero if the command fails.
  */
-static int ata_read_native_max_address(struct ata_device *dev, u64 *max_sectors)
+
+static u64 ata_read_native_max_address_ext(struct ata_device *dev)
 {
-	unsigned int err_mask;
+	unsigned int err;
 	struct ata_taskfile tf;
-	int lba48 = ata_id_has_lba48(dev->id);
 
 	ata_tf_init(dev, &tf);
 
-	/* always clear all address registers */
-	tf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_ISADDR;
+	tf.command = ATA_CMD_READ_NATIVE_MAX_EXT;
+	tf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_LBA48 | ATA_TFLAG_ISADDR;
+	tf.protocol |= ATA_PROT_NODATA;
+	tf.device |= 0x40;
 
-	if (lba48) {
-		tf.command = ATA_CMD_READ_NATIVE_MAX_EXT;
-		tf.flags |= ATA_TFLAG_LBA48;
-	} else
-		tf.command = ATA_CMD_READ_NATIVE_MAX;
+	err = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0);
+	if (err)
+		return 0;
+
+	return ata_tf_to_lba48(&tf);
+}
+
+/**
+ *	ata_read_native_max_address	-	LBA28 native max query
+ *	@dev: Device to query
+ *
+ *	Performa an LBA28 size query upon the device in question. Return the
+ *	actual LBA28 size or zero if the command fails.
+ */
+
+static u64 ata_read_native_max_address(struct ata_device *dev)
+{
+	unsigned int err;
+	struct ata_taskfile tf;
+
+	ata_tf_init(dev, &tf);
 
+	tf.command = ATA_CMD_READ_NATIVE_MAX;
+	tf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_ISADDR;
 	tf.protocol |= ATA_PROT_NODATA;
-	tf.device |= ATA_LBA;
+	tf.device |= 0x40;
 
-	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);
-	if (err_mask) {
-		ata_dev_printk(dev, KERN_WARNING, "failed to read native "
-			       "max address (err_mask=0x%x)\n", err_mask);
-		if (err_mask == AC_ERR_DEV && (tf.feature & ATA_ABORTED))
-			return -EACCES;
-		return -EIO;
-	}
+	err = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0);
+	if (err)
+		return 0;
 
-	if (lba48)
-		*max_sectors = ata_tf_to_lba48(&tf) + 1;
-	else
-		*max_sectors = ata_tf_to_lba(&tf) + 1;
-	if (dev->horkage & ATA_HORKAGE_HPA_SIZE)
-		(*max_sectors)--;
-	return 0;
+	return ata_tf_to_lba(&tf);
 }
 
 /**
- *	ata_set_max_sectors - Set max sectors
- *	@dev: target device
+ *	ata_set_native_max_address_ext	-	LBA48 native max set
+ *	@dev: Device to query
  *	@new_sectors: new max sectors value to set for the device
  *
- *	Set max sectors of @dev to @new_sectors.
- *
- *	RETURNS:
- *	0 on success, -EACCES if command is aborted or denied (due to
- *	previous non-volatile SET_MAX) by the drive.  -EIO on other
- *	errors.
+ *	Perform an LBA48 size set max upon the device in question. Return the
+ *	actual LBA48 size or zero if the command fails.
  */
-static int ata_set_max_sectors(struct ata_device *dev, u64 new_sectors)
+
+static u64 ata_set_native_max_address_ext(struct ata_device *dev, u64 new_sectors)
 {
-	unsigned int err_mask;
+	unsigned int err;
 	struct ata_taskfile tf;
-	int lba48 = ata_id_has_lba48(dev->id);
 
 	new_sectors--;
 
 	ata_tf_init(dev, &tf);
 
-	tf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_ISADDR;
+	tf.command = ATA_CMD_SET_MAX_EXT;
+	tf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_LBA48 | ATA_TFLAG_ISADDR;
+	tf.protocol |= ATA_PROT_NODATA;
+	tf.device |= 0x40;
 
-	if (lba48) {
-		tf.command = ATA_CMD_SET_MAX_EXT;
-		tf.flags |= ATA_TFLAG_LBA48;
-
-		tf.hob_lbal = (new_sectors >> 24) & 0xff;
-		tf.hob_lbam = (new_sectors >> 32) & 0xff;
-		tf.hob_lbah = (new_sectors >> 40) & 0xff;
-	} else {
-		tf.command = ATA_CMD_SET_MAX;
+	tf.lbal = (new_sectors >> 0) & 0xff;
+	tf.lbam = (new_sectors >> 8) & 0xff;
+	tf.lbah = (new_sectors >> 16) & 0xff;
 
-		tf.device |= (new_sectors >> 24) & 0xf;
-	}
+	tf.hob_lbal = (new_sectors >> 24) & 0xff;
+	tf.hob_lbam = (new_sectors >> 32) & 0xff;
+	tf.hob_lbah = (new_sectors >> 40) & 0xff;
+
+	err = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0);
+	if (err)
+		return 0;
+
+	return ata_tf_to_lba48(&tf);
+}
+
+/**
+ *	ata_set_native_max_address	-	LBA28 native max set
+ *	@dev: Device to query
+ *	@new_sectors: new max sectors value to set for the device
+ *
+ *	Perform an LBA28 size set max upon the device in question. Return the
+ *	actual LBA28 size or zero if the command fails.
+ */
 
+static u64 ata_set_native_max_address(struct ata_device *dev, u64 new_sectors)
+{
+	unsigned int err;
+	struct ata_taskfile tf;
+
+	new_sectors--;
+
+	ata_tf_init(dev, &tf);
+
+	tf.command = ATA_CMD_SET_MAX;
+	tf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_ISADDR;
 	tf.protocol |= ATA_PROT_NODATA;
-	tf.device |= ATA_LBA;
 
 	tf.lbal = (new_sectors >> 0) & 0xff;
 	tf.lbam = (new_sectors >> 8) & 0xff;
 	tf.lbah = (new_sectors >> 16) & 0xff;
+	tf.device |= ((new_sectors >> 24) & 0x0f) | 0x40;
 
-	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);
-	if (err_mask) {
-		ata_dev_printk(dev, KERN_WARNING, "failed to set "
-			       "max address (err_mask=0x%x)\n", err_mask);
-		if (err_mask == AC_ERR_DEV &&
-		    (tf.feature & (ATA_ABORTED | ATA_IDNF)))
-			return -EACCES;
-		return -EIO;
-	}
+	err = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0);
+	if (err)
+		return 0;
 
-	return 0;
+	return ata_tf_to_lba(&tf);
 }
 
 /**
@@ -1489,94 +980,185 @@
  *	Read the size of an LBA28 or LBA48 disk with HPA features and resize
  *	it if required to the full size of the media. The caller must check
  *	the drive has the HPA feature set enabled.
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
  */
-static int ata_hpa_resize(struct ata_device *dev)
+
+static u64 ata_hpa_resize(struct ata_device *dev)
 {
-	struct ata_eh_context *ehc = &dev->link->eh_context;
-	int print_info = ehc->i.flags & ATA_EHI_PRINTINFO;
-	u64 sectors = ata_id_n_sectors(dev->id);
-	u64 native_sectors;
-	int rc;
+	u64 sectors = dev->n_sectors;
+	u64 hpa_sectors;
 
-	/* do we need to do it? */
-	if (dev->class != ATA_DEV_ATA ||
-	    !ata_id_has_lba(dev->id) || !ata_id_hpa_enabled(dev->id) ||
-	    (dev->horkage & ATA_HORKAGE_BROKEN_HPA))
-		return 0;
+	if (ata_id_has_lba48(dev->id))
+		hpa_sectors = ata_read_native_max_address_ext(dev);
+	else
+		hpa_sectors = ata_read_native_max_address(dev);
 
-	/* read native max address */
-	rc = ata_read_native_max_address(dev, &native_sectors);
-	if (rc) {
-		/* If device aborted the command or HPA isn't going to
-		 * be unlocked, skip HPA resizing.
-		 */
-		if (rc == -EACCES || !ata_ignore_hpa) {
-			ata_dev_printk(dev, KERN_WARNING, "HPA support seems "
-				       "broken, skipping HPA handling\n");
-			dev->horkage |= ATA_HORKAGE_BROKEN_HPA;
-
-			/* we can continue if device aborted the command */
-			if (rc == -EACCES)
-				rc = 0;
+	if (hpa_sectors > sectors) {
+		ata_dev_printk(dev, KERN_INFO,
+			"Host Protected Area detected:\n"
+			"\tcurrent size: %lld sectors\n"
+			"\tnative size: %lld sectors\n",
+			(long long)sectors, (long long)hpa_sectors);
+
+		if (ata_ignore_hpa) {
+			if (ata_id_has_lba48(dev->id))
+				hpa_sectors = ata_set_native_max_address_ext(dev, hpa_sectors);
+			else
+				hpa_sectors = ata_set_native_max_address(dev,
+								hpa_sectors);
+
+			if (hpa_sectors) {
+				ata_dev_printk(dev, KERN_INFO, "native size "
+					"increased to %lld sectors\n",
+					(long long)hpa_sectors);
+				return hpa_sectors;
+			}
 		}
+	} else if (hpa_sectors < sectors)
+		ata_dev_printk(dev, KERN_WARNING, "%s 1: hpa sectors (%lld) "
+			       "is smaller than sectors (%lld)\n", __FUNCTION__,
+			       (long long)hpa_sectors, (long long)sectors);
 
-		return rc;
+	return sectors;
+}
+
+static u64 ata_id_n_sectors(const u16 *id)
+{
+	if (ata_id_has_lba(id)) {
+		if (ata_id_has_lba48(id))
+			return ata_id_u64(id, 100);
+		else
+			return ata_id_u32(id, 60);
+	} else {
+		if (ata_id_current_chs_valid(id))
+			return ata_id_u32(id, 57);
+		else
+			return id[1] * id[3] * id[6];
 	}
-	dev->n_native_sectors = native_sectors;
+}
 
-	/* nothing to do? */
-	if (native_sectors <= sectors || !ata_ignore_hpa) {
-		if (!print_info || native_sectors == sectors)
-			return 0;
+/**
+ *	ata_id_to_dma_mode	-	Identify DMA mode from id block
+ *	@dev: device to identify
+ *	@unknown: mode to assume if we cannot tell
+ *
+ *	Set up the timing values for the device based upon the identify
+ *	reported values for the DMA mode. This function is used by drivers
+ *	which rely upon firmware configured modes, but wish to report the
+ *	mode correctly when possible.
+ *
+ *	In addition we emit similarly formatted messages to the default
+ *	ata_dev_set_mode handler, in order to provide consistency of
+ *	presentation.
+ */
 
-		if (native_sectors > sectors)
-			ata_dev_printk(dev, KERN_INFO,
-				"HPA detected: current %llu, native %llu\n",
-				(unsigned long long)sectors,
-				(unsigned long long)native_sectors);
-		else if (native_sectors < sectors)
-			ata_dev_printk(dev, KERN_WARNING,
-				"native sectors (%llu) is smaller than "
-				"sectors (%llu)\n",
-				(unsigned long long)native_sectors,
-				(unsigned long long)sectors);
-		return 0;
-	}
+void ata_id_to_dma_mode(struct ata_device *dev, u8 unknown)
+{
+	unsigned int mask;
+	u8 mode;
 
-	/* let's unlock HPA */
-	rc = ata_set_max_sectors(dev, native_sectors);
-	if (rc == -EACCES) {
-		/* if device aborted the command, skip HPA resizing */
-		ata_dev_printk(dev, KERN_WARNING, "device aborted resize "
-			       "(%llu -> %llu), skipping HPA handling\n",
-			       (unsigned long long)sectors,
-			       (unsigned long long)native_sectors);
-		dev->horkage |= ATA_HORKAGE_BROKEN_HPA;
-		return 0;
-	} else if (rc)
-		return rc;
+	/* Pack the DMA modes */
+	mask = ((dev->id[63] >> 8) << ATA_SHIFT_MWDMA) & ATA_MASK_MWDMA;
+	if (dev->id[53] & 0x04)
+		mask |= ((dev->id[88] >> 8) << ATA_SHIFT_UDMA) & ATA_MASK_UDMA;
 
-	/* re-read IDENTIFY data */
-	rc = ata_dev_reread_id(dev, 0);
-	if (rc) {
-		ata_dev_printk(dev, KERN_ERR, "failed to re-read IDENTIFY "
-			       "data after HPA resizing\n");
-		return rc;
-	}
+	/* Select the mode in use */
+	mode = ata_xfer_mask2mode(mask);
 
-	if (print_info) {
-		u64 new_sectors = ata_id_n_sectors(dev->id);
-		ata_dev_printk(dev, KERN_INFO,
-			"HPA unlocked: %llu -> %llu, native %llu\n",
-			(unsigned long long)sectors,
-			(unsigned long long)new_sectors,
-			(unsigned long long)native_sectors);
+	if (mode != 0) {
+		ata_dev_printk(dev, KERN_INFO, "configured for %s\n",
+		       ata_mode_string(mask));
+	} else {
+		/* SWDMA perhaps ? */
+		mode = unknown;
+		ata_dev_printk(dev, KERN_INFO, "configured for DMA\n");
 	}
 
-	return 0;
+	/* Configure the device reporting */
+	dev->xfer_mode = mode;
+	dev->xfer_shift = ata_xfer_mode2shift(mode);
+}
+
+/**
+ *	ata_noop_dev_select - Select device 0/1 on ATA bus
+ *	@ap: ATA channel to manipulate
+ *	@device: ATA device (numbered from zero) to select
+ *
+ *	This function performs no actual function.
+ *
+ *	May be used as the dev_select() entry in ata_port_operations.
+ *
+ *	LOCKING:
+ *	caller.
+ */
+void ata_noop_dev_select (struct ata_port *ap, unsigned int device)
+{
+}
+
+
+/**
+ *	ata_std_dev_select - Select device 0/1 on ATA bus
+ *	@ap: ATA channel to manipulate
+ *	@device: ATA device (numbered from zero) to select
+ *
+ *	Use the method defined in the ATA specification to
+ *	make either device 0, or device 1, active on the
+ *	ATA channel.  Works with both PIO and MMIO.
+ *
+ *	May be used as the dev_select() entry in ata_port_operations.
+ *
+ *	LOCKING:
+ *	caller.
+ */
+
+void ata_std_dev_select (struct ata_port *ap, unsigned int device)
+{
+	u8 tmp;
+
+	if (device == 0)
+		tmp = ATA_DEVICE_OBS;
+	else
+		tmp = ATA_DEVICE_OBS | ATA_DEV1;
+
+	iowrite8(tmp, ap->ioaddr.device_addr);
+	ata_pause(ap);		/* needed; also flushes, for mmio */
+}
+
+/**
+ *	ata_dev_select - Select device 0/1 on ATA bus
+ *	@ap: ATA channel to manipulate
+ *	@device: ATA device (numbered from zero) to select
+ *	@wait: non-zero to wait for Status register BSY bit to clear
+ *	@can_sleep: non-zero if context allows sleeping
+ *
+ *	Use the method defined in the ATA specification to
+ *	make either device 0, or device 1, active on the
+ *	ATA channel.
+ *
+ *	This is a high-level version of ata_std_dev_select(),
+ *	which additionally provides the services of inserting
+ *	the proper pauses and status polling, where needed.
+ *
+ *	LOCKING:
+ *	caller.
+ */
+
+void ata_dev_select(struct ata_port *ap, unsigned int device,
+			   unsigned int wait, unsigned int can_sleep)
+{
+	if (ata_msg_probe(ap))
+		ata_port_printk(ap, KERN_INFO, "ata_dev_select: ENTER, "
+				"device %u, wait %u\n", device, wait);
+
+	if (wait)
+		ata_wait_idle(ap);
+
+	ap->ops->dev_select(ap, device);
+
+	if (wait) {
+		if (can_sleep && ap->device[device].class == ATA_DEV_ATAPI)
+			msleep(150);
+		ata_wait_idle(ap);
+	}
 }
 
 /**
@@ -1633,9 +1215,9 @@
  *	RETURNS:
  *	Computed xfermask
  */
-unsigned long ata_id_xfermask(const u16 *id)
+static unsigned int ata_id_xfermask(const u16 *id)
 {
-	unsigned long pio_mask, mwdma_mask, udma_mask;
+	unsigned int pio_mask, mwdma_mask, udma_mask;
 
 	/* Usual case. Word 53 indicates word 64 is valid */
 	if (id[ATA_ID_FIELD_VALID] & (1 << 1)) {
@@ -1649,7 +1231,7 @@
 		 */
 		u8 mode = (id[ATA_ID_OLD_PIO_MODES] >> 8) & 0xFF;
 		if (mode < 5)	/* Valid PIO range */
-			pio_mask = (2 << mode) - 1;
+                	pio_mask = (2 << mode) - 1;
 		else
 			pio_mask = 1;
 
@@ -1667,8 +1249,8 @@
 		/*
 		 *	Process compact flash extended modes
 		 */
-		int pio = (id[ATA_ID_CFA_MODES] >> 0) & 0x7;
-		int dma = (id[ATA_ID_CFA_MODES] >> 3) & 0x7;
+		int pio = id[163] & 0x7;
+		int dma = (id[163] >> 3) & 7;
 
 		if (pio)
 			pio_mask |= (1 << 5);
@@ -1688,10 +1270,11 @@
 }
 
 /**
- *	ata_pio_queue_task - Queue port_task
+ *	ata_port_queue_task - Queue port_task
  *	@ap: The ata_port to queue port_task for
+ *	@fn: workqueue function to be scheduled
  *	@data: data for @fn to use
- *	@delay: delay time in msecs for workqueue function
+ *	@delay: delay time for workqueue function
  *
  *	Schedule @fn(@data) for execution after @delay jiffies using
  *	port_task.  There is one port_task per port and it's the
@@ -1699,18 +1282,20 @@
  *	one task is active at any given time.
  *
  *	libata core layer takes care of synchronization between
- *	port_task and EH.  ata_pio_queue_task() may be ignored for EH
+ *	port_task and EH.  ata_port_queue_task() may be ignored for EH
  *	synchronization.
  *
  *	LOCKING:
  *	Inherited from caller.
  */
-void ata_pio_queue_task(struct ata_port *ap, void *data, unsigned long delay)
+void ata_port_queue_task(struct ata_port *ap, work_func_t fn, void *data,
+			 unsigned long delay)
 {
+	PREPARE_DELAYED_WORK(&ap->port_task, fn);
 	ap->port_task_data = data;
 
 	/* may fail if ata_port_flush_task() in progress */
-	queue_delayed_work(ata_wq, &ap->port_task, msecs_to_jiffies(delay));
+	queue_delayed_work(ata_wq, &ap->port_task, delay);
 }
 
 /**
@@ -1730,7 +1315,7 @@
 	cancel_rearming_delayed_work(&ap->port_task);
 
 	if (ata_msg_ctl(ap))
-		ata_port_printk(ap, KERN_DEBUG, "%s: EXIT\n", __func__);
+		ata_port_printk(ap, KERN_DEBUG, "%s: EXIT\n", __FUNCTION__);
 }
 
 static void ata_qc_complete_internal(struct ata_queued_cmd *qc)
@@ -1746,9 +1331,8 @@
  *	@tf: Taskfile registers for the command and the result
  *	@cdb: CDB for packet command
  *	@dma_dir: Data tranfer direction of the command
- *	@sgl: sg list for the data buffer of the command
+ *	@sg: sg list for the data buffer of the command
  *	@n_elem: Number of sg entries
- *	@timeout: Timeout in msecs (0 for default)
  *
  *	Executes libata internal command with timeout.  @tf contains
  *	command on entry and result on return.  Timeout and error
@@ -1764,17 +1348,14 @@
  */
 unsigned ata_exec_internal_sg(struct ata_device *dev,
 			      struct ata_taskfile *tf, const u8 *cdb,
-			      int dma_dir, struct scatterlist *sgl,
-			      unsigned int n_elem, unsigned long timeout)
+			      int dma_dir, struct scatterlist *sg,
+			      unsigned int n_elem)
 {
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
+	struct ata_port *ap = dev->ap;
 	u8 command = tf->command;
-	int auto_timeout = 0;
 	struct ata_queued_cmd *qc;
 	unsigned int tag, preempted_tag;
 	u32 preempted_sactive, preempted_qc_active;
-	int preempted_nr_active_links;
 	DECLARE_COMPLETION_ONSTACK(wait);
 	unsigned long flags;
 	unsigned int err_mask;
@@ -1810,14 +1391,12 @@
 	qc->dev = dev;
 	ata_qc_reinit(qc);
 
-	preempted_tag = link->active_tag;
-	preempted_sactive = link->sactive;
+	preempted_tag = ap->active_tag;
+	preempted_sactive = ap->sactive;
 	preempted_qc_active = ap->qc_active;
-	preempted_nr_active_links = ap->nr_active_links;
-	link->active_tag = ATA_TAG_POISON;
-	link->sactive = 0;
+	ap->active_tag = ATA_TAG_POISON;
+	ap->sactive = 0;
 	ap->qc_active = 0;
-	ap->nr_active_links = 0;
 
 	/* prepare & issue qc */
 	qc->tf = *tf;
@@ -1827,12 +1406,11 @@
 	qc->dma_dir = dma_dir;
 	if (dma_dir != DMA_NONE) {
 		unsigned int i, buflen = 0;
-		struct scatterlist *sg;
 
-		for_each_sg(sgl, sg, n_elem, i)
-			buflen += sg->length;
+		for (i = 0; i < n_elem; i++)
+			buflen += sg[i].length;
 
-		ata_sg_init(qc, sgl, n_elem);
+		ata_sg_init(qc, sg, n_elem);
 		qc->nbytes = buflen;
 	}
 
@@ -1843,16 +1421,7 @@
 
 	spin_unlock_irqrestore(ap->lock, flags);
 
-	if (!timeout) {
-		if (ata_probe_timeout)
-			timeout = ata_probe_timeout * 1000;
-		else {
-			timeout = ata_internal_cmd_timeout(dev, command);
-			auto_timeout = 1;
-		}
-	}
-
-	rc = wait_for_completion_timeout(&wait, msecs_to_jiffies(timeout));
+	rc = wait_for_completion_timeout(&wait, ata_probe_timeout);
 
 	ata_port_flush_task(ap);
 
@@ -1903,10 +1472,9 @@
 	err_mask = qc->err_mask;
 
 	ata_qc_free(qc);
-	link->active_tag = preempted_tag;
-	link->sactive = preempted_sactive;
+	ap->active_tag = preempted_tag;
+	ap->sactive = preempted_sactive;
 	ap->qc_active = preempted_qc_active;
-	ap->nr_active_links = preempted_nr_active_links;
 
 	/* XXX - Some LLDDs (sata_mv) disable port on command failure.
 	 * Until those drivers are fixed, we detect the condition
@@ -1926,9 +1494,6 @@
 
 	spin_unlock_irqrestore(ap->lock, flags);
 
-	if ((err_mask & AC_ERR_TIMEOUT) && auto_timeout)
-		ata_internal_cmd_timed_out(dev, command);
-
 	return err_mask;
 }
 
@@ -1940,7 +1505,6 @@
  *	@dma_dir: Data tranfer direction of the command
  *	@buf: Data buffer of the command
  *	@buflen: Length of data buffer
- *	@timeout: Timeout in msecs (0 for default)
  *
  *	Wrapper around ata_exec_internal_sg() which takes simple
  *	buffer instead of sg list.
@@ -1953,8 +1517,7 @@
  */
 unsigned ata_exec_internal(struct ata_device *dev,
 			   struct ata_taskfile *tf, const u8 *cdb,
-			   int dma_dir, void *buf, unsigned int buflen,
-			   unsigned long timeout)
+			   int dma_dir, void *buf, unsigned int buflen)
 {
 	struct scatterlist *psg = NULL, sg;
 	unsigned int n_elem = 0;
@@ -1966,8 +1529,7 @@
 		n_elem++;
 	}
 
-	return ata_exec_internal_sg(dev, tf, cdb, dma_dir, psg, n_elem,
-				    timeout);
+	return ata_exec_internal_sg(dev, tf, cdb, dma_dir, psg, n_elem);
 }
 
 /**
@@ -1994,7 +1556,7 @@
 	tf.flags |= ATA_TFLAG_DEVICE;
 	tf.protocol = ATA_PROT_NODATA;
 
-	return ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);
+	return ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0);
 }
 
 /**
@@ -2004,22 +1566,12 @@
  *	Check if the current speed of the device requires IORDY. Used
  *	by various controllers for chip configuration.
  */
+
 unsigned int ata_pio_need_iordy(const struct ata_device *adev)
 {
-	/* Don't set IORDY if we're preparing for reset.  IORDY may
-	 * lead to controller lock up on certain controllers if the
-	 * port is not occupied.  See bko#11703 for details.
-	 */
-	if (adev->link->ap->pflags & ATA_PFLAG_RESETTING)
-		return 0;
-	/* Controller doesn't support IORDY.  Probably a pointless
-	 * check as the caller should know this.
-	 */
-	if (adev->link->ap->flags & ATA_FLAG_NO_IORDY)
-		return 0;
-	/* CF spec. r4.1 Table 22 says no iordy on PIO5 and PIO6.  */
-	if (ata_id_is_cfa(adev->id)
-	    && (adev->pio_mode == XFER_PIO_5 || adev->pio_mode == XFER_PIO_6))
+	/* Controller doesn't support  IORDY. Probably a pointless check
+	   as the caller should know this */
+	if (adev->ap->flags & ATA_FLAG_NO_IORDY)
 		return 0;
 	/* PIO3 and higher it is mandatory */
 	if (adev->pio_mode > XFER_PIO_2)
@@ -2037,6 +1589,7 @@
  *	Compute the highest mode possible if we are not using iordy. Return
  *	-1 if no iordy mode is available.
  */
+
 static u32 ata_pio_mask_no_iordy(const struct ata_device *adev)
 {
 	/* If we have no drive specific rule, then PIO 2 is non IORDY */
@@ -2054,23 +1607,6 @@
 }
 
 /**
- *	ata_do_dev_read_id		-	default ID read method
- *	@dev: device
- *	@tf: proposed taskfile
- *	@id: data buffer
- *
- *	Issue the identify taskfile and hand back the buffer containing
- *	identify data. For some RAID controllers and for pre ATA devices
- *	this function is wrapped or replaced by the driver
- */
-unsigned int ata_do_dev_read_id(struct ata_device *dev,
-					struct ata_taskfile *tf, u16 *id)
-{
-	return ata_exec_internal(dev, tf, NULL, DMA_FROM_DEVICE,
-				     id, sizeof(id[0]) * ATA_ID_WORDS, 0);
-}
-
-/**
  *	ata_dev_read_id - Read ID data from the specified device
  *	@dev: target device
  *	@p_class: pointer to class of the target device (may be changed)
@@ -2082,9 +1618,6 @@
  *	devices.  This function also issues ATA_CMD_INIT_DEV_PARAMS
  *	for pre-ATA4 drives.
  *
- *	FIXME: ATA_CMD_ID_ATA is optional for early drives and right
- *	now we abort if we hit that case.
- *
  *	LOCKING:
  *	Kernel thread context (may sleep)
  *
@@ -2094,24 +1627,22 @@
 int ata_dev_read_id(struct ata_device *dev, unsigned int *p_class,
 		    unsigned int flags, u16 *id)
 {
-	struct ata_port *ap = dev->link->ap;
+	struct ata_port *ap = dev->ap;
 	unsigned int class = *p_class;
 	struct ata_taskfile tf;
 	unsigned int err_mask = 0;
 	const char *reason;
-	bool is_semb = class == ATA_DEV_SEMB;
 	int may_fallback = 1, tried_spinup = 0;
 	int rc;
 
 	if (ata_msg_ctl(ap))
-		ata_dev_printk(dev, KERN_DEBUG, "%s: ENTER\n", __func__);
+		ata_dev_printk(dev, KERN_DEBUG, "%s: ENTER\n", __FUNCTION__);
 
-retry:
+	ata_dev_select(ap, dev->devno, 1, 1); /* select device 0/1 */
+ retry:
 	ata_tf_init(dev, &tf);
 
 	switch (class) {
-	case ATA_DEV_SEMB:
-		class = ATA_DEV_ATA;	/* some hard drives report SEMB sig */
 	case ATA_DEV_ATA:
 		tf.command = ATA_CMD_ID_ATA;
 		break;
@@ -2136,49 +1667,28 @@
 	 */
 	tf.flags |= ATA_TFLAG_POLLING;
 
-	if (ap->ops->read_id)
-		err_mask = ap->ops->read_id(dev, &tf, id);
-	else
-		err_mask = ata_do_dev_read_id(dev, &tf, id);
-
+	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_FROM_DEVICE,
+				     id, sizeof(id[0]) * ATA_ID_WORDS);
 	if (err_mask) {
 		if (err_mask & AC_ERR_NODEV_HINT) {
-			ata_dev_printk(dev, KERN_DEBUG,
-				       "NODEV after polling detection\n");
+			DPRINTK("ata%u.%d: NODEV after polling detection\n",
+				ap->print_id, dev->devno);
 			return -ENOENT;
 		}
 
-		if (is_semb) {
-			ata_dev_printk(dev, KERN_INFO, "IDENTIFY failed on "
-				       "device w/ SEMB sig, disabled\n");
-			/* SEMB is not supported yet */
-			*p_class = ATA_DEV_SEMB_UNSUP;
-			return 0;
-		}
-
-		if ((err_mask == AC_ERR_DEV) && (tf.feature & ATA_ABORTED)) {
-			/* Device or controller might have reported
-			 * the wrong device class.  Give a shot at the
-			 * other IDENTIFY if the current one is
-			 * aborted by the device.
-			 */
-			if (may_fallback) {
-				may_fallback = 0;
-
-				if (class == ATA_DEV_ATA)
-					class = ATA_DEV_ATAPI;
-				else
-					class = ATA_DEV_ATA;
-				goto retry;
-			}
+		/* Device or controller might have reported the wrong
+		 * device class.  Give a shot at the other IDENTIFY if
+		 * the current one is aborted by the device.
+		 */
+		if (may_fallback &&
+		    (err_mask == AC_ERR_DEV) && (tf.feature & ATA_ABORTED)) {
+			may_fallback = 0;
 
-			/* Control reaches here iff the device aborted
-			 * both flavors of IDENTIFYs which happens
-			 * sometimes with phantom devices.
-			 */
-			ata_dev_printk(dev, KERN_DEBUG,
-				       "both IDENTIFYs aborted, assuming NODEV\n");
-			return -ENOENT;
+			if (class == ATA_DEV_ATA)
+				class = ATA_DEV_ATAPI;
+			else
+				class = ATA_DEV_ATA;
+			goto retry;
 		}
 
 		rc = -EIO;
@@ -2212,7 +1722,12 @@
 		 * SET_FEATURES spin-up subcommand before it will accept
 		 * anything other than the original IDENTIFY command.
 		 */
-		err_mask = ata_dev_set_feature(dev, SETFEATURES_SPINUP, 0);
+		ata_tf_init(dev, &tf);
+		tf.command = ATA_CMD_SET_FEATURES;
+		tf.feature = SETFEATURES_SPINUP;
+		tf.protocol = ATA_PROT_NODATA;
+		tf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;
+		err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0);
 		if (err_mask && id[2] != 0x738c) {
 			rc = -EIO;
 			reason = "SPINUP failed";
@@ -2230,13 +1745,10 @@
 		/*
 		 * The exact sequence expected by certain pre-ATA4 drives is:
 		 * SRST RESET
-		 * IDENTIFY (optional in early ATA)
-		 * INITIALIZE DEVICE PARAMETERS (later IDE and ATA)
+		 * IDENTIFY
+		 * INITIALIZE DEVICE PARAMETERS
 		 * anything else..
 		 * Some drives were very specific about that exact sequence.
-		 *
-		 * Note that ATA4 says lba is mandatory so the second check
-		 * shoud never trigger.
 		 */
 		if (ata_id_major_version(id) < 4 || !ata_id_has_lba(id)) {
 			err_mask = ata_dev_init_params(dev, id[3], id[6]);
@@ -2265,93 +1777,34 @@
 	return rc;
 }
 
-static int ata_do_link_spd_horkage(struct ata_device *dev)
-{
-	struct ata_link *plink = ata_dev_phys_link(dev);
-	u32 target, target_limit;
-
-	if (!sata_scr_valid(plink))
-		return 0;
-
-	if (dev->horkage & ATA_HORKAGE_1_5_GBPS)
-		target = 1;
-	else
-		return 0;
-
-	target_limit = (1 << target) - 1;
-
-	/* if already on stricter limit, no need to push further */
-	if (plink->sata_spd_limit <= target_limit)
-		return 0;
-
-	plink->sata_spd_limit = target_limit;
-
-	/* Request another EH round by returning -EAGAIN if link is
-	 * going faster than the target speed.  Forward progress is
-	 * guaranteed by setting sata_spd_limit to target_limit above.
-	 */
-	if (plink->sata_spd > target) {
-		ata_dev_printk(dev, KERN_INFO,
-			       "applying link speed limit horkage to %s\n",
-			       sata_spd_string(target));
-		return -EAGAIN;
-	}
-	return 0;
-}
-
 static inline u8 ata_dev_knobble(struct ata_device *dev)
 {
-	struct ata_port *ap = dev->link->ap;
-
-	if (ata_dev_blacklisted(dev) & ATA_HORKAGE_BRIDGE_OK)
-		return 0;
-
-	return ((ap->cbl == ATA_CBL_SATA) && (!ata_id_is_sata(dev->id)));
+	return ((dev->ap->cbl == ATA_CBL_SATA) && (!ata_id_is_sata(dev->id)));
 }
 
-static int ata_dev_config_ncq(struct ata_device *dev,
+static void ata_dev_config_ncq(struct ata_device *dev,
 			       char *desc, size_t desc_sz)
 {
-	struct ata_port *ap = dev->link->ap;
+	struct ata_port *ap = dev->ap;
 	int hdepth = 0, ddepth = ata_id_queue_depth(dev->id);
-	unsigned int err_mask;
-	char *aa_desc = "";
 
 	if (!ata_id_has_ncq(dev->id)) {
 		desc[0] = '\0';
-		return 0;
+		return;
 	}
 	if (dev->horkage & ATA_HORKAGE_NONCQ) {
 		snprintf(desc, desc_sz, "NCQ (not used)");
-		return 0;
+		return;
 	}
 	if (ap->flags & ATA_FLAG_NCQ) {
 		hdepth = min(ap->scsi_host->can_queue, ATA_MAX_QUEUE - 1);
 		dev->flags |= ATA_DFLAG_NCQ;
 	}
 
-	if (!(dev->horkage & ATA_HORKAGE_BROKEN_FPDMA_AA) &&
-		(ap->flags & ATA_FLAG_FPDMA_AA) &&
-		ata_id_has_fpdma_aa(dev->id)) {
-		err_mask = ata_dev_set_feature(dev, SETFEATURES_SATA_ENABLE,
-			SATA_FPDMA_AA);
-		if (err_mask) {
-			ata_dev_printk(dev, KERN_ERR, "failed to enable AA"
-				"(error_mask=0x%x)\n", err_mask);
-			if (err_mask != AC_ERR_DEV) {
-				dev->horkage |= ATA_HORKAGE_BROKEN_FPDMA_AA;
-				return -EIO;
-			}
-		} else
-			aa_desc = ", AA";
-	}
-
 	if (hdepth >= ddepth)
-		snprintf(desc, desc_sz, "NCQ (depth %d)%s", ddepth, aa_desc);
+		snprintf(desc, desc_sz, "NCQ (depth %d)", ddepth);
 	else
-		snprintf(desc, desc_sz, "NCQ (depth %d/%d)%s", hdepth,
-			ddepth, aa_desc);
-	return 0;
+		snprintf(desc, desc_sz, "NCQ (depth %d/%d)", hdepth, ddepth);
 }
 
 /**
@@ -2369,11 +1822,11 @@
  */
 int ata_dev_configure(struct ata_device *dev)
 {
-	struct ata_port *ap = dev->link->ap;
-	struct ata_eh_context *ehc = &dev->link->eh_context;
+	struct ata_port *ap = dev->ap;
+	struct ata_eh_context *ehc = &ap->eh_context;
 	int print_info = ehc->i.flags & ATA_EHI_PRINTINFO;
 	const u16 *id = dev->id;
-	unsigned long xfer_mask;
+	unsigned int xfer_mask;
 	char revbuf[7];		/* XYZ-99\0 */
 	char fwrevbuf[ATA_ID_FW_REV_LEN+1];
 	char modelbuf[ATA_ID_PROD_LEN+1];
@@ -2381,54 +1834,27 @@
 
 	if (!ata_dev_enabled(dev) && ata_msg_info(ap)) {
 		ata_dev_printk(dev, KERN_INFO, "%s: ENTER/EXIT -- nodev\n",
-			       __func__);
+			       __FUNCTION__);
 		return 0;
 	}
 
 	if (ata_msg_probe(ap))
-		ata_dev_printk(dev, KERN_DEBUG, "%s: ENTER\n", __func__);
+		ata_dev_printk(dev, KERN_DEBUG, "%s: ENTER\n", __FUNCTION__);
 
 	/* set horkage */
 	dev->horkage |= ata_dev_blacklisted(dev);
-	ata_force_horkage(dev);
-
-	if (dev->horkage & ATA_HORKAGE_DISABLE) {
-		ata_dev_printk(dev, KERN_INFO,
-			       "unsupported device, disabling\n");
-		ata_dev_disable(dev);
-		return 0;
-	}
-
-	if ((!atapi_enabled || (ap->flags & ATA_FLAG_NO_ATAPI)) &&
-	    dev->class == ATA_DEV_ATAPI) {
-		ata_dev_printk(dev, KERN_WARNING,
-			"WARNING: ATAPI is %s, device ignored.\n",
-			atapi_enabled ? "not supported with this driver"
-				      : "disabled");
-		ata_dev_disable(dev);
-		return 0;
-	}
-
-	rc = ata_do_link_spd_horkage(dev);
-	if (rc)
-		return rc;
 
 	/* let ACPI work its magic */
 	rc = ata_acpi_on_devcfg(dev);
 	if (rc)
 		return rc;
 
-	/* massage HPA, do it early as it might change IDENTIFY data */
-	rc = ata_hpa_resize(dev);
-	if (rc)
-		return rc;
-
 	/* print device capabilities */
 	if (ata_msg_probe(ap))
 		ata_dev_printk(dev, KERN_DEBUG,
 			       "%s: cfg 49:%04x 82:%04x 83:%04x 84:%04x "
 			       "85:%04x 86:%04x 87:%04x 88:%04x\n",
-			       __func__,
+			       __FUNCTION__,
 			       id[49], id[82], id[83], id[84],
 			       id[85], id[86], id[87], id[88]);
 
@@ -2440,7 +1866,6 @@
 	dev->cylinders = 0;
 	dev->heads = 0;
 	dev->sectors = 0;
-	dev->multi_count = 0;
 
 	/*
 	 * common ATA, ATAPI feature tests
@@ -2462,36 +1887,23 @@
 	/* ATA-specific feature tests */
 	if (dev->class == ATA_DEV_ATA) {
 		if (ata_id_is_cfa(id)) {
-			/* CPRM may make this media unusable */
-			if (id[ATA_ID_CFA_KEY_MGMT] & 1)
+			if (id[162] & 1) /* CPRM may make this media unusable */
 				ata_dev_printk(dev, KERN_WARNING,
 					       "supports DRM functions and may "
 					       "not be fully accessable.\n");
 			snprintf(revbuf, 7, "CFA");
-		} else {
-			snprintf(revbuf, 7, "ATA-%d", ata_id_major_version(id));
-			/* Warn the user if the device has TPM extensions */
-			if (ata_id_has_tpm(id))
-				ata_dev_printk(dev, KERN_WARNING,
-					       "supports DRM functions and may "
-					       "not be fully accessable.\n");
 		}
+		else
+			snprintf(revbuf, 7, "ATA-%d",  ata_id_major_version(id));
 
 		dev->n_sectors = ata_id_n_sectors(id);
 
-		/* get current R/W Multiple count setting */
-		if ((dev->id[47] >> 8) == 0x80 && (dev->id[59] & 0x100)) {
-			unsigned int max = dev->id[47] & 0xff;
-			unsigned int cnt = dev->id[59] & 0xff;
-			/* only recognize/allow powers of two here */
-			if (is_power_of_2(max) && is_power_of_2(cnt))
-				if (cnt <= max)
-					dev->multi_count = cnt;
-		}
+		if (dev->id[59] & 0x100)
+			dev->multi_count = dev->id[59] & 0xff;
 
 		if (ata_id_has_lba(id)) {
 			const char *lba_desc;
-			char ncq_desc[24];
+			char ncq_desc[20];
 
 			lba_desc = "LBA";
 			dev->flags |= ATA_DFLAG_LBA;
@@ -2504,10 +1916,12 @@
 					dev->flags |= ATA_DFLAG_FLUSH_EXT;
 			}
 
+			if (!(dev->horkage & ATA_HORKAGE_BROKEN_HPA) &&
+			    ata_id_hpa_enabled(dev->id))
+ 				dev->n_sectors = ata_hpa_resize(dev);
+
 			/* config NCQ */
-			rc = ata_dev_config_ncq(dev, ncq_desc, sizeof(ncq_desc));
-			if (rc)
-				return rc;
+			ata_dev_config_ncq(dev, ncq_desc, sizeof(ncq_desc));
 
 			/* print device info to dmesg */
 			if (ata_msg_drv(ap) && print_info) {
@@ -2554,10 +1968,7 @@
 
 	/* ATAPI-specific feature tests */
 	else if (dev->class == ATA_DEV_ATAPI) {
-		const char *cdb_intr_string = "";
-		const char *atapi_an_string = "";
-		const char *dma_dir_string = "";
-		u32 sntf;
+		char *cdb_intr_string = "";
 
 		rc = atapi_cdb_len(id);
 		if ((rc < 12) || (rc > ATAPI_CDB_LEN)) {
@@ -2569,48 +1980,18 @@
 		}
 		dev->cdb_len = (unsigned int) rc;
 
-		/* Enable ATAPI AN if both the host and device have
-		 * the support.  If PMP is attached, SNTF is required
-		 * to enable ATAPI AN to discern between PHY status
-		 * changed notifications and ATAPI ANs.
-		 */
-		if (atapi_an &&
-		    (ap->flags & ATA_FLAG_AN) && ata_id_has_atapi_AN(id) &&
-		    (!sata_pmp_attached(ap) ||
-		     sata_scr_read(&ap->link, SCR_NOTIFICATION, &sntf) == 0)) {
-			unsigned int err_mask;
-
-			/* issue SET feature command to turn this on */
-			err_mask = ata_dev_set_feature(dev,
-					SETFEATURES_SATA_ENABLE, SATA_AN);
-			if (err_mask)
-				ata_dev_printk(dev, KERN_ERR,
-					"failed to enable ATAPI AN "
-					"(err_mask=0x%x)\n", err_mask);
-			else {
-				dev->flags |= ATA_DFLAG_AN;
-				atapi_an_string = ", ATAPI AN";
-			}
-		}
-
 		if (ata_id_cdb_intr(dev->id)) {
 			dev->flags |= ATA_DFLAG_CDB_INTR;
 			cdb_intr_string = ", CDB intr";
 		}
 
-		if (atapi_dmadir || atapi_id_dmadir(dev->id)) {
-			dev->flags |= ATA_DFLAG_DMADIR;
-			dma_dir_string = ", DMADIR";
-		}
-
 		/* print device info to dmesg */
 		if (ata_msg_drv(ap) && print_info)
 			ata_dev_printk(dev, KERN_INFO,
-				       "ATAPI: %s, %s, max %s%s%s%s\n",
+				       "ATAPI: %s, %s, max %s%s\n",
 				       modelbuf, fwrevbuf,
 				       ata_mode_string(xfer_mask),
-				       cdb_intr_string, atapi_an_string,
-				       dma_dir_string);
+				       cdb_intr_string);
 	}
 
 	/* determine max_sectors */
@@ -2618,15 +1999,19 @@
 	if (dev->flags & ATA_DFLAG_LBA48)
 		dev->max_sectors = ATA_MAX_SECTORS_LBA48;
 
-	if (!(dev->horkage & ATA_HORKAGE_IPM)) {
-		if (ata_id_has_hipm(dev->id))
-			dev->flags |= ATA_DFLAG_HIPM;
-		if (ata_id_has_dipm(dev->id))
-			dev->flags |= ATA_DFLAG_DIPM;
+	if (dev->horkage & ATA_HORKAGE_DIAGNOSTIC) {
+		/* Let the user know. We don't want to disallow opens for
+		   rescue purposes, or in case the vendor is just a blithering
+		   idiot */
+                if (print_info) {
+			ata_dev_printk(dev, KERN_WARNING,
+"Drive reports diagnostics failure. This may indicate a drive\n");
+			ata_dev_printk(dev, KERN_WARNING,
+"fault or invalid emulation. Contact drive vendor for information.\n");
+		}
 	}
 
-	/* Limit PATA drive on SATA cable bridge transfers to udma5,
-	   200 sectors */
+	/* limit bridge transfers to udma5, 200 sectors */
 	if (ata_dev_knobble(dev)) {
 		if (ata_msg_drv(ap) && print_info)
 			ata_dev_printk(dev, KERN_INFO,
@@ -2635,54 +2020,22 @@
 		dev->max_sectors = ATA_MAX_SECTORS;
 	}
 
-	if ((dev->class == ATA_DEV_ATAPI) &&
-	    (atapi_command_packet_set(id) == TYPE_TAPE)) {
-		dev->max_sectors = ATA_MAX_SECTORS_TAPE;
-		dev->horkage |= ATA_HORKAGE_STUCK_ERR;
-	}
-
 	if (dev->horkage & ATA_HORKAGE_MAX_SEC_128)
 		dev->max_sectors = min_t(unsigned int, ATA_MAX_SECTORS_128,
 					 dev->max_sectors);
 
-	if (ata_dev_blacklisted(dev) & ATA_HORKAGE_IPM) {
-		dev->horkage |= ATA_HORKAGE_IPM;
-
-		/* reset link pm_policy for this port to no pm */
-		ap->pm_policy = MAX_PERFORMANCE;
-	}
-
 	if (ap->ops->dev_config)
 		ap->ops->dev_config(dev);
 
-	if (dev->horkage & ATA_HORKAGE_DIAGNOSTIC) {
-		/* Let the user know. We don't want to disallow opens for
-		   rescue purposes, or in case the vendor is just a blithering
-		   idiot. Do this after the dev_config call as some controllers
-		   with buggy firmware may want to avoid reporting false device
-		   bugs */
-
-		if (print_info) {
-			ata_dev_printk(dev, KERN_WARNING,
-"Drive reports diagnostics failure. This may indicate a drive\n");
-			ata_dev_printk(dev, KERN_WARNING,
-"fault or invalid emulation. Contact drive vendor for information.\n");
-		}
-	}
-
-	if ((dev->horkage & ATA_HORKAGE_FIRMWARE_WARN) && print_info) {
-		ata_dev_printk(dev, KERN_WARNING, "WARNING: device requires "
-			       "firmware update to be fully functional.\n");
-		ata_dev_printk(dev, KERN_WARNING, "         contact the vendor "
-			       "or visit http://ata.wiki.kernel.org.\n");
-	}
-
+	if (ata_msg_probe(ap))
+		ata_dev_printk(dev, KERN_DEBUG, "%s: EXIT, drv_stat = 0x%x\n",
+			__FUNCTION__, ata_chk_status(ap));
 	return 0;
 
 err_out_nosup:
 	if (ata_msg_probe(ap))
 		ata_dev_printk(dev, KERN_DEBUG,
-			       "%s: EXIT, err\n", __func__);
+			       "%s: EXIT, err\n", __FUNCTION__);
 	return rc;
 }
 
@@ -2725,18 +2078,6 @@
 }
 
 /**
- *	ata_cable_ignore	-	return ignored PATA cable.
- *	@ap: port
- *
- *	Helper method for drivers which don't use cable type to limit
- *	transfer mode.
- */
-int ata_cable_ignore(struct ata_port *ap)
-{
-	return ATA_CBL_PATA_IGN;
-}
-
-/**
  *	ata_cable_sata	-	return SATA cable type
  *	@ap: port
  *
@@ -2767,38 +2108,21 @@
 {
 	unsigned int classes[ATA_MAX_DEVICES];
 	int tries[ATA_MAX_DEVICES];
-	int rc;
+	int i, rc;
 	struct ata_device *dev;
 
 	ata_port_probe(ap);
 
-	ata_for_each_dev(dev, &ap->link, ALL)
-		tries[dev->devno] = ATA_PROBE_MAX_TRIES;
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		tries[i] = ATA_PROBE_MAX_TRIES;
 
  retry:
-	ata_for_each_dev(dev, &ap->link, ALL) {
-		/* If we issue an SRST then an ATA drive (not ATAPI)
-		 * may change configuration and be in PIO0 timing. If
-		 * we do a hard reset (or are coming from power on)
-		 * this is true for ATA or ATAPI. Until we've set a
-		 * suitable controller mode we should not touch the
-		 * bus as we may be talking too fast.
-		 */
-		dev->pio_mode = XFER_PIO_0;
-
-		/* If the controller has a pio mode setup function
-		 * then use it to set the chipset to rights. Don't
-		 * touch the DMA setup as that will be dealt with when
-		 * configuring devices.
-		 */
-		if (ap->ops->set_piomode)
-			ap->ops->set_piomode(ap, dev);
-	}
-
 	/* reset and determine device classes */
 	ap->ops->phy_reset(ap);
 
-	ata_for_each_dev(dev, &ap->link, ALL) {
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		dev = &ap->device[i];
+
 		if (!(ap->flags & ATA_FLAG_DISABLED) &&
 		    dev->class != ATA_DEV_UNKNOWN)
 			classes[dev->devno] = dev->class;
@@ -2810,13 +2134,21 @@
 
 	ata_port_probe(ap);
 
+	/* after the reset the device state is PIO 0 and the controller
+	   state is undefined. Record the mode */
+
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		ap->device[i].pio_mode = XFER_PIO_0;
+
 	/* read IDENTIFY page and configure devices. We have to do the identify
 	   specific sequence bass-ackwards so that PDIAG- is released by
 	   the slave device */
 
-	ata_for_each_dev(dev, &ap->link, ALL_REVERSE) {
-		if (tries[dev->devno])
-			dev->class = classes[dev->devno];
+	for (i = ATA_MAX_DEVICES - 1; i >=  0; i--) {
+		dev = &ap->device[i];
+
+		if (tries[i])
+			dev->class = classes[i];
 
 		if (!ata_dev_enabled(dev))
 			continue;
@@ -2831,36 +2163,33 @@
 	if (ap->ops->cable_detect)
 		ap->cbl = ap->ops->cable_detect(ap);
 
-	/* We may have SATA bridge glue hiding here irrespective of
-	 * the reported cable types and sensed types.  When SATA
-	 * drives indicate we have a bridge, we don't know which end
-	 * of the link the bridge is which is a problem.
-	 */
-	ata_for_each_dev(dev, &ap->link, ENABLED)
-		if (ata_id_is_sata(dev->id))
-			ap->cbl = ATA_CBL_SATA;
-
 	/* After the identify sequence we can now set up the devices. We do
 	   this in the normal order so that the user doesn't get confused */
 
-	ata_for_each_dev(dev, &ap->link, ENABLED) {
-		ap->link.eh_context.i.flags |= ATA_EHI_PRINTINFO;
+	for(i = 0; i < ATA_MAX_DEVICES; i++) {
+		dev = &ap->device[i];
+		if (!ata_dev_enabled(dev))
+			continue;
+
+		ap->eh_context.i.flags |= ATA_EHI_PRINTINFO;
 		rc = ata_dev_configure(dev);
-		ap->link.eh_context.i.flags &= ~ATA_EHI_PRINTINFO;
+		ap->eh_context.i.flags &= ~ATA_EHI_PRINTINFO;
 		if (rc)
 			goto fail;
 	}
 
 	/* configure transfer mode */
-	rc = ata_set_mode(&ap->link, &dev);
+	rc = ata_set_mode(ap, &dev);
 	if (rc)
 		goto fail;
 
-	ata_for_each_dev(dev, &ap->link, ENABLED)
-		return 0;
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		if (ata_dev_enabled(&ap->device[i]))
+			return 0;
 
 	/* no device present, disable port */
 	ata_port_disable(ap);
+	ap->ops->port_disable(ap);
 	return -ENODEV;
 
  fail:
@@ -2880,7 +2209,7 @@
 			/* This is the last chance, better to slow
 			 * down than lose it.
 			 */
-			sata_down_spd_limit(&ap->link, 0);
+			sata_down_spd_limit(ap);
 			ata_down_xfermask_limit(dev, ATA_DNXFER_PIO);
 		}
 	}
@@ -2909,34 +2238,108 @@
 
 /**
  *	sata_print_link_status - Print SATA link status
- *	@link: SATA link to printk link status about
+ *	@ap: SATA port to printk link status about
  *
  *	This function prints link speed and status of a SATA link.
  *
  *	LOCKING:
  *	None.
  */
-static void sata_print_link_status(struct ata_link *link)
+void sata_print_link_status(struct ata_port *ap)
 {
 	u32 sstatus, scontrol, tmp;
 
-	if (sata_scr_read(link, SCR_STATUS, &sstatus))
+	if (sata_scr_read(ap, SCR_STATUS, &sstatus))
 		return;
-	sata_scr_read(link, SCR_CONTROL, &scontrol);
+	sata_scr_read(ap, SCR_CONTROL, &scontrol);
 
-	if (ata_phys_link_online(link)) {
+	if (ata_port_online(ap)) {
 		tmp = (sstatus >> 4) & 0xf;
-		ata_link_printk(link, KERN_INFO,
+		ata_port_printk(ap, KERN_INFO,
 				"SATA link up %s (SStatus %X SControl %X)\n",
 				sata_spd_string(tmp), sstatus, scontrol);
 	} else {
-		ata_link_printk(link, KERN_INFO,
+		ata_port_printk(ap, KERN_INFO,
 				"SATA link down (SStatus %X SControl %X)\n",
 				sstatus, scontrol);
 	}
 }
 
 /**
+ *	__sata_phy_reset - Wake/reset a low-level SATA PHY
+ *	@ap: SATA port associated with target SATA PHY.
+ *
+ *	This function issues commands to standard SATA Sxxx
+ *	PHY registers, to wake up the phy (and device), and
+ *	clear any reset condition.
+ *
+ *	LOCKING:
+ *	PCI/etc. bus probe sem.
+ *
+ */
+void __sata_phy_reset(struct ata_port *ap)
+{
+	u32 sstatus;
+	unsigned long timeout = jiffies + (HZ * 5);
+
+	if (ap->flags & ATA_FLAG_SATA_RESET) {
+		/* issue phy wake/reset */
+		sata_scr_write_flush(ap, SCR_CONTROL, 0x301);
+		/* Couldn't find anything in SATA I/II specs, but
+		 * AHCI-1.1 10.4.2 says at least 1 ms. */
+		mdelay(1);
+	}
+	/* phy wake/clear reset */
+	sata_scr_write_flush(ap, SCR_CONTROL, 0x300);
+
+	/* wait for phy to become ready, if necessary */
+	do {
+		msleep(200);
+		sata_scr_read(ap, SCR_STATUS, &sstatus);
+		if ((sstatus & 0xf) != 1)
+			break;
+	} while (time_before(jiffies, timeout));
+
+	/* print link status */
+	sata_print_link_status(ap);
+
+	/* TODO: phy layer with polling, timeouts, etc. */
+	if (!ata_port_offline(ap))
+		ata_port_probe(ap);
+	else
+		ata_port_disable(ap);
+
+	if (ap->flags & ATA_FLAG_DISABLED)
+		return;
+
+	if (ata_busy_sleep(ap, ATA_TMOUT_BOOT_QUICK, ATA_TMOUT_BOOT)) {
+		ata_port_disable(ap);
+		return;
+	}
+
+	ap->cbl = ATA_CBL_SATA;
+}
+
+/**
+ *	sata_phy_reset - Reset SATA bus.
+ *	@ap: SATA port associated with target SATA PHY.
+ *
+ *	This function resets the SATA bus, and then probes
+ *	the bus for devices.
+ *
+ *	LOCKING:
+ *	PCI/etc. bus probe sem.
+ *
+ */
+void sata_phy_reset(struct ata_port *ap)
+{
+	__sata_phy_reset(ap);
+	if (ap->flags & ATA_FLAG_DISABLED)
+		return;
+	ata_bus_reset(ap);
+}
+
+/**
  *	ata_dev_pair		-	return other device on cable
  *	@adev: device
  *
@@ -2946,8 +2349,8 @@
 
 struct ata_device *ata_dev_pair(struct ata_device *adev)
 {
-	struct ata_link *link = adev->link;
-	struct ata_device *pair = &link->device[1 - adev->devno];
+	struct ata_port *ap = adev->ap;
+	struct ata_device *pair = &ap->device[1 - adev->devno];
 	if (!ata_dev_enabled(pair))
 		return NULL;
 	return pair;
@@ -2968,55 +2371,49 @@
 
 void ata_port_disable(struct ata_port *ap)
 {
-	ap->link.device[0].class = ATA_DEV_NONE;
-	ap->link.device[1].class = ATA_DEV_NONE;
+	ap->device[0].class = ATA_DEV_NONE;
+	ap->device[1].class = ATA_DEV_NONE;
 	ap->flags |= ATA_FLAG_DISABLED;
 }
 
 /**
  *	sata_down_spd_limit - adjust SATA spd limit downward
- *	@link: Link to adjust SATA spd limit for
- *	@spd_limit: Additional limit
+ *	@ap: Port to adjust SATA spd limit for
  *
- *	Adjust SATA spd limit of @link downward.  Note that this
+ *	Adjust SATA spd limit of @ap downward.  Note that this
  *	function only adjusts the limit.  The change must be applied
  *	using sata_set_spd().
  *
- *	If @spd_limit is non-zero, the speed is limited to equal to or
- *	lower than @spd_limit if such speed is supported.  If
- *	@spd_limit is slower than any supported speed, only the lowest
- *	supported speed is allowed.
- *
  *	LOCKING:
  *	Inherited from caller.
  *
  *	RETURNS:
  *	0 on success, negative errno on failure
  */
-int sata_down_spd_limit(struct ata_link *link, u32 spd_limit)
+int sata_down_spd_limit(struct ata_port *ap)
 {
 	u32 sstatus, spd, mask;
-	int rc, bit;
+	int rc, highbit;
 
-	if (!sata_scr_valid(link))
+	if (!sata_scr_valid(ap))
 		return -EOPNOTSUPP;
 
 	/* If SCR can be read, use it to determine the current SPD.
-	 * If not, use cached value in link->sata_spd.
+	 * If not, use cached value in ap->sata_spd.
 	 */
-	rc = sata_scr_read(link, SCR_STATUS, &sstatus);
-	if (rc == 0 && ata_sstatus_online(sstatus))
+	rc = sata_scr_read(ap, SCR_STATUS, &sstatus);
+	if (rc == 0)
 		spd = (sstatus >> 4) & 0xf;
 	else
-		spd = link->sata_spd;
+		spd = ap->sata_spd;
 
-	mask = link->sata_spd_limit;
+	mask = ap->sata_spd_limit;
 	if (mask <= 1)
 		return -EINVAL;
 
 	/* unconditionally mask off the highest bit */
-	bit = fls(mask) - 1;
-	mask &= ~(1 << bit);
+	highbit = fls(mask) - 1;
+	mask &= ~(1 << highbit);
 
 	/* Mask off all speeds higher than or equal to the current
 	 * one.  Force 1.5Gbps if current SPD is not available.
@@ -3030,54 +2427,35 @@
 	if (!mask)
 		return -EINVAL;
 
-	if (spd_limit) {
-		if (mask & ((1 << spd_limit) - 1))
-			mask &= (1 << spd_limit) - 1;
-		else {
-			bit = ffs(mask) - 1;
-			mask = 1 << bit;
-		}
-	}
-
-	link->sata_spd_limit = mask;
+	ap->sata_spd_limit = mask;
 
-	ata_link_printk(link, KERN_WARNING, "limiting SATA link speed to %s\n",
+	ata_port_printk(ap, KERN_WARNING, "limiting SATA link speed to %s\n",
 			sata_spd_string(fls(mask)));
 
 	return 0;
 }
 
-static int __sata_set_spd_needed(struct ata_link *link, u32 *scontrol)
+static int __sata_set_spd_needed(struct ata_port *ap, u32 *scontrol)
 {
-	struct ata_link *host_link = &link->ap->link;
-	u32 limit, target, spd;
+	u32 spd, limit;
 
-	limit = link->sata_spd_limit;
-
-	/* Don't configure downstream link faster than upstream link.
-	 * It doesn't speed up anything and some PMPs choke on such
-	 * configuration.
-	 */
-	if (!ata_is_host_link(link) && host_link->sata_spd)
-		limit &= (1 << host_link->sata_spd) - 1;
-
-	if (limit == UINT_MAX)
-		target = 0;
+	if (ap->sata_spd_limit == UINT_MAX)
+		limit = 0;
 	else
-		target = fls(limit);
+		limit = fls(ap->sata_spd_limit);
 
 	spd = (*scontrol >> 4) & 0xf;
-	*scontrol = (*scontrol & ~0xf0) | ((target & 0xf) << 4);
+	*scontrol = (*scontrol & ~0xf0) | ((limit & 0xf) << 4);
 
-	return spd != target;
+	return spd != limit;
 }
 
 /**
  *	sata_set_spd_needed - is SATA spd configuration needed
- *	@link: Link in question
+ *	@ap: Port in question
  *
  *	Test whether the spd limit in SControl matches
- *	@link->sata_spd_limit.  This function is used to determine
+ *	@ap->sata_spd_limit.  This function is used to determine
  *	whether hardreset is necessary to apply SATA spd
  *	configuration.
  *
@@ -3087,21 +2465,21 @@
  *	RETURNS:
  *	1 if SATA spd configuration is needed, 0 otherwise.
  */
-static int sata_set_spd_needed(struct ata_link *link)
+int sata_set_spd_needed(struct ata_port *ap)
 {
 	u32 scontrol;
 
-	if (sata_scr_read(link, SCR_CONTROL, &scontrol))
-		return 1;
+	if (sata_scr_read(ap, SCR_CONTROL, &scontrol))
+		return 0;
 
-	return __sata_set_spd_needed(link, &scontrol);
+	return __sata_set_spd_needed(ap, &scontrol);
 }
 
 /**
  *	sata_set_spd - set SATA spd according to spd limit
- *	@link: Link to set SATA spd for
+ *	@ap: Port to set SATA spd for
  *
- *	Set SATA spd of @link according to sata_spd_limit.
+ *	Set SATA spd of @ap according to sata_spd_limit.
  *
  *	LOCKING:
  *	Inherited from caller.
@@ -3110,18 +2488,18 @@
  *	0 if spd doesn't need to be changed, 1 if spd has been
  *	changed.  Negative errno if SCR registers are inaccessible.
  */
-int sata_set_spd(struct ata_link *link)
+int sata_set_spd(struct ata_port *ap)
 {
 	u32 scontrol;
 	int rc;
 
-	if ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))
+	if ((rc = sata_scr_read(ap, SCR_CONTROL, &scontrol)))
 		return rc;
 
-	if (!__sata_set_spd_needed(link, &scontrol))
+	if (!__sata_set_spd_needed(ap, &scontrol))
 		return 0;
 
-	if ((rc = sata_scr_write(link, SCR_CONTROL, scontrol)))
+	if ((rc = sata_scr_write(ap, SCR_CONTROL, scontrol)))
 		return rc;
 
 	return 1;
@@ -3140,51 +2518,55 @@
  */
 
 static const struct ata_timing ata_timing[] = {
-/*	{ XFER_PIO_SLOW, 120, 290, 240, 960, 290, 240, 0,  960,   0 }, */
-	{ XFER_PIO_0,     70, 290, 240, 600, 165, 150, 0,  600,   0 },
-	{ XFER_PIO_1,     50, 290,  93, 383, 125, 100, 0,  383,   0 },
-	{ XFER_PIO_2,     30, 290,  40, 330, 100,  90, 0,  240,   0 },
-	{ XFER_PIO_3,     30,  80,  70, 180,  80,  70, 0,  180,   0 },
-	{ XFER_PIO_4,     25,  70,  25, 120,  70,  25, 0,  120,   0 },
-	{ XFER_PIO_5,     15,  65,  25, 100,  65,  25, 0,  100,   0 },
-	{ XFER_PIO_6,     10,  55,  20,  80,  55,  20, 0,   80,   0 },
-
-	{ XFER_SW_DMA_0, 120,   0,   0,   0, 480, 480, 50, 960,   0 },
-	{ XFER_SW_DMA_1,  90,   0,   0,   0, 240, 240, 30, 480,   0 },
-	{ XFER_SW_DMA_2,  60,   0,   0,   0, 120, 120, 20, 240,   0 },
-
-	{ XFER_MW_DMA_0,  60,   0,   0,   0, 215, 215, 20, 480,   0 },
-	{ XFER_MW_DMA_1,  45,   0,   0,   0,  80,  50, 5,  150,   0 },
-	{ XFER_MW_DMA_2,  25,   0,   0,   0,  70,  25, 5,  120,   0 },
-	{ XFER_MW_DMA_3,  25,   0,   0,   0,  65,  25, 5,  100,   0 },
-	{ XFER_MW_DMA_4,  25,   0,   0,   0,  55,  20, 5,   80,   0 },
-
-/*	{ XFER_UDMA_SLOW,  0,   0,   0,   0,   0,   0, 0,    0, 150 }, */
-	{ XFER_UDMA_0,     0,   0,   0,   0,   0,   0, 0,    0, 120 },
-	{ XFER_UDMA_1,     0,   0,   0,   0,   0,   0, 0,    0,  80 },
-	{ XFER_UDMA_2,     0,   0,   0,   0,   0,   0, 0,    0,  60 },
-	{ XFER_UDMA_3,     0,   0,   0,   0,   0,   0, 0,    0,  45 },
-	{ XFER_UDMA_4,     0,   0,   0,   0,   0,   0, 0,    0,  30 },
-	{ XFER_UDMA_5,     0,   0,   0,   0,   0,   0, 0,    0,  20 },
-	{ XFER_UDMA_6,     0,   0,   0,   0,   0,   0, 0,    0,  15 },
+
+	{ XFER_UDMA_6,     0,   0,   0,   0,   0,   0,   0,  15 },
+	{ XFER_UDMA_5,     0,   0,   0,   0,   0,   0,   0,  20 },
+	{ XFER_UDMA_4,     0,   0,   0,   0,   0,   0,   0,  30 },
+	{ XFER_UDMA_3,     0,   0,   0,   0,   0,   0,   0,  45 },
+
+	{ XFER_MW_DMA_4,  25,   0,   0,   0,  55,  20,  80,   0 },
+	{ XFER_MW_DMA_3,  25,   0,   0,   0,  65,  25, 100,   0 },
+	{ XFER_UDMA_2,     0,   0,   0,   0,   0,   0,   0,  60 },
+	{ XFER_UDMA_1,     0,   0,   0,   0,   0,   0,   0,  80 },
+	{ XFER_UDMA_0,     0,   0,   0,   0,   0,   0,   0, 120 },
+
+/*	{ XFER_UDMA_SLOW,  0,   0,   0,   0,   0,   0,   0, 150 }, */
+
+	{ XFER_MW_DMA_2,  25,   0,   0,   0,  70,  25, 120,   0 },
+	{ XFER_MW_DMA_1,  45,   0,   0,   0,  80,  50, 150,   0 },
+	{ XFER_MW_DMA_0,  60,   0,   0,   0, 215, 215, 480,   0 },
+
+	{ XFER_SW_DMA_2,  60,   0,   0,   0, 120, 120, 240,   0 },
+	{ XFER_SW_DMA_1,  90,   0,   0,   0, 240, 240, 480,   0 },
+	{ XFER_SW_DMA_0, 120,   0,   0,   0, 480, 480, 960,   0 },
+
+	{ XFER_PIO_6,     10,  55,  20,  80,  55,  20,  80,   0 },
+	{ XFER_PIO_5,     15,  65,  25, 100,  65,  25, 100,   0 },
+	{ XFER_PIO_4,     25,  70,  25, 120,  70,  25, 120,   0 },
+	{ XFER_PIO_3,     30,  80,  70, 180,  80,  70, 180,   0 },
+
+	{ XFER_PIO_2,     30, 290,  40, 330, 100,  90, 240,   0 },
+	{ XFER_PIO_1,     50, 290,  93, 383, 125, 100, 383,   0 },
+	{ XFER_PIO_0,     70, 290, 240, 600, 165, 150, 600,   0 },
+
+/*	{ XFER_PIO_SLOW, 120, 290, 240, 960, 290, 240, 960,   0 }, */
 
 	{ 0xFF }
 };
 
-#define ENOUGH(v, unit)		(((v)-1)/(unit)+1)
-#define EZ(v, unit)		((v)?ENOUGH(v, unit):0)
+#define ENOUGH(v,unit)		(((v)-1)/(unit)+1)
+#define EZ(v,unit)		((v)?ENOUGH(v,unit):0)
 
 static void ata_timing_quantize(const struct ata_timing *t, struct ata_timing *q, int T, int UT)
 {
-	q->setup	= EZ(t->setup      * 1000,  T);
-	q->act8b	= EZ(t->act8b      * 1000,  T);
-	q->rec8b	= EZ(t->rec8b      * 1000,  T);
-	q->cyc8b	= EZ(t->cyc8b      * 1000,  T);
-	q->active	= EZ(t->active     * 1000,  T);
-	q->recover	= EZ(t->recover    * 1000,  T);
-	q->dmack_hold	= EZ(t->dmack_hold * 1000,  T);
-	q->cycle	= EZ(t->cycle      * 1000,  T);
-	q->udma		= EZ(t->udma       * 1000, UT);
+	q->setup   = EZ(t->setup   * 1000,  T);
+	q->act8b   = EZ(t->act8b   * 1000,  T);
+	q->rec8b   = EZ(t->rec8b   * 1000,  T);
+	q->cyc8b   = EZ(t->cyc8b   * 1000,  T);
+	q->active  = EZ(t->active  * 1000,  T);
+	q->recover = EZ(t->recover * 1000,  T);
+	q->cycle   = EZ(t->cycle   * 1000,  T);
+	q->udma    = EZ(t->udma    * 1000, UT);
 }
 
 void ata_timing_merge(const struct ata_timing *a, const struct ata_timing *b,
@@ -3196,21 +2578,18 @@
 	if (what & ATA_TIMING_CYC8B  ) m->cyc8b   = max(a->cyc8b,   b->cyc8b);
 	if (what & ATA_TIMING_ACTIVE ) m->active  = max(a->active,  b->active);
 	if (what & ATA_TIMING_RECOVER) m->recover = max(a->recover, b->recover);
-	if (what & ATA_TIMING_DMACK_HOLD) m->dmack_hold = max(a->dmack_hold, b->dmack_hold);
 	if (what & ATA_TIMING_CYCLE  ) m->cycle   = max(a->cycle,   b->cycle);
 	if (what & ATA_TIMING_UDMA   ) m->udma    = max(a->udma,    b->udma);
 }
 
-const struct ata_timing *ata_timing_find_mode(u8 xfer_mode)
+static const struct ata_timing* ata_timing_find_mode(unsigned short speed)
 {
-	const struct ata_timing *t = ata_timing;
-
-	while (xfer_mode > t->mode)
-		t++;
+	const struct ata_timing *t;
 
-	if (xfer_mode == t->mode)
-		return t;
-	return NULL;
+	for (t = ata_timing; t->mode != speed; t++)
+		if (t->mode == 0xFF)
+			return NULL;
+	return t;
 }
 
 int ata_timing_compute(struct ata_device *adev, unsigned short speed,
@@ -3235,10 +2614,10 @@
 
 	if (adev->id[ATA_ID_FIELD_VALID] & 2) {	/* EIDE drive */
 		memset(&p, 0, sizeof(p));
-		if (speed >= XFER_PIO_0 && speed <= XFER_SW_DMA_0) {
+		if(speed >= XFER_PIO_0 && speed <= XFER_SW_DMA_0) {
 			if (speed <= XFER_PIO_2) p.cycle = p.cyc8b = adev->id[ATA_ID_EIDE_PIO];
 					    else p.cycle = p.cyc8b = adev->id[ATA_ID_EIDE_PIO_IORDY];
-		} else if (speed >= XFER_MW_DMA_0 && speed <= XFER_MW_DMA_2) {
+		} else if(speed >= XFER_MW_DMA_0 && speed <= XFER_MW_DMA_2) {
 			p.cycle = adev->id[ATA_ID_EIDE_DMA_MIN];
 		}
 		ata_timing_merge(&p, t, t, ATA_TIMING_CYCLE | ATA_TIMING_CYC8B);
@@ -3285,57 +2664,6 @@
 }
 
 /**
- *	ata_timing_cycle2mode - find xfer mode for the specified cycle duration
- *	@xfer_shift: ATA_SHIFT_* value for transfer type to examine.
- *	@cycle: cycle duration in ns
- *
- *	Return matching xfer mode for @cycle.  The returned mode is of
- *	the transfer type specified by @xfer_shift.  If @cycle is too
- *	slow for @xfer_shift, 0xff is returned.  If @cycle is faster
- *	than the fastest known mode, the fasted mode is returned.
- *
- *	LOCKING:
- *	None.
- *
- *	RETURNS:
- *	Matching xfer_mode, 0xff if no match found.
- */
-u8 ata_timing_cycle2mode(unsigned int xfer_shift, int cycle)
-{
-	u8 base_mode = 0xff, last_mode = 0xff;
-	const struct ata_xfer_ent *ent;
-	const struct ata_timing *t;
-
-	for (ent = ata_xfer_tbl; ent->shift >= 0; ent++)
-		if (ent->shift == xfer_shift)
-			base_mode = ent->base;
-
-	for (t = ata_timing_find_mode(base_mode);
-	     t && ata_xfer_mode2shift(t->mode) == xfer_shift; t++) {
-		unsigned short this_cycle;
-
-		switch (xfer_shift) {
-		case ATA_SHIFT_PIO:
-		case ATA_SHIFT_MWDMA:
-			this_cycle = t->cycle;
-			break;
-		case ATA_SHIFT_UDMA:
-			this_cycle = t->udma;
-			break;
-		default:
-			return 0xff;
-		}
-
-		if (cycle > this_cycle)
-			break;
-
-		last_mode = t->mode;
-	}
-
-	return last_mode;
-}
-
-/**
  *	ata_down_xfermask_limit - adjust dev xfer masks downward
  *	@dev: Device to adjust xfer masks
  *	@sel: ATA_DNXFER_* selector
@@ -3353,8 +2681,8 @@
 int ata_down_xfermask_limit(struct ata_device *dev, unsigned int sel)
 {
 	char buf[32];
-	unsigned long orig_mask, xfer_mask;
-	unsigned long pio_mask, mwdma_mask, udma_mask;
+	unsigned int orig_mask, xfer_mask;
+	unsigned int pio_mask, mwdma_mask, udma_mask;
 	int quiet, highbit;
 
 	quiet = !!(sel & ATA_DNXFER_QUIET);
@@ -3426,90 +2754,43 @@
 
 static int ata_dev_set_mode(struct ata_device *dev)
 {
-	struct ata_port *ap = dev->link->ap;
-	struct ata_eh_context *ehc = &dev->link->eh_context;
-	const bool nosetxfer = dev->horkage & ATA_HORKAGE_NOSETXFER;
-	const char *dev_err_whine = "";
-	int ign_dev_err = 0;
-	unsigned int err_mask = 0;
+	struct ata_eh_context *ehc = &dev->ap->eh_context;
+	unsigned int err_mask;
 	int rc;
 
 	dev->flags &= ~ATA_DFLAG_PIO;
 	if (dev->xfer_shift == ATA_SHIFT_PIO)
 		dev->flags |= ATA_DFLAG_PIO;
 
-	if (nosetxfer && ap->flags & ATA_FLAG_SATA && ata_id_is_sata(dev->id))
-		dev_err_whine = " (SET_XFERMODE skipped)";
-	else {
-		if (nosetxfer)
-			ata_dev_printk(dev, KERN_WARNING,
-				       "NOSETXFER but PATA detected - can't "
-				       "skip SETXFER, might malfunction\n");
-		err_mask = ata_dev_set_xfermode(dev);
-	}
+	err_mask = ata_dev_set_xfermode(dev);
+	/* Old CFA may refuse this command, which is just fine */
+	if (dev->xfer_shift == ATA_SHIFT_PIO && ata_id_is_cfa(dev->id))
+        	err_mask &= ~AC_ERR_DEV;
 
-	if (err_mask & ~AC_ERR_DEV)
-		goto fail;
+	if (err_mask) {
+		ata_dev_printk(dev, KERN_ERR, "failed to set xfermode "
+			       "(err_mask=0x%x)\n", err_mask);
+		return -EIO;
+	}
 
-	/* revalidate */
 	ehc->i.flags |= ATA_EHI_POST_SETMODE;
-	rc = ata_dev_revalidate(dev, ATA_DEV_UNKNOWN, 0);
+	rc = ata_dev_revalidate(dev, 0);
 	ehc->i.flags &= ~ATA_EHI_POST_SETMODE;
 	if (rc)
 		return rc;
 
-	if (dev->xfer_shift == ATA_SHIFT_PIO) {
-		/* Old CFA may refuse this command, which is just fine */
-		if (ata_id_is_cfa(dev->id))
-			ign_dev_err = 1;
-		/* Catch several broken garbage emulations plus some pre
-		   ATA devices */
-		if (ata_id_major_version(dev->id) == 0 &&
-					dev->pio_mode <= XFER_PIO_2)
-			ign_dev_err = 1;
-		/* Some very old devices and some bad newer ones fail
-		   any kind of SET_XFERMODE request but support PIO0-2
-		   timings and no IORDY */
-		if (!ata_id_has_iordy(dev->id) && dev->pio_mode <= XFER_PIO_2)
-			ign_dev_err = 1;
-	}
-	/* Early MWDMA devices do DMA but don't allow DMA mode setting.
-	   Don't fail an MWDMA0 set IFF the device indicates it is in MWDMA0 */
-	if (dev->xfer_shift == ATA_SHIFT_MWDMA &&
-	    dev->dma_mode == XFER_MW_DMA_0 &&
-	    (dev->id[63] >> 8) & 1)
-		ign_dev_err = 1;
-
-	/* if the device is actually configured correctly, ignore dev err */
-	if (dev->xfer_mode == ata_xfer_mask2mode(ata_id_xfermask(dev->id)))
-		ign_dev_err = 1;
-
-	if (err_mask & AC_ERR_DEV) {
-		if (!ign_dev_err)
-			goto fail;
-		else
-			dev_err_whine = " (device error ignored)";
-	}
-
 	DPRINTK("xfer_shift=%u, xfer_mode=0x%x\n",
 		dev->xfer_shift, (int)dev->xfer_mode);
 
-	ata_dev_printk(dev, KERN_INFO, "configured for %s%s\n",
-		       ata_mode_string(ata_xfer_mode2mask(dev->xfer_mode)),
-		       dev_err_whine);
-
+	ata_dev_printk(dev, KERN_INFO, "configured for %s\n",
+		       ata_mode_string(ata_xfer_mode2mask(dev->xfer_mode)));
 	return 0;
-
- fail:
-	ata_dev_printk(dev, KERN_ERR, "failed to set xfermode "
-		       "(err_mask=0x%x)\n", err_mask);
-	return -EIO;
 }
 
 /**
  *	ata_do_set_mode - Program timings and issue SET FEATURES - XFER
- *	@link: link on which timings will be programmed
- *	@r_failed_dev: out parameter for failed device
+ *	@ap: port on which timings will be programmed
+ *	@r_failed_dev: out paramter for failed device
  *
  *	Standard implementation of the function used to tune and set
  *	ATA device disk transfer mode (PIO3, UDMA6, etc.).  If
@@ -3523,47 +2804,42 @@
  *	0 on success, negative errno otherwise
  */
 
-int ata_do_set_mode(struct ata_link *link, struct ata_device **r_failed_dev)
+int ata_do_set_mode(struct ata_port *ap, struct ata_device **r_failed_dev)
 {
-	struct ata_port *ap = link->ap;
 	struct ata_device *dev;
-	int rc = 0, used_dma = 0, found = 0;
+	int i, rc = 0, used_dma = 0, found = 0;
+
 
 	/* step 1: calculate xfer_mask */
-	ata_for_each_dev(dev, link, ENABLED) {
-		unsigned long pio_mask, dma_mask;
-		unsigned int mode_mask;
-
-		mode_mask = ATA_DMA_MASK_ATA;
-		if (dev->class == ATA_DEV_ATAPI)
-			mode_mask = ATA_DMA_MASK_ATAPI;
-		else if (ata_id_is_cfa(dev->id))
-			mode_mask = ATA_DMA_MASK_CFA;
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		unsigned int pio_mask, dma_mask;
+
+		dev = &ap->device[i];
+
+		if (!ata_dev_enabled(dev))
+			continue;
 
 		ata_dev_xfermask(dev);
-		ata_force_xfermask(dev);
 
 		pio_mask = ata_pack_xfermask(dev->pio_mask, 0, 0);
 		dma_mask = ata_pack_xfermask(0, dev->mwdma_mask, dev->udma_mask);
-
-		if (libata_dma_mask & mode_mask)
-			dma_mask = ata_pack_xfermask(0, dev->mwdma_mask, dev->udma_mask);
-		else
-			dma_mask = 0;
-
 		dev->pio_mode = ata_xfer_mask2mode(pio_mask);
 		dev->dma_mode = ata_xfer_mask2mode(dma_mask);
 
 		found = 1;
-		if (ata_dma_enabled(dev))
+		if (dev->dma_mode)
 			used_dma = 1;
 	}
 	if (!found)
 		goto out;
 
 	/* step 2: always set host PIO timings */
-	ata_for_each_dev(dev, link, ENABLED) {
-		if (dev->pio_mode == 0xff) {
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		dev = &ap->device[i];
+		if (!ata_dev_enabled(dev))
+			continue;
+
+		if (!dev->pio_mode) {
 			ata_dev_printk(dev, KERN_WARNING, "no PIO support\n");
 			rc = -EINVAL;
 			goto out;
@@ -3576,8 +2852,10 @@
 	}
 
 	/* step 3: set host DMA timings */
-	ata_for_each_dev(dev, link, ENABLED) {
-		if (!ata_dma_enabled(dev))
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		dev = &ap->device[i];
+
+		if (!ata_dev_enabled(dev) || !dev->dma_mode)
 			continue;
 
 		dev->xfer_mode = dev->dma_mode;
@@ -3587,7 +2865,13 @@
 	}
 
 	/* step 4: update devices' xfer mode */
-	ata_for_each_dev(dev, link, ENABLED) {
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		dev = &ap->device[i];
+
+		/* don't update suspended devices' xfer mode */
+		if (!ata_dev_enabled(dev))
+			continue;
+
 		rc = ata_dev_set_mode(dev);
 		if (rc)
 			goto out;
@@ -3606,251 +2890,441 @@
 }
 
 /**
- *	ata_wait_ready - wait for link to become ready
- *	@link: link to be waited on
- *	@deadline: deadline jiffies for the operation
- *	@check_ready: callback to check link readiness
- *
- *	Wait for @link to become ready.  @check_ready should return
- *	positive number if @link is ready, 0 if it isn't, -ENODEV if
- *	link doesn't seem to be occupied, other errno for other error
- *	conditions.
+ *	ata_set_mode - Program timings and issue SET FEATURES - XFER
+ *	@ap: port on which timings will be programmed
+ *	@r_failed_dev: out paramter for failed device
  *
- *	Transient -ENODEV conditions are allowed for
- *	ATA_TMOUT_FF_WAIT.
+ *	Set ATA device disk transfer mode (PIO3, UDMA6, etc.).  If
+ *	ata_set_mode() fails, pointer to the failing device is
+ *	returned in @r_failed_dev.
  *
  *	LOCKING:
- *	EH context.
+ *	PCI/etc. bus probe sem.
  *
  *	RETURNS:
- *	0 if @linke is ready before @deadline; otherwise, -errno.
+ *	0 on success, negative errno otherwise
  */
-int ata_wait_ready(struct ata_link *link, unsigned long deadline,
-		   int (*check_ready)(struct ata_link *link))
+int ata_set_mode(struct ata_port *ap, struct ata_device **r_failed_dev)
 {
-	unsigned long start = jiffies;
-	unsigned long nodev_deadline = ata_deadline(start, ATA_TMOUT_FF_WAIT);
-	int warned = 0;
-
-	/* Slave readiness can't be tested separately from master.  On
-	 * M/S emulation configuration, this function should be called
-	 * only on the master and it will handle both master and slave.
-	 */
-	WARN_ON(link == link->ap->slave_link);
-
-	if (time_after(nodev_deadline, deadline))
-		nodev_deadline = deadline;
-
-	while (1) {
-		unsigned long now = jiffies;
-		int ready, tmp;
-
-		ready = tmp = check_ready(link);
-		if (ready > 0)
-			return 0;
-
-		/* -ENODEV could be transient.  Ignore -ENODEV if link
-		 * is online.  Also, some SATA devices take a long
-		 * time to clear 0xff after reset.  For example,
-		 * HHD424020F7SV00 iVDR needs >= 800ms while Quantum
-		 * GoVault needs even more than that.  Wait for
-		 * ATA_TMOUT_FF_WAIT on -ENODEV if link isn't offline.
-		 *
-		 * Note that some PATA controllers (pata_ali) explode
-		 * if status register is read more than once when
-		 * there's no device attached.
-		 */
-		if (ready == -ENODEV) {
-			if (ata_link_online(link))
-				ready = 0;
-			else if ((link->ap->flags & ATA_FLAG_SATA) &&
-				 !ata_link_offline(link) &&
-				 time_before(now, nodev_deadline))
-				ready = 0;
-		}
-
-		if (ready)
-			return ready;
-		if (time_after(now, deadline))
-			return -EBUSY;
-
-		if (!warned && time_after(now, start + 5 * HZ) &&
-		    (deadline - now > 3 * HZ)) {
-			ata_link_printk(link, KERN_WARNING,
-				"link is slow to respond, please be patient "
-				"(ready=%d)\n", tmp);
-			warned = 1;
-		}
-
-		msleep(50);
-	}
+	/* has private set_mode? */
+	if (ap->ops->set_mode)
+		return ap->ops->set_mode(ap, r_failed_dev);
+	return ata_do_set_mode(ap, r_failed_dev);
 }
 
 /**
- *	ata_wait_after_reset - wait for link to become ready after reset
- *	@link: link to be waited on
- *	@deadline: deadline jiffies for the operation
- *	@check_ready: callback to check link readiness
+ *	ata_tf_to_host - issue ATA taskfile to host controller
+ *	@ap: port to which command is being issued
+ *	@tf: ATA taskfile register set
  *
- *	Wait for @link to become ready after reset.
+ *	Issues ATA taskfile register set to ATA host controller,
+ *	with proper synchronization with interrupt handler and
+ *	other threads.
  *
  *	LOCKING:
- *	EH context.
- *
- *	RETURNS:
- *	0 if @linke is ready before @deadline; otherwise, -errno.
+ *	spin_lock_irqsave(host lock)
  */
-int ata_wait_after_reset(struct ata_link *link, unsigned long deadline,
-				int (*check_ready)(struct ata_link *link))
-{
-	msleep(ATA_WAIT_AFTER_RESET);
 
-	return ata_wait_ready(link, deadline, check_ready);
+static inline void ata_tf_to_host(struct ata_port *ap,
+				  const struct ata_taskfile *tf)
+{
+	ap->ops->tf_load(ap, tf);
+	ap->ops->exec_command(ap, tf);
 }
 
 /**
- *	sata_link_debounce - debounce SATA phy status
- *	@link: ATA link to debounce SATA phy status for
- *	@params: timing parameters { interval, duratinon, timeout } in msec
- *	@deadline: deadline jiffies for the operation
- *
-*	Make sure SStatus of @link reaches stable state, determined by
- *	holding the same value where DET is not 1 for @duration polled
- *	every @interval, before @timeout.  Timeout constraints the
- *	beginning of the stable state.  Because DET gets stuck at 1 on
- *	some controllers after hot unplugging, this functions waits
- *	until timeout then returns 0 if DET is stable at 1.
+ *	ata_busy_sleep - sleep until BSY clears, or timeout
+ *	@ap: port containing status register to be polled
+ *	@tmout_pat: impatience timeout
+ *	@tmout: overall timeout
  *
- *	@timeout is further limited by @deadline.  The sooner of the
- *	two is used.
+ *	Sleep until ATA Status register bit BSY clears,
+ *	or a timeout occurs.
  *
  *	LOCKING:
- *	Kernel thread context (may sleep)
+ *	Kernel thread context (may sleep).
  *
  *	RETURNS:
- *	0 on success, -errno on failure.
+ *	0 on success, -errno otherwise.
  */
-int sata_link_debounce(struct ata_link *link, const unsigned long *params,
-		       unsigned long deadline)
+int ata_busy_sleep(struct ata_port *ap,
+		   unsigned long tmout_pat, unsigned long tmout)
 {
-	unsigned long interval = params[0];
-	unsigned long duration = params[1];
-	unsigned long last_jiffies, t;
-	u32 last, cur;
-	int rc;
-
-	t = ata_deadline(jiffies, params[2]);
-	if (time_before(t, deadline))
-		deadline = t;
+	unsigned long timer_start, timeout;
+	u8 status;
 
-	if ((rc = sata_scr_read(link, SCR_STATUS, &cur)))
-		return rc;
-	cur &= 0xf;
-
-	last = cur;
-	last_jiffies = jiffies;
+	status = ata_busy_wait(ap, ATA_BUSY, 300);
+	timer_start = jiffies;
+	timeout = timer_start + tmout_pat;
+	while (status != 0xff && (status & ATA_BUSY) &&
+	       time_before(jiffies, timeout)) {
+		msleep(50);
+		status = ata_busy_wait(ap, ATA_BUSY, 3);
+	}
 
-	while (1) {
-		msleep(interval);
-		if ((rc = sata_scr_read(link, SCR_STATUS, &cur)))
-			return rc;
-		cur &= 0xf;
+	if (status != 0xff && (status & ATA_BUSY))
+		ata_port_printk(ap, KERN_WARNING,
+				"port is slow to respond, please be patient "
+				"(Status 0x%x)\n", status);
 
-		/* DET stable? */
-		if (cur == last) {
-			if (cur == 1 && time_before(jiffies, deadline))
-				continue;
-			if (time_after(jiffies,
-				       ata_deadline(last_jiffies, duration)))
-				return 0;
-			continue;
-		}
+	timeout = timer_start + tmout;
+	while (status != 0xff && (status & ATA_BUSY) &&
+	       time_before(jiffies, timeout)) {
+		msleep(50);
+		status = ata_chk_status(ap);
+	}
 
-		/* unstable, start over */
-		last = cur;
-		last_jiffies = jiffies;
+	if (status == 0xff)
+		return -ENODEV;
 
-		/* Check deadline.  If debouncing failed, return
-		 * -EPIPE to tell upper layer to lower link speed.
-		 */
-		if (time_after(jiffies, deadline))
-			return -EPIPE;
+	if (status & ATA_BUSY) {
+		ata_port_printk(ap, KERN_ERR, "port failed to respond "
+				"(%lu secs, Status 0x%x)\n",
+				tmout / HZ, status);
+		return -EBUSY;
 	}
+
+	return 0;
 }
 
 /**
- *	sata_link_resume - resume SATA link
- *	@link: ATA link to resume SATA
- *	@params: timing parameters { interval, duratinon, timeout } in msec
+ *	ata_wait_ready - sleep until BSY clears, or timeout
+ *	@ap: port containing status register to be polled
  *	@deadline: deadline jiffies for the operation
  *
- *	Resume SATA phy @link and debounce it.
+ *	Sleep until ATA Status register bit BSY clears, or timeout
+ *	occurs.
  *
  *	LOCKING:
- *	Kernel thread context (may sleep)
+ *	Kernel thread context (may sleep).
  *
  *	RETURNS:
- *	0 on success, -errno on failure.
+ *	0 on success, -errno otherwise.
  */
-int sata_link_resume(struct ata_link *link, const unsigned long *params,
-		     unsigned long deadline)
+int ata_wait_ready(struct ata_port *ap, unsigned long deadline)
 {
-	int tries = ATA_LINK_RESUME_TRIES;
-	u32 scontrol, serror;
-	int rc;
+	unsigned long start = jiffies;
+	int warned = 0;
 
-	if ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))
-		return rc;
+	while (1) {
+		u8 status = ata_chk_status(ap);
+		unsigned long now = jiffies;
 
-	/*
-	 * Writes to SControl sometimes get ignored under certain
-	 * controllers (ata_piix SIDPR).  Make sure DET actually is
-	 * cleared.
+		if (!(status & ATA_BUSY))
+			return 0;
+		if (!ata_port_online(ap) && status == 0xff)
+			return -ENODEV;
+		if (time_after(now, deadline))
+			return -EBUSY;
+
+		if (!warned && time_after(now, start + 5 * HZ) &&
+		    (deadline - now > 3 * HZ)) {
+			ata_port_printk(ap, KERN_WARNING,
+				"port is slow to respond, please be patient "
+				"(Status 0x%x)\n", status);
+			warned = 1;
+		}
+
+		msleep(50);
+	}
+}
+
+static int ata_bus_post_reset(struct ata_port *ap, unsigned int devmask,
+			      unsigned long deadline)
+{
+	struct ata_ioports *ioaddr = &ap->ioaddr;
+	unsigned int dev0 = devmask & (1 << 0);
+	unsigned int dev1 = devmask & (1 << 1);
+	int rc, ret = 0;
+
+	/* if device 0 was found in ata_devchk, wait for its
+	 * BSY bit to clear
 	 */
-	do {
-		scontrol = (scontrol & 0x0f0) | 0x300;
-		if ((rc = sata_scr_write(link, SCR_CONTROL, scontrol)))
-			return rc;
-		/*
-		 * Some PHYs react badly if SStatus is pounded
-		 * immediately after resuming.  Delay 200ms before
-		 * debouncing.
+	if (dev0) {
+		rc = ata_wait_ready(ap, deadline);
+		if (rc) {
+			if (rc != -ENODEV)
+				return rc;
+			ret = rc;
+		}
+	}
+
+	/* if device 1 was found in ata_devchk, wait for register
+	 * access briefly, then wait for BSY to clear.
+	 */
+	if (dev1) {
+		int i;
+
+		ap->ops->dev_select(ap, 1);
+
+		/* Wait for register access.  Some ATAPI devices fail
+		 * to set nsect/lbal after reset, so don't waste too
+		 * much time on it.  We're gonna wait for !BSY anyway.
 		 */
-		msleep(200);
+		for (i = 0; i < 2; i++) {
+			u8 nsect, lbal;
+
+			nsect = ioread8(ioaddr->nsect_addr);
+			lbal = ioread8(ioaddr->lbal_addr);
+			if ((nsect == 1) && (lbal == 1))
+				break;
+			msleep(50);	/* give drive a breather */
+		}
+
+		rc = ata_wait_ready(ap, deadline);
+		if (rc) {
+			if (rc != -ENODEV)
+				return rc;
+			ret = rc;
+		}
+	}
+
+	/* is all this really necessary? */
+	ap->ops->dev_select(ap, 0);
+	if (dev1)
+		ap->ops->dev_select(ap, 1);
+	if (dev0)
+		ap->ops->dev_select(ap, 0);
+
+	return ret;
+}
+
+static int ata_bus_softreset(struct ata_port *ap, unsigned int devmask,
+			     unsigned long deadline)
+{
+	struct ata_ioports *ioaddr = &ap->ioaddr;
+
+	DPRINTK("ata%u: bus reset via SRST\n", ap->print_id);
+
+	/* software reset.  causes dev0 to be selected */
+	iowrite8(ap->ctl, ioaddr->ctl_addr);
+	udelay(20);	/* FIXME: flush */
+	iowrite8(ap->ctl | ATA_SRST, ioaddr->ctl_addr);
+	udelay(20);	/* FIXME: flush */
+	iowrite8(ap->ctl, ioaddr->ctl_addr);
+	ap->last_ctl = ap->ctl;
+
+	/* spec mandates ">= 2ms" before checking status.
+	 * We wait 150ms, because that was the magic delay used for
+	 * ATAPI devices in Hale Landis's ATADRVR, for the period of time
+	 * between when the ATA command register is written, and then
+	 * status is checked.  Because waiting for "a while" before
+	 * checking status is fine, post SRST, we perform this magic
+	 * delay here as well.
+	 *
+	 * Old drivers/ide uses the 2mS rule and then waits for ready
+	 */
+	msleep(150);
+
+	/* Before we perform post reset processing we want to see if
+	 * the bus shows 0xFF because the odd clown forgets the D7
+	 * pulldown resistor.
+	 */
+	if (ata_check_status(ap) == 0xFF)
+		return -ENODEV;
+
+	return ata_bus_post_reset(ap, devmask, deadline);
+}
+
+/**
+ *	ata_bus_reset - reset host port and associated ATA channel
+ *	@ap: port to reset
+ *
+ *	This is typically the first time we actually start issuing
+ *	commands to the ATA channel.  We wait for BSY to clear, then
+ *	issue EXECUTE DEVICE DIAGNOSTIC command, polling for its
+ *	result.  Determine what devices, if any, are on the channel
+ *	by looking at the device 0/1 error register.  Look at the signature
+ *	stored in each device's taskfile registers, to determine if
+ *	the device is ATA or ATAPI.
+ *
+ *	LOCKING:
+ *	PCI/etc. bus probe sem.
+ *	Obtains host lock.
+ *
+ *	SIDE EFFECTS:
+ *	Sets ATA_FLAG_DISABLED if bus reset fails.
+ */
 
-		/* is SControl restored correctly? */
-		if ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))
+void ata_bus_reset(struct ata_port *ap)
+{
+	struct ata_ioports *ioaddr = &ap->ioaddr;
+	unsigned int slave_possible = ap->flags & ATA_FLAG_SLAVE_POSS;
+	u8 err;
+	unsigned int dev0, dev1 = 0, devmask = 0;
+	int rc;
+
+	DPRINTK("ENTER, host %u, port %u\n", ap->print_id, ap->port_no);
+
+	/* determine if device 0/1 are present */
+	if (ap->flags & ATA_FLAG_SATA_RESET)
+		dev0 = 1;
+	else {
+		dev0 = ata_devchk(ap, 0);
+		if (slave_possible)
+			dev1 = ata_devchk(ap, 1);
+	}
+
+	if (dev0)
+		devmask |= (1 << 0);
+	if (dev1)
+		devmask |= (1 << 1);
+
+	/* select device 0 again */
+	ap->ops->dev_select(ap, 0);
+
+	/* issue bus reset */
+	if (ap->flags & ATA_FLAG_SRST) {
+		rc = ata_bus_softreset(ap, devmask, jiffies + 40 * HZ);
+		if (rc && rc != -ENODEV)
+			goto err_out;
+	}
+
+	/*
+	 * determine by signature whether we have ATA or ATAPI devices
+	 */
+	ap->device[0].class = ata_dev_try_classify(ap, 0, &err);
+	if ((slave_possible) && (err != 0x81))
+		ap->device[1].class = ata_dev_try_classify(ap, 1, &err);
+
+	/* is double-select really necessary? */
+	if (ap->device[1].class != ATA_DEV_NONE)
+		ap->ops->dev_select(ap, 1);
+	if (ap->device[0].class != ATA_DEV_NONE)
+		ap->ops->dev_select(ap, 0);
+
+	/* if no devices were detected, disable this port */
+	if ((ap->device[0].class == ATA_DEV_NONE) &&
+	    (ap->device[1].class == ATA_DEV_NONE))
+		goto err_out;
+
+	if (ap->flags & (ATA_FLAG_SATA_RESET | ATA_FLAG_SRST)) {
+		/* set up device control for ATA_FLAG_SATA_RESET */
+		iowrite8(ap->ctl, ioaddr->ctl_addr);
+		ap->last_ctl = ap->ctl;
+	}
+
+	DPRINTK("EXIT\n");
+	return;
+
+err_out:
+	ata_port_printk(ap, KERN_ERR, "disabling port\n");
+	ap->ops->port_disable(ap);
+
+	DPRINTK("EXIT\n");
+}
+
+/**
+ *	sata_phy_debounce - debounce SATA phy status
+ *	@ap: ATA port to debounce SATA phy status for
+ *	@params: timing parameters { interval, duratinon, timeout } in msec
+ *	@deadline: deadline jiffies for the operation
+ *
+ *	Make sure SStatus of @ap reaches stable state, determined by
+ *	holding the same value where DET is not 1 for @duration polled
+ *	every @interval, before @timeout.  Timeout constraints the
+ *	beginning of the stable state.  Because DET gets stuck at 1 on
+ *	some controllers after hot unplugging, this functions waits
+ *	until timeout then returns 0 if DET is stable at 1.
+ *
+ *	@timeout is further limited by @deadline.  The sooner of the
+ *	two is used.
+ *
+ *	LOCKING:
+ *	Kernel thread context (may sleep)
+ *
+ *	RETURNS:
+ *	0 on success, -errno on failure.
+ */
+int sata_phy_debounce(struct ata_port *ap, const unsigned long *params,
+		      unsigned long deadline)
+{
+	unsigned long interval_msec = params[0];
+	unsigned long duration = msecs_to_jiffies(params[1]);
+	unsigned long last_jiffies, t;
+	u32 last, cur;
+	int rc;
+
+	t = jiffies + msecs_to_jiffies(params[2]);
+	if (time_before(t, deadline))
+		deadline = t;
+
+	if ((rc = sata_scr_read(ap, SCR_STATUS, &cur)))
+		return rc;
+	cur &= 0xf;
+
+	last = cur;
+	last_jiffies = jiffies;
+
+	while (1) {
+		msleep(interval_msec);
+		if ((rc = sata_scr_read(ap, SCR_STATUS, &cur)))
 			return rc;
-	} while ((scontrol & 0xf0f) != 0x300 && --tries);
+		cur &= 0xf;
 
-	if ((scontrol & 0xf0f) != 0x300) {
-		ata_link_printk(link, KERN_ERR,
-				"failed to resume link (SControl %X)\n",
-				scontrol);
-		return 0;
+		/* DET stable? */
+		if (cur == last) {
+			if (cur == 1 && time_before(jiffies, deadline))
+				continue;
+			if (time_after(jiffies, last_jiffies + duration))
+				return 0;
+			continue;
+		}
+
+		/* unstable, start over */
+		last = cur;
+		last_jiffies = jiffies;
+
+		/* Check deadline.  If debouncing failed, return
+		 * -EPIPE to tell upper layer to lower link speed.
+		 */
+		if (time_after(jiffies, deadline))
+			return -EPIPE;
 	}
+}
+
+/**
+ *	sata_phy_resume - resume SATA phy
+ *	@ap: ATA port to resume SATA phy for
+ *	@params: timing parameters { interval, duratinon, timeout } in msec
+ *	@deadline: deadline jiffies for the operation
+ *
+ *	Resume SATA phy of @ap and debounce it.
+ *
+ *	LOCKING:
+ *	Kernel thread context (may sleep)
+ *
+ *	RETURNS:
+ *	0 on success, -errno on failure.
+ */
+int sata_phy_resume(struct ata_port *ap, const unsigned long *params,
+		    unsigned long deadline)
+{
+	u32 scontrol;
+	int rc;
+
+	if ((rc = sata_scr_read(ap, SCR_CONTROL, &scontrol)))
+		return rc;
 
-	if (tries < ATA_LINK_RESUME_TRIES)
-		ata_link_printk(link, KERN_WARNING,
-				"link resume succeeded after %d retries\n",
-				ATA_LINK_RESUME_TRIES - tries);
+	scontrol = (scontrol & 0x0f0) | 0x300;
 
-	if ((rc = sata_link_debounce(link, params, deadline)))
+	if ((rc = sata_scr_write(ap, SCR_CONTROL, scontrol)))
 		return rc;
 
-	/* clear SError, some PHYs require this even for SRST to work */
-	if (!(rc = sata_scr_read(link, SCR_ERROR, &serror)))
-		rc = sata_scr_write(link, SCR_ERROR, serror);
+	/* Some PHYs react badly if SStatus is pounded immediately
+	 * after resuming.  Delay 200ms before debouncing.
+	 */
+	msleep(200);
 
-	return rc != -EINVAL ? rc : 0;
+	return sata_phy_debounce(ap, params, deadline);
 }
 
 /**
  *	ata_std_prereset - prepare for reset
- *	@link: ATA link to be reset
+ *	@ap: ATA port to be reset
  *	@deadline: deadline jiffies for the operation
  *
- *	@link is about to be reset.  Initialize it.  Failure from
+ *	@ap is about to be reset.  Initialize it.  Failure from
  *	prereset makes libata abort whole reset sequence and give up
  *	that port, so prereset should be best-effort.  It does its
  *	best to prepare for reset sequence but if things go wrong, it
@@ -3862,50 +3336,109 @@
  *	RETURNS:
  *	0 on success, -errno otherwise.
  */
-int ata_std_prereset(struct ata_link *link, unsigned long deadline)
+int ata_std_prereset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_eh_context *ehc = &link->eh_context;
+	struct ata_eh_context *ehc = &ap->eh_context;
 	const unsigned long *timing = sata_ehc_deb_timing(ehc);
 	int rc;
 
+	/* handle link resume */
+	if ((ehc->i.flags & ATA_EHI_RESUME_LINK) &&
+	    (ap->flags & ATA_FLAG_HRST_TO_RESUME))
+		ehc->i.action |= ATA_EH_HARDRESET;
+
 	/* if we're about to do hardreset, nothing more to do */
 	if (ehc->i.action & ATA_EH_HARDRESET)
 		return 0;
 
-	/* if SATA, resume link */
+	/* if SATA, resume phy */
 	if (ap->flags & ATA_FLAG_SATA) {
-		rc = sata_link_resume(link, timing, deadline);
+		rc = sata_phy_resume(ap, timing, deadline);
 		/* whine about phy resume failure but proceed */
 		if (rc && rc != -EOPNOTSUPP)
-			ata_link_printk(link, KERN_WARNING, "failed to resume "
+			ata_port_printk(ap, KERN_WARNING, "failed to resume "
 					"link for reset (errno=%d)\n", rc);
 	}
 
-	/* no point in trying softreset on offline link */
-	if (ata_phys_link_offline(link))
-		ehc->i.action &= ~ATA_EH_SOFTRESET;
+	/* Wait for !BSY if the controller can wait for the first D2H
+	 * Reg FIS and we don't know that no device is attached.
+	 */
+	if (!(ap->flags & ATA_FLAG_SKIP_D2H_BSY) && !ata_port_offline(ap)) {
+		rc = ata_wait_ready(ap, deadline);
+		if (rc && rc != -ENODEV) {
+			ata_port_printk(ap, KERN_WARNING, "device not ready "
+					"(errno=%d), forcing hardreset\n", rc);
+			ehc->i.action |= ATA_EH_HARDRESET;
+		}
+	}
+
+	return 0;
+}
+
+/**
+ *	ata_std_softreset - reset host port via ATA SRST
+ *	@ap: port to reset
+ *	@classes: resulting classes of attached devices
+ *	@deadline: deadline jiffies for the operation
+ *
+ *	Reset host port using ATA SRST.
+ *
+ *	LOCKING:
+ *	Kernel thread context (may sleep)
+ *
+ *	RETURNS:
+ *	0 on success, -errno otherwise.
+ */
+int ata_std_softreset(struct ata_port *ap, unsigned int *classes,
+		      unsigned long deadline)
+{
+	unsigned int slave_possible = ap->flags & ATA_FLAG_SLAVE_POSS;
+	unsigned int devmask = 0;
+	int rc;
+	u8 err;
+
+	DPRINTK("ENTER\n");
+
+	if (ata_port_offline(ap)) {
+		classes[0] = ATA_DEV_NONE;
+		goto out;
+	}
+
+	/* determine if device 0/1 are present */
+	if (ata_devchk(ap, 0))
+		devmask |= (1 << 0);
+	if (slave_possible && ata_devchk(ap, 1))
+		devmask |= (1 << 1);
+
+	/* select device 0 again */
+	ap->ops->dev_select(ap, 0);
+
+	/* issue bus reset */
+	DPRINTK("about to softreset, devmask=%x\n", devmask);
+	rc = ata_bus_softreset(ap, devmask, deadline);
+	/* if link is occupied, -ENODEV too is an error */
+	if (rc && (rc != -ENODEV || sata_scr_valid(ap))) {
+		ata_port_printk(ap, KERN_ERR, "SRST failed (errno=%d)\n", rc);
+		return rc;
+	}
+
+	/* determine by signature whether we have ATA or ATAPI devices */
+	classes[0] = ata_dev_try_classify(ap, 0, &err);
+	if (slave_possible && err != 0x81)
+		classes[1] = ata_dev_try_classify(ap, 1, &err);
 
+ out:
+	DPRINTK("EXIT, classes[0]=%u [1]=%u\n", classes[0], classes[1]);
 	return 0;
 }
 
 /**
- *	sata_link_hardreset - reset link via SATA phy reset
- *	@link: link to reset
+ *	sata_port_hardreset - reset port via SATA phy reset
+ *	@ap: port to reset
  *	@timing: timing parameters { interval, duratinon, timeout } in msec
  *	@deadline: deadline jiffies for the operation
- *	@online: optional out parameter indicating link onlineness
- *	@check_ready: optional callback to check link readiness
- *
- *	SATA phy-reset @link using DET bits of SControl register.
- *	After hardreset, link readiness is waited upon using
- *	ata_wait_ready() if @check_ready is specified.  LLDs are
- *	allowed to not specify @check_ready and wait itself after this
- *	function returns.  Device classification is LLD's
- *	responsibility.
  *
- *	*@online is set to one iff reset succeeded and @link is online
- *	after reset.
+ *	SATA phy-reset host port using DET bits of SControl register.
  *
  *	LOCKING:
  *	Kernel thread context (may sleep)
@@ -3913,42 +3446,38 @@
  *	RETURNS:
  *	0 on success, -errno otherwise.
  */
-int sata_link_hardreset(struct ata_link *link, const unsigned long *timing,
-			unsigned long deadline,
-			bool *online, int (*check_ready)(struct ata_link *))
+int sata_port_hardreset(struct ata_port *ap, const unsigned long *timing,
+			unsigned long deadline)
 {
 	u32 scontrol;
 	int rc;
 
 	DPRINTK("ENTER\n");
 
-	if (online)
-		*online = false;
-
-	if (sata_set_spd_needed(link)) {
+	if (sata_set_spd_needed(ap)) {
 		/* SATA spec says nothing about how to reconfigure
 		 * spd.  To be on the safe side, turn off phy during
 		 * reconfiguration.  This works for at least ICH7 AHCI
 		 * and Sil3124.
 		 */
-		if ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))
+		if ((rc = sata_scr_read(ap, SCR_CONTROL, &scontrol)))
 			goto out;
 
 		scontrol = (scontrol & 0x0f0) | 0x304;
 
-		if ((rc = sata_scr_write(link, SCR_CONTROL, scontrol)))
+		if ((rc = sata_scr_write(ap, SCR_CONTROL, scontrol)))
 			goto out;
 
-		sata_set_spd(link);
+		sata_set_spd(ap);
 	}
 
 	/* issue phy wake/reset */
-	if ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))
+	if ((rc = sata_scr_read(ap, SCR_CONTROL, &scontrol)))
 		goto out;
 
 	scontrol = (scontrol & 0x0f0) | 0x301;
 
-	if ((rc = sata_scr_write_flush(link, SCR_CONTROL, scontrol)))
+	if ((rc = sata_scr_write_flush(ap, SCR_CONTROL, scontrol)))
 		goto out;
 
 	/* Couldn't find anything in SATA I/II specs, but AHCI-1.1
@@ -3956,81 +3485,73 @@
 	 */
 	msleep(1);
 
-	/* bring link back */
-	rc = sata_link_resume(link, timing, deadline);
-	if (rc)
-		goto out;
-	/* if link is offline nothing more to do */
-	if (ata_phys_link_offline(link))
-		goto out;
-
-	/* Link is online.  From this point, -ENODEV too is an error. */
-	if (online)
-		*online = true;
-
-	if (sata_pmp_supported(link->ap) && ata_is_host_link(link)) {
-		/* If PMP is supported, we have to do follow-up SRST.
-		 * Some PMPs don't send D2H Reg FIS after hardreset if
-		 * the first port is empty.  Wait only for
-		 * ATA_TMOUT_PMP_SRST_WAIT.
-		 */
-		if (check_ready) {
-			unsigned long pmp_deadline;
-
-			pmp_deadline = ata_deadline(jiffies,
-						    ATA_TMOUT_PMP_SRST_WAIT);
-			if (time_after(pmp_deadline, deadline))
-				pmp_deadline = deadline;
-			ata_wait_ready(link, pmp_deadline, check_ready);
-		}
-		rc = -EAGAIN;
-		goto out;
-	}
-
-	rc = 0;
-	if (check_ready)
-		rc = ata_wait_ready(link, deadline, check_ready);
+	/* bring phy back */
+	rc = sata_phy_resume(ap, timing, deadline);
  out:
-	if (rc && rc != -EAGAIN) {
-		/* online is set iff link is online && reset succeeded */
-		if (online)
-			*online = false;
-		ata_link_printk(link, KERN_ERR,
-				"COMRESET failed (errno=%d)\n", rc);
-	}
 	DPRINTK("EXIT, rc=%d\n", rc);
 	return rc;
 }
 
 /**
- *	sata_std_hardreset - COMRESET w/o waiting or classification
- *	@link: link to reset
+ *	sata_std_hardreset - reset host port via SATA phy reset
+ *	@ap: port to reset
  *	@class: resulting class of attached device
  *	@deadline: deadline jiffies for the operation
  *
- *	Standard SATA COMRESET w/o waiting or classification.
+ *	SATA phy-reset host port using DET bits of SControl register,
+ *	wait for !BSY and classify the attached device.
  *
  *	LOCKING:
  *	Kernel thread context (may sleep)
  *
  *	RETURNS:
- *	0 if link offline, -EAGAIN if link online, -errno on errors.
+ *	0 on success, -errno otherwise.
  */
-int sata_std_hardreset(struct ata_link *link, unsigned int *class,
+int sata_std_hardreset(struct ata_port *ap, unsigned int *class,
 		       unsigned long deadline)
 {
-	const unsigned long *timing = sata_ehc_deb_timing(&link->eh_context);
-	bool online;
+	const unsigned long *timing = sata_ehc_deb_timing(&ap->eh_context);
 	int rc;
 
+	DPRINTK("ENTER\n");
+
 	/* do hardreset */
-	rc = sata_link_hardreset(link, timing, deadline, &online, NULL);
-	return online ? -EAGAIN : rc;
+	rc = sata_port_hardreset(ap, timing, deadline);
+	if (rc) {
+		ata_port_printk(ap, KERN_ERR,
+				"COMRESET failed (errno=%d)\n", rc);
+		return rc;
+	}
+
+	/* TODO: phy layer with polling, timeouts, etc. */
+	if (ata_port_offline(ap)) {
+		*class = ATA_DEV_NONE;
+		DPRINTK("EXIT, link offline\n");
+		return 0;
+	}
+
+	/* wait a while before checking status, see SRST for more info */
+	msleep(150);
+
+	rc = ata_wait_ready(ap, deadline);
+	/* link occupied, -ENODEV too is an error */
+	if (rc) {
+		ata_port_printk(ap, KERN_ERR,
+				"COMRESET failed (errno=%d)\n", rc);
+		return rc;
+	}
+
+	ap->ops->dev_select(ap, 0);	/* probably unnecessary */
+
+	*class = ata_dev_try_classify(ap, 0, NULL);
+
+	DPRINTK("EXIT, class=%u\n", *class);
+	return 0;
 }
 
 /**
  *	ata_std_postreset - standard postreset callback
- *	@link: the target ata_link
+ *	@ap: the target ata_port
  *	@classes: classes of attached devices
  *
  *	This function is invoked after a successful reset.  Note that
@@ -4040,18 +3561,36 @@
  *	LOCKING:
  *	Kernel thread context (may sleep)
  */
-void ata_std_postreset(struct ata_link *link, unsigned int *classes)
+void ata_std_postreset(struct ata_port *ap, unsigned int *classes)
 {
 	u32 serror;
 
 	DPRINTK("ENTER\n");
 
-	/* reset complete, clear SError */
-	if (!sata_scr_read(link, SCR_ERROR, &serror))
-		sata_scr_write(link, SCR_ERROR, serror);
-
 	/* print link status */
-	sata_print_link_status(link);
+	sata_print_link_status(ap);
+
+	/* clear SError */
+	if (sata_scr_read(ap, SCR_ERROR, &serror) == 0)
+		sata_scr_write(ap, SCR_ERROR, serror);
+
+	/* is double-select really necessary? */
+	if (classes[0] != ATA_DEV_NONE)
+		ap->ops->dev_select(ap, 1);
+	if (classes[1] != ATA_DEV_NONE)
+		ap->ops->dev_select(ap, 0);
+
+	/* bail out if no device is present */
+	if (classes[0] == ATA_DEV_NONE && classes[1] == ATA_DEV_NONE) {
+		DPRINTK("EXIT, no device\n");
+		return;
+	}
+
+	/* set up device control */
+	if (ap->ioaddr.ctl_addr) {
+		iowrite8(ap->ctl, ap->ioaddr.ctl_addr);
+		ap->last_ctl = ap->ctl;
+	}
 
 	DPRINTK("EXIT\n");
 }
@@ -4122,7 +3661,7 @@
 int ata_dev_reread_id(struct ata_device *dev, unsigned int readid_flags)
 {
 	unsigned int class = dev->class;
-	u16 *id = (void *)dev->link->ap->sector_buf;
+	u16 *id = (void *)dev->ap->sector_buf;
 	int rc;
 
 	/* read ID data */
@@ -4141,7 +3680,6 @@
 /**
  *	ata_dev_revalidate - Revalidate ATA device
  *	@dev: device to revalidate
- *	@new_class: new class code
  *	@readid_flags: read ID flags
  *
  *	Re-read IDENTIFY page, make sure @dev is still attached to the
@@ -4153,27 +3691,14 @@
  *	RETURNS:
  *	0 on success, negative errno otherwise
  */
-int ata_dev_revalidate(struct ata_device *dev, unsigned int new_class,
-		       unsigned int readid_flags)
+int ata_dev_revalidate(struct ata_device *dev, unsigned int readid_flags)
 {
 	u64 n_sectors = dev->n_sectors;
-	u64 n_native_sectors = dev->n_native_sectors;
 	int rc;
 
 	if (!ata_dev_enabled(dev))
 		return -ENODEV;
 
-	/* fail early if !ATA && !ATAPI to avoid issuing [P]IDENTIFY to PMP */
-	if (ata_class_enabled(new_class) &&
-	    new_class != ATA_DEV_ATA &&
-	    new_class != ATA_DEV_ATAPI &&
-	    new_class != ATA_DEV_SEMB) {
-		ata_dev_printk(dev, KERN_INFO, "class mismatch %u != %u\n",
-			       dev->class, new_class);
-		rc = -ENODEV;
-		goto fail;
-	}
-
 	/* re-read ID */
 	rc = ata_dev_reread_id(dev, readid_flags);
 	if (rc)
@@ -4187,30 +3712,16 @@
 	/* verify n_sectors hasn't changed */
 	if (dev->class == ATA_DEV_ATA && n_sectors &&
 	    dev->n_sectors != n_sectors) {
-		ata_dev_printk(dev, KERN_WARNING, "n_sectors mismatch "
+		ata_dev_printk(dev, KERN_INFO, "n_sectors mismatch "
 			       "%llu != %llu\n",
 			       (unsigned long long)n_sectors,
 			       (unsigned long long)dev->n_sectors);
-		/*
-		 * Something could have caused HPA to be unlocked
-		 * involuntarily.  If n_native_sectors hasn't changed
-		 * and the new size matches it, keep the device.
-		 */
-		if (dev->n_native_sectors == n_native_sectors &&
-		    dev->n_sectors > n_sectors &&
-		    dev->n_sectors == n_native_sectors) {
-			ata_dev_printk(dev, KERN_WARNING,
-				       "new n_sectors matches native, probably "
-				       "late HPA unlock, continuing\n");
-			/* keep using the old n_sectors */
-			dev->n_sectors = n_sectors;
-		} else {
-			/* restore original n_[native]_sectors and fail */
-			dev->n_native_sectors = n_native_sectors;
-			dev->n_sectors = n_sectors;
-			rc = -ENODEV;
-			goto fail;
-		}
+
+		/* restore original n_sectors */
+		dev->n_sectors = n_sectors;
+
+		rc = -ENODEV;
+		goto fail;
 	}
 
 	return 0;
@@ -4256,183 +3767,64 @@
 	{ "SAMSUNG CD-ROM SC",	NULL,		ATA_HORKAGE_NODMA },
 	{ "ATAPI CD-ROM DRIVE 40X MAXIMUM",NULL,ATA_HORKAGE_NODMA },
 	{ "_NEC DV5800A", 	NULL,		ATA_HORKAGE_NODMA },
-	{ "SAMSUNG CD-ROM SN-124", "N001",	ATA_HORKAGE_NODMA },
+	{ "SAMSUNG CD-ROM SN-124","N001",	ATA_HORKAGE_NODMA },
 	{ "Seagate STT20000A", NULL,		ATA_HORKAGE_NODMA },
-	/* Odd clown on sil3726/4726 PMPs */
-	{ "Config  Disk",	NULL,		ATA_HORKAGE_DISABLE },
+	{ "IOMEGA  ZIP 250       ATAPI", NULL,	ATA_HORKAGE_NODMA }, /* temporary fix */
+	{ "IOMEGA  ZIP 250       ATAPI       Floppy",
+				NULL,		ATA_HORKAGE_NODMA },
 
 	/* Weird ATAPI devices */
 	{ "TORiSAN DVD-ROM DRD-N216", NULL,	ATA_HORKAGE_MAX_SEC_128 },
-	{ "QUANTUM DAT    DAT72-000", NULL,	ATA_HORKAGE_ATAPI_MOD16_DMA },
 
 	/* Devices we expect to fail diagnostics */
 
 	/* Devices where NCQ should be avoided */
 	/* NCQ is slow */
-	{ "WDC WD740ADFD-00",	NULL,		ATA_HORKAGE_NONCQ },
+        { "WDC WD740ADFD-00",   NULL,		ATA_HORKAGE_NONCQ },
 	{ "WDC WD740ADFD-00NLR1", NULL,		ATA_HORKAGE_NONCQ, },
 	/* http://thread.gmane.org/gmane.linux.ide/14907 */
 	{ "FUJITSU MHT2060BH",	NULL,		ATA_HORKAGE_NONCQ },
 	/* NCQ is broken */
-	{ "Maxtor *",		"BANC*",	ATA_HORKAGE_NONCQ },
+	{ "Maxtor 6L250S0",     "BANC1G10",     ATA_HORKAGE_NONCQ },
+	{ "Maxtor 6B200M0",	"BANC1BM0",	ATA_HORKAGE_NONCQ },
+	{ "Maxtor 6B200M0",	"BANC1B10",	ATA_HORKAGE_NONCQ },
+	{ "Maxtor 7B250S0",	"BANC1B70",	ATA_HORKAGE_NONCQ, },
+	{ "Maxtor 7B300S0",	"BANC1B70",	ATA_HORKAGE_NONCQ },
 	{ "Maxtor 7V300F0",	"VA111630",	ATA_HORKAGE_NONCQ },
-	{ "ST380817AS",		"3.42",		ATA_HORKAGE_NONCQ },
-	{ "ST3160023AS",	"3.42",		ATA_HORKAGE_NONCQ },
-	{ "OCZ CORE_SSD",	"02.10104",	ATA_HORKAGE_NONCQ },
-
-	/* Seagate NCQ + FLUSH CACHE firmware bug */
-	{ "ST31500341AS",	"SD15",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST31500341AS",	"SD16",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST31500341AS",	"SD17",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST31500341AS",	"SD18",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST31500341AS",	"SD19",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-
-	{ "ST31000333AS",	"SD15",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST31000333AS",	"SD16",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST31000333AS",	"SD17",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST31000333AS",	"SD18",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST31000333AS",	"SD19",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-
-	{ "ST3640623AS",	"SD15",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3640623AS",	"SD16",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3640623AS",	"SD17",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3640623AS",	"SD18",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3640623AS",	"SD19",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-
-	{ "ST3640323AS",	"SD15",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3640323AS",	"SD16",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3640323AS",	"SD17",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3640323AS",	"SD18",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3640323AS",	"SD19",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-
-	{ "ST3320813AS",	"SD15",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3320813AS",	"SD16",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3320813AS",	"SD17",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3320813AS",	"SD18",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3320813AS",	"SD19",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-
-	{ "ST3320613AS",	"SD15",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3320613AS",	"SD16",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3320613AS",	"SD17",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3320613AS",	"SD18",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-	{ "ST3320613AS",	"SD19",		ATA_HORKAGE_NONCQ |
-						ATA_HORKAGE_FIRMWARE_WARN },
-
+	{ "HITACHI HDS7250SASUN500G 0621KTAWSD", "K2AOAJ0AHITACHI",
+	 ATA_HORKAGE_NONCQ },
+	/* NCQ hard hangs device under heavier load, needs hard power cycle */
+	{ "Maxtor 6B250S0",	"BANC1B70",	ATA_HORKAGE_NONCQ },
 	/* Blacklist entries taken from Silicon Image 3124/3132
 	   Windows driver .inf file - also several Linux problem reports */
 	{ "HTS541060G9SA00",    "MB3OC60D",     ATA_HORKAGE_NONCQ, },
 	{ "HTS541080G9SA00",    "MB4OC60D",     ATA_HORKAGE_NONCQ, },
 	{ "HTS541010G9SA00",    "MBZOC60D",     ATA_HORKAGE_NONCQ, },
 
-	/* https://bugzilla.kernel.org/show_bug.cgi?id=15573 */
-	{ "C300-CTFDDAC128MAG",	"0001",		ATA_HORKAGE_NONCQ, },
-
 	/* devices which puke on READ_NATIVE_MAX */
 	{ "HDS724040KLSA80",	"KFAOA20N",	ATA_HORKAGE_BROKEN_HPA, },
 	{ "WDC WD3200JD-00KLB0", "WD-WCAMR1130137", ATA_HORKAGE_BROKEN_HPA },
 	{ "WDC WD2500JD-00HBB0", "WD-WMAL71490727", ATA_HORKAGE_BROKEN_HPA },
 	{ "MAXTOR 6L080L4",	"A93.0500",	ATA_HORKAGE_BROKEN_HPA },
 
-	/* this one allows HPA unlocking but fails IOs on the area */
-	{ "OCZ-VERTEX",		    "1.30",	ATA_HORKAGE_BROKEN_HPA },
-
-	/* Devices which report 1 sector over size HPA */
-	{ "ST340823A",		NULL,		ATA_HORKAGE_HPA_SIZE, },
-	{ "ST320413A",		NULL,		ATA_HORKAGE_HPA_SIZE, },
-	{ "ST310211A",		NULL,		ATA_HORKAGE_HPA_SIZE, },
-
-	/* Devices which get the IVB wrong */
-	{ "QUANTUM FIREBALLlct10 05", "A03.0900", ATA_HORKAGE_IVB, },
-	/* Maybe we should just blacklist TSSTcorp... */
-	{ "TSSTcorp CDDVDW SH-S202H", "SB00",	  ATA_HORKAGE_IVB, },
-	{ "TSSTcorp CDDVDW SH-S202H", "SB01",	  ATA_HORKAGE_IVB, },
-	{ "TSSTcorp CDDVDW SH-S202J", "SB00",	  ATA_HORKAGE_IVB, },
-	{ "TSSTcorp CDDVDW SH-S202J", "SB01",	  ATA_HORKAGE_IVB, },
-	{ "TSSTcorp CDDVDW SH-S202N", "SB00",	  ATA_HORKAGE_IVB, },
-	{ "TSSTcorp CDDVDW SH-S202N", "SB01",	  ATA_HORKAGE_IVB, },
-
-	/* Devices that do not need bridging limits applied */
-	{ "MTRON MSP-SATA*",		NULL,	ATA_HORKAGE_BRIDGE_OK, },
-
-	/* Devices which aren't very happy with higher link speeds */
-	{ "WD My Book",			NULL,	ATA_HORKAGE_1_5_GBPS, },
-
-	/*
-	 * Devices which choke on SETXFER.  Applies only if both the
-	 * device and controller are SATA.
-	 */
-	{ "PIONEER DVD-RW  DVRTD08",	"1.00",	ATA_HORKAGE_NOSETXFER },
-
 	/* End Marker */
 	{ }
 };
 
-static int strn_pattern_cmp(const char *patt, const char *name, int wildchar)
+static unsigned long ata_dev_blacklisted(const struct ata_device *dev)
 {
-	const char *p;
-	int len;
-
-	/*
-	 * check for trailing wildcard: *\0
-	 */
-	p = strchr(patt, wildchar);
-	if (p && ((*(p + 1)) == 0))
-		len = p - patt;
-	else {
-		len = strlen(name);
-		if (!len) {
-			if (!*patt)
-				return 0;
-			return -1;
-		}
-	}
-
-	return strncmp(patt, name, len);
-}
-
-static unsigned long ata_dev_blacklisted(const struct ata_device *dev)
-{
-	unsigned char model_num[ATA_ID_PROD_LEN + 1];
-	unsigned char model_rev[ATA_ID_FW_REV_LEN + 1];
-	const struct ata_blacklist_entry *ad = ata_device_blacklist;
+	unsigned char model_num[ATA_ID_PROD_LEN + 1];
+	unsigned char model_rev[ATA_ID_FW_REV_LEN + 1];
+	const struct ata_blacklist_entry *ad = ata_device_blacklist;
 
 	ata_id_c_string(dev->id, model_num, ATA_ID_PROD, sizeof(model_num));
 	ata_id_c_string(dev->id, model_rev, ATA_ID_FW_REV, sizeof(model_rev));
 
 	while (ad->model_num) {
-		if (!strn_pattern_cmp(ad->model_num, model_num, '*')) {
+		if (!strcmp(ad->model_num, model_num)) {
 			if (ad->model_rev == NULL)
 				return ad->horkage;
-			if (!strn_pattern_cmp(ad->model_rev, model_rev, '*'))
+			if (!strcmp(ad->model_rev, model_rev))
 				return ad->horkage;
 		}
 		ad++;
@@ -4446,79 +3838,13 @@
 	 * DMA blacklist those ATAPI devices with CDB-intr (and use PIO)
 	 * if the LLDD handles only interrupts in the HSM_ST_LAST state.
 	 */
-	if ((dev->link->ap->flags & ATA_FLAG_PIO_POLLING) &&
+	if ((dev->ap->flags & ATA_FLAG_PIO_POLLING) &&
 	    (dev->flags & ATA_DFLAG_CDB_INTR))
 		return 1;
 	return (dev->horkage & ATA_HORKAGE_NODMA) ? 1 : 0;
 }
 
 /**
- *	ata_is_40wire		-	check drive side detection
- *	@dev: device
- *
- *	Perform drive side detection decoding, allowing for device vendors
- *	who can't follow the documentation.
- */
-
-static int ata_is_40wire(struct ata_device *dev)
-{
-	if (dev->horkage & ATA_HORKAGE_IVB)
-		return ata_drive_40wire_relaxed(dev->id);
-	return ata_drive_40wire(dev->id);
-}
-
-/**
- *	cable_is_40wire		-	40/80/SATA decider
- *	@ap: port to consider
- *
- *	This function encapsulates the policy for speed management
- *	in one place. At the moment we don't cache the result but
- *	there is a good case for setting ap->cbl to the result when
- *	we are called with unknown cables (and figuring out if it
- *	impacts hotplug at all).
- *
- *	Return 1 if the cable appears to be 40 wire.
- */
-
-static int cable_is_40wire(struct ata_port *ap)
-{
-	struct ata_link *link;
-	struct ata_device *dev;
-
-	/* If the controller thinks we are 40 wire, we are. */
-	if (ap->cbl == ATA_CBL_PATA40)
-		return 1;
-
-	/* If the controller thinks we are 80 wire, we are. */
-	if (ap->cbl == ATA_CBL_PATA80 || ap->cbl == ATA_CBL_SATA)
-		return 0;
-
-	/* If the system is known to be 40 wire short cable (eg
-	 * laptop), then we allow 80 wire modes even if the drive
-	 * isn't sure.
-	 */
-	if (ap->cbl == ATA_CBL_PATA40_SHORT)
-		return 0;
-
-	/* If the controller doesn't know, we scan.
-	 *
-	 * Note: We look for all 40 wire detects at this point.  Any
-	 *       80 wire detect is taken to be 80 wire cable because
-	 * - in many setups only the one drive (slave if present) will
-	 *   give a valid detect
-	 * - if you have a non detect capable drive you don't want it
-	 *   to colour the choice
-	 */
-	ata_for_each_link(link, ap, EDGE) {
-		ata_for_each_dev(dev, link, ENABLED) {
-			if (!ata_is_40wire(dev))
-				return 0;
-		}
-	}
-	return 1;
-}
-
-/**
  *	ata_dev_xfermask - Compute supported xfermask of the given device
  *	@dev: Device to compute xfermask for
  *
@@ -4532,8 +3858,7 @@
  */
 static void ata_dev_xfermask(struct ata_device *dev)
 {
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
+	struct ata_port *ap = dev->ap;
 	struct ata_host *host = ap->host;
 	unsigned long xfer_mask;
 
@@ -4564,7 +3889,7 @@
 	}
 
 	if ((host->flags & ATA_HOST_SIMPLEX) &&
-	    host->simplex_claimed && host->simplex_claimed != ap) {
+            host->simplex_claimed && host->simplex_claimed != ap) {
 		xfer_mask &= ~(ATA_MASK_MWDMA | ATA_MASK_UDMA);
 		ata_dev_printk(dev, KERN_WARNING, "simplex DMA is claimed by "
 			       "other device, disabling DMA\n");
@@ -4586,8 +3911,11 @@
 	 */
 	if (xfer_mask & (0xF8 << ATA_SHIFT_UDMA))
 		/* UDMA/44 or higher would be available */
-		if (cable_is_40wire(ap)) {
-			ata_dev_printk(dev, KERN_WARNING,
+		if((ap->cbl == ATA_CBL_PATA40) ||
+   		    (ata_drive_40wire(dev->id) &&
+		     (ap->cbl == ATA_CBL_PATA_UNK ||
+                     ap->cbl == ATA_CBL_PATA80))) {
+		      	ata_dev_printk(dev, KERN_WARNING,
 				 "limited to UDMA/33 due to 40-wire cable\n");
 			xfer_mask &= ~(0xF8 << ATA_SHIFT_UDMA);
 		}
@@ -4626,52 +3954,9 @@
 	tf.feature = SETFEATURES_XFER;
 	tf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE | ATA_TFLAG_POLLING;
 	tf.protocol = ATA_PROT_NODATA;
-	/* If we are using IORDY we must send the mode setting command */
-	if (ata_pio_need_iordy(dev))
-		tf.nsect = dev->xfer_mode;
-	/* If the device has IORDY and the controller does not - turn it off */
- 	else if (ata_id_has_iordy(dev->id))
-		tf.nsect = 0x01;
-	else /* In the ancient relic department - skip all of this */
-		return 0;
-
-	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);
-
-	DPRINTK("EXIT, err_mask=%x\n", err_mask);
-	return err_mask;
-}
-/**
- *	ata_dev_set_feature - Issue SET FEATURES - SATA FEATURES
- *	@dev: Device to which command will be sent
- *	@enable: Whether to enable or disable the feature
- *	@feature: The sector count represents the feature to set
- *
- *	Issue SET FEATURES - SATA FEATURES command to device @dev
- *	on port @ap with sector count
- *
- *	LOCKING:
- *	PCI/etc. bus probe sem.
- *
- *	RETURNS:
- *	0 on success, AC_ERR_* mask otherwise.
- */
-static unsigned int ata_dev_set_feature(struct ata_device *dev, u8 enable,
-					u8 feature)
-{
-	struct ata_taskfile tf;
-	unsigned int err_mask;
-
-	/* set up set-features taskfile */
-	DPRINTK("set features - SATA features\n");
-
-	ata_tf_init(dev, &tf);
-	tf.command = ATA_CMD_SET_FEATURES;
-	tf.feature = enable;
-	tf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;
-	tf.protocol = ATA_PROT_NODATA;
-	tf.nsect = feature;
+	tf.nsect = dev->xfer_mode;
 
-	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);
+	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0);
 
 	DPRINTK("EXIT, err_mask=%x\n", err_mask);
 	return err_mask;
@@ -4709,7 +3994,7 @@
 	tf.nsect = sectors;
 	tf.device |= (heads - 1) & 0x0f; /* max head = num. of heads - 1 */
 
-	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);
+	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0);
 	/* A clean abort indicates an original or just out of spec drive
 	   and we should continue as we issue the setup based on the
 	   drive reported working geometry */
@@ -4732,22 +4017,168 @@
 void ata_sg_clean(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
-	struct scatterlist *sg = qc->sg;
+	struct scatterlist *sg = qc->__sg;
 	int dir = qc->dma_dir;
+	void *pad_buf = NULL;
 
-	WARN_ON_ONCE(sg == NULL);
+	WARN_ON(!(qc->flags & ATA_QCFLAG_DMAMAP));
+	WARN_ON(sg == NULL);
+
+	if (qc->flags & ATA_QCFLAG_SINGLE)
+		WARN_ON(qc->n_elem > 1);
 
 	VPRINTK("unmapping %u sg elements\n", qc->n_elem);
 
-	if (qc->n_elem)
-		dma_unmap_sg(ap->dev, sg, qc->orig_n_elem, dir);
+	/* if we padded the buffer out to 32-bit bound, and data
+	 * xfer direction is from-device, we must copy from the
+	 * pad buffer back into the supplied buffer
+	 */
+	if (qc->pad_len && !(qc->tf.flags & ATA_TFLAG_WRITE))
+		pad_buf = ap->pad + (qc->tag * ATA_DMA_PAD_SZ);
+
+	if (qc->flags & ATA_QCFLAG_SG) {
+		if (qc->n_elem)
+			dma_unmap_sg(ap->dev, sg, qc->n_elem, dir);
+		/* restore last sg */
+		sg[qc->orig_n_elem - 1].length += qc->pad_len;
+		if (pad_buf) {
+			struct scatterlist *psg = &qc->pad_sgent;
+			void *addr = kmap_atomic(sg_page(psg), KM_IRQ0);
+			memcpy(addr + psg->offset, pad_buf, qc->pad_len);
+			kunmap_atomic(addr, KM_IRQ0);
+		}
+	} else {
+		if (qc->n_elem)
+			dma_unmap_single(ap->dev,
+				sg_dma_address(&sg[0]), sg_dma_len(&sg[0]),
+				dir);
+		/* restore sg */
+		sg->length += qc->pad_len;
+		if (pad_buf)
+			memcpy(qc->buf_virt + sg->length - qc->pad_len,
+			       pad_buf, qc->pad_len);
+	}
 
 	qc->flags &= ~ATA_QCFLAG_DMAMAP;
-	qc->sg = NULL;
+	qc->__sg = NULL;
+}
+
+/**
+ *	ata_fill_sg - Fill PCI IDE PRD table
+ *	@qc: Metadata associated with taskfile to be transferred
+ *
+ *	Fill PCI IDE PRD (scatter-gather) table with segments
+ *	associated with the current disk command.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ */
+static void ata_fill_sg(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	struct scatterlist *sg;
+	unsigned int idx;
+
+	WARN_ON(qc->__sg == NULL);
+	WARN_ON(qc->n_elem == 0 && qc->pad_len == 0);
+
+	idx = 0;
+	ata_for_each_sg(sg, qc) {
+		u32 addr, offset;
+		u32 sg_len, len;
+
+		/* determine if physical DMA addr spans 64K boundary.
+		 * Note h/w doesn't support 64-bit, so we unconditionally
+		 * truncate dma_addr_t to u32.
+		 */
+		addr = (u32) sg_dma_address(sg);
+		sg_len = sg_dma_len(sg);
+
+		while (sg_len) {
+			offset = addr & 0xffff;
+			len = sg_len;
+			if ((offset + sg_len) > 0x10000)
+				len = 0x10000 - offset;
+
+			ap->prd[idx].addr = cpu_to_le32(addr);
+			ap->prd[idx].flags_len = cpu_to_le32(len & 0xffff);
+			VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", idx, addr, len);
+
+			idx++;
+			sg_len -= len;
+			addr += len;
+		}
+	}
+
+	if (idx)
+		ap->prd[idx - 1].flags_len |= cpu_to_le32(ATA_PRD_EOT);
+}
+
+/**
+ *	ata_fill_sg_dumb - Fill PCI IDE PRD table
+ *	@qc: Metadata associated with taskfile to be transferred
+ *
+ *	Fill PCI IDE PRD (scatter-gather) table with segments
+ *	associated with the current disk command. Perform the fill
+ *	so that we avoid writing any length 64K records for
+ *	controllers that don't follow the spec.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ */
+static void ata_fill_sg_dumb(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	struct scatterlist *sg;
+	unsigned int idx;
+
+	WARN_ON(qc->__sg == NULL);
+	WARN_ON(qc->n_elem == 0 && qc->pad_len == 0);
+
+	idx = 0;
+	ata_for_each_sg(sg, qc) {
+		u32 addr, offset;
+		u32 sg_len, len, blen;
+
+ 		/* determine if physical DMA addr spans 64K boundary.
+		 * Note h/w doesn't support 64-bit, so we unconditionally
+		 * truncate dma_addr_t to u32.
+		 */
+		addr = (u32) sg_dma_address(sg);
+		sg_len = sg_dma_len(sg);
+
+		while (sg_len) {
+			offset = addr & 0xffff;
+			len = sg_len;
+			if ((offset + sg_len) > 0x10000)
+				len = 0x10000 - offset;
+
+			blen = len & 0xffff;
+			ap->prd[idx].addr = cpu_to_le32(addr);
+			if (blen == 0) {
+			   /* Some PATA chipsets like the CS5530 can't
+			      cope with 0x0000 meaning 64K as the spec says */
+				ap->prd[idx].flags_len = cpu_to_le32(0x8000);
+				blen = 0x8000;
+				ap->prd[++idx].addr = cpu_to_le32(addr + 0x8000);
+			}
+			ap->prd[idx].flags_len = cpu_to_le32(blen);
+			VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", idx, addr, len);
+
+			idx++;
+			sg_len -= len;
+			addr += len;
+		}
+	}
+
+	if (idx)
+		ap->prd[idx - 1].flags_len |= cpu_to_le32(ATA_PRD_EOT);
 }
 
 /**
- *	atapi_check_dma - Check whether ATAPI DMA can be supported
+ *	ata_check_atapi_dma - Check whether ATAPI DMA can be supported
  *	@qc: Metadata associated with taskfile to check
  *
  *	Allow low-level driver to filter ATA PACKET commands, returning
@@ -4760,15 +4191,14 @@
  *	RETURNS: 0 when ATAPI DMA can be used
  *               nonzero otherwise
  */
-int atapi_check_dma(struct ata_queued_cmd *qc)
+int ata_check_atapi_dma(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 
 	/* Don't allow DMA if it isn't multiple of 16 bytes.  Quite a
 	 * few ATAPI devices choke on such DMA requests.
 	 */
-	if (!(qc->dev->horkage & ATA_HORKAGE_ATAPI_MOD16_DMA) &&
-	    unlikely(qc->nbytes & 15))
+	if (unlikely(qc->nbytes & 15))
 		return 1;
 
 	if (ap->ops->check_atapi_dma)
@@ -4778,38 +4208,68 @@
 }
 
 /**
- *	ata_std_qc_defer - Check whether a qc needs to be deferred
- *	@qc: ATA command in question
+ *	ata_qc_prep - Prepare taskfile for submission
+ *	@qc: Metadata associated with taskfile to be prepared
  *
- *	Non-NCQ commands cannot run with any other command, NCQ or
- *	not.  As upper layer only knows the queue depth, we are
- *	responsible for maintaining exclusion.  This function checks
- *	whether a new command @qc can be issued.
+ *	Prepare ATA taskfile for submission.
  *
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
- *
- *	RETURNS:
- *	ATA_DEFER_* if deferring is needed, 0 otherwise.
  */
-int ata_std_qc_defer(struct ata_queued_cmd *qc)
+void ata_qc_prep(struct ata_queued_cmd *qc)
 {
-	struct ata_link *link = qc->dev->link;
+	if (!(qc->flags & ATA_QCFLAG_DMAMAP))
+		return;
 
-	if (qc->tf.protocol == ATA_PROT_NCQ) {
-		if (!ata_tag_valid(link->active_tag))
-			return 0;
-	} else {
-		if (!ata_tag_valid(link->active_tag) && !link->sactive)
-			return 0;
-	}
+	ata_fill_sg(qc);
+}
+
+/**
+ *	ata_dumb_qc_prep - Prepare taskfile for submission
+ *	@qc: Metadata associated with taskfile to be prepared
+ *
+ *	Prepare ATA taskfile for submission.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ */
+void ata_dumb_qc_prep(struct ata_queued_cmd *qc)
+{
+	if (!(qc->flags & ATA_QCFLAG_DMAMAP))
+		return;
 
-	return ATA_DEFER_LINK;
+	ata_fill_sg_dumb(qc);
 }
 
 void ata_noop_qc_prep(struct ata_queued_cmd *qc) { }
 
 /**
+ *	ata_sg_init_one - Associate command with memory buffer
+ *	@qc: Command to be associated
+ *	@buf: Memory buffer
+ *	@buflen: Length of memory buffer, in bytes.
+ *
+ *	Initialize the data-related elements of queued_cmd @qc
+ *	to point to a single memory buffer, @buf of byte length @buflen.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ */
+
+void ata_sg_init_one(struct ata_queued_cmd *qc, void *buf, unsigned int buflen)
+{
+	qc->flags |= ATA_QCFLAG_SINGLE;
+
+	qc->__sg = &qc->sgent;
+	qc->n_elem = 1;
+	qc->orig_n_elem = 1;
+	qc->buf_virt = buf;
+	qc->nbytes = buflen;
+
+	sg_init_one(&qc->sgent, buf, buflen);
+}
+
+/**
  *	ata_sg_init - Associate command with scatter-gather table.
  *	@qc: Command to be associated
  *	@sg: Scatter-gather table.
@@ -4822,12 +4282,83 @@
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
+
 void ata_sg_init(struct ata_queued_cmd *qc, struct scatterlist *sg,
 		 unsigned int n_elem)
 {
-	qc->sg = sg;
+	qc->flags |= ATA_QCFLAG_SG;
+	qc->__sg = sg;
 	qc->n_elem = n_elem;
-	qc->cursg = qc->sg;
+	qc->orig_n_elem = n_elem;
+}
+
+/**
+ *	ata_sg_setup_one - DMA-map the memory buffer associated with a command.
+ *	@qc: Command with memory buffer to be mapped.
+ *
+ *	DMA-map the memory buffer associated with queued_cmd @qc.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ *	RETURNS:
+ *	Zero on success, negative on error.
+ */
+
+static int ata_sg_setup_one(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	int dir = qc->dma_dir;
+	struct scatterlist *sg = qc->__sg;
+	dma_addr_t dma_address;
+	int trim_sg = 0;
+
+	/* we must lengthen transfers to end on a 32-bit boundary */
+	qc->pad_len = sg->length & 3;
+	if (qc->pad_len) {
+		void *pad_buf = ap->pad + (qc->tag * ATA_DMA_PAD_SZ);
+		struct scatterlist *psg = &qc->pad_sgent;
+
+		WARN_ON(qc->dev->class != ATA_DEV_ATAPI);
+
+		memset(pad_buf, 0, ATA_DMA_PAD_SZ);
+
+		if (qc->tf.flags & ATA_TFLAG_WRITE)
+			memcpy(pad_buf, qc->buf_virt + sg->length - qc->pad_len,
+			       qc->pad_len);
+
+		sg_dma_address(psg) = ap->pad_dma + (qc->tag * ATA_DMA_PAD_SZ);
+		sg_dma_len(psg) = ATA_DMA_PAD_SZ;
+		/* trim sg */
+		sg->length -= qc->pad_len;
+		if (sg->length == 0)
+			trim_sg = 1;
+
+		DPRINTK("padding done, sg->length=%u pad_len=%u\n",
+			sg->length, qc->pad_len);
+	}
+
+	if (trim_sg) {
+		qc->n_elem--;
+		goto skip_map;
+	}
+
+	dma_address = dma_map_single(ap->dev, qc->buf_virt,
+				     sg->length, dir);
+	if (dma_address == 0) {    // Oxygen-1 -> equals dma_mapping_error
+		/* restore sg */
+		sg->length += qc->pad_len;
+		return -1;
+	}
+
+	sg_dma_address(sg) = dma_address;
+	sg_dma_len(sg) = sg->length;
+
+skip_map:
+	DPRINTK("mapped buffer of %d bytes for %s\n", sg_dma_len(sg),
+		qc->tf.flags & ATA_TFLAG_WRITE ? "write" : "read");
+
+	return 0;
 }
 
 /**
@@ -4843,21 +4374,74 @@
  *	Zero on success, negative on error.
  *
  */
+
 static int ata_sg_setup(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
-	unsigned int n_elem;
+	struct scatterlist *sg = qc->__sg;
+	struct scatterlist *lsg = &sg[qc->n_elem - 1];
+	int n_elem, pre_n_elem, dir, trim_sg = 0;
 
 	VPRINTK("ENTER, ata%u\n", ap->print_id);
+	WARN_ON(!(qc->flags & ATA_QCFLAG_SG));
+
+	/* we must lengthen transfers to end on a 32-bit boundary */
+	qc->pad_len = lsg->length & 3;
+	if (qc->pad_len) {
+		void *pad_buf = ap->pad + (qc->tag * ATA_DMA_PAD_SZ);
+		struct scatterlist *psg = &qc->pad_sgent;
+		unsigned int offset;
+
+		WARN_ON(qc->dev->class != ATA_DEV_ATAPI);
+
+		memset(pad_buf, 0, ATA_DMA_PAD_SZ);
+
+		/*
+		 * psg->page/offset are used to copy to-be-written
+		 * data in this function or read data in ata_sg_clean.
+		 */
+		offset = lsg->offset + lsg->length - qc->pad_len;
+		sg_assign_page(psg,  nth_page(sg_page(lsg), offset >> PAGE_SHIFT));
+		psg->offset = offset_in_page(offset);
+
+		if (qc->tf.flags & ATA_TFLAG_WRITE) {
+			void *addr = kmap_atomic(sg_page(psg), KM_IRQ0);
+			memcpy(pad_buf, addr + psg->offset, qc->pad_len);
+			kunmap_atomic(addr, KM_IRQ0);
+		}
+
+		sg_dma_address(psg) = ap->pad_dma + (qc->tag * ATA_DMA_PAD_SZ);
+		sg_dma_len(psg) = ATA_DMA_PAD_SZ;
+		/* trim last sg */
+		lsg->length -= qc->pad_len;
+		if (lsg->length == 0)
+			trim_sg = 1;
+
+		DPRINTK("padding done, sg[%d].length=%u pad_len=%u\n",
+			qc->n_elem - 1, lsg->length, qc->pad_len);
+	}
+
+	pre_n_elem = qc->n_elem;
+	if (trim_sg && pre_n_elem)
+		pre_n_elem--;
+
+	if (!pre_n_elem) {
+		n_elem = 0;
+		goto skip_map;
+	}
 
-	n_elem = dma_map_sg(ap->dev, qc->sg, qc->n_elem, qc->dma_dir);
-	if (n_elem < 1)
+	dir = qc->dma_dir;
+	n_elem = dma_map_sg(ap->dev, sg, pre_n_elem, dir);
+	if (n_elem < 1) {
+		/* restore last sg */
+		lsg->length += qc->pad_len;
 		return -1;
+	}
 
 	DPRINTK("%d sg elements mapped\n", n_elem);
-	qc->orig_n_elem = qc->n_elem;
+
+skip_map:
 	qc->n_elem = n_elem;
-	qc->flags |= ATA_QCFLAG_DMAMAP;
 
 	return 0;
 }
@@ -4885,113 +4469,781 @@
 }
 
 /**
- *	ata_qc_new - Request an available ATA command, for queueing
- *	@ap: target port
+ *	ata_data_xfer - Transfer data by PIO
+ *	@adev: device to target
+ *	@buf: data buffer
+ *	@buflen: buffer length
+ *	@write_data: read/write
+ *
+ *	Transfer data from/to the device data register by PIO.
  *
  *	LOCKING:
- *	None.
+ *	Inherited from caller.
  */
-
-static struct ata_queued_cmd *ata_qc_new(struct ata_port *ap)
+void ata_data_xfer(struct ata_device *adev, unsigned char *buf,
+		   unsigned int buflen, int write_data)
 {
-	struct ata_queued_cmd *qc = NULL;
-	unsigned int i;
+	struct ata_port *ap = adev->ap;
+	unsigned int words = buflen >> 1;
 
-	/* no command while frozen */
-	if (unlikely(ap->pflags & ATA_PFLAG_FROZEN))
-		return NULL;
+	/* Transfer multiple of 2 bytes */
+	if (write_data)
+		iowrite16_rep(ap->ioaddr.data_addr, buf, words);
+	else
+		ioread16_rep(ap->ioaddr.data_addr, buf, words);
 
-	/* the last tag is reserved for internal command. */
-	for (i = 0; i < ATA_MAX_QUEUE - 1; i++)
-		if (!test_and_set_bit(i, &ap->qc_allocated)) {
-			qc = __ata_qc_from_tag(ap, i);
-			break;
+	/* Transfer trailing 1 byte, if any. */
+	if (unlikely(buflen & 0x01)) {
+		u16 align_buf[1] = { 0 };
+		unsigned char *trailing_buf = buf + buflen - 1;
+
+		if (write_data) {
+			memcpy(align_buf, trailing_buf, 1);
+			iowrite16(le16_to_cpu(align_buf[0]), ap->ioaddr.data_addr);
+		} else {
+			align_buf[0] = cpu_to_le16(ioread16(ap->ioaddr.data_addr));
+			memcpy(trailing_buf, align_buf, 1);
 		}
-
-	if (qc)
-		qc->tag = i;
-
-	return qc;
+	}
 }
 
 /**
- *	ata_qc_new_init - Request an available ATA command, and initialize it
- *	@dev: Device from whom we request an available command structure
+ *	ata_data_xfer_noirq - Transfer data by PIO
+ *	@adev: device to target
+ *	@buf: data buffer
+ *	@buflen: buffer length
+ *	@write_data: read/write
+ *
+ *	Transfer data from/to the device data register by PIO. Do the
+ *	transfer with interrupts disabled.
  *
  *	LOCKING:
- *	None.
+ *	Inherited from caller.
  */
-
-struct ata_queued_cmd *ata_qc_new_init(struct ata_device *dev)
+void ata_data_xfer_noirq(struct ata_device *adev, unsigned char *buf,
+			 unsigned int buflen, int write_data)
 {
-	struct ata_port *ap = dev->link->ap;
-	struct ata_queued_cmd *qc;
-
-	qc = ata_qc_new(ap);
-	if (qc) {
-		qc->scsicmd = NULL;
-		qc->ap = ap;
-		qc->dev = dev;
-
-		ata_qc_reinit(qc);
-	}
-
-	return qc;
+	unsigned long flags;
+	local_irq_save(flags);
+	ata_data_xfer(adev, buf, buflen, write_data);
+	local_irq_restore(flags);
 }
 
+
 /**
- *	ata_qc_free - free unused ata_queued_cmd
- *	@qc: Command to complete
+ *	ata_pio_sector - Transfer a sector of data.
+ *	@qc: Command on going
  *
- *	Designed to free unused ata_queued_cmd object
- *	in case something prevents using it.
+ *	Transfer qc->sect_size bytes of data from/to the ATA device.
  *
  *	LOCKING:
- *	spin_lock_irqsave(host lock)
+ *	Inherited from caller.
  */
-void ata_qc_free(struct ata_queued_cmd *qc)
+
+static void ata_pio_sector(struct ata_queued_cmd *qc)
 {
-	struct ata_port *ap;
-	unsigned int tag;
+	int do_write = (qc->tf.flags & ATA_TFLAG_WRITE);
+	struct scatterlist *sg = qc->__sg;
+	struct ata_port *ap = qc->ap;
+	struct page *page;
+	unsigned int offset;
+	unsigned char *buf;
 
-	WARN_ON_ONCE(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
-	ap = qc->ap;
+	if (qc->curbytes == qc->nbytes - qc->sect_size)
+		ap->hsm_task_state = HSM_ST_LAST;
 
-	qc->flags = 0;
-	tag = qc->tag;
-	if (likely(ata_tag_valid(tag))) {
-		qc->tag = ATA_TAG_POISON;
-		clear_bit(tag, &ap->qc_allocated);
+	page = sg_page(&sg[qc->cursg]);
+	offset = sg[qc->cursg].offset + qc->cursg_ofs;
+
+	/* get the current page and offset */
+	page = nth_page(page, (offset >> PAGE_SHIFT));
+	offset %= PAGE_SIZE;
+
+	DPRINTK("data %s\n", qc->tf.flags & ATA_TFLAG_WRITE ? "write" : "read");
+
+	if (PageHighMem(page)) {
+		unsigned long flags;
+
+		/* FIXME: use a bounce buffer */
+		local_irq_save(flags);
+		buf = kmap_atomic(page, KM_IRQ0);
+
+		/* do the actual data transfer */
+		ap->ops->data_xfer(qc->dev, buf + offset, qc->sect_size, do_write);
+
+		kunmap_atomic(buf, KM_IRQ0);
+		local_irq_restore(flags);
+	} else {
+		buf = page_address(page);
+		ap->ops->data_xfer(qc->dev, buf + offset, qc->sect_size, do_write);
+	}
+
+	qc->curbytes += qc->sect_size;
+	qc->cursg_ofs += qc->sect_size;
+
+	if (qc->cursg_ofs == (&sg[qc->cursg])->length) {
+		qc->cursg++;
+		qc->cursg_ofs = 0;
+	}
+}
+
+/**
+ *	ata_pio_sectors - Transfer one or many sectors.
+ *	@qc: Command on going
+ *
+ *	Transfer one or many sectors of data from/to the
+ *	ATA device for the DRQ request.
+ *
+ *	LOCKING:
+ *	Inherited from caller.
+ */
+
+static void ata_pio_sectors(struct ata_queued_cmd *qc)
+{
+	if (is_multi_taskfile(&qc->tf)) {
+		/* READ/WRITE MULTIPLE */
+		unsigned int nsect;
+
+		WARN_ON(qc->dev->multi_count == 0);
+
+		nsect = min((qc->nbytes - qc->curbytes) / qc->sect_size,
+			    qc->dev->multi_count);
+		while (nsect--)
+			ata_pio_sector(qc);
+	} else
+		ata_pio_sector(qc);
+}
+
+/**
+ *	atapi_send_cdb - Write CDB bytes to hardware
+ *	@ap: Port to which ATAPI device is attached.
+ *	@qc: Taskfile currently active
+ *
+ *	When device has indicated its readiness to accept
+ *	a CDB, this function is called.  Send the CDB.
+ *
+ *	LOCKING:
+ *	caller.
+ */
+
+static void atapi_send_cdb(struct ata_port *ap, struct ata_queued_cmd *qc)
+{
+	/* send SCSI cdb */
+	DPRINTK("send cdb\n");
+	WARN_ON(qc->dev->cdb_len < 12);
+
+	ap->ops->data_xfer(qc->dev, qc->cdb, qc->dev->cdb_len, 1);
+	ata_altstatus(ap); /* flush */
+
+	switch (qc->tf.protocol) {
+	case ATA_PROT_ATAPI:
+		ap->hsm_task_state = HSM_ST;
+		break;
+	case ATA_PROT_ATAPI_NODATA:
+		ap->hsm_task_state = HSM_ST_LAST;
+		break;
+	case ATA_PROT_ATAPI_DMA:
+		ap->hsm_task_state = HSM_ST_LAST;
+		/* initiate bmdma */
+		ap->ops->bmdma_start(qc);
+		break;
+	}
+}
+
+/**
+ *	__atapi_pio_bytes - Transfer data from/to the ATAPI device.
+ *	@qc: Command on going
+ *	@bytes: number of bytes
+ *
+ *	Transfer Transfer data from/to the ATAPI device.
+ *
+ *	LOCKING:
+ *	Inherited from caller.
+ *
+ */
+
+static void __atapi_pio_bytes(struct ata_queued_cmd *qc, unsigned int bytes)
+{
+	int do_write = (qc->tf.flags & ATA_TFLAG_WRITE);
+	struct scatterlist *sg = qc->__sg;
+	struct ata_port *ap = qc->ap;
+	struct page *page;
+	unsigned char *buf;
+	unsigned int offset, count;
+
+	if (qc->curbytes + bytes >= qc->nbytes)
+		ap->hsm_task_state = HSM_ST_LAST;
+
+next_sg:
+	if (unlikely(qc->cursg >= qc->n_elem)) {
+		/*
+		 * The end of qc->sg is reached and the device expects
+		 * more data to transfer. In order not to overrun qc->sg
+		 * and fulfill length specified in the byte count register,
+		 *    - for read case, discard trailing data from the device
+		 *    - for write case, padding zero data to the device
+		 */
+		u16 pad_buf[1] = { 0 };
+		unsigned int words = bytes >> 1;
+		unsigned int i;
+
+		if (words) /* warning if bytes > 1 */
+			ata_dev_printk(qc->dev, KERN_WARNING,
+				       "%u bytes trailing data\n", bytes);
+
+		for (i = 0; i < words; i++)
+			ap->ops->data_xfer(qc->dev, (unsigned char*)pad_buf, 2, do_write);
+
+		ap->hsm_task_state = HSM_ST_LAST;
+		return;
+	}
+
+	sg = &qc->__sg[qc->cursg];
+
+	page = sg_page(sg);
+	offset = sg->offset + qc->cursg_ofs;
+
+	/* get the current page and offset */
+	page = nth_page(page, (offset >> PAGE_SHIFT));
+	offset %= PAGE_SIZE;
+
+	/* don't overrun current sg */
+	count = min(sg->length - qc->cursg_ofs, bytes);
+
+	/* don't cross page boundaries */
+	count = min(count, (unsigned int)PAGE_SIZE - offset);
+
+	DPRINTK("data %s\n", qc->tf.flags & ATA_TFLAG_WRITE ? "write" : "read");
+
+	if (PageHighMem(page)) {
+		unsigned long flags;
+
+		/* FIXME: use bounce buffer */
+		local_irq_save(flags);
+		buf = kmap_atomic(page, KM_IRQ0);
+
+		/* do the actual data transfer */
+		ap->ops->data_xfer(qc->dev,  buf + offset, count, do_write);
+
+		kunmap_atomic(buf, KM_IRQ0);
+		local_irq_restore(flags);
+	} else {
+		buf = page_address(page);
+		ap->ops->data_xfer(qc->dev,  buf + offset, count, do_write);
+	}
+
+	bytes -= count;
+	qc->curbytes += count;
+	qc->cursg_ofs += count;
+
+	if (qc->cursg_ofs == sg->length) {
+		qc->cursg++;
+		qc->cursg_ofs = 0;
+	}
+
+	if (bytes)
+		goto next_sg;
+}
+
+/**
+ *	atapi_pio_bytes - Transfer data from/to the ATAPI device.
+ *	@qc: Command on going
+ *
+ *	Transfer Transfer data from/to the ATAPI device.
+ *
+ *	LOCKING:
+ *	Inherited from caller.
+ */
+
+static void atapi_pio_bytes(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	struct ata_device *dev = qc->dev;
+	unsigned int ireason, bc_lo, bc_hi, bytes;
+	int i_write, do_write = (qc->tf.flags & ATA_TFLAG_WRITE) ? 1 : 0;
+
+	/* Abuse qc->result_tf for temp storage of intermediate TF
+	 * here to save some kernel stack usage.
+	 * For normal completion, qc->result_tf is not relevant. For
+	 * error, qc->result_tf is later overwritten by ata_qc_complete().
+	 * So, the correctness of qc->result_tf is not affected.
+	 */
+	ap->ops->tf_read(ap, &qc->result_tf);
+	ireason = qc->result_tf.nsect;
+	bc_lo = qc->result_tf.lbam;
+	bc_hi = qc->result_tf.lbah;
+	bytes = (bc_hi << 8) | bc_lo;
+
+	/* shall be cleared to zero, indicating xfer of data */
+	if (ireason & (1 << 0))
+		goto err_out;
+
+	/* make sure transfer direction matches expected */
+	i_write = ((ireason & (1 << 1)) == 0) ? 1 : 0;
+	if (do_write != i_write)
+		goto err_out;
+
+	VPRINTK("ata%u: xfering %d bytes\n", ap->print_id, bytes);
+
+	__atapi_pio_bytes(qc, bytes);
+
+	return;
+
+err_out:
+	ata_dev_printk(dev, KERN_INFO, "ATAPI check failed\n");
+	qc->err_mask |= AC_ERR_HSM;
+	ap->hsm_task_state = HSM_ST_ERR;
+}
+
+/**
+ *	ata_hsm_ok_in_wq - Check if the qc can be handled in the workqueue.
+ *	@ap: the target ata_port
+ *	@qc: qc on going
+ *
+ *	RETURNS:
+ *	1 if ok in workqueue, 0 otherwise.
+ */
+
+static inline int ata_hsm_ok_in_wq(struct ata_port *ap, struct ata_queued_cmd *qc)
+{
+	if (qc->tf.flags & ATA_TFLAG_POLLING)
+		return 1;
+
+	if (ap->hsm_task_state == HSM_ST_FIRST) {
+		if (qc->tf.protocol == ATA_PROT_PIO &&
+		    (qc->tf.flags & ATA_TFLAG_WRITE))
+		    return 1;
+
+		if (is_atapi_taskfile(&qc->tf) &&
+		    !(qc->dev->flags & ATA_DFLAG_CDB_INTR))
+			return 1;
+	}
+
+	return 0;
+}
+
+/**
+ *	ata_hsm_qc_complete - finish a qc running on standard HSM
+ *	@qc: Command to complete
+ *	@in_wq: 1 if called from workqueue, 0 otherwise
+ *
+ *	Finish @qc which is running on standard HSM.
+ *
+ *	LOCKING:
+ *	If @in_wq is zero, spin_lock_irqsave(host lock).
+ *	Otherwise, none on entry and grabs host lock.
+ */
+static void ata_hsm_qc_complete(struct ata_queued_cmd *qc, int in_wq)
+{
+	struct ata_port *ap = qc->ap;
+	unsigned long flags;
+
+	if (ap->ops->error_handler) {
+		if (in_wq) {
+			spin_lock_irqsave(ap->lock, flags);
+
+			/* EH might have kicked in while host lock is
+			 * released.
+			 */
+			qc = ata_qc_from_tag(ap, qc->tag);
+			if (qc) {
+				if (likely(!(qc->err_mask & AC_ERR_HSM))) {
+					ap->ops->irq_on(ap);
+					ata_qc_complete(qc);
+				} else
+					ata_port_freeze(ap);
+			}
+
+			spin_unlock_irqrestore(ap->lock, flags);
+		} else {
+			if (likely(!(qc->err_mask & AC_ERR_HSM)))
+				ata_qc_complete(qc);
+			else
+				ata_port_freeze(ap);
+		}
+	} else {
+		if (in_wq) {
+			spin_lock_irqsave(ap->lock, flags);
+			ap->ops->irq_on(ap);
+			ata_qc_complete(qc);
+			spin_unlock_irqrestore(ap->lock, flags);
+		} else
+			ata_qc_complete(qc);
+	}
+}
+
+/**
+ *	ata_hsm_move - move the HSM to the next state.
+ *	@ap: the target ata_port
+ *	@qc: qc on going
+ *	@status: current device status
+ *	@in_wq: 1 if called from workqueue, 0 otherwise
+ *
+ *	RETURNS:
+ *	1 when poll next status needed, 0 otherwise.
+ */
+int ata_hsm_move(struct ata_port *ap, struct ata_queued_cmd *qc,
+		 u8 status, int in_wq)
+{
+	unsigned long flags = 0;
+	int poll_next;
+
+	WARN_ON((qc->flags & ATA_QCFLAG_ACTIVE) == 0);
+
+	/* Make sure ata_qc_issue_prot() does not throw things
+	 * like DMA polling into the workqueue. Notice that
+	 * in_wq is not equivalent to (qc->tf.flags & ATA_TFLAG_POLLING).
+	 */
+	WARN_ON(in_wq != ata_hsm_ok_in_wq(ap, qc));
+
+fsm_start:
+	DPRINTK("ata%u: protocol %d task_state %d (dev_stat 0x%X)\n",
+		ap->print_id, qc->tf.protocol, ap->hsm_task_state, status);
+
+	switch (ap->hsm_task_state) {
+	case HSM_ST_FIRST:
+		/* Send first data block or PACKET CDB */
+
+		/* If polling, we will stay in the work queue after
+		 * sending the data. Otherwise, interrupt handler
+		 * takes over after sending the data.
+		 */
+		poll_next = (qc->tf.flags & ATA_TFLAG_POLLING);
+
+		/* check device status */
+		if (unlikely((status & ATA_DRQ) == 0)) {
+			/* handle BSY=0, DRQ=0 as error */
+			if (likely(status & (ATA_ERR | ATA_DF)))
+				/* device stops HSM for abort/error */
+				qc->err_mask |= AC_ERR_DEV;
+			else
+				/* HSM violation. Let EH handle this */
+				qc->err_mask |= AC_ERR_HSM;
+
+			ap->hsm_task_state = HSM_ST_ERR;
+			goto fsm_start;
+		}
+
+		/* Device should not ask for data transfer (DRQ=1)
+		 * when it finds something wrong.
+		 * We ignore DRQ here and stop the HSM by
+		 * changing hsm_task_state to HSM_ST_ERR and
+		 * let the EH abort the command or reset the device.
+		 */
+		if (unlikely(status & (ATA_ERR | ATA_DF))) {
+			ata_port_printk(ap, KERN_WARNING, "DRQ=1 with device "
+					"error, dev_stat 0x%X\n", status);
+			qc->err_mask |= AC_ERR_HSM;
+			ap->hsm_task_state = HSM_ST_ERR;
+			goto fsm_start;
+		}
+
+		/* Send the CDB (atapi) or the first data block (ata pio out).
+		 * During the state transition, interrupt handler shouldn't
+		 * be invoked before the data transfer is complete and
+		 * hsm_task_state is changed. Hence, the following locking.
+		 */
+		if (in_wq)
+			spin_lock_irqsave(ap->lock, flags);
+
+		if (qc->tf.protocol == ATA_PROT_PIO) {
+			/* PIO data out protocol.
+			 * send first data block.
+			 */
+
+			/* ata_pio_sectors() might change the state
+			 * to HSM_ST_LAST. so, the state is changed here
+			 * before ata_pio_sectors().
+			 */
+			ap->hsm_task_state = HSM_ST;
+			ata_pio_sectors(qc);
+			ata_altstatus(ap); /* flush */
+		} else
+			/* send CDB */
+			atapi_send_cdb(ap, qc);
+
+		if (in_wq)
+			spin_unlock_irqrestore(ap->lock, flags);
+
+		/* if polling, ata_pio_task() handles the rest.
+		 * otherwise, interrupt handler takes over from here.
+		 */
+		break;
+
+	case HSM_ST:
+		/* complete command or read/write the data register */
+		if (qc->tf.protocol == ATA_PROT_ATAPI) {
+			/* ATAPI PIO protocol */
+			if ((status & ATA_DRQ) == 0) {
+				/* No more data to transfer or device error.
+				 * Device error will be tagged in HSM_ST_LAST.
+				 */
+				ap->hsm_task_state = HSM_ST_LAST;
+				goto fsm_start;
+			}
+
+			/* Device should not ask for data transfer (DRQ=1)
+			 * when it finds something wrong.
+			 * We ignore DRQ here and stop the HSM by
+			 * changing hsm_task_state to HSM_ST_ERR and
+			 * let the EH abort the command or reset the device.
+			 */
+			if (unlikely(status & (ATA_ERR | ATA_DF))) {
+				ata_port_printk(ap, KERN_WARNING, "DRQ=1 with "
+						"device error, dev_stat 0x%X\n",
+						status);
+				qc->err_mask |= AC_ERR_HSM;
+				ap->hsm_task_state = HSM_ST_ERR;
+				goto fsm_start;
+			}
+
+			atapi_pio_bytes(qc);
+
+			if (unlikely(ap->hsm_task_state == HSM_ST_ERR))
+				/* bad ireason reported by device */
+				goto fsm_start;
+
+		} else {
+			/* ATA PIO protocol */
+			if (unlikely((status & ATA_DRQ) == 0)) {
+				/* handle BSY=0, DRQ=0 as error */
+				if (likely(status & (ATA_ERR | ATA_DF)))
+					/* device stops HSM for abort/error */
+					qc->err_mask |= AC_ERR_DEV;
+				else
+					/* HSM violation. Let EH handle this.
+					 * Phantom devices also trigger this
+					 * condition.  Mark hint.
+					 */
+					qc->err_mask |= AC_ERR_HSM |
+							AC_ERR_NODEV_HINT;
+
+				ap->hsm_task_state = HSM_ST_ERR;
+				goto fsm_start;
+			}
+
+			/* For PIO reads, some devices may ask for
+			 * data transfer (DRQ=1) alone with ERR=1.
+			 * We respect DRQ here and transfer one
+			 * block of junk data before changing the
+			 * hsm_task_state to HSM_ST_ERR.
+			 *
+			 * For PIO writes, ERR=1 DRQ=1 doesn't make
+			 * sense since the data block has been
+			 * transferred to the device.
+			 */
+			if (unlikely(status & (ATA_ERR | ATA_DF))) {
+				/* data might be corrputed */
+				qc->err_mask |= AC_ERR_DEV;
+
+				if (!(qc->tf.flags & ATA_TFLAG_WRITE)) {
+					ata_pio_sectors(qc);
+					ata_altstatus(ap);
+					status = ata_wait_idle(ap);
+				}
+
+				if (status & (ATA_BUSY | ATA_DRQ))
+					qc->err_mask |= AC_ERR_HSM;
+
+				/* ata_pio_sectors() might change the
+				 * state to HSM_ST_LAST. so, the state
+				 * is changed after ata_pio_sectors().
+				 */
+				ap->hsm_task_state = HSM_ST_ERR;
+				goto fsm_start;
+			}
+
+			ata_pio_sectors(qc);
+
+			if (ap->hsm_task_state == HSM_ST_LAST &&
+			    (!(qc->tf.flags & ATA_TFLAG_WRITE))) {
+				/* all data read */
+				ata_altstatus(ap);
+				status = ata_wait_idle(ap);
+				goto fsm_start;
+			}
+		}
+
+		ata_altstatus(ap); /* flush */
+		poll_next = 1;
+		break;
+
+	case HSM_ST_LAST:
+		if (unlikely(!ata_ok(status))) {
+			qc->err_mask |= __ac_err_mask(status);
+			ap->hsm_task_state = HSM_ST_ERR;
+			goto fsm_start;
+		}
+
+		/* no more data to transfer */
+		DPRINTK("ata%u: dev %u command complete, drv_stat 0x%x\n",
+			ap->print_id, qc->dev->devno, status);
+
+		WARN_ON(qc->err_mask);
+
+		ap->hsm_task_state = HSM_ST_IDLE;
+
+		/* complete taskfile transaction */
+		ata_hsm_qc_complete(qc, in_wq);
+
+		poll_next = 0;
+		break;
+
+	case HSM_ST_ERR:
+		/* make sure qc->err_mask is available to
+		 * know what's wrong and recover
+		 */
+		WARN_ON(qc->err_mask == 0);
+
+		ap->hsm_task_state = HSM_ST_IDLE;
+
+		/* complete taskfile transaction */
+		ata_hsm_qc_complete(qc, in_wq);
+
+		poll_next = 0;
+		break;
+	default:
+		poll_next = 0;
+		BUG();
+	}
+
+	return poll_next;
+}
+
+static void ata_pio_task(struct work_struct *work)
+{
+	struct ata_port *ap =
+		container_of(work, struct ata_port, port_task.work);
+	struct ata_queued_cmd *qc = ap->port_task_data;
+	u8 status;
+	int poll_next;
+
+fsm_start:
+	WARN_ON(ap->hsm_task_state == HSM_ST_IDLE);
+
+	/*
+	 * This is purely heuristic.  This is a fast path.
+	 * Sometimes when we enter, BSY will be cleared in
+	 * a chk-status or two.  If not, the drive is probably seeking
+	 * or something.  Snooze for a couple msecs, then
+	 * chk-status again.  If still busy, queue delayed work.
+	 */
+	status = ata_busy_wait(ap, ATA_BUSY, 5);
+	if (status & ATA_BUSY) {
+		msleep(2);
+		status = ata_busy_wait(ap, ATA_BUSY, 10);
+		if (status & ATA_BUSY) {
+			ata_port_queue_task(ap, ata_pio_task, qc, ATA_SHORT_PAUSE);
+			return;
+		}
+	}
+
+	/* move the HSM */
+	poll_next = ata_hsm_move(ap, qc, status, 1);
+
+	/* another command or interrupt handler
+	 * may be running at this point.
+	 */
+	if (poll_next)
+		goto fsm_start;
+}
+
+/**
+ *	ata_qc_new - Request an available ATA command, for queueing
+ *	@ap: Port associated with device @dev
+ *	@dev: Device from whom we request an available command structure
+ *
+ *	LOCKING:
+ *	None.
+ */
+
+static struct ata_queued_cmd *ata_qc_new(struct ata_port *ap)
+{
+	struct ata_queued_cmd *qc = NULL;
+	unsigned int i;
+
+	/* no command while frozen */
+	if (unlikely(ap->pflags & ATA_PFLAG_FROZEN))
+		return NULL;
+
+	/* the last tag is reserved for internal command. */
+	for (i = 0; i < ATA_MAX_QUEUE - 1; i++)
+		if (!test_and_set_bit(i, &ap->qc_allocated)) {
+			qc = __ata_qc_from_tag(ap, i);
+			break;
+		}
+
+	if (qc)
+		qc->tag = i;
+
+	return qc;
+}
+
+/**
+ *	ata_qc_new_init - Request an available ATA command, and initialize it
+ *	@dev: Device from whom we request an available command structure
+ *
+ *	LOCKING:
+ *	None.
+ */
+
+struct ata_queued_cmd *ata_qc_new_init(struct ata_device *dev)
+{
+	struct ata_port *ap = dev->ap;
+	struct ata_queued_cmd *qc;
+
+	qc = ata_qc_new(ap);
+	if (qc) {
+		qc->scsicmd = NULL;
+		qc->ap = ap;
+		qc->dev = dev;
+
+		ata_qc_reinit(qc);
+	}
+
+	return qc;
+}
+
+/**
+ *	ata_qc_free - free unused ata_queued_cmd
+ *	@qc: Command to complete
+ *
+ *	Designed to free unused ata_queued_cmd object
+ *	in case something prevents using it.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ */
+void ata_qc_free(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	unsigned int tag;
+
+	WARN_ON(qc == NULL);	/* ata_qc_from_tag _might_ return NULL */
+
+	qc->flags = 0;
+	tag = qc->tag;
+	if (likely(ata_tag_valid(tag))) {
+		qc->tag = ATA_TAG_POISON;
+		clear_bit(tag, &ap->qc_allocated);
 	}
 }
 
 void __ata_qc_complete(struct ata_queued_cmd *qc)
 {
-	struct ata_port *ap;
-	struct ata_link *link;
+	struct ata_port *ap = qc->ap;
 
-	WARN_ON_ONCE(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
-	WARN_ON_ONCE(!(qc->flags & ATA_QCFLAG_ACTIVE));
-	ap = qc->ap;
-	link = qc->dev->link;
+	WARN_ON(qc == NULL);	/* ata_qc_from_tag _might_ return NULL */
+	WARN_ON(!(qc->flags & ATA_QCFLAG_ACTIVE));
 
 	if (likely(qc->flags & ATA_QCFLAG_DMAMAP))
 		ata_sg_clean(qc);
 
 	/* command should be marked inactive atomically with qc completion */
-	if (qc->tf.protocol == ATA_PROT_NCQ) {
-		link->sactive &= ~(1 << qc->tag);
-		if (!link->sactive)
-			ap->nr_active_links--;
-	} else {
-		link->active_tag = ATA_TAG_POISON;
-		ap->nr_active_links--;
-	}
-
-	/* clear exclusive status */
-	if (unlikely(qc->flags & ATA_QCFLAG_CLEAR_EXCL &&
-		     ap->excl_link == link))
-		ap->excl_link = NULL;
+	if (qc->tf.protocol == ATA_PROT_NCQ)
+		ap->sactive &= ~(1 << qc->tag);
+	else
+		ap->active_tag = ATA_TAG_POISON;
 
 	/* atapi: mark qc as inactive to prevent the interrupt handler
 	 * from completing the command twice later, before the error handler
@@ -5009,25 +5261,13 @@
 	struct ata_port *ap = qc->ap;
 
 	qc->result_tf.flags = qc->tf.flags;
-	ap->ops->qc_fill_rtf(qc);
-}
-
-static void ata_verify_xfer(struct ata_queued_cmd *qc)
-{
-	struct ata_device *dev = qc->dev;
-
-	if (ata_is_nodata(qc->tf.protocol))
-		return;
-
-	if ((dev->mwdma_mask || dev->udma_mask) && ata_is_pio(qc->tf.protocol))
-		return;
-
-	dev->flags &= ~ATA_DFLAG_DUBIOUS_XFER;
+	ap->ops->tf_read(ap, &qc->result_tf);
 }
 
 /**
  *	ata_qc_complete - Complete an active ATA command
  *	@qc: Command to complete
+ *	@err_mask: ATA Status register contents
  *
  *	Indicate to the mid and upper layers that an ATA
  *	command has completed, with either an ok or not-ok status.
@@ -5053,62 +5293,24 @@
 	 * taken care of.
 	 */
 	if (ap->ops->error_handler) {
-		struct ata_device *dev = qc->dev;
-		struct ata_eh_info *ehi = &dev->link->eh_info;
+		WARN_ON(ap->pflags & ATA_PFLAG_FROZEN);
 
 		if (unlikely(qc->err_mask))
 			qc->flags |= ATA_QCFLAG_FAILED;
 
-		/*
-		 * Finish internal commands without any further processing
-		 * and always with the result TF filled.
-		 */
-		if (unlikely(ata_tag_internal(qc->tag))) {
-			fill_result_tf(qc);
-			__ata_qc_complete(qc);
-			return;
-		}
-
-		/*
-		 * Non-internal qc has failed.  Fill the result TF and
-		 * summon EH.
-		 */
 		if (unlikely(qc->flags & ATA_QCFLAG_FAILED)) {
-			fill_result_tf(qc);
-			ata_qc_schedule_eh(qc);
-			return;
+			if (!ata_tag_internal(qc->tag)) {
+				/* always fill result TF for failed qc */
+				fill_result_tf(qc);
+				ata_qc_schedule_eh(qc);
+				return;
+			}
 		}
 
-		WARN_ON_ONCE(ap->pflags & ATA_PFLAG_FROZEN);
-
 		/* read result TF if requested */
 		if (qc->flags & ATA_QCFLAG_RESULT_TF)
 			fill_result_tf(qc);
 
-		/* Some commands need post-processing after successful
-		 * completion.
-		 */
-		switch (qc->tf.command) {
-		case ATA_CMD_SET_FEATURES:
-			if (qc->tf.feature != SETFEATURES_WC_ON &&
-			    qc->tf.feature != SETFEATURES_WC_OFF)
-				break;
-			/* fall through */
-		case ATA_CMD_INIT_DEV_PARAMS: /* CHS translation changed */
-		case ATA_CMD_SET_MULTI: /* multi_count changed */
-			/* revalidate device */
-			ehi->dev_action[dev->devno] |= ATA_EH_REVALIDATE;
-			ata_port_schedule_eh(ap);
-			break;
-
-		case ATA_CMD_SLEEP:
-			dev->flags |= ATA_DFLAG_SLEEPING;
-			break;
-		}
-
-		if (unlikely(dev->flags & ATA_DFLAG_DUBIOUS_XFER))
-			ata_verify_xfer(qc);
-
 		__ata_qc_complete(qc);
 	} else {
 		if (qc->flags & ATA_QCFLAG_EH_SCHEDULED)
@@ -5126,6 +5328,7 @@
  *	ata_qc_complete_multiple - Complete multiple qcs successfully
  *	@ap: port in question
  *	@qc_active: new qc_active mask
+ *	@finish_qc: LLDD callback invoked before completing a qc
  *
  *	Complete in-flight commands.  This functions is meant to be
  *	called from low-level driver's interrupt routine to complete
@@ -5138,10 +5341,12 @@
  *	RETURNS:
  *	Number of completed commands on success, -errno otherwise.
  */
-int ata_qc_complete_multiple(struct ata_port *ap, u32 qc_active)
+int ata_qc_complete_multiple(struct ata_port *ap, u32 qc_active,
+			     void (*finish_qc)(struct ata_queued_cmd *))
 {
 	int nr_done = 0;
 	u32 done_mask;
+	int i;
 
 	done_mask = ap->qc_active ^ qc_active;
 
@@ -5151,21 +5356,47 @@
 		return -EINVAL;
 	}
 
-	while (done_mask) {
+	for (i = 0; i < ATA_MAX_QUEUE; i++) {
 		struct ata_queued_cmd *qc;
-		unsigned int tag = __ffs(done_mask);
 
-		qc = ata_qc_from_tag(ap, tag);
-		if (qc) {
+		if (!(done_mask & (1 << i)))
+			continue;
+
+		if ((qc = ata_qc_from_tag(ap, i))) {
+			if (finish_qc)
+				finish_qc(qc);
 			ata_qc_complete(qc);
 			nr_done++;
 		}
-		done_mask &= ~(1 << tag);
 	}
 
 	return nr_done;
 }
 
+static inline int ata_should_dma_map(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+
+	switch (qc->tf.protocol) {
+	case ATA_PROT_NCQ:
+	case ATA_PROT_DMA:
+	case ATA_PROT_ATAPI_DMA:
+		return 1;
+
+	case ATA_PROT_ATAPI:
+	case ATA_PROT_PIO:
+		if (ap->flags & ATA_FLAG_PIO_DMA)
+			return 1;
+
+		/* fall through */
+
+	default:
+		return 0;
+	}
+
+	/* never reached */
+}
+
 /**
  *	ata_qc_issue - issue taskfile to device
  *	@qc: command to issue to device
@@ -5181,47 +5412,34 @@
 void ata_qc_issue(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
-	struct ata_link *link = qc->dev->link;
-	u8 prot = qc->tf.protocol;
 
 	/* Make sure only one non-NCQ command is outstanding.  The
 	 * check is skipped for old EH because it reuses active qc to
 	 * request ATAPI sense.
 	 */
-	WARN_ON_ONCE(ap->ops->error_handler && ata_tag_valid(link->active_tag));
-
-	if (ata_is_ncq(prot)) {
-		WARN_ON_ONCE(link->sactive & (1 << qc->tag));
+	WARN_ON(ap->ops->error_handler && ata_tag_valid(ap->active_tag));
 
-		if (!link->sactive)
-			ap->nr_active_links++;
-		link->sactive |= 1 << qc->tag;
+	if (qc->tf.protocol == ATA_PROT_NCQ) {
+		WARN_ON(ap->sactive & (1 << qc->tag));
+		ap->sactive |= 1 << qc->tag;
 	} else {
-		WARN_ON_ONCE(link->sactive);
-
-		ap->nr_active_links++;
-		link->active_tag = qc->tag;
+		WARN_ON(ap->sactive);
+		ap->active_tag = qc->tag;
 	}
 
 	qc->flags |= ATA_QCFLAG_ACTIVE;
 	ap->qc_active |= 1 << qc->tag;
 
-	/* We guarantee to LLDs that they will have at least one
-	 * non-zero sg if the command is a data command.
-	 */
-	BUG_ON(ata_is_data(prot) && (!qc->sg || !qc->n_elem || !qc->nbytes));
-
-	if (ata_is_dma(prot) || (ata_is_pio(prot) &&
-				 (ap->flags & ATA_FLAG_PIO_DMA)))
-		if (ata_sg_setup(qc))
-			goto sg_err;
-
-	/* if device is sleeping, schedule reset and abort the link */
-	if (unlikely(qc->dev->flags & ATA_DFLAG_SLEEPING)) {
-		link->eh_info.action |= ATA_EH_RESET;
-		ata_ehi_push_desc(&link->eh_info, "waking up from sleep");
-		ata_link_abort(link);
-		return;
+	if (ata_should_dma_map(qc)) {
+		if (qc->flags & ATA_QCFLAG_SG) {
+			if (ata_sg_setup(qc))
+				goto sg_err;
+		} else if (qc->flags & ATA_QCFLAG_SINGLE) {
+			if (ata_sg_setup_one(qc))
+				goto sg_err;
+		}
+	} else {
+		qc->flags &= ~ATA_QCFLAG_DMAMAP;
 	}
 
 	ap->ops->qc_prep(qc);
@@ -5232,16 +5450,295 @@
 	return;
 
 sg_err:
+	qc->flags &= ~ATA_QCFLAG_DMAMAP;
 	qc->err_mask |= AC_ERR_SYSTEM;
 err:
 	ata_qc_complete(qc);
 }
 
 /**
+ *	ata_qc_issue_prot - issue taskfile to device in proto-dependent manner
+ *	@qc: command to issue to device
+ *
+ *	Using various libata functions and hooks, this function
+ *	starts an ATA command.  ATA commands are grouped into
+ *	classes called "protocols", and issuing each type of protocol
+ *	is slightly different.
+ *
+ *	May be used as the qc_issue() entry in ata_port_operations.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ *	RETURNS:
+ *	Zero on success, AC_ERR_* mask on failure
+ */
+
+unsigned int ata_qc_issue_prot(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+
+	/* Use polling pio if the LLD doesn't handle
+	 * interrupt driven pio and atapi CDB interrupt.
+	 */
+	if (ap->flags & ATA_FLAG_PIO_POLLING) {
+		switch (qc->tf.protocol) {
+		case ATA_PROT_PIO:
+		case ATA_PROT_NODATA:
+		case ATA_PROT_ATAPI:
+		case ATA_PROT_ATAPI_NODATA:
+			qc->tf.flags |= ATA_TFLAG_POLLING;
+			break;
+		case ATA_PROT_ATAPI_DMA:
+			if (qc->dev->flags & ATA_DFLAG_CDB_INTR)
+				/* see ata_dma_blacklisted() */
+				BUG();
+			break;
+		default:
+			break;
+		}
+	}
+
+	/* select the device */
+	ata_dev_select(ap, qc->dev->devno, 1, 0);
+
+	/* start the command */
+	switch (qc->tf.protocol) {
+	case ATA_PROT_NODATA:
+		if (qc->tf.flags & ATA_TFLAG_POLLING)
+			ata_qc_set_polling(qc);
+
+		ata_tf_to_host(ap, &qc->tf);
+		ap->hsm_task_state = HSM_ST_LAST;
+
+		if (qc->tf.flags & ATA_TFLAG_POLLING)
+			ata_port_queue_task(ap, ata_pio_task, qc, 0);
+
+		break;
+
+	case ATA_PROT_DMA:
+		WARN_ON(qc->tf.flags & ATA_TFLAG_POLLING);
+
+		ap->ops->tf_load(ap, &qc->tf);	 /* load tf registers */
+		ap->ops->bmdma_setup(qc);	    /* set up bmdma */
+		ap->ops->bmdma_start(qc);	    /* initiate bmdma */
+		ap->hsm_task_state = HSM_ST_LAST;
+		break;
+
+	case ATA_PROT_PIO:
+		if (qc->tf.flags & ATA_TFLAG_POLLING)
+			ata_qc_set_polling(qc);
+
+		ata_tf_to_host(ap, &qc->tf);
+
+		if (qc->tf.flags & ATA_TFLAG_WRITE) {
+			/* PIO data out protocol */
+			ap->hsm_task_state = HSM_ST_FIRST;
+			ata_port_queue_task(ap, ata_pio_task, qc, 0);
+
+			/* always send first data block using
+			 * the ata_pio_task() codepath.
+			 */
+		} else {
+			/* PIO data in protocol */
+			ap->hsm_task_state = HSM_ST;
+
+			if (qc->tf.flags & ATA_TFLAG_POLLING)
+				ata_port_queue_task(ap, ata_pio_task, qc, 0);
+
+			/* if polling, ata_pio_task() handles the rest.
+			 * otherwise, interrupt handler takes over from here.
+			 */
+		}
+
+		break;
+
+	case ATA_PROT_ATAPI:
+	case ATA_PROT_ATAPI_NODATA:
+		if (qc->tf.flags & ATA_TFLAG_POLLING)
+			ata_qc_set_polling(qc);
+
+		ata_tf_to_host(ap, &qc->tf);
+
+		ap->hsm_task_state = HSM_ST_FIRST;
+
+		/* send cdb by polling if no cdb interrupt */
+		if ((!(qc->dev->flags & ATA_DFLAG_CDB_INTR)) ||
+		    (qc->tf.flags & ATA_TFLAG_POLLING))
+			ata_port_queue_task(ap, ata_pio_task, qc, 0);
+		break;
+
+	case ATA_PROT_ATAPI_DMA:
+		WARN_ON(qc->tf.flags & ATA_TFLAG_POLLING);
+
+		ap->ops->tf_load(ap, &qc->tf);	 /* load tf registers */
+		ap->ops->bmdma_setup(qc);	    /* set up bmdma */
+		ap->hsm_task_state = HSM_ST_FIRST;
+
+		/* send cdb by polling if no cdb interrupt */
+		if (!(qc->dev->flags & ATA_DFLAG_CDB_INTR))
+			ata_port_queue_task(ap, ata_pio_task, qc, 0);
+		break;
+
+	default:
+		WARN_ON(1);
+		return AC_ERR_SYSTEM;
+	}
+
+	return 0;
+}
+
+/**
+ *	ata_host_intr - Handle host interrupt for given (port, task)
+ *	@ap: Port on which interrupt arrived (possibly...)
+ *	@qc: Taskfile currently active in engine
+ *
+ *	Handle host interrupt for given queued command.  Currently,
+ *	only DMA interrupts are handled.  All other commands are
+ *	handled via polling with interrupts disabled (nIEN bit).
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ *	RETURNS:
+ *	One if interrupt was handled, zero if not (shared irq).
+ */
+
+inline unsigned int ata_host_intr (struct ata_port *ap,
+				   struct ata_queued_cmd *qc)
+{
+	struct ata_eh_info *ehi = &ap->eh_info;
+	u8 status, host_stat = 0;
+
+	VPRINTK("ata%u: protocol %d task_state %d\n",
+		ap->print_id, qc->tf.protocol, ap->hsm_task_state);
+
+	/* Check whether we are expecting interrupt in this state */
+	switch (ap->hsm_task_state) {
+	case HSM_ST_FIRST:
+		/* Some pre-ATAPI-4 devices assert INTRQ
+		 * at this state when ready to receive CDB.
+		 */
+
+		/* Check the ATA_DFLAG_CDB_INTR flag is enough here.
+		 * The flag was turned on only for atapi devices.
+		 * No need to check is_atapi_taskfile(&qc->tf) again.
+		 */
+		if (!(qc->dev->flags & ATA_DFLAG_CDB_INTR))
+			goto idle_irq;
+		break;
+	case HSM_ST_LAST:
+		if (qc->tf.protocol == ATA_PROT_DMA ||
+		    qc->tf.protocol == ATA_PROT_ATAPI_DMA) {
+			/* check status of DMA engine */
+			host_stat = ap->ops->bmdma_status(ap);
+			VPRINTK("ata%u: host_stat 0x%X\n",
+				ap->print_id, host_stat);
+
+			/* if it's not our irq... */
+			if (!(host_stat & ATA_DMA_INTR))
+				goto idle_irq;
+
+			/* before we do anything else, clear DMA-Start bit */
+			ap->ops->bmdma_stop(qc);
+
+			if (unlikely(host_stat & ATA_DMA_ERR)) {
+				/* error when transfering data to/from memory */
+				qc->err_mask |= AC_ERR_HOST_BUS;
+				ap->hsm_task_state = HSM_ST_ERR;
+			}
+		}
+		break;
+	case HSM_ST:
+		break;
+	default:
+		goto idle_irq;
+	}
+
+	/* check altstatus */
+	status = ata_altstatus(ap);
+	if (status & ATA_BUSY)
+		goto idle_irq;
+
+	/* check main status, clearing INTRQ */
+	status = ata_chk_status(ap);
+	if (unlikely(status & ATA_BUSY))
+		goto idle_irq;
+
+	/* ack bmdma irq events */
+	ap->ops->irq_clear(ap);
+
+	ata_hsm_move(ap, qc, status, 0);
+
+	if (unlikely(qc->err_mask) && (qc->tf.protocol == ATA_PROT_DMA ||
+				       qc->tf.protocol == ATA_PROT_ATAPI_DMA))
+		ata_ehi_push_desc(ehi, "BMDMA stat 0x%x", host_stat);
+
+	return 1;	/* irq handled */
+
+idle_irq:
+	ap->stats.idle_irq++;
+
+#ifdef ATA_IRQ_TRAP
+	if ((ap->stats.idle_irq % 1000) == 0) {
+		ap->ops->irq_ack(ap, 0); /* debug trap */
+		ata_port_printk(ap, KERN_WARNING, "irq trap\n");
+		return 1;
+	}
+#endif
+	return 0;	/* irq not handled */
+}
+
+/**
+ *	ata_interrupt - Default ATA host interrupt handler
+ *	@irq: irq line (unused)
+ *	@dev_instance: pointer to our ata_host information structure
+ *
+ *	Default interrupt handler for PCI IDE devices.  Calls
+ *	ata_host_intr() for each port that is not disabled.
+ *
+ *	LOCKING:
+ *	Obtains host lock during operation.
+ *
+ *	RETURNS:
+ *	IRQ_NONE or IRQ_HANDLED.
+ */
+
+irqreturn_t ata_interrupt (int irq, void *dev_instance)
+{
+	struct ata_host *host = dev_instance;
+	unsigned int i;
+	unsigned int handled = 0;
+	unsigned long flags;
+
+	/* TODO: make _irqsave conditional on x86 PCI IDE legacy mode */
+	spin_lock_irqsave(&host->lock, flags);
+
+	for (i = 0; i < host->n_ports; i++) {
+		struct ata_port *ap;
+
+		ap = host->ports[i];
+		if (ap &&
+		    !(ap->flags & ATA_FLAG_DISABLED)) {
+			struct ata_queued_cmd *qc;
+
+			qc = ata_qc_from_tag(ap, ap->active_tag);
+			if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)) &&
+			    (qc->flags & ATA_QCFLAG_ACTIVE))
+				handled |= ata_host_intr(ap, qc);
+		}
+	}
+
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	return IRQ_RETVAL(handled);
+}
+
+/**
  *	sata_scr_valid - test whether SCRs are accessible
- *	@link: ATA link to test SCR accessibility for
+ *	@ap: ATA port to test SCR accessibility for
  *
- *	Test whether SCRs are accessible for @link.
+ *	Test whether SCRs are accessible for @ap.
  *
  *	LOCKING:
  *	None.
@@ -5249,70 +5746,60 @@
  *	RETURNS:
  *	1 if SCRs are accessible, 0 otherwise.
  */
-int sata_scr_valid(struct ata_link *link)
+int sata_scr_valid(struct ata_port *ap)
 {
-	struct ata_port *ap = link->ap;
-
 	return (ap->flags & ATA_FLAG_SATA) && ap->ops->scr_read;
 }
 
 /**
  *	sata_scr_read - read SCR register of the specified port
- *	@link: ATA link to read SCR for
+ *	@ap: ATA port to read SCR for
  *	@reg: SCR to read
  *	@val: Place to store read value
  *
- *	Read SCR register @reg of @link into *@val.  This function is
- *	guaranteed to succeed if @link is ap->link, the cable type of
- *	the port is SATA and the port implements ->scr_read.
+ *	Read SCR register @reg of @ap into *@val.  This function is
+ *	guaranteed to succeed if the cable type of the port is SATA
+ *	and the port implements ->scr_read.
  *
  *	LOCKING:
- *	None if @link is ap->link.  Kernel thread context otherwise.
+ *	None.
  *
  *	RETURNS:
  *	0 on success, negative errno on failure.
  */
-int sata_scr_read(struct ata_link *link, int reg, u32 *val)
+int sata_scr_read(struct ata_port *ap, int reg, u32 *val)
 {
-	if (ata_is_host_link(link)) {
-		if (sata_scr_valid(link))
-			return link->ap->ops->scr_read(link, reg, val);
-		return -EOPNOTSUPP;
-	}
-
-	return sata_pmp_scr_read(link, reg, val);
+	if (sata_scr_valid(ap))
+		return ap->ops->scr_read(ap, reg, val);
+	return -EOPNOTSUPP;
 }
 
 /**
  *	sata_scr_write - write SCR register of the specified port
- *	@link: ATA link to write SCR for
+ *	@ap: ATA port to write SCR for
  *	@reg: SCR to write
  *	@val: value to write
  *
- *	Write @val to SCR register @reg of @link.  This function is
- *	guaranteed to succeed if @link is ap->link, the cable type of
- *	the port is SATA and the port implements ->scr_read.
+ *	Write @val to SCR register @reg of @ap.  This function is
+ *	guaranteed to succeed if the cable type of the port is SATA
+ *	and the port implements ->scr_read.
  *
  *	LOCKING:
- *	None if @link is ap->link.  Kernel thread context otherwise.
+ *	None.
  *
  *	RETURNS:
  *	0 on success, negative errno on failure.
  */
-int sata_scr_write(struct ata_link *link, int reg, u32 val)
+int sata_scr_write(struct ata_port *ap, int reg, u32 val)
 {
-	if (ata_is_host_link(link)) {
-		if (sata_scr_valid(link))
-			return link->ap->ops->scr_write(link, reg, val);
-		return -EOPNOTSUPP;
-	}
-
-	return sata_pmp_scr_write(link, reg, val);
+	if (sata_scr_valid(ap))
+		return ap->ops->scr_write(ap, reg, val);
+	return -EOPNOTSUPP;
 }
 
 /**
  *	sata_scr_write_flush - write SCR register of the specified port and flush
- *	@link: ATA link to write SCR for
+ *	@ap: ATA port to write SCR for
  *	@reg: SCR to write
  *	@val: value to write
  *
@@ -5320,126 +5807,90 @@
  *	function performs flush after writing to the register.
  *
  *	LOCKING:
- *	None if @link is ap->link.  Kernel thread context otherwise.
+ *	None.
  *
  *	RETURNS:
  *	0 on success, negative errno on failure.
  */
-int sata_scr_write_flush(struct ata_link *link, int reg, u32 val)
+int sata_scr_write_flush(struct ata_port *ap, int reg, u32 val)
 {
-	if (ata_is_host_link(link)) {
-		int rc;
+	int rc;
 
-		if (sata_scr_valid(link)) {
-			rc = link->ap->ops->scr_write(link, reg, val);
-			if (rc == 0)
-				rc = link->ap->ops->scr_read(link, reg, &val);
-			return rc;
-		}
-		return -EOPNOTSUPP;
+	if (sata_scr_valid(ap)) {
+		rc = ap->ops->scr_write(ap, reg, val);
+		if (rc == 0)
+			rc = ap->ops->scr_read(ap, reg, &val);
+		return rc;
 	}
-
-	return sata_pmp_scr_write(link, reg, val);
-}
-
-/**
- *	ata_phys_link_online - test whether the given link is online
- *	@link: ATA link to test
- *
- *	Test whether @link is online.  Note that this function returns
- *	0 if online status of @link cannot be obtained, so
- *	ata_link_online(link) != !ata_link_offline(link).
- *
- *	LOCKING:
- *	None.
- *
- *	RETURNS:
- *	True if the port online status is available and online.
- */
-bool ata_phys_link_online(struct ata_link *link)
-{
-	u32 sstatus;
-
-	if (sata_scr_read(link, SCR_STATUS, &sstatus) == 0 &&
-	    ata_sstatus_online(sstatus))
-		return true;
-	return false;
+	return -EOPNOTSUPP;
 }
 
 /**
- *	ata_phys_link_offline - test whether the given link is offline
- *	@link: ATA link to test
+ *	ata_port_online - test whether the given port is online
+ *	@ap: ATA port to test
  *
- *	Test whether @link is offline.  Note that this function
- *	returns 0 if offline status of @link cannot be obtained, so
- *	ata_link_online(link) != !ata_link_offline(link).
+ *	Test whether @ap is online.  Note that this function returns 0
+ *	if online status of @ap cannot be obtained, so
+ *	ata_port_online(ap) != !ata_port_offline(ap).
  *
  *	LOCKING:
  *	None.
  *
  *	RETURNS:
- *	True if the port offline status is available and offline.
+ *	1 if the port online status is available and online.
  */
-bool ata_phys_link_offline(struct ata_link *link)
+int ata_port_online(struct ata_port *ap)
 {
 	u32 sstatus;
 
-	if (sata_scr_read(link, SCR_STATUS, &sstatus) == 0 &&
-	    !ata_sstatus_online(sstatus))
-		return true;
-	return false;
+	if (!sata_scr_read(ap, SCR_STATUS, &sstatus) && (sstatus & 0xf) == 0x3)
+		return 1;
+	return 0;
 }
 
 /**
- *	ata_link_online - test whether the given link is online
- *	@link: ATA link to test
+ *	ata_port_offline - test whether the given port is offline
+ *	@ap: ATA port to test
  *
- *	Test whether @link is online.  This is identical to
- *	ata_phys_link_online() when there's no slave link.  When
- *	there's a slave link, this function should only be called on
- *	the master link and will return true if any of M/S links is
- *	online.
+ *	Test whether @ap is offline.  Note that this function returns
+ *	0 if offline status of @ap cannot be obtained, so
+ *	ata_port_online(ap) != !ata_port_offline(ap).
  *
  *	LOCKING:
  *	None.
  *
  *	RETURNS:
- *	True if the port online status is available and online.
+ *	1 if the port offline status is available and offline.
  */
-bool ata_link_online(struct ata_link *link)
+int ata_port_offline(struct ata_port *ap)
 {
-	struct ata_link *slave = link->ap->slave_link;
-
-	WARN_ON(link == slave);	/* shouldn't be called on slave link */
+	u32 sstatus;
 
-	return ata_phys_link_online(link) ||
-		(slave && ata_phys_link_online(slave));
+	if (!sata_scr_read(ap, SCR_STATUS, &sstatus) && (sstatus & 0xf) != 0x3)
+		return 1;
+	return 0;
 }
 
-/**
- *	ata_link_offline - test whether the given link is offline
- *	@link: ATA link to test
- *
- *	Test whether @link is offline.  This is identical to
- *	ata_phys_link_offline() when there's no slave link.  When
- *	there's a slave link, this function should only be called on
- *	the master link and will return true if both M/S links are
- *	offline.
- *
- *	LOCKING:
- *	None.
- *
- *	RETURNS:
- *	True if the port offline status is available and offline.
- */
-bool ata_link_offline(struct ata_link *link)
+int ata_flush_cache(struct ata_device *dev)
 {
-	struct ata_link *slave = link->ap->slave_link;
+	unsigned int err_mask;
+	u8 cmd;
 
-	WARN_ON(link == slave);	/* shouldn't be called on slave link */
+	if (!ata_try_flush_cache(dev))
+		return 0;
+
+	if (dev->flags & ATA_DFLAG_FLUSH_EXT)
+		cmd = ATA_CMD_FLUSH_EXT;
+	else
+		cmd = ATA_CMD_FLUSH;
+
+	err_mask = ata_do_simple_cmd(dev, cmd);
+	if (err_mask) {
+		ata_dev_printk(dev, KERN_ERR, "failed to flush cache\n");
+		return -EIO;
+	}
 
-	return ata_phys_link_offline(link) &&
-		(!slave || ata_phys_link_offline(slave));
+	return 0;
 }
 
 #ifdef CONFIG_PM
@@ -5452,7 +5903,6 @@
 
 	for (i = 0; i < host->n_ports; i++) {
 		struct ata_port *ap = host->ports[i];
-		struct ata_link *link;
 
 		/* Previous resume operation might still be in
 		 * progress.  Wait for PM_PENDING to clear.
@@ -5472,10 +5922,8 @@
 		}
 
 		ap->pflags |= ATA_PFLAG_PM_PENDING;
-		ata_for_each_link(link, ap, HOST_FIRST) {
-			link->eh_info.action |= action;
-			link->eh_info.flags |= ehi_flags;
-		}
+		ap->eh_info.action |= action;
+		ap->eh_info.flags |= ehi_flags;
 
 		ata_port_schedule_eh(ap);
 
@@ -5510,27 +5958,9 @@
  */
 int ata_host_suspend(struct ata_host *host, pm_message_t mesg)
 {
-	unsigned int ehi_flags = ATA_EHI_QUIET;
 	int rc;
 
-	/*
-	 * disable link pm on all ports before requesting
-	 * any pm activity
-	 */
-	ata_lpm_enable(host);
-
-	/*
-	 * On some hardware, device fails to respond after spun down
-	 * for suspend.  As the device won't be used before being
-	 * resumed, we don't need to touch the device.  Ask EH to skip
-	 * the usual stuff and proceed directly to suspend.
-	 *
-	 * http://thread.gmane.org/gmane.linux.ide/46764
-	 */
-	if (mesg.event == PM_EVENT_SUSPEND)
-		ehi_flags |= ATA_EHI_NO_AUTOPSY | ATA_EHI_NO_RECOVERY;
-
-	rc = ata_host_request_pm(host, mesg, 0, ehi_flags, 1);
+	rc = ata_host_request_pm(host, mesg, 0, ATA_EHI_QUIET, 1);
 	if (rc == 0)
 		host->dev->power.power_state = mesg;
 	return rc;
@@ -5549,12 +5979,9 @@
  */
 void ata_host_resume(struct ata_host *host)
 {
-	ata_host_request_pm(host, PMSG_ON, ATA_EH_RESET,
+	ata_host_request_pm(host, PMSG_ON, ATA_EH_SOFTRESET,
 			    ATA_EHI_NO_AUTOPSY | ATA_EHI_QUIET, 0);
 	host->dev->power.power_state = PMSG_ON;
-
-	/* reenable link pm */
-	ata_lpm_disable(host);
 }
 #endif
 
@@ -5573,12 +6000,19 @@
 int ata_port_start(struct ata_port *ap)
 {
 	struct device *dev = ap->dev;
+	int rc;
 
 	ap->prd = dmam_alloc_coherent(dev, ATA_PRD_TBL_SZ, &ap->prd_dma,
 				      GFP_KERNEL);
 	if (!ap->prd)
 		return -ENOMEM;
 
+	rc = ata_pad_alloc(ap, dev);
+	if (rc)
+		return rc;
+
+	DPRINTK("prd alloc, virt %p, dma %llx\n", ap->prd,
+		(unsigned long long)ap->prd_dma);
 	return 0;
 }
 
@@ -5593,13 +6027,12 @@
  */
 void ata_dev_init(struct ata_device *dev)
 {
-	struct ata_link *link = ata_dev_phys_link(dev);
-	struct ata_port *ap = link->ap;
+	struct ata_port *ap = dev->ap;
 	unsigned long flags;
 
-	/* SATA spd limit is bound to the attached device, reset together */
-	link->sata_spd_limit = link->hw_sata_spd_limit;
-	link->sata_spd = 0;
+	/* SATA spd limit is bound to the first device */
+	ap->sata_spd_limit = ap->hw_sata_spd_limit;
+	ap->sata_spd = 0;
 
 	/* High bits of dev->flags are used to record warm plug
 	 * requests which occur asynchronously.  Synchronize using
@@ -5610,83 +6043,14 @@
 	dev->horkage = 0;
 	spin_unlock_irqrestore(ap->lock, flags);
 
-	memset((void *)dev + ATA_DEVICE_CLEAR_BEGIN, 0,
-	       ATA_DEVICE_CLEAR_END - ATA_DEVICE_CLEAR_BEGIN);
+	memset((void *)dev + ATA_DEVICE_CLEAR_OFFSET, 0,
+	       sizeof(*dev) - ATA_DEVICE_CLEAR_OFFSET);
 	dev->pio_mask = UINT_MAX;
 	dev->mwdma_mask = UINT_MAX;
 	dev->udma_mask = UINT_MAX;
 }
 
 /**
- *	ata_link_init - Initialize an ata_link structure
- *	@ap: ATA port link is attached to
- *	@link: Link structure to initialize
- *	@pmp: Port multiplier port number
- *
- *	Initialize @link.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep)
- */
-void ata_link_init(struct ata_port *ap, struct ata_link *link, int pmp)
-{
-	int i;
-
-	/* clear everything except for devices */
-	memset(link, 0, offsetof(struct ata_link, device[0]));
-
-	link->ap = ap;
-	link->pmp = pmp;
-	link->active_tag = ATA_TAG_POISON;
-	link->hw_sata_spd_limit = UINT_MAX;
-
-	/* can't use iterator, ap isn't initialized yet */
-	for (i = 0; i < ATA_MAX_DEVICES; i++) {
-		struct ata_device *dev = &link->device[i];
-
-		dev->link = link;
-		dev->devno = dev - link->device;
-#ifdef CONFIG_ATA_ACPI
-		dev->gtf_filter = ata_acpi_gtf_filter;
-#endif
-		ata_dev_init(dev);
-	}
-}
-
-/**
- *	sata_link_init_spd - Initialize link->sata_spd_limit
- *	@link: Link to configure sata_spd_limit for
- *
- *	Initialize @link->[hw_]sata_spd_limit to the currently
- *	configured value.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-int sata_link_init_spd(struct ata_link *link)
-{
-	u8 spd;
-	int rc;
-
-	rc = sata_scr_read(link, SCR_CONTROL, &link->saved_scontrol);
-	if (rc)
-		return rc;
-
-	spd = (link->saved_scontrol >> 4) & 0xf;
-	if (spd)
-		link->hw_sata_spd_limit &= (1 << spd) - 1;
-
-	ata_force_link_limits(link);
-
-	link->sata_spd_limit = link->hw_sata_spd_limit;
-
-	return 0;
-}
-
-/**
  *	ata_port_alloc - allocate and initialize basic ATA port resources
  *	@host: ATA host this allocated port belongs to
  *
@@ -5701,6 +6065,7 @@
 struct ata_port *ata_port_alloc(struct ata_host *host)
 {
 	struct ata_port *ap;
+	unsigned int i;
 
 	DPRINTK("ENTER\n");
 
@@ -5715,6 +6080,9 @@
 	ap->ctl = ATA_DEVCTL_OBS;
 	ap->host = host;
 	ap->dev = host->dev;
+
+	ap->hw_sata_spd_limit = UINT_MAX;
+	ap->active_tag = ATA_TAG_POISON;
 	ap->last_ctl = 0xFF;
 
 #if defined(ATA_VERBOSE_DEBUG)
@@ -5726,23 +6094,23 @@
 	ap->msg_enable = ATA_MSG_DRV | ATA_MSG_ERR | ATA_MSG_WARN;
 #endif
 
-#ifdef CONFIG_ATA_SFF
-	INIT_DELAYED_WORK(&ap->port_task, ata_pio_task);
-#else
 	INIT_DELAYED_WORK(&ap->port_task, NULL);
-#endif
 	INIT_DELAYED_WORK(&ap->hotplug_task, ata_scsi_hotplug);
 	INIT_WORK(&ap->scsi_rescan_task, ata_scsi_dev_rescan);
 	INIT_LIST_HEAD(&ap->eh_done_q);
 	init_waitqueue_head(&ap->eh_wait_q);
-	init_completion(&ap->park_req_pending);
 	init_timer_deferrable(&ap->fastdrain_timer);
 	ap->fastdrain_timer.function = ata_eh_fastdrain_timerfn;
 	ap->fastdrain_timer.data = (unsigned long)ap;
 
 	ap->cbl = ATA_CBL_NONE;
 
-	ata_link_init(ap, &ap->link, 0);
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+		dev->ap = ap;
+		dev->devno = i;
+		ata_dev_init(dev);
+	}
 
 #ifdef ATA_IRQ_TRAP
 	ap->stats.unhandled_irq = 1;
@@ -5765,8 +6133,6 @@
 		if (ap->scsi_host)
 			scsi_host_put(ap->scsi_host);
 
-		kfree(ap->pmp_link);
-		kfree(ap->slave_link);
 		kfree(ap);
 		host->ports[i] = NULL;
 	}
@@ -5877,78 +6243,17 @@
 		ap->mwdma_mask = pi->mwdma_mask;
 		ap->udma_mask = pi->udma_mask;
 		ap->flags |= pi->flags;
-		ap->link.flags |= pi->link_flags;
 		ap->ops = pi->port_ops;
 
 		if (!host->ops && (pi->port_ops != &ata_dummy_port_ops))
 			host->ops = pi->port_ops;
+		if (!host->private_data && pi->private_data)
+			host->private_data = pi->private_data;
 	}
 
 	return host;
 }
 
-/**
- *	ata_slave_link_init - initialize slave link
- *	@ap: port to initialize slave link for
- *
- *	Create and initialize slave link for @ap.  This enables slave
- *	link handling on the port.
- *
- *	In libata, a port contains links and a link contains devices.
- *	There is single host link but if a PMP is attached to it,
- *	there can be multiple fan-out links.  On SATA, there's usually
- *	a single device connected to a link but PATA and SATA
- *	controllers emulating TF based interface can have two - master
- *	and slave.
- *
- *	However, there are a few controllers which don't fit into this
- *	abstraction too well - SATA controllers which emulate TF
- *	interface with both master and slave devices but also have
- *	separate SCR register sets for each device.  These controllers
- *	need separate links for physical link handling
- *	(e.g. onlineness, link speed) but should be treated like a
- *	traditional M/S controller for everything else (e.g. command
- *	issue, softreset).
- *
- *	slave_link is libata's way of handling this class of
- *	controllers without impacting core layer too much.  For
- *	anything other than physical link handling, the default host
- *	link is used for both master and slave.  For physical link
- *	handling, separate @ap->slave_link is used.  All dirty details
- *	are implemented inside libata core layer.  From LLD's POV, the
- *	only difference is that prereset, hardreset and postreset are
- *	called once more for the slave link, so the reset sequence
- *	looks like the following.
- *
- *	prereset(M) -> prereset(S) -> hardreset(M) -> hardreset(S) ->
- *	softreset(M) -> postreset(M) -> postreset(S)
- *
- *	Note that softreset is called only for the master.  Softreset
- *	resets both M/S by definition, so SRST on master should handle
- *	both (the standard method will work just fine).
- *
- *	LOCKING:
- *	Should be called before host is registered.
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-int ata_slave_link_init(struct ata_port *ap)
-{
-	struct ata_link *link;
-
-	WARN_ON(ap->slave_link);
-	WARN_ON(ap->flags & ATA_FLAG_PMP);
-
-	link = kzalloc(sizeof(*link), GFP_KERNEL);
-	if (!link)
-		return -ENOMEM;
-
-	ata_link_init(ap, link, 1);
-	ap->slave_link = link;
-	return 0;
-}
-
 static void ata_host_stop(struct device *gendev, void *res)
 {
 	struct ata_host *host = dev_get_drvdata(gendev);
@@ -5968,56 +6273,6 @@
 }
 
 /**
- *	ata_finalize_port_ops - finalize ata_port_operations
- *	@ops: ata_port_operations to finalize
- *
- *	An ata_port_operations can inherit from another ops and that
- *	ops can again inherit from another.  This can go on as many
- *	times as necessary as long as there is no loop in the
- *	inheritance chain.
- *
- *	Ops tables are finalized when the host is started.  NULL or
- *	unspecified entries are inherited from the closet ancestor
- *	which has the method and the entry is populated with it.
- *	After finalization, the ops table directly points to all the
- *	methods and ->inherits is no longer necessary and cleared.
- *
- *	Using ATA_OP_NULL, inheriting ops can force a method to NULL.
- *
- *	LOCKING:
- *	None.
- */
-static void ata_finalize_port_ops(struct ata_port_operations *ops)
-{
-	static DEFINE_SPINLOCK(lock);
-	const struct ata_port_operations *cur;
-	void **begin = (void **)ops;
-	void **end = (void **)&ops->inherits;
-	void **pp;
-
-	if (!ops || !ops->inherits)
-		return;
-
-	spin_lock(&lock);
-
-	for (cur = ops->inherits; cur; cur = cur->inherits) {
-		void **inherit = (void **)cur;
-
-		for (pp = begin; pp < end; pp++, inherit++)
-			if (!*pp)
-				*pp = *inherit;
-	}
-
-	for (pp = begin; pp < end; pp++)
-		if (IS_ERR(*pp))
-			*pp = NULL;
-
-	ops->inherits = NULL;
-
-	spin_unlock(&lock);
-}
-
-/**
  *	ata_host_start - start and freeze ports of an ATA host
  *	@host: ATA host to start ports for
  *
@@ -6042,13 +6297,9 @@
 	if (host->flags & ATA_HOST_STARTED)
 		return 0;
 
-	ata_finalize_port_ops(host->ops);
-
 	for (i = 0; i < host->n_ports; i++) {
 		struct ata_port *ap = host->ports[i];
 
-		ata_finalize_port_ops(ap->ops);
-
 		if (!host->ops && !ata_port_is_dummy(ap))
 			host->ops = ap->ops;
 
@@ -6071,13 +6322,12 @@
 		if (ap->ops->port_start) {
 			rc = ap->ops->port_start(ap);
 			if (rc) {
-				if (rc != -ENODEV)
-					dev_printk(KERN_ERR, host->dev,
-						"failed to start port %d "
-						"(errno=%d)\n", i, rc);
+				ata_port_printk(ap, KERN_ERR, "failed to "
+						"start port (errno=%d)\n", rc);
 				goto err_out;
 			}
 		}
+
 		ata_eh_freeze_port(ap);
 	}
 
@@ -6110,7 +6360,7 @@
  */
 /* KILLME - the only user left is ipr */
 void ata_host_init(struct ata_host *host, struct device *dev,
-		   unsigned long flags, struct ata_port_operations *ops)
+		   unsigned long flags, const struct ata_port_operations *ops)
 {
 	spin_lock_init(&host->lock);
 	host->dev = dev;
@@ -6118,65 +6368,6 @@
 	host->ops = ops;
 }
 
-
-static void async_port_probe(void *data, async_cookie_t cookie)
-{
-	int rc;
-	struct ata_port *ap = data;
-
-	/*
-	 * If we're not allowed to scan this host in parallel,
-	 * we need to wait until all previous scans have completed
-	 * before going further.
-	 * Jeff Garzik says this is only within a controller, so we
-	 * don't need to wait for port 0, only for later ports.
-	 */
-	if (!(ap->host->flags & ATA_HOST_PARALLEL_SCAN) && ap->port_no != 0)
-		async_synchronize_cookie(cookie);
-
-	/* probe */
-	if (ap->ops->error_handler) {
-		struct ata_eh_info *ehi = &ap->link.eh_info;
-		unsigned long flags;
-
-		ata_port_probe(ap);
-
-		/* kick EH for boot probing */
-		spin_lock_irqsave(ap->lock, flags);
-
-		ehi->probe_mask |= ATA_ALL_DEVICES;
-		ehi->action |= ATA_EH_RESET | ATA_EH_LPM;
-		ehi->flags |= ATA_EHI_NO_AUTOPSY | ATA_EHI_QUIET;
-
-		ap->pflags &= ~ATA_PFLAG_INITIALIZING;
-		ap->pflags |= ATA_PFLAG_LOADING;
-		ata_port_schedule_eh(ap);
-
-		spin_unlock_irqrestore(ap->lock, flags);
-
-		/* wait for EH to finish */
-		ata_port_wait_eh(ap);
-	} else {
-		DPRINTK("ata%u: bus probe begin\n", ap->print_id);
-		rc = ata_bus_probe(ap);
-		DPRINTK("ata%u: bus probe end\n", ap->print_id);
-
-		if (rc) {
-			/* FIXME: do something useful here?
-			 * Current libata behavior will
-			 * tear down everything when
-			 * the module is removed
-			 * or the h/w is unplugged.
-			 */
-		}
-	}
-
-	/* in order to keep device order, we need to synchronize at this point */
-	async_synchronize_cookie(cookie);
-
-	ata_scsi_scan_host(ap, 1);
-
-}
 /**
  *	ata_host_register - register initialized ATA host
  *	@host: ATA host to register
@@ -6226,6 +6417,8 @@
 	/* set cable, sata_spd_limit and report */
 	for (i = 0; i < host->n_ports; i++) {
 		struct ata_port *ap = host->ports[i];
+		int irq_line;
+		u32 scontrol;
 		unsigned long xfer_mask;
 
 		/* set SATA cable type if still unset */
@@ -6233,29 +6426,85 @@
 			ap->cbl = ATA_CBL_SATA;
 
 		/* init sata_spd_limit to the current value */
-		sata_link_init_spd(&ap->link);
-		if (ap->slave_link)
-			sata_link_init_spd(ap->slave_link);
+		if (sata_scr_read(ap, SCR_CONTROL, &scontrol) == 0) {
+			int spd = (scontrol >> 4) & 0xf;
+			if (spd)
+				ap->hw_sata_spd_limit &= (1 << spd) - 1;
+		}
+		ap->sata_spd_limit = ap->hw_sata_spd_limit;
+
+		/* report the secondary IRQ for second channel legacy */
+		irq_line = host->irq;
+		if (i == 1 && host->irq2)
+			irq_line = host->irq2;
 
-		/* print per-port info to dmesg */
 		xfer_mask = ata_pack_xfermask(ap->pio_mask, ap->mwdma_mask,
 					      ap->udma_mask);
 
-		if (!ata_port_is_dummy(ap)) {
-			ata_port_printk(ap, KERN_INFO,
-					"%cATA max %s %s\n",
+		/* print per-port info to dmesg */
+		if (!ata_port_is_dummy(ap))
+			ata_port_printk(ap, KERN_INFO, "%cATA max %s cmd 0x%p "
+					"ctl 0x%p bmdma 0x%p irq %d\n",
 					(ap->flags & ATA_FLAG_SATA) ? 'S' : 'P',
 					ata_mode_string(xfer_mask),
-					ap->link.eh_info.desc);
-			ata_ehi_clear_desc(&ap->link.eh_info);
-		} else
+					ap->ioaddr.cmd_addr,
+					ap->ioaddr.ctl_addr,
+					ap->ioaddr.bmdma_addr,
+					irq_line);
+		else
 			ata_port_printk(ap, KERN_INFO, "DUMMY\n");
 	}
 
-	/* perform each probe asynchronously */
+	/* perform each probe synchronously */
+	DPRINTK("probe begin\n");
+	for (i = 0; i < host->n_ports; i++) {
+		struct ata_port *ap = host->ports[i];
+		int rc;
+
+		/* probe */
+		if (ap->ops->error_handler) {
+			struct ata_eh_info *ehi = &ap->eh_info;
+			unsigned long flags;
+
+			ata_port_probe(ap);
+
+			/* kick EH for boot probing */
+			spin_lock_irqsave(ap->lock, flags);
+
+			ehi->probe_mask = (1 << ATA_MAX_DEVICES) - 1;
+			ehi->action |= ATA_EH_SOFTRESET;
+			ehi->flags |= ATA_EHI_NO_AUTOPSY | ATA_EHI_QUIET;
+
+			ap->pflags &= ~ATA_PFLAG_INITIALIZING;
+			ap->pflags |= ATA_PFLAG_LOADING;
+			ata_port_schedule_eh(ap);
+
+			spin_unlock_irqrestore(ap->lock, flags);
+
+			/* wait for EH to finish */
+			ata_port_wait_eh(ap);
+		} else {
+			DPRINTK("ata%u: bus probe begin\n", ap->print_id);
+			rc = ata_bus_probe(ap);
+			DPRINTK("ata%u: bus probe end\n", ap->print_id);
+
+			if (rc) {
+				/* FIXME: do something useful here?
+				 * Current libata behavior will
+				 * tear down everything when
+				 * the module is removed
+				 * or the h/w is unplugged.
+				 */
+			}
+		}
+	}
+
+	/* probes are done, now scan each port's disk(s) */
+	DPRINTK("host probe begin\n");
 	for (i = 0; i < host->n_ports; i++) {
 		struct ata_port *ap = host->ports[i];
-		async_schedule(async_port_probe, ap);
+
+		ata_scsi_scan_host(ap, 1);
 	}
 
 	return 0;
@@ -6274,10 +6523,6 @@
  *	request IRQ and register it.  This helper takes necessasry
  *	arguments and performs the three steps in one go.
  *
- *	An invalid IRQ skips the IRQ registration and expects the host to
- *	have set polling mode on the port. In this case, @irq_handler
- *	should be NULL.
- *
  *	LOCKING:
  *	Inherited from calling layer (may sleep).
  *
@@ -6288,25 +6533,19 @@
 		      irq_handler_t irq_handler, unsigned long irq_flags,
 		      struct scsi_host_template *sht)
 {
-	int i, rc;
+	int rc;
 
 	rc = ata_host_start(host);
 	if (rc)
 		return rc;
 
-	/* Special case for polling mode */
-	if (!irq) {
-		WARN_ON(irq_handler);
-		return ata_host_register(host, sht);
-	}
-
 	rc = devm_request_irq(host->dev, irq, irq_handler, irq_flags,
 			      dev_driver_string(host->dev), host);
 	if (rc)
 		return rc;
 
-	for (i = 0; i < host->n_ports; i++)
-		ata_port_desc(host->ports[i], "irq %d", irq);
+	/* Used to print device info at probe */
+	host->irq = irq;
 
 	rc = ata_host_register(host, sht);
 	/* if failed, just free the IRQ and leave ports alone */
@@ -6327,9 +6566,10 @@
  *	LOCKING:
  *	Kernel thread context (may sleep).
  */
-static void ata_port_detach(struct ata_port *ap)
+void ata_port_detach(struct ata_port *ap)
 {
 	unsigned long flags;
+	int i;
 
 	if (!ap->ops->error_handler)
 		goto skip_eh;
@@ -6337,15 +6577,29 @@
 	/* tell EH we're leaving & flush EH */
 	spin_lock_irqsave(ap->lock, flags);
 	ap->pflags |= ATA_PFLAG_UNLOADING;
-	ata_port_schedule_eh(ap);
 	spin_unlock_irqrestore(ap->lock, flags);
 
-	/* wait till EH commits suicide */
 	ata_port_wait_eh(ap);
 
-	/* it better be dead now */
-	WARN_ON(!(ap->pflags & ATA_PFLAG_UNLOADED));
+	/* EH is now guaranteed to see UNLOADING, so no new device
+	 * will be attached.  Disable all existing devices.
+	 */
+	spin_lock_irqsave(ap->lock, flags);
+
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		ata_dev_disable(&ap->device[i]);
+
+	spin_unlock_irqrestore(ap->lock, flags);
+
+	/* Final freeze & EH.  All in-flight commands are aborted.  EH
+	 * will be skipped and retrials will be terminated with bad
+	 * target.
+	 */
+	spin_lock_irqsave(ap->lock, flags);
+	ata_port_freeze(ap);	/* won't be thawed */
+	spin_unlock_irqrestore(ap->lock, flags);
 
+	ata_port_wait_eh(ap);
 	cancel_rearming_delayed_work(&ap->hotplug_task);
 
  skip_eh:
@@ -6368,11 +6622,35 @@
 
 	for (i = 0; i < host->n_ports; i++)
 		ata_port_detach(host->ports[i]);
+}
 
-	/* the host is dead now, dissociate ACPI */
-	ata_acpi_dissociate(host);
+/**
+ *	ata_std_ports - initialize ioaddr with standard port offsets.
+ *	@ioaddr: IO address structure to be initialized
+ *
+ *	Utility function which initializes data_addr, error_addr,
+ *	feature_addr, nsect_addr, lbal_addr, lbam_addr, lbah_addr,
+ *	device_addr, status_addr, and command_addr to standard offsets
+ *	relative to cmd_addr.
+ *
+ *	Does not set ctl_addr, altstatus_addr, bmdma_addr, or scr_addr.
+ */
+
+void ata_std_ports(struct ata_ioports *ioaddr)
+{
+	ioaddr->data_addr = ioaddr->cmd_addr + ATA_REG_DATA;
+	ioaddr->error_addr = ioaddr->cmd_addr + ATA_REG_ERR;
+	ioaddr->feature_addr = ioaddr->cmd_addr + ATA_REG_FEATURE;
+	ioaddr->nsect_addr = ioaddr->cmd_addr + ATA_REG_NSECT;
+	ioaddr->lbal_addr = ioaddr->cmd_addr + ATA_REG_LBAL;
+	ioaddr->lbam_addr = ioaddr->cmd_addr + ATA_REG_LBAM;
+	ioaddr->lbah_addr = ioaddr->cmd_addr + ATA_REG_LBAH;
+	ioaddr->device_addr = ioaddr->cmd_addr + ATA_REG_DEVICE;
+	ioaddr->status_addr = ioaddr->cmd_addr + ATA_REG_STATUS;
+	ioaddr->command_addr = ioaddr->cmd_addr + ATA_REG_CMD;
 }
 
+
 #ifdef CONFIG_PCI
 
 /**
@@ -6388,7 +6666,7 @@
  */
 void ata_pci_remove_one(struct pci_dev *pdev)
 {
-	struct device *dev = &pdev->dev;
+	struct device *dev = pci_dev_to_dev(pdev);
 	struct ata_host *host = dev_get_drvdata(dev);
 
 	ata_host_detach(host);
@@ -6434,7 +6712,7 @@
 	pci_save_state(pdev);
 	pci_disable_device(pdev);
 
-	if (mesg.event & PM_EVENT_SLEEP)
+	if (mesg.event == PM_EVENT_SUSPEND)
 		pci_set_power_state(pdev, PCI_D3hot);
 }
 
@@ -6484,209 +6762,26 @@
 
 #endif /* CONFIG_PCI */
 
-static int __init ata_parse_force_one(char **cur,
-				      struct ata_force_ent *force_ent,
-				      const char **reason)
-{
-	/* FIXME: Currently, there's no way to tag init const data and
-	 * using __initdata causes build failure on some versions of
-	 * gcc.  Once __initdataconst is implemented, add const to the
-	 * following structure.
-	 */
-	static struct ata_force_param force_tbl[] __initdata = {
-		{ "40c",	.cbl		= ATA_CBL_PATA40 },
-		{ "80c",	.cbl		= ATA_CBL_PATA80 },
-		{ "short40c",	.cbl		= ATA_CBL_PATA40_SHORT },
-		{ "unk",	.cbl		= ATA_CBL_PATA_UNK },
-		{ "ign",	.cbl		= ATA_CBL_PATA_IGN },
-		{ "sata",	.cbl		= ATA_CBL_SATA },
-		{ "1.5Gbps",	.spd_limit	= 1 },
-		{ "3.0Gbps",	.spd_limit	= 2 },
-		{ "noncq",	.horkage_on	= ATA_HORKAGE_NONCQ },
-		{ "ncq",	.horkage_off	= ATA_HORKAGE_NONCQ },
-		{ "pio0",	.xfer_mask	= 1 << (ATA_SHIFT_PIO + 0) },
-		{ "pio1",	.xfer_mask	= 1 << (ATA_SHIFT_PIO + 1) },
-		{ "pio2",	.xfer_mask	= 1 << (ATA_SHIFT_PIO + 2) },
-		{ "pio3",	.xfer_mask	= 1 << (ATA_SHIFT_PIO + 3) },
-		{ "pio4",	.xfer_mask	= 1 << (ATA_SHIFT_PIO + 4) },
-		{ "pio5",	.xfer_mask	= 1 << (ATA_SHIFT_PIO + 5) },
-		{ "pio6",	.xfer_mask	= 1 << (ATA_SHIFT_PIO + 6) },
-		{ "mwdma0",	.xfer_mask	= 1 << (ATA_SHIFT_MWDMA + 0) },
-		{ "mwdma1",	.xfer_mask	= 1 << (ATA_SHIFT_MWDMA + 1) },
-		{ "mwdma2",	.xfer_mask	= 1 << (ATA_SHIFT_MWDMA + 2) },
-		{ "mwdma3",	.xfer_mask	= 1 << (ATA_SHIFT_MWDMA + 3) },
-		{ "mwdma4",	.xfer_mask	= 1 << (ATA_SHIFT_MWDMA + 4) },
-		{ "udma0",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 0) },
-		{ "udma16",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 0) },
-		{ "udma/16",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 0) },
-		{ "udma1",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 1) },
-		{ "udma25",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 1) },
-		{ "udma/25",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 1) },
-		{ "udma2",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 2) },
-		{ "udma33",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 2) },
-		{ "udma/33",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 2) },
-		{ "udma3",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 3) },
-		{ "udma44",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 3) },
-		{ "udma/44",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 3) },
-		{ "udma4",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 4) },
-		{ "udma66",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 4) },
-		{ "udma/66",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 4) },
-		{ "udma5",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 5) },
-		{ "udma100",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 5) },
-		{ "udma/100",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 5) },
-		{ "udma6",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 6) },
-		{ "udma133",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 6) },
-		{ "udma/133",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 6) },
-		{ "udma7",	.xfer_mask	= 1 << (ATA_SHIFT_UDMA + 7) },
-		{ "nohrst",	.lflags		= ATA_LFLAG_NO_HRST },
-		{ "nosrst",	.lflags		= ATA_LFLAG_NO_SRST },
-		{ "norst",	.lflags		= ATA_LFLAG_NO_HRST | ATA_LFLAG_NO_SRST },
-	};
-	char *start = *cur, *p = *cur;
-	char *id, *val, *endp;
-	const struct ata_force_param *match_fp = NULL;
-	int nr_matches = 0, i;
-
-	/* find where this param ends and update *cur */
-	while (*p != '\0' && *p != ',')
-		p++;
-
-	if (*p == '\0')
-		*cur = p;
-	else
-		*cur = p + 1;
-
-	*p = '\0';
-
-	/* parse */
-	p = strchr(start, ':');
-	if (!p) {
-		val = strstrip(start);
-		goto parse_val;
-	}
-	*p = '\0';
-
-	id = strstrip(start);
-	val = strstrip(p + 1);
-
-	/* parse id */
-	p = strchr(id, '.');
-	if (p) {
-		*p++ = '\0';
-		force_ent->device = simple_strtoul(p, &endp, 10);
-		if (p == endp || *endp != '\0') {
-			*reason = "invalid device";
-			return -EINVAL;
-		}
-	}
-
-	force_ent->port = simple_strtoul(id, &endp, 10);
-	if (p == endp || *endp != '\0') {
-		*reason = "invalid port/link";
-		return -EINVAL;
-	}
-
- parse_val:
-	/* parse val, allow shortcuts so that both 1.5 and 1.5Gbps work */
-	for (i = 0; i < ARRAY_SIZE(force_tbl); i++) {
-		const struct ata_force_param *fp = &force_tbl[i];
-
-		if (strncasecmp(val, fp->name, strlen(val)))
-			continue;
-
-		nr_matches++;
-		match_fp = fp;
-
-		if (strcasecmp(val, fp->name) == 0) {
-			nr_matches = 1;
-			break;
-		}
-	}
-
-	if (!nr_matches) {
-		*reason = "unknown value";
-		return -EINVAL;
-	}
-	if (nr_matches > 1) {
-		*reason = "ambigious value";
-		return -EINVAL;
-	}
-
-	force_ent->param = *match_fp;
-
-	return 0;
-}
-
-static void __init ata_parse_force_param(void)
-{
-	int idx = 0, size = 1;
-	int last_port = -1, last_device = -1;
-	char *p, *cur, *next;
-
-	/* calculate maximum number of params and allocate force_tbl */
-	for (p = ata_force_param_buf; *p; p++)
-		if (*p == ',')
-			size++;
-
-	ata_force_tbl = kzalloc(sizeof(ata_force_tbl[0]) * size, GFP_KERNEL);
-	if (!ata_force_tbl) {
-		printk(KERN_WARNING "ata: failed to extend force table, "
-		       "libata.force ignored\n");
-		return;
-	}
-
-	/* parse and populate the table */
-	for (cur = ata_force_param_buf; *cur != '\0'; cur = next) {
-		const char *reason = "";
-		struct ata_force_ent te = { .port = -1, .device = -1 };
-
-		next = cur;
-		if (ata_parse_force_one(&next, &te, &reason)) {
-			printk(KERN_WARNING "ata: failed to parse force "
-			       "parameter \"%s\" (%s)\n",
-			       cur, reason);
-			continue;
-		}
-
-		if (te.port == -1) {
-			te.port = last_port;
-			te.device = last_device;
-		}
-
-		ata_force_tbl[idx++] = te;
-
-		last_port = te.port;
-		last_device = te.device;
-	}
-
-	ata_force_tbl_size = idx;
-}
 
 static int __init ata_init(void)
 {
-	ata_parse_force_param();
-
+	ata_probe_timeout *= HZ;
 	ata_wq = create_workqueue("ata");
 	if (!ata_wq)
-		goto free_force_tbl;
+		return -ENOMEM;
 
 	ata_aux_wq = create_singlethread_workqueue("ata_aux");
-	if (!ata_aux_wq)
-		goto free_wq;
+	if (!ata_aux_wq) {
+		destroy_workqueue(ata_wq);
+		return -ENOMEM;
+	}
 
 	printk(KERN_DEBUG "libata version " DRV_VERSION " loaded.\n");
 	return 0;
-
-free_wq:
-	destroy_workqueue(ata_wq);
-free_force_tbl:
-	kfree(ata_force_tbl);
-	return -ENOMEM;
 }
 
 static void __exit ata_exit(void)
 {
-	kfree(ata_force_tbl);
 	destroy_workqueue(ata_wq);
 	destroy_workqueue(ata_aux_wq);
 }
@@ -6720,8 +6815,8 @@
  *	@reg: IO-mapped register
  *	@mask: Mask to apply to read register value
  *	@val: Wait condition
- *	@interval: polling interval in milliseconds
- *	@timeout: timeout in milliseconds
+ *	@interval_msec: polling interval in milliseconds
+ *	@timeout_msec: timeout in milliseconds
  *
  *	Waiting for some bits of register to change is a common
  *	operation for ATA controllers.  This function reads 32bit LE
@@ -6739,9 +6834,10 @@
  *	The final register value.
  */
 u32 ata_wait_register(void __iomem *reg, u32 mask, u32 val,
-		      unsigned long interval, unsigned long timeout)
+		      unsigned long interval_msec,
+		      unsigned long timeout_msec)
 {
-	unsigned long deadline;
+	unsigned long timeout;
 	u32 tmp;
 
 	tmp = ioread32(reg);
@@ -6750,10 +6846,10 @@
 	 * preceding writes reach the controller before starting to
 	 * eat away the timeout.
 	 */
-	deadline = ata_deadline(jiffies, timeout);
+	timeout = jiffies + (timeout_msec * HZ) / 1000;
 
-	while ((tmp & mask) == val && time_before(jiffies, deadline)) {
-		msleep(interval);
+	while ((tmp & mask) == val && time_before(jiffies, timeout)) {
+		msleep(interval_msec);
 		tmp = ioread32(reg);
 	}
 
@@ -6763,20 +6859,34 @@
 /*
  * Dummy port_ops
  */
-static unsigned int ata_dummy_qc_issue(struct ata_queued_cmd *qc)
+static void ata_dummy_noret(struct ata_port *ap)	{ }
+static int ata_dummy_ret0(struct ata_port *ap)		{ return 0; }
+static void ata_dummy_qc_noret(struct ata_queued_cmd *qc) { }
+
+static u8 ata_dummy_check_status(struct ata_port *ap)
 {
-	return AC_ERR_SYSTEM;
+	return ATA_DRDY;
 }
 
-static void ata_dummy_error_handler(struct ata_port *ap)
+static unsigned int ata_dummy_qc_issue(struct ata_queued_cmd *qc)
 {
-	/* truly dummy */
+	return AC_ERR_SYSTEM;
 }
 
-struct ata_port_operations ata_dummy_port_ops = {
+const struct ata_port_operations ata_dummy_port_ops = {
+	.port_disable		= ata_port_disable,
+	.check_status		= ata_dummy_check_status,
+	.check_altstatus	= ata_dummy_check_status,
+	.dev_select		= ata_noop_dev_select,
 	.qc_prep		= ata_noop_qc_prep,
 	.qc_issue		= ata_dummy_qc_issue,
-	.error_handler		= ata_dummy_error_handler,
+	.freeze			= ata_dummy_noret,
+	.thaw			= ata_dummy_noret,
+	.error_handler		= ata_dummy_noret,
+	.post_internal_cmd	= ata_dummy_qc_noret,
+	.irq_clear		= ata_dummy_noret,
+	.port_start		= ata_dummy_ret0,
+	.port_stop		= ata_dummy_noret,
 };
 
 const struct ata_port_info ata_dummy_port_info = {
@@ -6789,49 +6899,67 @@
  * likely to change as new drivers are added and updated.
  * Do not depend on ABI/API stability.
  */
+
 EXPORT_SYMBOL_GPL(sata_deb_timing_normal);
 EXPORT_SYMBOL_GPL(sata_deb_timing_hotplug);
 EXPORT_SYMBOL_GPL(sata_deb_timing_long);
-EXPORT_SYMBOL_GPL(ata_base_port_ops);
-EXPORT_SYMBOL_GPL(sata_port_ops);
 EXPORT_SYMBOL_GPL(ata_dummy_port_ops);
 EXPORT_SYMBOL_GPL(ata_dummy_port_info);
-EXPORT_SYMBOL_GPL(ata_link_next);
-EXPORT_SYMBOL_GPL(ata_dev_next);
 EXPORT_SYMBOL_GPL(ata_std_bios_param);
+EXPORT_SYMBOL_GPL(ata_std_ports);
 EXPORT_SYMBOL_GPL(ata_host_init);
 EXPORT_SYMBOL_GPL(ata_host_alloc);
 EXPORT_SYMBOL_GPL(ata_host_alloc_pinfo);
-EXPORT_SYMBOL_GPL(ata_slave_link_init);
 EXPORT_SYMBOL_GPL(ata_host_start);
 EXPORT_SYMBOL_GPL(ata_host_register);
 EXPORT_SYMBOL_GPL(ata_host_activate);
 EXPORT_SYMBOL_GPL(ata_host_detach);
 EXPORT_SYMBOL_GPL(ata_sg_init);
+EXPORT_SYMBOL_GPL(ata_sg_init_one);
+EXPORT_SYMBOL_GPL(ata_hsm_move);
 EXPORT_SYMBOL_GPL(ata_qc_complete);
 EXPORT_SYMBOL_GPL(ata_qc_complete_multiple);
-EXPORT_SYMBOL_GPL(atapi_cmd_type);
+EXPORT_SYMBOL_GPL(ata_qc_issue_prot);
+EXPORT_SYMBOL_GPL(ata_tf_load);
+EXPORT_SYMBOL_GPL(ata_tf_read);
+EXPORT_SYMBOL_GPL(ata_noop_dev_select);
+EXPORT_SYMBOL_GPL(ata_std_dev_select);
+EXPORT_SYMBOL_GPL(sata_print_link_status);
 EXPORT_SYMBOL_GPL(ata_tf_to_fis);
 EXPORT_SYMBOL_GPL(ata_tf_from_fis);
-EXPORT_SYMBOL_GPL(ata_pack_xfermask);
-EXPORT_SYMBOL_GPL(ata_unpack_xfermask);
-EXPORT_SYMBOL_GPL(ata_xfer_mask2mode);
-EXPORT_SYMBOL_GPL(ata_xfer_mode2mask);
-EXPORT_SYMBOL_GPL(ata_xfer_mode2shift);
-EXPORT_SYMBOL_GPL(ata_mode_string);
-EXPORT_SYMBOL_GPL(ata_id_xfermask);
+EXPORT_SYMBOL_GPL(ata_check_status);
+EXPORT_SYMBOL_GPL(ata_altstatus);
+EXPORT_SYMBOL_GPL(ata_exec_command);
 EXPORT_SYMBOL_GPL(ata_port_start);
+EXPORT_SYMBOL_GPL(ata_sff_port_start);
+EXPORT_SYMBOL_GPL(ata_interrupt);
 EXPORT_SYMBOL_GPL(ata_do_set_mode);
-EXPORT_SYMBOL_GPL(ata_std_qc_defer);
+EXPORT_SYMBOL_GPL(ata_data_xfer);
+EXPORT_SYMBOL_GPL(ata_data_xfer_noirq);
+EXPORT_SYMBOL_GPL(ata_qc_prep);
+EXPORT_SYMBOL_GPL(ata_dumb_qc_prep);
 EXPORT_SYMBOL_GPL(ata_noop_qc_prep);
+EXPORT_SYMBOL_GPL(ata_bmdma_setup);
+EXPORT_SYMBOL_GPL(ata_bmdma_start);
+EXPORT_SYMBOL_GPL(ata_bmdma_irq_clear);
+EXPORT_SYMBOL_GPL(ata_bmdma_status);
+EXPORT_SYMBOL_GPL(ata_bmdma_stop);
+EXPORT_SYMBOL_GPL(ata_bmdma_freeze);
+EXPORT_SYMBOL_GPL(ata_bmdma_thaw);
+EXPORT_SYMBOL_GPL(ata_bmdma_drive_eh);
+EXPORT_SYMBOL_GPL(ata_bmdma_error_handler);
+EXPORT_SYMBOL_GPL(ata_bmdma_post_internal_cmd);
 EXPORT_SYMBOL_GPL(ata_port_probe);
 EXPORT_SYMBOL_GPL(ata_dev_disable);
 EXPORT_SYMBOL_GPL(sata_set_spd);
-EXPORT_SYMBOL_GPL(ata_wait_after_reset);
-EXPORT_SYMBOL_GPL(sata_link_debounce);
-EXPORT_SYMBOL_GPL(sata_link_resume);
+EXPORT_SYMBOL_GPL(sata_phy_debounce);
+EXPORT_SYMBOL_GPL(sata_phy_resume);
+EXPORT_SYMBOL_GPL(sata_phy_reset);
+EXPORT_SYMBOL_GPL(__sata_phy_reset);
+EXPORT_SYMBOL_GPL(ata_bus_reset);
 EXPORT_SYMBOL_GPL(ata_std_prereset);
-EXPORT_SYMBOL_GPL(sata_link_hardreset);
+EXPORT_SYMBOL_GPL(ata_std_softreset);
+EXPORT_SYMBOL_GPL(sata_port_hardreset);
 EXPORT_SYMBOL_GPL(sata_std_hardreset);
 EXPORT_SYMBOL_GPL(ata_std_postreset);
 EXPORT_SYMBOL_GPL(ata_dev_classify);
@@ -6839,34 +6967,40 @@
 EXPORT_SYMBOL_GPL(ata_port_disable);
 EXPORT_SYMBOL_GPL(ata_ratelimit);
 EXPORT_SYMBOL_GPL(ata_wait_register);
+EXPORT_SYMBOL_GPL(ata_busy_sleep);
+EXPORT_SYMBOL_GPL(ata_wait_ready);
+EXPORT_SYMBOL_GPL(ata_port_queue_task);
+EXPORT_SYMBOL_GPL(ata_scsi_ioctl);
 EXPORT_SYMBOL_GPL(ata_scsi_queuecmd);
 EXPORT_SYMBOL_GPL(ata_scsi_slave_config);
 EXPORT_SYMBOL_GPL(ata_scsi_slave_destroy);
 EXPORT_SYMBOL_GPL(ata_scsi_change_queue_depth);
+EXPORT_SYMBOL_GPL(ata_host_intr);
 EXPORT_SYMBOL_GPL(sata_scr_valid);
 EXPORT_SYMBOL_GPL(sata_scr_read);
 EXPORT_SYMBOL_GPL(sata_scr_write);
 EXPORT_SYMBOL_GPL(sata_scr_write_flush);
-EXPORT_SYMBOL_GPL(ata_link_online);
-EXPORT_SYMBOL_GPL(ata_link_offline);
+EXPORT_SYMBOL_GPL(ata_port_online);
+EXPORT_SYMBOL_GPL(ata_port_offline);
 #ifdef CONFIG_PM
 EXPORT_SYMBOL_GPL(ata_host_suspend);
 EXPORT_SYMBOL_GPL(ata_host_resume);
 #endif /* CONFIG_PM */
 EXPORT_SYMBOL_GPL(ata_id_string);
 EXPORT_SYMBOL_GPL(ata_id_c_string);
-EXPORT_SYMBOL_GPL(ata_do_dev_read_id);
+EXPORT_SYMBOL_GPL(ata_id_to_dma_mode);
 EXPORT_SYMBOL_GPL(ata_scsi_simulate);
 
-EXPORT_SYMBOL_GPL(ata_pio_queue_task);
 EXPORT_SYMBOL_GPL(ata_pio_need_iordy);
-EXPORT_SYMBOL_GPL(ata_timing_find_mode);
 EXPORT_SYMBOL_GPL(ata_timing_compute);
 EXPORT_SYMBOL_GPL(ata_timing_merge);
-EXPORT_SYMBOL_GPL(ata_timing_cycle2mode);
 
 #ifdef CONFIG_PCI
 EXPORT_SYMBOL_GPL(pci_test_config_bits);
+EXPORT_SYMBOL_GPL(ata_pci_init_sff_host);
+EXPORT_SYMBOL_GPL(ata_pci_init_bmdma);
+EXPORT_SYMBOL_GPL(ata_pci_prepare_sff_host);
+EXPORT_SYMBOL_GPL(ata_pci_init_one);
 EXPORT_SYMBOL_GPL(ata_pci_remove_one);
 #ifdef CONFIG_PM
 EXPORT_SYMBOL_GPL(ata_pci_device_do_suspend);
@@ -6874,30 +7008,29 @@
 EXPORT_SYMBOL_GPL(ata_pci_device_suspend);
 EXPORT_SYMBOL_GPL(ata_pci_device_resume);
 #endif /* CONFIG_PM */
+EXPORT_SYMBOL_GPL(ata_pci_default_filter);
+EXPORT_SYMBOL_GPL(ata_pci_clear_simplex);
 #endif /* CONFIG_PCI */
 
 EXPORT_SYMBOL_GPL(__ata_ehi_push_desc);
 EXPORT_SYMBOL_GPL(ata_ehi_push_desc);
 EXPORT_SYMBOL_GPL(ata_ehi_clear_desc);
-EXPORT_SYMBOL_GPL(ata_port_desc);
-#ifdef CONFIG_PCI
-EXPORT_SYMBOL_GPL(ata_port_pbar_desc);
-#endif /* CONFIG_PCI */
+EXPORT_SYMBOL_GPL(ata_eng_timeout);
 EXPORT_SYMBOL_GPL(ata_port_schedule_eh);
-EXPORT_SYMBOL_GPL(ata_link_abort);
 EXPORT_SYMBOL_GPL(ata_port_abort);
 EXPORT_SYMBOL_GPL(ata_port_freeze);
-EXPORT_SYMBOL_GPL(sata_async_notification);
 EXPORT_SYMBOL_GPL(ata_eh_freeze_port);
 EXPORT_SYMBOL_GPL(ata_eh_thaw_port);
 EXPORT_SYMBOL_GPL(ata_eh_qc_complete);
 EXPORT_SYMBOL_GPL(ata_eh_qc_retry);
-EXPORT_SYMBOL_GPL(ata_eh_analyze_ncq_error);
 EXPORT_SYMBOL_GPL(ata_do_eh);
-EXPORT_SYMBOL_GPL(ata_std_error_handler);
+EXPORT_SYMBOL_GPL(ata_irq_on);
+EXPORT_SYMBOL_GPL(ata_dummy_irq_on);
+EXPORT_SYMBOL_GPL(ata_irq_ack);
+EXPORT_SYMBOL_GPL(ata_dummy_irq_ack);
+EXPORT_SYMBOL_GPL(ata_dev_try_classify);
 
 EXPORT_SYMBOL_GPL(ata_cable_40wire);
 EXPORT_SYMBOL_GPL(ata_cable_80wire);
 EXPORT_SYMBOL_GPL(ata_cable_unknown);
-EXPORT_SYMBOL_GPL(ata_cable_ignore);
 EXPORT_SYMBOL_GPL(ata_cable_sata);
diff -Nur linux-sh4/drivers/ata.org/libata-eh.c linux-sh4/drivers/ata/libata-eh.c
--- linux-sh4/drivers/ata.org/libata-eh.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/libata-eh.c	2012-01-15 06:30:14.000000000 -0800
@@ -33,14 +33,11 @@
  */
 
 #include <linux/kernel.h>
-#include <linux/blkdev.h>
-#include <linux/pci.h>
 #include <scsi/scsi.h>
 #include <scsi/scsi_host.h>
 #include <scsi/scsi_eh.h>
 #include <scsi/scsi_device.h>
 #include <scsi/scsi_cmnd.h>
-#include <scsi/scsi_dbg.h>
 #include "../scsi/scsi_transport_api.h"
 
 #include <linux/libata.h>
@@ -48,45 +45,18 @@
 #include "libata.h"
 
 enum {
-	/* speed down verdicts */
 	ATA_EH_SPDN_NCQ_OFF		= (1 << 0),
 	ATA_EH_SPDN_SPEED_DOWN		= (1 << 1),
 	ATA_EH_SPDN_FALLBACK_TO_PIO	= (1 << 2),
-	ATA_EH_SPDN_KEEP_ERRORS		= (1 << 3),
-
-	/* error flags */
-	ATA_EFLAG_IS_IO			= (1 << 0),
-	ATA_EFLAG_DUBIOUS_XFER		= (1 << 1),
-
-	/* error categories */
-	ATA_ECAT_NONE			= 0,
-	ATA_ECAT_ATA_BUS		= 1,
-	ATA_ECAT_TOUT_HSM		= 2,
-	ATA_ECAT_UNK_DEV		= 3,
-	ATA_ECAT_DUBIOUS_NONE		= 4,
-	ATA_ECAT_DUBIOUS_ATA_BUS	= 5,
-	ATA_ECAT_DUBIOUS_TOUT_HSM	= 6,
-	ATA_ECAT_DUBIOUS_UNK_DEV	= 7,
-	ATA_ECAT_NR			= 8,
-
-	ATA_EH_CMD_DFL_TIMEOUT		=  5000,
-
-	/* always put at least this amount of time between resets */
-	ATA_EH_RESET_COOL_DOWN		=  5000,
-
-	/* Waiting in ->prereset can never be reliable.  It's
-	 * sometimes nice to wait there but it can't be depended upon;
-	 * otherwise, we wouldn't be resetting.  Just give it enough
-	 * time for most drives to spin up.
-	 */
-	ATA_EH_PRERESET_TIMEOUT		= 10000,
-	ATA_EH_FASTDRAIN_INTERVAL	=  3000,
-
-	ATA_EH_UA_TRIES			= 5,
+};
 
-	/* probe speed down parameters, see ata_eh_schedule_probe() */
-	ATA_EH_PROBE_TRIAL_INTERVAL	= 60000,	/* 1 min */
-	ATA_EH_PROBE_TRIALS		= 2,
+/* Waiting in ->prereset can never be reliable.  It's sometimes nice
+ * to wait there but it can't be depended upon; otherwise, we wouldn't
+ * be resetting.  Just give it enough time for most drives to spin up.
+ */
+enum {
+	ATA_EH_PRERESET_TIMEOUT		= 10 * HZ,
+	ATA_EH_FASTDRAIN_INTERVAL	= 3 * HZ,
 };
 
 /* The following table determines how we sequence resets.  Each entry
@@ -96,61 +66,15 @@
  * are mostly for error handling, hotplug and retarded devices.
  */
 static const unsigned long ata_eh_reset_timeouts[] = {
-	10000,	/* most drives spin up by 10sec */
-	10000,	/* > 99% working drives spin up before 20sec */
-	35000,	/* give > 30 secs of idleness for retarded devices */
-	 5000,	/* and sweet one last chance */
-	ULONG_MAX, /* > 1 min has elapsed, give up */
-};
-
-static const unsigned long ata_eh_identify_timeouts[] = {
-	 5000,	/* covers > 99% of successes and not too boring on failures */
-	10000,  /* combined time till here is enough even for media access */
-	30000,	/* for true idiots */
-	ULONG_MAX,
+	10 * HZ,	/* most drives spin up by 10sec */
+	10 * HZ,	/* > 99% working drives spin up before 20sec */
+	35 * HZ,	/* give > 30 secs of idleness for retarded devices */
+	5 * HZ,		/* and sweet one last chance */
+	/* > 1 min has elapsed, give up */
 };
 
-static const unsigned long ata_eh_other_timeouts[] = {
-	 5000,	/* same rationale as identify timeout */
-	10000,	/* ditto */
-	/* but no merciful 30sec for other commands, it just isn't worth it */
-	ULONG_MAX,
-};
-
-struct ata_eh_cmd_timeout_ent {
-	const u8		*commands;
-	const unsigned long	*timeouts;
-};
-
-/* The following table determines timeouts to use for EH internal
- * commands.  Each table entry is a command class and matches the
- * commands the entry applies to and the timeout table to use.
- *
- * On the retry after a command timed out, the next timeout value from
- * the table is used.  If the table doesn't contain further entries,
- * the last value is used.
- *
- * ehc->cmd_timeout_idx keeps track of which timeout to use per
- * command class, so if SET_FEATURES times out on the first try, the
- * next try will use the second timeout value only for that class.
- */
-#define CMDS(cmds...)	(const u8 []){ cmds, 0 }
-static const struct ata_eh_cmd_timeout_ent
-ata_eh_cmd_timeout_table[ATA_EH_CMD_TIMEOUT_TABLE_SIZE] = {
-	{ .commands = CMDS(ATA_CMD_ID_ATA, ATA_CMD_ID_ATAPI),
-	  .timeouts = ata_eh_identify_timeouts, },
-	{ .commands = CMDS(ATA_CMD_READ_NATIVE_MAX, ATA_CMD_READ_NATIVE_MAX_EXT),
-	  .timeouts = ata_eh_other_timeouts, },
-	{ .commands = CMDS(ATA_CMD_SET_MAX, ATA_CMD_SET_MAX_EXT),
-	  .timeouts = ata_eh_other_timeouts, },
-	{ .commands = CMDS(ATA_CMD_SET_FEATURES),
-	  .timeouts = ata_eh_other_timeouts, },
-	{ .commands = CMDS(ATA_CMD_INIT_DEV_PARAMS),
-	  .timeouts = ata_eh_other_timeouts, },
-};
-#undef CMDS
-
 static void __ata_port_freeze(struct ata_port *ap);
+static void ata_eh_finish(struct ata_port *ap);
 #ifdef CONFIG_PM
 static void ata_eh_handle_port_suspend(struct ata_port *ap);
 static void ata_eh_handle_port_resume(struct ata_port *ap);
@@ -227,142 +151,7 @@
 	ehi->desc_len = 0;
 }
 
-/**
- *	ata_port_desc - append port description
- *	@ap: target ATA port
- *	@fmt: printf format string
- *
- *	Format string according to @fmt and append it to port
- *	description.  If port description is not empty, " " is added
- *	in-between.  This function is to be used while initializing
- *	ata_host.  The description is printed on host registration.
- *
- *	LOCKING:
- *	None.
- */
-void ata_port_desc(struct ata_port *ap, const char *fmt, ...)
-{
-	va_list args;
-
-	WARN_ON(!(ap->pflags & ATA_PFLAG_INITIALIZING));
-
-	if (ap->link.eh_info.desc_len)
-		__ata_ehi_push_desc(&ap->link.eh_info, " ");
-
-	va_start(args, fmt);
-	__ata_ehi_pushv_desc(&ap->link.eh_info, fmt, args);
-	va_end(args);
-}
-
-#ifdef CONFIG_PCI
-
-/**
- *	ata_port_pbar_desc - append PCI BAR description
- *	@ap: target ATA port
- *	@bar: target PCI BAR
- *	@offset: offset into PCI BAR
- *	@name: name of the area
- *
- *	If @offset is negative, this function formats a string which
- *	contains the name, address, size and type of the BAR and
- *	appends it to the port description.  If @offset is zero or
- *	positive, only name and offsetted address is appended.
- *
- *	LOCKING:
- *	None.
- */
-void ata_port_pbar_desc(struct ata_port *ap, int bar, ssize_t offset,
-			const char *name)
-{
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	char *type = "";
-	unsigned long long start, len;
-
-	if (pci_resource_flags(pdev, bar) & IORESOURCE_MEM)
-		type = "m";
-	else if (pci_resource_flags(pdev, bar) & IORESOURCE_IO)
-		type = "i";
-
-	start = (unsigned long long)pci_resource_start(pdev, bar);
-	len = (unsigned long long)pci_resource_len(pdev, bar);
-
-	if (offset < 0)
-		ata_port_desc(ap, "%s %s%llu@0x%llx", name, type, len, start);
-	else
-		ata_port_desc(ap, "%s 0x%llx", name,
-				start + (unsigned long long)offset);
-}
-
-#endif /* CONFIG_PCI */
-
-static int ata_lookup_timeout_table(u8 cmd)
-{
-	int i;
-
-	for (i = 0; i < ATA_EH_CMD_TIMEOUT_TABLE_SIZE; i++) {
-		const u8 *cur;
-
-		for (cur = ata_eh_cmd_timeout_table[i].commands; *cur; cur++)
-			if (*cur == cmd)
-				return i;
-	}
-
-	return -1;
-}
-
-/**
- *	ata_internal_cmd_timeout - determine timeout for an internal command
- *	@dev: target device
- *	@cmd: internal command to be issued
- *
- *	Determine timeout for internal command @cmd for @dev.
- *
- *	LOCKING:
- *	EH context.
- *
- *	RETURNS:
- *	Determined timeout.
- */
-unsigned long ata_internal_cmd_timeout(struct ata_device *dev, u8 cmd)
-{
-	struct ata_eh_context *ehc = &dev->link->eh_context;
-	int ent = ata_lookup_timeout_table(cmd);
-	int idx;
-
-	if (ent < 0)
-		return ATA_EH_CMD_DFL_TIMEOUT;
-
-	idx = ehc->cmd_timeout_idx[dev->devno][ent];
-	return ata_eh_cmd_timeout_table[ent].timeouts[idx];
-}
-
-/**
- *	ata_internal_cmd_timed_out - notification for internal command timeout
- *	@dev: target device
- *	@cmd: internal command which timed out
- *
- *	Notify EH that internal command @cmd for @dev timed out.  This
- *	function should be called only for commands whose timeouts are
- *	determined using ata_internal_cmd_timeout().
- *
- *	LOCKING:
- *	EH context.
- */
-void ata_internal_cmd_timed_out(struct ata_device *dev, u8 cmd)
-{
-	struct ata_eh_context *ehc = &dev->link->eh_context;
-	int ent = ata_lookup_timeout_table(cmd);
-	int idx;
-
-	if (ent < 0)
-		return;
-
-	idx = ehc->cmd_timeout_idx[dev->devno][ent];
-	if (ata_eh_cmd_timeout_table[ent].timeouts[idx + 1] != ULONG_MAX)
-		ehc->cmd_timeout_idx[dev->devno][ent]++;
-}
-
-static void ata_ering_record(struct ata_ering *ering, unsigned int eflags,
+static void ata_ering_record(struct ata_ering *ering, int is_io,
 			     unsigned int err_mask)
 {
 	struct ata_ering_entry *ent;
@@ -373,20 +162,11 @@
 	ering->cursor %= ATA_ERING_SIZE;
 
 	ent = &ering->ring[ering->cursor];
-	ent->eflags = eflags;
+	ent->is_io = is_io;
 	ent->err_mask = err_mask;
 	ent->timestamp = get_jiffies_64();
 }
 
-static struct ata_ering_entry *ata_ering_top(struct ata_ering *ering)
-{
-	struct ata_ering_entry *ent = &ering->ring[ering->cursor];
-
-	if (ent->err_mask)
-		return ent;
-	return NULL;
-}
-
 static void ata_ering_clear(struct ata_ering *ering)
 {
 	memset(ering, 0, sizeof(*ering));
@@ -415,29 +195,28 @@
 
 static unsigned int ata_eh_dev_action(struct ata_device *dev)
 {
-	struct ata_eh_context *ehc = &dev->link->eh_context;
+	struct ata_eh_context *ehc = &dev->ap->eh_context;
 
 	return ehc->i.action | ehc->i.dev_action[dev->devno];
 }
 
-static void ata_eh_clear_action(struct ata_link *link, struct ata_device *dev,
+static void ata_eh_clear_action(struct ata_device *dev,
 				struct ata_eh_info *ehi, unsigned int action)
 {
-	struct ata_device *tdev;
+	int i;
 
 	if (!dev) {
 		ehi->action &= ~action;
-		ata_for_each_dev(tdev, link, ALL)
-			ehi->dev_action[tdev->devno] &= ~action;
+		for (i = 0; i < ATA_MAX_DEVICES; i++)
+			ehi->dev_action[i] &= ~action;
 	} else {
 		/* doesn't make sense for port-wide EH actions */
 		WARN_ON(!(action & ATA_EH_PERDEV_MASK));
 
 		/* break ehi->action into ehi->dev_action */
 		if (ehi->action & action) {
-			ata_for_each_dev(tdev, link, ALL)
-				ehi->dev_action[tdev->devno] |=
-					ehi->action & action;
+			for (i = 0; i < ATA_MAX_DEVICES; i++)
+				ehi->dev_action[i] |= ehi->action & action;
 			ehi->action &= ~action;
 		}
 
@@ -482,7 +261,7 @@
 
 	ret = BLK_EH_HANDLED;
 	spin_lock_irqsave(ap->lock, flags);
-	qc = ata_qc_from_tag(ap, ap->link.active_tag);
+	qc = ata_qc_from_tag(ap, ap->active_tag);
 	if (qc) {
 		WARN_ON(qc->scsicmd != cmd);
 		qc->flags |= ATA_QCFLAG_EH_SCHEDULED;
@@ -496,31 +275,6 @@
 	return ret;
 }
 
-static void ata_eh_unload(struct ata_port *ap)
-{
-	struct ata_link *link;
-	struct ata_device *dev;
-	unsigned long flags;
-
-	/* Restore SControl IPM and SPD for the next driver and
-	 * disable attached devices.
-	 */
-	ata_for_each_link(link, ap, PMP_FIRST) {
-		sata_scr_write(link, SCR_CONTROL, link->saved_scontrol & 0xff0);
-		ata_for_each_dev(dev, link, ALL)
-			ata_dev_disable(dev);
-	}
-
-	/* freeze and set UNLOADED */
-	spin_lock_irqsave(ap->lock, flags);
-
-	ata_port_freeze(ap);			/* won't be thawed */
-	ap->pflags &= ~ATA_PFLAG_EH_PENDING;	/* clear pending from freeze */
-	ap->pflags |= ATA_PFLAG_UNLOADED;
-
-	spin_unlock_irqrestore(ap->lock, flags);
-}
-
 /**
  *	ata_scsi_error - SCSI layer error handler callback
  *	@host: SCSI host on which error occurred
@@ -536,7 +290,7 @@
 void ata_scsi_error(struct Scsi_Host *host)
 {
 	struct ata_port *ap = ata_shost_to_port(host);
-	int i;
+	int i, repeat_cnt = ATA_EH_MAX_REPEAT;
 	unsigned long flags;
 
 	DPRINTK("ENTER\n");
@@ -548,7 +302,7 @@
 
 	/* For new EH, all qcs are finished in one of three ways -
 	 * normal completion, error completion, and SCSI timeout.
-	 * Both completions can race against SCSI timeout.  When normal
+	 * Both cmpletions can race against SCSI timeout.  When normal
 	 * completion wins, the qc never reaches EH.  When error
 	 * completion wins, the qc has ATA_QCFLAG_FAILED set.
 	 *
@@ -563,19 +317,7 @@
 		int nr_timedout = 0;
 
 		spin_lock_irqsave(ap->lock, flags);
-		
-		/* This must occur under the ap->lock as we don't want
-		   a polled recovery to race the real interrupt handler
-		   
-		   The lost_interrupt handler checks for any completed but
-		   non-notified command and completes much like an IRQ handler.
-		   
-		   We then fall into the error recovery code which will treat
-		   this as if normal completion won the race */
-
-		if (ap->ops->lost_interrupt)
-			ap->ops->lost_interrupt(ap);
-			
+
 		list_for_each_entry_safe(scmd, tmp, &host->eh_cmd_q, eh_entry) {
 			struct ata_queued_cmd *qc;
 
@@ -614,20 +356,12 @@
 			__ata_port_freeze(ap);
 
 		spin_unlock_irqrestore(ap->lock, flags);
-
-		/* initialize eh_tries */
-		ap->eh_tries = ATA_EH_MAX_TRIES;
 	} else
 		spin_unlock_wait(ap->lock);
-		
-	/* If we timed raced normal completion and there is nothing to
-	   recover nr_timedout == 0 why exactly are we doing error recovery ? */
 
  repeat:
 	/* invoke error handler */
 	if (ap->ops->error_handler) {
-		struct ata_link *link;
-
 		/* kill fast drain timer */
 		del_timer_sync(&ap->fastdrain_timer);
 
@@ -637,39 +371,20 @@
 		/* fetch & clear EH info */
 		spin_lock_irqsave(ap->lock, flags);
 
-		ata_for_each_link(link, ap, HOST_FIRST) {
-			struct ata_eh_context *ehc = &link->eh_context;
-			struct ata_device *dev;
-
-			memset(&link->eh_context, 0, sizeof(link->eh_context));
-			link->eh_context.i = link->eh_info;
-			memset(&link->eh_info, 0, sizeof(link->eh_info));
-
-			ata_for_each_dev(dev, link, ENABLED) {
-				int devno = dev->devno;
-
-				ehc->saved_xfer_mode[devno] = dev->xfer_mode;
-				if (ata_ncq_enabled(dev))
-					ehc->saved_ncq_enabled |= 1 << devno;
-			}
-		}
+		memset(&ap->eh_context, 0, sizeof(ap->eh_context));
+		ap->eh_context.i = ap->eh_info;
+		memset(&ap->eh_info, 0, sizeof(ap->eh_info));
 
 		ap->pflags |= ATA_PFLAG_EH_IN_PROGRESS;
 		ap->pflags &= ~ATA_PFLAG_EH_PENDING;
-		ap->excl_link = NULL;	/* don't maintain exclusion over EH */
 
 		spin_unlock_irqrestore(ap->lock, flags);
 
 		/* invoke EH, skip if unloading or suspended */
 		if (!(ap->pflags & (ATA_PFLAG_UNLOADING | ATA_PFLAG_SUSPENDED)))
 			ap->ops->error_handler(ap);
-		else {
-			/* if unloading, commence suicide */
-			if ((ap->pflags & ATA_PFLAG_UNLOADING) &&
-			    !(ap->pflags & ATA_PFLAG_UNLOADED))
-				ata_eh_unload(ap);
+		else
 			ata_eh_finish(ap);
-		}
 
 		/* process port suspend request */
 		ata_eh_handle_port_suspend(ap);
@@ -681,18 +396,20 @@
 		spin_lock_irqsave(ap->lock, flags);
 
 		if (ap->pflags & ATA_PFLAG_EH_PENDING) {
-			if (--ap->eh_tries) {
+			if (--repeat_cnt) {
+				ata_port_printk(ap, KERN_INFO,
+					"EH pending after completion, "
+					"repeating EH (cnt=%d)\n", repeat_cnt);
 				spin_unlock_irqrestore(ap->lock, flags);
 				goto repeat;
 			}
 			ata_port_printk(ap, KERN_ERR, "EH pending after %d "
-					"tries, giving up\n", ATA_EH_MAX_TRIES);
+					"tries, giving up\n", ATA_EH_MAX_REPEAT);
 			ap->pflags &= ~ATA_PFLAG_EH_PENDING;
 		}
 
 		/* this run is complete, make sure EH info is clear */
-		ata_for_each_link(link, ap, HOST_FIRST)
-			memset(&link->eh_info, 0, sizeof(link->eh_info));
+		memset(&ap->eh_info, 0, sizeof(ap->eh_info));
 
 		/* Clear host_eh_scheduled while holding ap->lock such
 		 * that if exception occurs after this point but
@@ -703,7 +420,7 @@
 
 		spin_unlock_irqrestore(ap->lock, flags);
 	} else {
-		WARN_ON(ata_qc_from_tag(ap, ap->link.active_tag) == NULL);
+		WARN_ON(ata_qc_from_tag(ap, ap->active_tag) == NULL);
 		ap->ops->eng_timeout(ap);
 	}
 
@@ -768,6 +485,101 @@
 	}
 }
 
+/**
+ *	ata_qc_timeout - Handle timeout of queued command
+ *	@qc: Command that timed out
+ *
+ *	Some part of the kernel (currently, only the SCSI layer)
+ *	has noticed that the active command on port @ap has not
+ *	completed after a specified length of time.  Handle this
+ *	condition by disabling DMA (if necessary) and completing
+ *	transactions, with error if necessary.
+ *
+ *	This also handles the case of the "lost interrupt", where
+ *	for some reason (possibly hardware bug, possibly driver bug)
+ *	an interrupt was not delivered to the driver, even though the
+ *	transaction completed successfully.
+ *
+ *	TODO: kill this function once old EH is gone.
+ *
+ *	LOCKING:
+ *	Inherited from SCSI layer (none, can sleep)
+ */
+static void ata_qc_timeout(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	u8 host_stat = 0, drv_stat;
+	unsigned long flags;
+
+	DPRINTK("ENTER\n");
+
+	ap->hsm_task_state = HSM_ST_IDLE;
+
+	spin_lock_irqsave(ap->lock, flags);
+
+	switch (qc->tf.protocol) {
+
+	case ATA_PROT_DMA:
+	case ATA_PROT_ATAPI_DMA:
+		host_stat = ap->ops->bmdma_status(ap);
+
+		/* before we do anything else, clear DMA-Start bit */
+		ap->ops->bmdma_stop(qc);
+
+		/* fall through */
+
+	default:
+		ata_altstatus(ap);
+		drv_stat = ata_chk_status(ap);
+
+		/* ack bmdma irq events */
+		ap->ops->irq_clear(ap);
+
+		ata_dev_printk(qc->dev, KERN_ERR, "command 0x%x timeout, "
+			       "stat 0x%x host_stat 0x%x\n",
+			       qc->tf.command, drv_stat, host_stat);
+
+		/* complete taskfile transaction */
+		qc->err_mask |= AC_ERR_TIMEOUT;
+		break;
+	}
+
+	spin_unlock_irqrestore(ap->lock, flags);
+
+	ata_eh_qc_complete(qc);
+
+	DPRINTK("EXIT\n");
+}
+
+/**
+ *	ata_eng_timeout - Handle timeout of queued command
+ *	@ap: Port on which timed-out command is active
+ *
+ *	Some part of the kernel (currently, only the SCSI layer)
+ *	has noticed that the active command on port @ap has not
+ *	completed after a specified length of time.  Handle this
+ *	condition by disabling DMA (if necessary) and completing
+ *	transactions, with error if necessary.
+ *
+ *	This also handles the case of the "lost interrupt", where
+ *	for some reason (possibly hardware bug, possibly driver bug)
+ *	an interrupt was not delivered to the driver, even though the
+ *	transaction completed successfully.
+ *
+ *	TODO: kill this function once old EH is gone.
+ *
+ *	LOCKING:
+ *	Inherited from SCSI layer (none, can sleep)
+ */
+void ata_eng_timeout(struct ata_port *ap)
+{
+	DPRINTK("ENTER\n");
+
+	ata_qc_timeout(ata_qc_from_tag(ap, ap->active_tag));
+
+	DPRINTK("EXIT\n");
+}
+
 static int ata_eh_nr_in_flight(struct ata_port *ap)
 {
 	unsigned int tag;
@@ -812,7 +624,7 @@
 		/* some qcs have finished, give it another chance */
 		ap->fastdrain_cnt = cnt;
 		ap->fastdrain_timer.expires =
-			ata_deadline(jiffies, ATA_EH_FASTDRAIN_INTERVAL);
+			jiffies + ATA_EH_FASTDRAIN_INTERVAL;
 		add_timer(&ap->fastdrain_timer);
 	}
 
@@ -852,8 +664,7 @@
 
 	/* activate fast drain */
 	ap->fastdrain_cnt = cnt;
-	ap->fastdrain_timer.expires =
-		ata_deadline(jiffies, ATA_EH_FASTDRAIN_INTERVAL);
+	ap->fastdrain_timer.expires = jiffies + ATA_EH_FASTDRAIN_INTERVAL;
 	add_timer(&ap->fastdrain_timer);
 }
 
@@ -911,7 +722,19 @@
 	DPRINTK("port EH scheduled\n");
 }
 
-static int ata_do_link_abort(struct ata_port *ap, struct ata_link *link)
+/**
+ *	ata_port_abort - abort all qc's on the port
+ *	@ap: ATA port to abort qc's for
+ *
+ *	Abort all active qc's of @ap and schedule EH.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ *	RETURNS:
+ *	Number of aborted qc's.
+ */
+int ata_port_abort(struct ata_port *ap)
 {
 	int tag, nr_aborted = 0;
 
@@ -923,7 +746,7 @@
 	for (tag = 0; tag < ATA_MAX_QUEUE; tag++) {
 		struct ata_queued_cmd *qc = ata_qc_from_tag(ap, tag);
 
-		if (qc && (!link || qc->dev->link == link)) {
+		if (qc) {
 			qc->flags |= ATA_QCFLAG_FAILED;
 			ata_qc_complete(qc);
 			nr_aborted++;
@@ -937,40 +760,6 @@
 }
 
 /**
- *	ata_link_abort - abort all qc's on the link
- *	@link: ATA link to abort qc's for
- *
- *	Abort all active qc's active on @link and schedule EH.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
- *	RETURNS:
- *	Number of aborted qc's.
- */
-int ata_link_abort(struct ata_link *link)
-{
-	return ata_do_link_abort(link->ap, link);
-}
-
-/**
- *	ata_port_abort - abort all qc's on the port
- *	@ap: ATA port to abort qc's for
- *
- *	Abort all active qc's of @ap and schedule EH.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host_set lock)
- *
- *	RETURNS:
- *	Number of aborted qc's.
- */
-int ata_port_abort(struct ata_port *ap)
-{
-	return ata_do_link_abort(ap, NULL);
-}
-
-/**
  *	__ata_port_freeze - freeze port
  *	@ap: ATA port to freeze
  *
@@ -1004,9 +793,7 @@
  *	ata_port_freeze - abort & freeze port
  *	@ap: ATA port to freeze
  *
- *	Abort and freeze @ap.  The freeze operation must be called
- *	first, because some hardware requires special operations
- *	before the taskfile registers are accessible.
+ *	Abort and freeze @ap.
  *
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
@@ -1020,86 +807,13 @@
 
 	WARN_ON(!ap->ops->error_handler);
 
-	__ata_port_freeze(ap);
 	nr_aborted = ata_port_abort(ap);
+	__ata_port_freeze(ap);
 
 	return nr_aborted;
 }
 
 /**
- *	sata_async_notification - SATA async notification handler
- *	@ap: ATA port where async notification is received
- *
- *	Handler to be called when async notification via SDB FIS is
- *	received.  This function schedules EH if necessary.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
- *	RETURNS:
- *	1 if EH is scheduled, 0 otherwise.
- */
-int sata_async_notification(struct ata_port *ap)
-{
-	u32 sntf;
-	int rc;
-
-	if (!(ap->flags & ATA_FLAG_AN))
-		return 0;
-
-	rc = sata_scr_read(&ap->link, SCR_NOTIFICATION, &sntf);
-	if (rc == 0)
-		sata_scr_write(&ap->link, SCR_NOTIFICATION, sntf);
-
-	if (!sata_pmp_attached(ap) || rc) {
-		/* PMP is not attached or SNTF is not available */
-		if (!sata_pmp_attached(ap)) {
-			/* PMP is not attached.  Check whether ATAPI
-			 * AN is configured.  If so, notify media
-			 * change.
-			 */
-			struct ata_device *dev = ap->link.device;
-
-			if ((dev->class == ATA_DEV_ATAPI) &&
-			    (dev->flags & ATA_DFLAG_AN))
-				ata_scsi_media_change_notify(dev);
-			return 0;
-		} else {
-			/* PMP is attached but SNTF is not available.
-			 * ATAPI async media change notification is
-			 * not used.  The PMP must be reporting PHY
-			 * status change, schedule EH.
-			 */
-			ata_port_schedule_eh(ap);
-			return 1;
-		}
-	} else {
-		/* PMP is attached and SNTF is available */
-		struct ata_link *link;
-
-		/* check and notify ATAPI AN */
-		ata_for_each_link(link, ap, EDGE) {
-			if (!(sntf & (1 << link->pmp)))
-				continue;
-
-			if ((link->device->class == ATA_DEV_ATAPI) &&
-			    (link->device->flags & ATA_DFLAG_AN))
-				ata_scsi_media_change_notify(link->device);
-		}
-
-		/* If PMP is reporting that PHY status of some
-		 * downstream ports has changed, schedule EH.
-		 */
-		if (sntf & (1 << SATA_PMP_CTRL_PORT)) {
-			ata_port_schedule_eh(ap);
-			return 1;
-		}
-
-		return 0;
-	}
-}
-
-/**
  *	ata_eh_freeze_port - EH helper to freeze port
  *	@ap: ATA port to freeze
  *
@@ -1202,32 +916,6 @@
 }
 
 /**
- *	ata_dev_disable - disable ATA device
- *	@dev: ATA device to disable
- *
- *	Disable @dev.
- *
- *	Locking:
- *	EH context.
- */
-void ata_dev_disable(struct ata_device *dev)
-{
-	if (!ata_dev_enabled(dev))
-		return;
-
-	if (ata_msg_drv(dev->link->ap))
-		ata_dev_printk(dev, KERN_WARNING, "disabled\n");
-	ata_acpi_on_disable(dev);
-	ata_down_xfermask_limit(dev, ATA_DNXFER_FORCE_PIO0 | ATA_DNXFER_QUIET);
-	dev->class++;
-
-	/* From now till the next successful probe, ering is used to
-	 * track probe failures.  Clear accumulated device error info.
-	 */
-	ata_ering_clear(&dev->ering);
-}
-
-/**
  *	ata_eh_detach_dev - detach ATA device
  *	@dev: ATA device to detach
  *
@@ -1236,11 +924,9 @@
  *	LOCKING:
  *	None.
  */
-void ata_eh_detach_dev(struct ata_device *dev)
+static void ata_eh_detach_dev(struct ata_device *dev)
 {
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
-	struct ata_eh_context *ehc = &link->eh_context;
+	struct ata_port *ap = dev->ap;
 	unsigned long flags;
 
 	ata_dev_disable(dev);
@@ -1254,44 +940,51 @@
 		ap->pflags |= ATA_PFLAG_SCSI_HOTPLUG;
 	}
 
-	/* clear per-dev EH info */
-	ata_eh_clear_action(link, dev, &link->eh_info, ATA_EH_PERDEV_MASK);
-	ata_eh_clear_action(link, dev, &link->eh_context.i, ATA_EH_PERDEV_MASK);
-	ehc->saved_xfer_mode[dev->devno] = 0;
-	ehc->saved_ncq_enabled &= ~(1 << dev->devno);
+	/* clear per-dev EH actions */
+	ata_eh_clear_action(dev, &ap->eh_info, ATA_EH_PERDEV_MASK);
+	ata_eh_clear_action(dev, &ap->eh_context.i, ATA_EH_PERDEV_MASK);
 
 	spin_unlock_irqrestore(ap->lock, flags);
 }
 
 /**
  *	ata_eh_about_to_do - about to perform eh_action
- *	@link: target ATA link
+ *	@ap: target ATA port
  *	@dev: target ATA dev for per-dev action (can be NULL)
  *	@action: action about to be performed
  *
  *	Called just before performing EH actions to clear related bits
- *	in @link->eh_info such that eh actions are not unnecessarily
+ *	in @ap->eh_info such that eh actions are not unnecessarily
  *	repeated.
  *
  *	LOCKING:
  *	None.
  */
-void ata_eh_about_to_do(struct ata_link *link, struct ata_device *dev,
-			unsigned int action)
+static void ata_eh_about_to_do(struct ata_port *ap, struct ata_device *dev,
+			       unsigned int action)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_eh_info *ehi = &link->eh_info;
-	struct ata_eh_context *ehc = &link->eh_context;
 	unsigned long flags;
+	struct ata_eh_info *ehi = &ap->eh_info;
+	struct ata_eh_context *ehc = &ap->eh_context;
 
 	spin_lock_irqsave(ap->lock, flags);
 
-	ata_eh_clear_action(link, dev, ehi, action);
-
-	/* About to take EH action, set RECOVERED.  Ignore actions on
-	 * slave links as master will do them again.
+	/* Reset is represented by combination of actions and EHI
+	 * flags.  Suck in all related bits before clearing eh_info to
+	 * avoid losing requested action.
 	 */
-	if (!(ehc->i.flags & ATA_EHI_QUIET) && link != ap->slave_link)
+	if (action & ATA_EH_RESET_MASK) {
+		ehc->i.action |= ehi->action & ATA_EH_RESET_MASK;
+		ehc->i.flags |= ehi->flags & ATA_EHI_RESET_MODIFIER_MASK;
+
+		/* make sure all reset actions are cleared & clear EHI flags */
+		action |= ATA_EH_RESET_MASK;
+		ehi->flags &= ~ATA_EHI_RESET_MODIFIER_MASK;
+	}
+
+	ata_eh_clear_action(dev, ehi, action);
+
+	if (!(ehc->i.flags & ATA_EHI_QUIET))
 		ap->pflags |= ATA_PFLAG_RECOVERED;
 
 	spin_unlock_irqrestore(ap->lock, flags);
@@ -1299,22 +992,26 @@
 
 /**
  *	ata_eh_done - EH action complete
-*	@ap: target ATA port
+ *	@ap: target ATA port
  *	@dev: target ATA dev for per-dev action (can be NULL)
  *	@action: action just completed
  *
  *	Called right after performing EH actions to clear related bits
- *	in @link->eh_context.
+ *	in @ap->eh_context.
  *
  *	LOCKING:
  *	None.
  */
-void ata_eh_done(struct ata_link *link, struct ata_device *dev,
-		 unsigned int action)
+static void ata_eh_done(struct ata_port *ap, struct ata_device *dev,
+			unsigned int action)
 {
-	struct ata_eh_context *ehc = &link->eh_context;
+	/* if reset is complete, clear all reset actions & reset modifier */
+	if (action & ATA_EH_RESET_MASK) {
+		action |= ATA_EH_RESET_MASK;
+		ap->eh_context.i.flags &= ~ATA_EHI_RESET_MODIFIER_MASK;
+	}
 
-	ata_eh_clear_action(link, dev, &ehc->i, action);
+	ata_eh_clear_action(dev, &ap->eh_context.i, action);
 }
 
 /**
@@ -1331,7 +1028,7 @@
  *	RETURNS:
  *	Descriptive string for @err_mask
  */
-static const char *ata_err_string(unsigned int err_mask)
+static const char * ata_err_string(unsigned int err_mask)
 {
 	if (err_mask & AC_ERR_HOST_BUS)
 		return "host bus error";
@@ -1384,7 +1081,7 @@
 	tf.protocol = ATA_PROT_PIO;
 
 	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_FROM_DEVICE,
-				     buf, sectors * ATA_SECT_SIZE, 0);
+				     buf, sectors * ATA_SECT_SIZE);
 
 	DPRINTK("EXIT, err_mask=%x\n", err_mask);
 	return err_mask;
@@ -1408,7 +1105,7 @@
 static int ata_eh_read_log_10h(struct ata_device *dev,
 			       int *tag, struct ata_taskfile *tf)
 {
-	u8 *buf = dev->link->ap->sector_buf;
+	u8 *buf = dev->ap->sector_buf;
 	unsigned int err_mask;
 	u8 csum;
 	int i;
@@ -1445,44 +1142,12 @@
 }
 
 /**
- *	atapi_eh_tur - perform ATAPI TEST_UNIT_READY
- *	@dev: target ATAPI device
- *	@r_sense_key: out parameter for sense_key
+ *	atapi_eh_request_sense - perform ATAPI REQUEST_SENSE
+ *	@dev: device to perform REQUEST_SENSE to
+ *	@sense_buf: result sense data buffer (SCSI_SENSE_BUFFERSIZE bytes long)
  *
- *	Perform ATAPI TEST_UNIT_READY.
- *
- *	LOCKING:
- *	EH context (may sleep).
- *
- *	RETURNS:
- *	0 on success, AC_ERR_* mask on failure.
- */
-static unsigned int atapi_eh_tur(struct ata_device *dev, u8 *r_sense_key)
-{
-	u8 cdb[ATAPI_CDB_LEN] = { TEST_UNIT_READY, 0, 0, 0, 0, 0 };
-	struct ata_taskfile tf;
-	unsigned int err_mask;
-
-	ata_tf_init(dev, &tf);
-
-	tf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;
-	tf.command = ATA_CMD_PACKET;
-	tf.protocol = ATAPI_PROT_NODATA;
-
-	err_mask = ata_exec_internal(dev, &tf, cdb, DMA_NONE, NULL, 0, 0);
-	if (err_mask == AC_ERR_DEV)
-		*r_sense_key = tf.feature >> 4;
-	return err_mask;
-}
-
-/**
- *	atapi_eh_request_sense - perform ATAPI REQUEST_SENSE
- *	@dev: device to perform REQUEST_SENSE to
- *	@sense_buf: result sense data buffer (SCSI_SENSE_BUFFERSIZE bytes long)
- *	@dfl_sense_key: default sense key to use
- *
- *	Perform ATAPI REQUEST_SENSE after the device reported CHECK
- *	SENSE.  This function is EH helper.
+ *	Perform ATAPI REQUEST_SENSE after the device reported CHECK
+ *	SENSE.  This function is EH helper.
  *
  *	LOCKING:
  *	Kernel thread context (may sleep).
@@ -1490,13 +1155,13 @@
  *	RETURNS:
  *	0 on success, AC_ERR_* mask on failure
  */
-static unsigned int atapi_eh_request_sense(struct ata_device *dev,
-					   u8 *sense_buf, u8 dfl_sense_key)
+static unsigned int atapi_eh_request_sense(struct ata_queued_cmd *qc)
 {
-	u8 cdb[ATAPI_CDB_LEN] =
-		{ REQUEST_SENSE, 0, 0, 0, SCSI_SENSE_BUFFERSIZE, 0 };
-	struct ata_port *ap = dev->link->ap;
+	struct ata_device *dev = qc->dev;
+	unsigned char *sense_buf = qc->scsicmd->sense_buffer;
+	struct ata_port *ap = dev->ap;
 	struct ata_taskfile tf;
+	u8 cdb[ATAPI_CDB_LEN];
 
 	DPRINTK("ATAPI request sense\n");
 
@@ -1507,31 +1172,35 @@
 	 * for the case where they are -not- overwritten
 	 */
 	sense_buf[0] = 0x70;
-	sense_buf[2] = dfl_sense_key;
+	sense_buf[2] = qc->result_tf.feature >> 4;
 
 	/* some devices time out if garbage left in tf */
 	ata_tf_init(dev, &tf);
 
+	memset(cdb, 0, ATAPI_CDB_LEN);
+	cdb[0] = REQUEST_SENSE;
+	cdb[4] = SCSI_SENSE_BUFFERSIZE;
+
 	tf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;
 	tf.command = ATA_CMD_PACKET;
 
 	/* is it pointless to prefer PIO for "safety reasons"? */
 	if (ap->flags & ATA_FLAG_PIO_DMA) {
-		tf.protocol = ATAPI_PROT_DMA;
+		tf.protocol = ATA_PROT_ATAPI_DMA;
 		tf.feature |= ATAPI_PKT_DMA;
 	} else {
-		tf.protocol = ATAPI_PROT_PIO;
-		tf.lbam = SCSI_SENSE_BUFFERSIZE;
-		tf.lbah = 0;
+		tf.protocol = ATA_PROT_ATAPI;
+		tf.lbam = (8 * 1024) & 0xff;
+		tf.lbah = (8 * 1024) >> 8;
 	}
 
 	return ata_exec_internal(dev, &tf, cdb, DMA_FROM_DEVICE,
-				 sense_buf, SCSI_SENSE_BUFFERSIZE, 0);
+				 sense_buf, SCSI_SENSE_BUFFERSIZE);
 }
 
 /**
  *	ata_eh_analyze_serror - analyze SError for a failed port
- *	@link: ATA link to analyze SError for
+ *	@ap: ATA port to analyze SError for
  *
  *	Analyze SError if available and further determine cause of
  *	failure.
@@ -1539,39 +1208,30 @@
  *	LOCKING:
  *	None.
  */
-static void ata_eh_analyze_serror(struct ata_link *link)
+static void ata_eh_analyze_serror(struct ata_port *ap)
 {
-	struct ata_eh_context *ehc = &link->eh_context;
+	struct ata_eh_context *ehc = &ap->eh_context;
 	u32 serror = ehc->i.serror;
 	unsigned int err_mask = 0, action = 0;
-	u32 hotplug_mask;
 
-	if (serror & (SERR_PERSISTENT | SERR_DATA)) {
+	if (serror & SERR_PERSISTENT) {
 		err_mask |= AC_ERR_ATA_BUS;
-		action |= ATA_EH_RESET;
+		action |= ATA_EH_HARDRESET;
+	}
+	if (serror &
+	    (SERR_DATA_RECOVERED | SERR_COMM_RECOVERED | SERR_DATA)) {
+		err_mask |= AC_ERR_ATA_BUS;
+		action |= ATA_EH_SOFTRESET;
 	}
 	if (serror & SERR_PROTOCOL) {
 		err_mask |= AC_ERR_HSM;
-		action |= ATA_EH_RESET;
+		action |= ATA_EH_SOFTRESET;
 	}
 	if (serror & SERR_INTERNAL) {
 		err_mask |= AC_ERR_SYSTEM;
-		action |= ATA_EH_RESET;
+		action |= ATA_EH_HARDRESET;
 	}
-
-	/* Determine whether a hotplug event has occurred.  Both
-	 * SError.N/X are considered hotplug events for enabled or
-	 * host links.  For disabled PMP links, only N bit is
-	 * considered as X bit is left at 1 for link plugging.
-	 */
-	hotplug_mask = 0;
-
-	if (!(link->flags & ATA_LFLAG_DISABLED) || ata_is_host_link(link))
-		hotplug_mask = SERR_PHYRDY_CHG | SERR_DEV_XCHG;
-	else
-		hotplug_mask = SERR_PHYRDY_CHG;
-
-	if (serror & hotplug_mask)
+	if (serror & (SERR_PHYRDY_CHG | SERR_DEV_XCHG))
 		ata_ehi_hotplugged(&ehc->i);
 
 	ehc->i.err_mask |= err_mask;
@@ -1580,7 +1240,7 @@
 
 /**
  *	ata_eh_analyze_ncq_error - analyze NCQ error
- *	@link: ATA link to analyze NCQ error for
+ *	@ap: ATA port to analyze NCQ error for
  *
  *	Read log page 10h, determine the offending qc and acquire
  *	error status TF.  For NCQ device errors, all LLDDs have to do
@@ -1590,11 +1250,10 @@
  *	LOCKING:
  *	Kernel thread context (may sleep).
  */
-void ata_eh_analyze_ncq_error(struct ata_link *link)
+static void ata_eh_analyze_ncq_error(struct ata_port *ap)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_eh_context *ehc = &link->eh_context;
-	struct ata_device *dev = link->device;
+	struct ata_eh_context *ehc = &ap->eh_context;
+	struct ata_device *dev = ap->device;
 	struct ata_queued_cmd *qc;
 	struct ata_taskfile tf;
 	int tag, rc;
@@ -1604,7 +1263,7 @@
 		return;
 
 	/* is it NCQ device error? */
-	if (!link->sactive || !(ehc->i.err_mask & AC_ERR_DEV))
+	if (!ap->sactive || !(ehc->i.err_mask & AC_ERR_DEV))
 		return;
 
 	/* has LLDD analyzed already? */
@@ -1619,16 +1278,15 @@
 	}
 
 	/* okay, this error is ours */
-	memset(&tf, 0, sizeof(tf));
 	rc = ata_eh_read_log_10h(dev, &tag, &tf);
 	if (rc) {
-		ata_link_printk(link, KERN_ERR, "failed to read log page 10h "
+		ata_port_printk(ap, KERN_ERR, "failed to read log page 10h "
 				"(errno=%d)\n", rc);
 		return;
 	}
 
-	if (!(link->sactive & (1 << tag))) {
-		ata_link_printk(link, KERN_ERR, "log page 10h reported "
+	if (!(ap->sactive & (1 << tag))) {
+		ata_port_printk(ap, KERN_ERR, "log page 10h reported "
 				"inactive tag %d\n", tag);
 		return;
 	}
@@ -1636,7 +1294,6 @@
 	/* we've got the perpetrator, condemn it */
 	qc = __ata_qc_from_tag(ap, tag);
 	memcpy(&qc->result_tf, &tf, sizeof(tf));
-	qc->result_tf.flags = ATA_TFLAG_ISADDR | ATA_TFLAG_LBA | ATA_TFLAG_LBA48;
 	qc->err_mask |= AC_ERR_DEV | AC_ERR_NCQ;
 	ehc->i.err_mask &= ~AC_ERR_DEV;
 }
@@ -1664,7 +1321,7 @@
 
 	if ((stat & (ATA_BUSY | ATA_DRQ | ATA_DRDY)) != ATA_DRDY) {
 		qc->err_mask |= AC_ERR_HSM;
-		return ATA_EH_RESET;
+		return ATA_EH_SOFTRESET;
 	}
 
 	if (stat & (ATA_ERR | ATA_DF))
@@ -1684,9 +1341,7 @@
 
 	case ATA_DEV_ATAPI:
 		if (!(qc->ap->pflags & ATA_PFLAG_FROZEN)) {
-			tmp = atapi_eh_request_sense(qc->dev,
-						qc->scsicmd->sense_buffer,
-						qc->result_tf.feature >> 4);
+			tmp = atapi_eh_request_sense(qc);
 			if (!tmp) {
 				/* ATA_QCFLAG_SENSE_VALID is used to
 				 * tell atapi_qc_complete() that sense
@@ -1702,34 +1357,25 @@
 	}
 
 	if (qc->err_mask & (AC_ERR_HSM | AC_ERR_TIMEOUT | AC_ERR_ATA_BUS))
-		action |= ATA_EH_RESET;
+		action |= ATA_EH_SOFTRESET;
 
 	return action;
 }
 
-static int ata_eh_categorize_error(unsigned int eflags, unsigned int err_mask,
-				   int *xfer_ok)
+static int ata_eh_categorize_error(int is_io, unsigned int err_mask)
 {
-	int base = 0;
-
-	if (!(eflags & ATA_EFLAG_DUBIOUS_XFER))
-		*xfer_ok = 1;
-
-	if (!*xfer_ok)
-		base = ATA_ECAT_DUBIOUS_NONE;
-
 	if (err_mask & AC_ERR_ATA_BUS)
-		return base + ATA_ECAT_ATA_BUS;
+		return 1;
 
 	if (err_mask & AC_ERR_TIMEOUT)
-		return base + ATA_ECAT_TOUT_HSM;
+		return 2;
 
-	if (eflags & ATA_EFLAG_IS_IO) {
+	if (is_io) {
 		if (err_mask & AC_ERR_HSM)
-			return base + ATA_ECAT_TOUT_HSM;
+			return 2;
 		if ((err_mask &
 		     (AC_ERR_DEV|AC_ERR_MEDIA|AC_ERR_INVALID)) == AC_ERR_DEV)
-			return base + ATA_ECAT_UNK_DEV;
+			return 3;
 	}
 
 	return 0;
@@ -1737,22 +1383,18 @@
 
 struct speed_down_verdict_arg {
 	u64 since;
-	int xfer_ok;
-	int nr_errors[ATA_ECAT_NR];
+	int nr_errors[4];
 };
 
 static int speed_down_verdict_cb(struct ata_ering_entry *ent, void *void_arg)
 {
 	struct speed_down_verdict_arg *arg = void_arg;
-	int cat;
+	int cat = ata_eh_categorize_error(ent->is_io, ent->err_mask);
 
 	if (ent->timestamp < arg->since)
 		return -1;
 
-	cat = ata_eh_categorize_error(ent->eflags, ent->err_mask,
-				      &arg->xfer_ok);
 	arg->nr_errors[cat]++;
-
 	return 0;
 }
 
@@ -1764,48 +1406,22 @@
  *	whether NCQ needs to be turned off, transfer speed should be
  *	stepped down, or falling back to PIO is necessary.
  *
- *	ECAT_ATA_BUS	: ATA_BUS error for any command
- *
- *	ECAT_TOUT_HSM	: TIMEOUT for any command or HSM violation for
- *			  IO commands
- *
- *	ECAT_UNK_DEV	: Unknown DEV error for IO commands
+ *	Cat-1 is ATA_BUS error for any command.
  *
- *	ECAT_DUBIOUS_*	: Identical to above three but occurred while
- *			  data transfer hasn't been verified.
+ *	Cat-2 is TIMEOUT for any command or HSM violation for known
+ *	supported commands.
  *
- *	Verdicts are
+ *	Cat-3 is is unclassified DEV error for known supported
+ *	command.
  *
- *	NCQ_OFF		: Turn off NCQ.
+ *	NCQ needs to be turned off if there have been more than 3
+ *	Cat-2 + Cat-3 errors during last 10 minutes.
  *
- *	SPEED_DOWN	: Speed down transfer speed but don't fall back
- *			  to PIO.
+ *	Speed down is necessary if there have been more than 3 Cat-1 +
+ *	Cat-2 errors or 10 Cat-3 errors during last 10 minutes.
  *
- *	FALLBACK_TO_PIO	: Fall back to PIO.
- *
- *	Even if multiple verdicts are returned, only one action is
- *	taken per error.  An action triggered by non-DUBIOUS errors
- *	clears ering, while one triggered by DUBIOUS_* errors doesn't.
- *	This is to expedite speed down decisions right after device is
- *	initially configured.
- *
- *	The followings are speed down rules.  #1 and #2 deal with
- *	DUBIOUS errors.
- *
- *	1. If more than one DUBIOUS_ATA_BUS or DUBIOUS_TOUT_HSM errors
- *	   occurred during last 5 mins, SPEED_DOWN and FALLBACK_TO_PIO.
- *
- *	2. If more than one DUBIOUS_TOUT_HSM or DUBIOUS_UNK_DEV errors
- *	   occurred during last 5 mins, NCQ_OFF.
- *
- *	3. If more than 8 ATA_BUS, TOUT_HSM or UNK_DEV errors
- *	   ocurred during last 5 mins, FALLBACK_TO_PIO
- *
- *	4. If more than 3 TOUT_HSM or UNK_DEV errors occurred
- *	   during last 10 mins, NCQ_OFF.
- *
- *	5. If more than 3 ATA_BUS or TOUT_HSM errors, or more than 6
- *	   UNK_DEV errors occurred during last 10 mins, SPEED_DOWN.
+ *	Falling back to PIO mode is necessary if there have been more
+ *	than 10 Cat-1 + Cat-2 + Cat-3 errors during last 5 minutes.
  *
  *	LOCKING:
  *	Inherited from caller.
@@ -1820,46 +1436,31 @@
 	struct speed_down_verdict_arg arg;
 	unsigned int verdict = 0;
 
-	/* scan past 5 mins of error history */
-	memset(&arg, 0, sizeof(arg));
-	arg.since = j64 - min(j64, j5mins);
-	ata_ering_map(&dev->ering, speed_down_verdict_cb, &arg);
-
-	if (arg.nr_errors[ATA_ECAT_DUBIOUS_ATA_BUS] +
-	    arg.nr_errors[ATA_ECAT_DUBIOUS_TOUT_HSM] > 1)
-		verdict |= ATA_EH_SPDN_SPEED_DOWN |
-			ATA_EH_SPDN_FALLBACK_TO_PIO | ATA_EH_SPDN_KEEP_ERRORS;
-
-	if (arg.nr_errors[ATA_ECAT_DUBIOUS_TOUT_HSM] +
-	    arg.nr_errors[ATA_ECAT_DUBIOUS_UNK_DEV] > 1)
-		verdict |= ATA_EH_SPDN_NCQ_OFF | ATA_EH_SPDN_KEEP_ERRORS;
-
-	if (arg.nr_errors[ATA_ECAT_ATA_BUS] +
-	    arg.nr_errors[ATA_ECAT_TOUT_HSM] +
-	    arg.nr_errors[ATA_ECAT_UNK_DEV] > 6)
-		verdict |= ATA_EH_SPDN_FALLBACK_TO_PIO;
-
 	/* scan past 10 mins of error history */
 	memset(&arg, 0, sizeof(arg));
 	arg.since = j64 - min(j64, j10mins);
 	ata_ering_map(&dev->ering, speed_down_verdict_cb, &arg);
 
-	if (arg.nr_errors[ATA_ECAT_TOUT_HSM] +
-	    arg.nr_errors[ATA_ECAT_UNK_DEV] > 3)
+	if (arg.nr_errors[2] + arg.nr_errors[3] > 3)
 		verdict |= ATA_EH_SPDN_NCQ_OFF;
-
-	if (arg.nr_errors[ATA_ECAT_ATA_BUS] +
-	    arg.nr_errors[ATA_ECAT_TOUT_HSM] > 3 ||
-	    arg.nr_errors[ATA_ECAT_UNK_DEV] > 6)
+	if (arg.nr_errors[1] + arg.nr_errors[2] > 3 || arg.nr_errors[3] > 10)
 		verdict |= ATA_EH_SPDN_SPEED_DOWN;
 
+	/* scan past 3 mins of error history */
+	memset(&arg, 0, sizeof(arg));
+	arg.since = j64 - min(j64, j5mins);
+	ata_ering_map(&dev->ering, speed_down_verdict_cb, &arg);
+
+	if (arg.nr_errors[1] + arg.nr_errors[2] + arg.nr_errors[3] > 10)
+		verdict |= ATA_EH_SPDN_FALLBACK_TO_PIO;
+
 	return verdict;
 }
 
 /**
  *	ata_eh_speed_down - record error and speed down if necessary
  *	@dev: Failed device
- *	@eflags: mask of ATA_EFLAG_* flags
+ *	@is_io: Did the device fail during normal IO?
  *	@err_mask: err_mask of the error
  *
  *	Record error and examine error history to determine whether
@@ -1873,20 +1474,18 @@
  *	RETURNS:
  *	Determined recovery action.
  */
-static unsigned int ata_eh_speed_down(struct ata_device *dev,
-				unsigned int eflags, unsigned int err_mask)
+static unsigned int ata_eh_speed_down(struct ata_device *dev, int is_io,
+				      unsigned int err_mask)
 {
-	struct ata_link *link = ata_dev_phys_link(dev);
-	int xfer_ok = 0;
 	unsigned int verdict;
 	unsigned int action = 0;
 
 	/* don't bother if Cat-0 error */
-	if (ata_eh_categorize_error(eflags, err_mask, &xfer_ok) == 0)
+	if (ata_eh_categorize_error(is_io, err_mask) == 0)
 		return 0;
 
 	/* record error and determine whether speed down is necessary */
-	ata_ering_record(&dev->ering, eflags, err_mask);
+	ata_ering_record(&dev->ering, is_io, err_mask);
 	verdict = ata_eh_speed_down_verdict(dev);
 
 	/* turn off NCQ? */
@@ -1902,8 +1501,8 @@
 	/* speed down? */
 	if (verdict & ATA_EH_SPDN_SPEED_DOWN) {
 		/* speed down SATA link speed if possible */
-		if (sata_down_spd_limit(link, 0) == 0) {
-			action |= ATA_EH_RESET;
+		if (sata_down_spd_limit(dev->ap) == 0) {
+			action |= ATA_EH_HARDRESET;
 			goto done;
 		}
 
@@ -1923,21 +1522,21 @@
 			dev->spdn_cnt++;
 
 			if (ata_down_xfermask_limit(dev, sel) == 0) {
-				action |= ATA_EH_RESET;
+				action |= ATA_EH_SOFTRESET;
 				goto done;
 			}
 		}
 	}
 
 	/* Fall back to PIO?  Slowing down to PIO is meaningless for
-	 * SATA ATA devices.  Consider it only for PATA and SATAPI.
+	 * SATA.  Consider it only for PATA.
 	 */
 	if ((verdict & ATA_EH_SPDN_FALLBACK_TO_PIO) && (dev->spdn_cnt >= 2) &&
-	    (link->ap->cbl != ATA_CBL_SATA || dev->class == ATA_DEV_ATAPI) &&
+	    (dev->ap->cbl != ATA_CBL_SATA) &&
 	    (dev->xfer_shift != ATA_SHIFT_PIO)) {
 		if (ata_down_xfermask_limit(dev, ATA_DNXFER_FORCE_PIO) == 0) {
 			dev->spdn_cnt = 0;
-			action |= ATA_EH_RESET;
+			action |= ATA_EH_SOFTRESET;
 			goto done;
 		}
 	}
@@ -1945,29 +1544,26 @@
 	return 0;
  done:
 	/* device has been slowed down, blow error history */
-	if (!(verdict & ATA_EH_SPDN_KEEP_ERRORS))
-		ata_ering_clear(&dev->ering);
+	ata_ering_clear(&dev->ering);
 	return action;
 }
 
 /**
- *	ata_eh_link_autopsy - analyze error and determine recovery action
- *	@link: host link to perform autopsy on
+ *	ata_eh_autopsy - analyze error and determine recovery action
+ *	@ap: ATA port to perform autopsy on
  *
- *	Analyze why @link failed and determine which recovery actions
- *	are needed.  This function also sets more detailed AC_ERR_*
- *	values and fills sense data for ATAPI CHECK SENSE.
+ *	Analyze why @ap failed and determine which recovery action is
+ *	needed.  This function also sets more detailed AC_ERR_* values
+ *	and fills sense data for ATAPI CHECK SENSE.
  *
  *	LOCKING:
  *	Kernel thread context (may sleep).
  */
-static void ata_eh_link_autopsy(struct ata_link *link)
+static void ata_eh_autopsy(struct ata_port *ap)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_eh_context *ehc = &link->eh_context;
-	struct ata_device *dev;
-	unsigned int all_err_mask = 0, eflags = 0;
-	int tag;
+	struct ata_eh_context *ehc = &ap->eh_context;
+	unsigned int all_err_mask = 0;
+	int tag, is_io = 0;
 	u32 serror;
 	int rc;
 
@@ -1977,19 +1573,19 @@
 		return;
 
 	/* obtain and analyze SError */
-	rc = sata_scr_read(link, SCR_ERROR, &serror);
+	rc = sata_scr_read(ap, SCR_ERROR, &serror);
 	if (rc == 0) {
 		ehc->i.serror |= serror;
-		ata_eh_analyze_serror(link);
+		ata_eh_analyze_serror(ap);
 	} else if (rc != -EOPNOTSUPP) {
-		/* SError read failed, force reset and probing */
-		ehc->i.probe_mask |= ATA_ALL_DEVICES;
-		ehc->i.action |= ATA_EH_RESET;
+		/* SError read failed, force hardreset and probing */
+		ata_ehi_schedule_probe(&ehc->i);
+		ehc->i.action |= ATA_EH_HARDRESET;
 		ehc->i.err_mask |= AC_ERR_OTHER;
 	}
 
 	/* analyze NCQ failure */
-	ata_eh_analyze_ncq_error(link);
+	ata_eh_analyze_ncq_error(ap);
 
 	/* any real error trumps AC_ERR_OTHER */
 	if (ehc->i.err_mask & ~AC_ERR_OTHER)
@@ -2000,8 +1596,7 @@
 	for (tag = 0; tag < ATA_MAX_QUEUE; tag++) {
 		struct ata_queued_cmd *qc = __ata_qc_from_tag(ap, tag);
 
-		if (!(qc->flags & ATA_QCFLAG_FAILED) ||
-		    ata_dev_phys_link(qc->dev) != link)
+		if (!(qc->flags & ATA_QCFLAG_FAILED))
 			continue;
 
 		/* inherit upper level err_mask */
@@ -2020,234 +1615,55 @@
 			qc->err_mask &= ~AC_ERR_OTHER;
 
 		/* SENSE_VALID trumps dev/unknown error and revalidation */
-		if (qc->flags & ATA_QCFLAG_SENSE_VALID)
+		if (qc->flags & ATA_QCFLAG_SENSE_VALID) {
 			qc->err_mask &= ~(AC_ERR_DEV | AC_ERR_OTHER);
-
-		/* determine whether the command is worth retrying */
-		if (qc->flags & ATA_QCFLAG_IO ||
-		    (!(qc->err_mask & AC_ERR_INVALID) &&
-		     qc->err_mask != AC_ERR_DEV))
-			qc->flags |= ATA_QCFLAG_RETRY;
+			ehc->i.action &= ~ATA_EH_REVALIDATE;
+		}
 
 		/* accumulate error info */
 		ehc->i.dev = qc->dev;
 		all_err_mask |= qc->err_mask;
 		if (qc->flags & ATA_QCFLAG_IO)
-			eflags |= ATA_EFLAG_IS_IO;
+			is_io = 1;
 	}
 
 	/* enforce default EH actions */
 	if (ap->pflags & ATA_PFLAG_FROZEN ||
 	    all_err_mask & (AC_ERR_HSM | AC_ERR_TIMEOUT))
-		ehc->i.action |= ATA_EH_RESET;
-	else if (((eflags & ATA_EFLAG_IS_IO) && all_err_mask) ||
-		 (!(eflags & ATA_EFLAG_IS_IO) && (all_err_mask & ~AC_ERR_DEV)))
+		ehc->i.action |= ATA_EH_SOFTRESET;
+	else if (all_err_mask)
 		ehc->i.action |= ATA_EH_REVALIDATE;
 
-	/* If we have offending qcs and the associated failed device,
-	 * perform per-dev EH action only on the offending device.
-	 */
+	/* if we have offending qcs and the associated failed device */
 	if (ehc->i.dev) {
+		/* speed down */
+		ehc->i.action |= ata_eh_speed_down(ehc->i.dev, is_io,
+						   all_err_mask);
+
+		/* perform per-dev EH action only on the offending device */
 		ehc->i.dev_action[ehc->i.dev->devno] |=
 			ehc->i.action & ATA_EH_PERDEV_MASK;
 		ehc->i.action &= ~ATA_EH_PERDEV_MASK;
 	}
 
-	/* propagate timeout to host link */
-	if ((all_err_mask & AC_ERR_TIMEOUT) && !ata_is_host_link(link))
-		ap->link.eh_context.i.err_mask |= AC_ERR_TIMEOUT;
-
-	/* record error and consider speeding down */
-	dev = ehc->i.dev;
-	if (!dev && ((ata_link_max_devices(link) == 1 &&
-		      ata_dev_enabled(link->device))))
-	    dev = link->device;
-
-	if (dev) {
-		if (dev->flags & ATA_DFLAG_DUBIOUS_XFER)
-			eflags |= ATA_EFLAG_DUBIOUS_XFER;
-		ehc->i.action |= ata_eh_speed_down(dev, eflags, all_err_mask);
-	}
-
 	DPRINTK("EXIT\n");
 }
 
 /**
- *	ata_eh_autopsy - analyze error and determine recovery action
- *	@ap: host port to perform autopsy on
- *
- *	Analyze all links of @ap and determine why they failed and
- *	which recovery actions are needed.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- */
-void ata_eh_autopsy(struct ata_port *ap)
-{
-	struct ata_link *link;
-
-	ata_for_each_link(link, ap, EDGE)
-		ata_eh_link_autopsy(link);
-
-	/* Handle the frigging slave link.  Autopsy is done similarly
-	 * but actions and flags are transferred over to the master
-	 * link and handled from there.
-	 */
-	if (ap->slave_link) {
-		struct ata_eh_context *mehc = &ap->link.eh_context;
-		struct ata_eh_context *sehc = &ap->slave_link->eh_context;
-
-		/* transfer control flags from master to slave */
-		sehc->i.flags |= mehc->i.flags & ATA_EHI_TO_SLAVE_MASK;
-
-		/* perform autopsy on the slave link */
-		ata_eh_link_autopsy(ap->slave_link);
-
-		/* transfer actions from slave to master and clear slave */
-		ata_eh_about_to_do(ap->slave_link, NULL, ATA_EH_ALL_ACTIONS);
-		mehc->i.action		|= sehc->i.action;
-		mehc->i.dev_action[1]	|= sehc->i.dev_action[1];
-		mehc->i.flags		|= sehc->i.flags;
-		ata_eh_done(ap->slave_link, NULL, ATA_EH_ALL_ACTIONS);
-	}
-
-	/* Autopsy of fanout ports can affect host link autopsy.
-	 * Perform host link autopsy last.
-	 */
-	if (sata_pmp_attached(ap))
-		ata_eh_link_autopsy(&ap->link);
-}
-
-/**
- *	ata_get_cmd_descript - get description for ATA command
- *	@command: ATA command code to get description for
- *
- *	Return a textual description of the given command, or NULL if the
- *	command is not known.
- *
- *	LOCKING:
- *	None
- */
-const char *ata_get_cmd_descript(u8 command)
-{
-#ifdef CONFIG_ATA_VERBOSE_ERROR
-	static const struct
-	{
-		u8 command;
-		const char *text;
-	} cmd_descr[] = {
-		{ ATA_CMD_DEV_RESET,		"DEVICE RESET" },
-		{ ATA_CMD_CHK_POWER, 		"CHECK POWER MODE" },
-		{ ATA_CMD_STANDBY, 		"STANDBY" },
-		{ ATA_CMD_IDLE, 		"IDLE" },
-		{ ATA_CMD_EDD, 			"EXECUTE DEVICE DIAGNOSTIC" },
-		{ ATA_CMD_DOWNLOAD_MICRO,   	"DOWNLOAD MICROCODE" },
-		{ ATA_CMD_NOP,			"NOP" },
-		{ ATA_CMD_FLUSH, 		"FLUSH CACHE" },
-		{ ATA_CMD_FLUSH_EXT, 		"FLUSH CACHE EXT" },
-		{ ATA_CMD_ID_ATA,  		"IDENTIFY DEVICE" },
-		{ ATA_CMD_ID_ATAPI, 		"IDENTIFY PACKET DEVICE" },
-		{ ATA_CMD_SERVICE, 		"SERVICE" },
-		{ ATA_CMD_READ, 		"READ DMA" },
-		{ ATA_CMD_READ_EXT, 		"READ DMA EXT" },
-		{ ATA_CMD_READ_QUEUED, 		"READ DMA QUEUED" },
-		{ ATA_CMD_READ_STREAM_EXT, 	"READ STREAM EXT" },
-		{ ATA_CMD_READ_STREAM_DMA_EXT,  "READ STREAM DMA EXT" },
-		{ ATA_CMD_WRITE, 		"WRITE DMA" },
-		{ ATA_CMD_WRITE_EXT, 		"WRITE DMA EXT" },
-		{ ATA_CMD_WRITE_QUEUED, 	"WRITE DMA QUEUED EXT" },
-		{ ATA_CMD_WRITE_STREAM_EXT, 	"WRITE STREAM EXT" },
-		{ ATA_CMD_WRITE_STREAM_DMA_EXT, "WRITE STREAM DMA EXT" },
-		{ ATA_CMD_WRITE_FUA_EXT,	"WRITE DMA FUA EXT" },
-		{ ATA_CMD_WRITE_QUEUED_FUA_EXT, "WRITE DMA QUEUED FUA EXT" },
-		{ ATA_CMD_FPDMA_READ,		"READ FPDMA QUEUED" },
-		{ ATA_CMD_FPDMA_WRITE,		"WRITE FPDMA QUEUED" },
-		{ ATA_CMD_PIO_READ,		"READ SECTOR(S)" },
-		{ ATA_CMD_PIO_READ_EXT,		"READ SECTOR(S) EXT" },
-		{ ATA_CMD_PIO_WRITE,		"WRITE SECTOR(S)" },
-		{ ATA_CMD_PIO_WRITE_EXT,	"WRITE SECTOR(S) EXT" },
-		{ ATA_CMD_READ_MULTI,		"READ MULTIPLE" },
-		{ ATA_CMD_READ_MULTI_EXT,	"READ MULTIPLE EXT" },
-		{ ATA_CMD_WRITE_MULTI,		"WRITE MULTIPLE" },
-		{ ATA_CMD_WRITE_MULTI_EXT,	"WRITE MULTIPLE EXT" },
-		{ ATA_CMD_WRITE_MULTI_FUA_EXT, 	"WRITE MULTIPLE FUA EXT" },
-		{ ATA_CMD_SET_FEATURES,		"SET FEATURES" },
-		{ ATA_CMD_SET_MULTI,		"SET MULTIPLE MODE" },
-		{ ATA_CMD_VERIFY,		"READ VERIFY SECTOR(S)" },
-		{ ATA_CMD_VERIFY_EXT,		"READ VERIFY SECTOR(S) EXT" },
-		{ ATA_CMD_WRITE_UNCORR_EXT,	"WRITE UNCORRECTABLE EXT" },
-		{ ATA_CMD_STANDBYNOW1,		"STANDBY IMMEDIATE" },
-		{ ATA_CMD_IDLEIMMEDIATE,	"IDLE IMMEDIATE" },
-		{ ATA_CMD_SLEEP,		"SLEEP" },
-		{ ATA_CMD_INIT_DEV_PARAMS,	"INITIALIZE DEVICE PARAMETERS" },
-		{ ATA_CMD_READ_NATIVE_MAX,	"READ NATIVE MAX ADDRESS" },
-		{ ATA_CMD_READ_NATIVE_MAX_EXT,	"READ NATIVE MAX ADDRESS EXT" },
-		{ ATA_CMD_SET_MAX,		"SET MAX ADDRESS" },
-		{ ATA_CMD_SET_MAX_EXT,		"SET MAX ADDRESS EXT" },
-		{ ATA_CMD_READ_LOG_EXT,		"READ LOG EXT" },
-		{ ATA_CMD_WRITE_LOG_EXT,	"WRITE LOG EXT" },
-		{ ATA_CMD_READ_LOG_DMA_EXT,	"READ LOG DMA EXT" },
-		{ ATA_CMD_WRITE_LOG_DMA_EXT, 	"WRITE LOG DMA EXT" },
-		{ ATA_CMD_TRUSTED_RCV,		"TRUSTED RECEIVE" },
-		{ ATA_CMD_TRUSTED_RCV_DMA, 	"TRUSTED RECEIVE DMA" },
-		{ ATA_CMD_TRUSTED_SND,		"TRUSTED SEND" },
-		{ ATA_CMD_TRUSTED_SND_DMA, 	"TRUSTED SEND DMA" },
-		{ ATA_CMD_PMP_READ,		"READ BUFFER" },
-		{ ATA_CMD_PMP_WRITE,		"WRITE BUFFER" },
-		{ ATA_CMD_CONF_OVERLAY,		"DEVICE CONFIGURATION OVERLAY" },
-		{ ATA_CMD_SEC_SET_PASS,		"SECURITY SET PASSWORD" },
-		{ ATA_CMD_SEC_UNLOCK,		"SECURITY UNLOCK" },
-		{ ATA_CMD_SEC_ERASE_PREP,	"SECURITY ERASE PREPARE" },
-		{ ATA_CMD_SEC_ERASE_UNIT,	"SECURITY ERASE UNIT" },
-		{ ATA_CMD_SEC_FREEZE_LOCK,	"SECURITY FREEZE LOCK" },
-		{ ATA_CMD_SEC_DISABLE_PASS,	"SECURITY DISABLE PASSWORD" },
-		{ ATA_CMD_CONFIG_STREAM,	"CONFIGURE STREAM" },
-		{ ATA_CMD_SMART,		"SMART" },
-		{ ATA_CMD_MEDIA_LOCK,		"DOOR LOCK" },
-		{ ATA_CMD_MEDIA_UNLOCK,		"DOOR UNLOCK" },
-		{ ATA_CMD_CHK_MED_CRD_TYP, 	"CHECK MEDIA CARD TYPE" },
-		{ ATA_CMD_CFA_REQ_EXT_ERR, 	"CFA REQUEST EXTENDED ERROR" },
-		{ ATA_CMD_CFA_WRITE_NE,		"CFA WRITE SECTORS WITHOUT ERASE" },
-		{ ATA_CMD_CFA_TRANS_SECT,	"CFA TRANSLATE SECTOR" },
-		{ ATA_CMD_CFA_ERASE,		"CFA ERASE SECTORS" },
-		{ ATA_CMD_CFA_WRITE_MULT_NE, 	"CFA WRITE MULTIPLE WITHOUT ERASE" },
-		{ ATA_CMD_READ_LONG,		"READ LONG (with retries)" },
-		{ ATA_CMD_READ_LONG_ONCE,	"READ LONG (without retries)" },
-		{ ATA_CMD_WRITE_LONG,		"WRITE LONG (with retries)" },
-		{ ATA_CMD_WRITE_LONG_ONCE,	"WRITE LONG (without retries)" },
-		{ ATA_CMD_RESTORE,		"RECALIBRATE" },
-		{ 0,				NULL } /* terminate list */
-	};
-
-	unsigned int i;
-	for (i = 0; cmd_descr[i].text; i++)
-		if (cmd_descr[i].command == command)
-			return cmd_descr[i].text;
-#endif
-
-	return NULL;
-}
-
-/**
- *	ata_eh_link_report - report error handling to user
- *	@link: ATA link EH is going on
+ *	ata_eh_report - report error handling to user
+ *	@ap: ATA port EH is going on
  *
  *	Report EH to user.
  *
  *	LOCKING:
  *	None.
  */
-static void ata_eh_link_report(struct ata_link *link)
+static void ata_eh_report(struct ata_port *ap)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_eh_context *ehc = &link->eh_context;
+	struct ata_eh_context *ehc = &ap->eh_context;
 	const char *frozen, *desc;
-	char tries_buf[6];
 	int tag, nr_failed = 0;
 
-	if (ehc->i.flags & ATA_EHI_QUIET)
-		return;
-
 	desc = NULL;
 	if (ehc->i.desc[0] != '\0')
 		desc = ehc->i.desc;
@@ -2255,10 +1671,7 @@
 	for (tag = 0; tag < ATA_MAX_QUEUE; tag++) {
 		struct ata_queued_cmd *qc = __ata_qc_from_tag(ap, tag);
 
-		if (!(qc->flags & ATA_QCFLAG_FAILED) ||
-		    ata_dev_phys_link(qc->dev) != link ||
-		    ((qc->flags & ATA_QCFLAG_QUIET) &&
-		     qc->err_mask == AC_ERR_DEV))
+		if (!(qc->flags & ATA_QCFLAG_FAILED))
 			continue;
 		if (qc->flags & ATA_QCFLAG_SENSE_VALID && !qc->err_mask)
 			continue;
@@ -2273,636 +1686,274 @@
 	if (ap->pflags & ATA_PFLAG_FROZEN)
 		frozen = " frozen";
 
-	memset(tries_buf, 0, sizeof(tries_buf));
-	if (ap->eh_tries < ATA_EH_MAX_TRIES)
-		snprintf(tries_buf, sizeof(tries_buf) - 1, " t%d",
-			 ap->eh_tries);
-
 	if (ehc->i.dev) {
 		ata_dev_printk(ehc->i.dev, KERN_ERR, "exception Emask 0x%x "
-			       "SAct 0x%x SErr 0x%x action 0x%x%s%s\n",
-			       ehc->i.err_mask, link->sactive, ehc->i.serror,
-			       ehc->i.action, frozen, tries_buf);
+			       "SAct 0x%x SErr 0x%x action 0x%x%s\n",
+			       ehc->i.err_mask, ap->sactive, ehc->i.serror,
+			       ehc->i.action, frozen);
 		if (desc)
 			ata_dev_printk(ehc->i.dev, KERN_ERR, "%s\n", desc);
 	} else {
-		ata_link_printk(link, KERN_ERR, "exception Emask 0x%x "
-				"SAct 0x%x SErr 0x%x action 0x%x%s%s\n",
-				ehc->i.err_mask, link->sactive, ehc->i.serror,
-				ehc->i.action, frozen, tries_buf);
+		ata_port_printk(ap, KERN_ERR, "exception Emask 0x%x "
+				"SAct 0x%x SErr 0x%x action 0x%x%s\n",
+				ehc->i.err_mask, ap->sactive, ehc->i.serror,
+				ehc->i.action, frozen);
 		if (desc)
-			ata_link_printk(link, KERN_ERR, "%s\n", desc);
+			ata_port_printk(ap, KERN_ERR, "%s\n", desc);
 	}
 
-#ifdef CONFIG_ATA_VERBOSE_ERROR
-	if (ehc->i.serror)
-		ata_link_printk(link, KERN_ERR,
-		  "SError: { %s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s}\n",
-		  ehc->i.serror & SERR_DATA_RECOVERED ? "RecovData " : "",
-		  ehc->i.serror & SERR_COMM_RECOVERED ? "RecovComm " : "",
-		  ehc->i.serror & SERR_DATA ? "UnrecovData " : "",
-		  ehc->i.serror & SERR_PERSISTENT ? "Persist " : "",
-		  ehc->i.serror & SERR_PROTOCOL ? "Proto " : "",
-		  ehc->i.serror & SERR_INTERNAL ? "HostInt " : "",
-		  ehc->i.serror & SERR_PHYRDY_CHG ? "PHYRdyChg " : "",
-		  ehc->i.serror & SERR_PHY_INT_ERR ? "PHYInt " : "",
-		  ehc->i.serror & SERR_COMM_WAKE ? "CommWake " : "",
-		  ehc->i.serror & SERR_10B_8B_ERR ? "10B8B " : "",
-		  ehc->i.serror & SERR_DISPARITY ? "Dispar " : "",
-		  ehc->i.serror & SERR_CRC ? "BadCRC " : "",
-		  ehc->i.serror & SERR_HANDSHAKE ? "Handshk " : "",
-		  ehc->i.serror & SERR_LINK_SEQ_ERR ? "LinkSeq " : "",
-		  ehc->i.serror & SERR_TRANS_ST_ERROR ? "TrStaTrns " : "",
-		  ehc->i.serror & SERR_UNRECOG_FIS ? "UnrecFIS " : "",
-		  ehc->i.serror & SERR_DEV_XCHG ? "DevExch " : "");
-#endif
-
 	for (tag = 0; tag < ATA_MAX_QUEUE; tag++) {
+		static const char *dma_str[] = {
+			[DMA_BIDIRECTIONAL]	= "bidi",
+			[DMA_TO_DEVICE]		= "out",
+			[DMA_FROM_DEVICE]	= "in",
+			[DMA_NONE]		= "",
+		};
 		struct ata_queued_cmd *qc = __ata_qc_from_tag(ap, tag);
 		struct ata_taskfile *cmd = &qc->tf, *res = &qc->result_tf;
-		const u8 *cdb = qc->cdb;
-		char data_buf[20] = "";
-		char cdb_buf[70] = "";
 
-		if (!(qc->flags & ATA_QCFLAG_FAILED) ||
-		    ata_dev_phys_link(qc->dev) != link || !qc->err_mask)
+		if (!(qc->flags & ATA_QCFLAG_FAILED) || !qc->err_mask)
 			continue;
 
-		if (qc->dma_dir != DMA_NONE) {
-			static const char *dma_str[] = {
-				[DMA_BIDIRECTIONAL]	= "bidi",
-				[DMA_TO_DEVICE]		= "out",
-				[DMA_FROM_DEVICE]	= "in",
-			};
-			static const char *prot_str[] = {
-				[ATA_PROT_PIO]		= "pio",
-				[ATA_PROT_DMA]		= "dma",
-				[ATA_PROT_NCQ]		= "ncq",
-				[ATAPI_PROT_PIO]	= "pio",
-				[ATAPI_PROT_DMA]	= "dma",
-			};
-
-			snprintf(data_buf, sizeof(data_buf), " %s %u %s",
-				 prot_str[qc->tf.protocol], qc->nbytes,
-				 dma_str[qc->dma_dir]);
-		}
-
-		if (ata_is_atapi(qc->tf.protocol)) {
-			if (qc->scsicmd)
-				scsi_print_command(qc->scsicmd);
-			else
-				snprintf(cdb_buf, sizeof(cdb_buf),
-				 "cdb %02x %02x %02x %02x %02x %02x %02x %02x  "
-				 "%02x %02x %02x %02x %02x %02x %02x %02x\n         ",
-				 cdb[0], cdb[1], cdb[2], cdb[3],
-				 cdb[4], cdb[5], cdb[6], cdb[7],
-				 cdb[8], cdb[9], cdb[10], cdb[11],
-				 cdb[12], cdb[13], cdb[14], cdb[15]);
-		} else {
-			const char *descr = ata_get_cmd_descript(cmd->command);
-			if (descr)
-				ata_dev_printk(qc->dev, KERN_ERR,
-					"failed command: %s\n", descr);
-		}
-
 		ata_dev_printk(qc->dev, KERN_ERR,
 			"cmd %02x/%02x:%02x:%02x:%02x:%02x/%02x:%02x:%02x:%02x:%02x/%02x "
-			"tag %d%s\n         %s"
+			"tag %d cdb 0x%x data %u %s\n         "
 			"res %02x/%02x:%02x:%02x:%02x:%02x/%02x:%02x:%02x:%02x:%02x/%02x "
 			"Emask 0x%x (%s)%s\n",
 			cmd->command, cmd->feature, cmd->nsect,
 			cmd->lbal, cmd->lbam, cmd->lbah,
 			cmd->hob_feature, cmd->hob_nsect,
 			cmd->hob_lbal, cmd->hob_lbam, cmd->hob_lbah,
-			cmd->device, qc->tag, data_buf, cdb_buf,
+			cmd->device, qc->tag, qc->cdb[0], qc->nbytes,
+			dma_str[qc->dma_dir],
 			res->command, res->feature, res->nsect,
 			res->lbal, res->lbam, res->lbah,
 			res->hob_feature, res->hob_nsect,
 			res->hob_lbal, res->hob_lbam, res->hob_lbah,
 			res->device, qc->err_mask, ata_err_string(qc->err_mask),
 			qc->err_mask & AC_ERR_NCQ ? " <F>" : "");
-
-#ifdef CONFIG_ATA_VERBOSE_ERROR
-		if (res->command & (ATA_BUSY | ATA_DRDY | ATA_DF | ATA_DRQ |
-				    ATA_ERR)) {
-			if (res->command & ATA_BUSY)
-				ata_dev_printk(qc->dev, KERN_ERR,
-				  "status: { Busy }\n");
-			else
-				ata_dev_printk(qc->dev, KERN_ERR,
-				  "status: { %s%s%s%s}\n",
-				  res->command & ATA_DRDY ? "DRDY " : "",
-				  res->command & ATA_DF ? "DF " : "",
-				  res->command & ATA_DRQ ? "DRQ " : "",
-				  res->command & ATA_ERR ? "ERR " : "");
-		}
-
-		if (cmd->command != ATA_CMD_PACKET &&
-		    (res->feature & (ATA_ICRC | ATA_UNC | ATA_IDNF |
-				     ATA_ABORTED)))
-			ata_dev_printk(qc->dev, KERN_ERR,
-			  "error: { %s%s%s%s}\n",
-			  res->feature & ATA_ICRC ? "ICRC " : "",
-			  res->feature & ATA_UNC ? "UNC " : "",
-			  res->feature & ATA_IDNF ? "IDNF " : "",
-			  res->feature & ATA_ABORTED ? "ABRT " : "");
-#endif
 	}
 }
 
-/**
- *	ata_eh_report - report error handling to user
- *	@ap: ATA port to report EH about
- *
- *	Report EH to user.
- *
- *	LOCKING:
- *	None.
- */
-void ata_eh_report(struct ata_port *ap)
+static int ata_do_reset(struct ata_port *ap, ata_reset_fn_t reset,
+			unsigned int *classes, unsigned long deadline)
 {
-	struct ata_link *link;
+	int i, rc;
 
-	ata_for_each_link(link, ap, HOST_FIRST)
-		ata_eh_link_report(link);
-}
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		classes[i] = ATA_DEV_UNKNOWN;
 
-static int ata_do_reset(struct ata_link *link, ata_reset_fn_t reset,
-			unsigned int *classes, unsigned long deadline,
-			bool clear_classes)
-{
-	struct ata_device *dev;
+	rc = reset(ap, classes, deadline);
+	if (rc)
+		return rc;
 
-	if (clear_classes)
-		ata_for_each_dev(dev, link, ALL)
-			classes[dev->devno] = ATA_DEV_UNKNOWN;
+	/* If any class isn't ATA_DEV_UNKNOWN, consider classification
+	 * is complete and convert all ATA_DEV_UNKNOWN to
+	 * ATA_DEV_NONE.
+	 */
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		if (classes[i] != ATA_DEV_UNKNOWN)
+			break;
 
-	return reset(link, classes, deadline);
+	if (i < ATA_MAX_DEVICES)
+		for (i = 0; i < ATA_MAX_DEVICES; i++)
+			if (classes[i] == ATA_DEV_UNKNOWN)
+				classes[i] = ATA_DEV_NONE;
+
+	return 0;
 }
 
-static int ata_eh_followup_srst_needed(struct ata_link *link,
-				       int rc, const unsigned int *classes)
+static int ata_eh_followup_srst_needed(struct ata_port *ap, int rc,
+				int classify, const unsigned int *classes)
 {
-	if ((link->flags & ATA_LFLAG_NO_SRST) || ata_link_offline(link))
+	if (ap->flags & ATA_FLAG_NO_SRST)
 		return 0;
 	if (rc == -EAGAIN)
 		return 1;
-	if (sata_pmp_supported(link->ap) && ata_is_host_link(link))
+	if (rc != 0)
+		return 0;
+	if (classify && classes[0] == ATA_DEV_UNKNOWN)
 		return 1;
 	return 0;
 }
 
-int ata_eh_reset(struct ata_link *link, int classify,
-		 ata_prereset_fn_t prereset, ata_reset_fn_t softreset,
-		 ata_reset_fn_t hardreset, ata_postreset_fn_t postreset)
-{
-	struct ata_port *ap = link->ap;
-	struct ata_link *slave = ap->slave_link;
-	struct ata_eh_context *ehc = &link->eh_context;
-	struct ata_eh_context *sehc = slave ? &slave->eh_context : NULL;
+static int ata_eh_reset(struct ata_port *ap, int classify,
+			ata_prereset_fn_t prereset, ata_reset_fn_t softreset,
+			ata_reset_fn_t hardreset, ata_postreset_fn_t postreset)
+{
+	struct ata_eh_context *ehc = &ap->eh_context;
 	unsigned int *classes = ehc->classes;
-	unsigned int lflags = link->flags;
 	int verbose = !(ehc->i.flags & ATA_EHI_QUIET);
-	int max_tries = 0, try = 0;
-	struct ata_link *failed_link;
-	struct ata_device *dev;
-	unsigned long deadline, now;
+	int try = 0;
+	unsigned long deadline;
+	unsigned int action;
 	ata_reset_fn_t reset;
-	unsigned long flags;
-	u32 sstatus;
-	int nr_unknown, rc;
+	int i, rc;
 
-	/*
-	 * Prepare to reset
-	 */
-	while (ata_eh_reset_timeouts[max_tries] != ULONG_MAX)
-		max_tries++;
-	if (link->flags & ATA_LFLAG_NO_HRST)
-		hardreset = NULL;
-	if (link->flags & ATA_LFLAG_NO_SRST)
-		softreset = NULL;
-
-	/* make sure each reset attemp is at least COOL_DOWN apart */
-	if (ehc->i.flags & ATA_EHI_DID_RESET) {
-		now = jiffies;
-		WARN_ON(time_after(ehc->last_reset, now));
-		deadline = ata_deadline(ehc->last_reset,
-					ATA_EH_RESET_COOL_DOWN);
-		if (time_before(now, deadline))
-			schedule_timeout_uninterruptible(deadline - now);
-	}
+	/* about to reset */
+	ata_eh_about_to_do(ap, NULL, ehc->i.action & ATA_EH_RESET_MASK);
 
-	spin_lock_irqsave(ap->lock, flags);
-	ap->pflags |= ATA_PFLAG_RESETTING;
-	spin_unlock_irqrestore(ap->lock, flags);
-
-	ata_eh_about_to_do(link, NULL, ATA_EH_RESET);
-
-	ata_for_each_dev(dev, link, ALL) {
-		/* If we issue an SRST then an ATA drive (not ATAPI)
-		 * may change configuration and be in PIO0 timing. If
-		 * we do a hard reset (or are coming from power on)
-		 * this is true for ATA or ATAPI. Until we've set a
-		 * suitable controller mode we should not touch the
-		 * bus as we may be talking too fast.
-		 */
-		dev->pio_mode = XFER_PIO_0;
-
-		/* If the controller has a pio mode setup function
-		 * then use it to set the chipset to rights. Don't
-		 * touch the DMA setup as that will be dealt with when
-		 * configuring devices.
-		 */
-		if (ap->ops->set_piomode)
-			ap->ops->set_piomode(ap, dev);
-	}
-
-	/* prefer hardreset */
-	reset = NULL;
-	ehc->i.action &= ~ATA_EH_RESET;
-	if (hardreset) {
-		reset = hardreset;
-		ehc->i.action |= ATA_EH_HARDRESET;
-	} else if (softreset) {
-		reset = softreset;
+	/* Determine which reset to use and record in ehc->i.action.
+	 * prereset() may examine and modify it.
+	 */
+	action = ehc->i.action;
+	ehc->i.action &= ~ATA_EH_RESET_MASK;
+	if (softreset && (!hardreset || (!(ap->flags & ATA_FLAG_NO_SRST) &&
+					 !sata_set_spd_needed(ap) &&
+					 !(action & ATA_EH_HARDRESET))))
 		ehc->i.action |= ATA_EH_SOFTRESET;
-	}
+	else
+		ehc->i.action |= ATA_EH_HARDRESET;
 
 	if (prereset) {
-		unsigned long deadline = ata_deadline(jiffies,
-						      ATA_EH_PRERESET_TIMEOUT);
-
-		if (slave) {
-			sehc->i.action &= ~ATA_EH_RESET;
-			sehc->i.action |= ehc->i.action;
-		}
-
-		rc = prereset(link, deadline);
-
-		/* If present, do prereset on slave link too.  Reset
-		 * is skipped iff both master and slave links report
-		 * -ENOENT or clear ATA_EH_RESET.
-		 */
-		if (slave && (rc == 0 || rc == -ENOENT)) {
-			int tmp;
-
-			tmp = prereset(slave, deadline);
-			if (tmp != -ENOENT)
-				rc = tmp;
-
-			ehc->i.action |= sehc->i.action;
-		}
-
+		rc = prereset(ap, jiffies + ATA_EH_PRERESET_TIMEOUT);
 		if (rc) {
 			if (rc == -ENOENT) {
-				ata_link_printk(link, KERN_DEBUG,
+				ata_port_printk(ap, KERN_DEBUG,
 						"port disabled. ignoring.\n");
-				ehc->i.action &= ~ATA_EH_RESET;
+				ap->eh_context.i.action &= ~ATA_EH_RESET_MASK;
 
-				ata_for_each_dev(dev, link, ALL)
-					classes[dev->devno] = ATA_DEV_NONE;
+				for (i = 0; i < ATA_MAX_DEVICES; i++)
+					classes[i] = ATA_DEV_NONE;
 
 				rc = 0;
 			} else
-				ata_link_printk(link, KERN_ERR,
+				ata_port_printk(ap, KERN_ERR,
 					"prereset failed (errno=%d)\n", rc);
 			goto out;
 		}
-
-		/* prereset() might have cleared ATA_EH_RESET.  If so,
-		 * bang classes, thaw and return.
-		 */
-		if (reset && !(ehc->i.action & ATA_EH_RESET)) {
-			ata_for_each_dev(dev, link, ALL)
-				classes[dev->devno] = ATA_DEV_NONE;
-			if ((ap->pflags & ATA_PFLAG_FROZEN) &&
-			    ata_is_host_link(link))
-				ata_eh_thaw_port(ap);
-			rc = 0;
-			goto out;
-		}
 	}
 
- retry:
-	/*
-	 * Perform reset
-	 */
-	if (ata_is_host_link(link))
-		ata_eh_freeze_port(ap);
-
-	deadline = ata_deadline(jiffies, ata_eh_reset_timeouts[try++]);
-
-	if (reset) {
-		if (verbose)
-			ata_link_printk(link, KERN_INFO, "%s resetting link\n",
-					reset == softreset ? "soft" : "hard");
-
-		/* mark that this EH session started with reset */
-		ehc->last_reset = jiffies;
-		if (reset == hardreset)
-			ehc->i.flags |= ATA_EHI_DID_HARDRESET;
-		else
-			ehc->i.flags |= ATA_EHI_DID_SOFTRESET;
-
-		rc = ata_do_reset(link, reset, classes, deadline, true);
-		if (rc && rc != -EAGAIN) {
-			failed_link = link;
-			goto fail;
-		}
-
-		/* hardreset slave link if existent */
-		if (slave && reset == hardreset) {
-			int tmp;
-
-			if (verbose)
-				ata_link_printk(slave, KERN_INFO,
-						"hard resetting link\n");
-
-			ata_eh_about_to_do(slave, NULL, ATA_EH_RESET);
-			tmp = ata_do_reset(slave, reset, classes, deadline,
-					   false);
-			switch (tmp) {
-			case -EAGAIN:
-				rc = -EAGAIN;
-			case 0:
-				break;
-			default:
-				failed_link = slave;
-				rc = tmp;
-				goto fail;
-			}
-		}
+	/* prereset() might have modified ehc->i.action */
+	if (ehc->i.action & ATA_EH_HARDRESET)
+		reset = hardreset;
+	else if (ehc->i.action & ATA_EH_SOFTRESET)
+		reset = softreset;
+	else {
+		/* prereset told us not to reset, bang classes and return */
+		for (i = 0; i < ATA_MAX_DEVICES; i++)
+			classes[i] = ATA_DEV_NONE;
+		rc = 0;
+		goto out;
+	}
 
-		/* perform follow-up SRST if necessary */
-		if (reset == hardreset &&
-		    ata_eh_followup_srst_needed(link, rc, classes)) {
+	/* did prereset() screw up?  if so, fix up to avoid oopsing */
+	if (!reset) {
+		if (softreset)
 			reset = softreset;
-
-			if (!reset) {
-				ata_link_printk(link, KERN_ERR,
-						"follow-up softreset required "
-						"but no softreset avaliable\n");
-				failed_link = link;
-				rc = -EINVAL;
-				goto fail;
-			}
-
-			ata_eh_about_to_do(link, NULL, ATA_EH_RESET);
-			rc = ata_do_reset(link, reset, classes, deadline, true);
-			if (rc) {
-				failed_link = link;
-				goto fail;
-			}
-		}
-	} else {
-		if (verbose)
-			ata_link_printk(link, KERN_INFO, "no reset method "
-					"available, skipping reset\n");
-		if (!(lflags & ATA_LFLAG_ASSUME_CLASS))
-			lflags |= ATA_LFLAG_ASSUME_ATA;
+		else
+			reset = hardreset;
 	}
 
-	/*
-	 * Post-reset processing
-	 */
-	ata_for_each_dev(dev, link, ALL) {
-		/* After the reset, the device state is PIO 0 and the
-		 * controller state is undefined.  Reset also wakes up
-		 * drives from sleeping mode.
-		 */
-		dev->pio_mode = XFER_PIO_0;
-		dev->flags &= ~ATA_DFLAG_SLEEPING;
-
-		if (ata_phys_link_offline(ata_dev_phys_link(dev)))
-			continue;
-
-		/* apply class override */
-		if (lflags & ATA_LFLAG_ASSUME_ATA)
-			classes[dev->devno] = ATA_DEV_ATA;
-		else if (lflags & ATA_LFLAG_ASSUME_SEMB)
-			classes[dev->devno] = ATA_DEV_SEMB_UNSUP;
-	}
+ retry:
+	deadline = jiffies + ata_eh_reset_timeouts[try++];
 
-	/* record current link speed */
-	if (sata_scr_read(link, SCR_STATUS, &sstatus) == 0)
-		link->sata_spd = (sstatus >> 4) & 0xf;
-	if (slave && sata_scr_read(slave, SCR_STATUS, &sstatus) == 0)
-		slave->sata_spd = (sstatus >> 4) & 0xf;
+	/* shut up during boot probing */
+	if (verbose)
+		ata_port_printk(ap, KERN_INFO, "%s resetting port\n",
+				reset == softreset ? "soft" : "hard");
+
+	/* mark that this EH session started with reset */
+	if (reset == hardreset)
+		ehc->i.flags |= ATA_EHI_DID_HARDRESET;
+	else
+		ehc->i.flags |= ATA_EHI_DID_SOFTRESET;
 
-	/* thaw the port */
-	if (ata_is_host_link(link))
-		ata_eh_thaw_port(ap);
+	rc = ata_do_reset(ap, reset, classes, deadline);
 
-	/* postreset() should clear hardware SError.  Although SError
-	 * is cleared during link resume, clearing SError here is
-	 * necessary as some PHYs raise hotplug events after SRST.
-	 * This introduces race condition where hotplug occurs between
-	 * reset and here.  This race is mediated by cross checking
-	 * link onlineness and classification result later.
-	 */
-	if (postreset) {
-		postreset(link, classes);
-		if (slave)
-			postreset(slave, classes);
-	}
+	if (reset == hardreset &&
+	    ata_eh_followup_srst_needed(ap, rc, classify, classes)) {
+		/* okay, let's do follow-up softreset */
+		reset = softreset;
 
-	/*
-	 * Some controllers can't be frozen very well and may set spurious
-	 * error conditions during reset.  Clear accumulated error
-	 * information and re-thaw the port if frozen.  As reset is the
-	 * final recovery action and we cross check link onlineness against
-	 * device classification later, no hotplug event is lost by this.
-	 */
-	spin_lock_irqsave(link->ap->lock, flags);
-	memset(&link->eh_info, 0, sizeof(link->eh_info));
-	if (slave)
-		memset(&slave->eh_info, 0, sizeof(link->eh_info));
-	ap->pflags &= ~ATA_PFLAG_EH_PENDING;
-	spin_unlock_irqrestore(link->ap->lock, flags);
+		if (!reset) {
+			ata_port_printk(ap, KERN_ERR,
+					"follow-up softreset required "
+					"but no softreset avaliable\n");
+			rc = -EINVAL;
+			goto out;
+		}
 
-	if (ap->pflags & ATA_PFLAG_FROZEN)
-		ata_eh_thaw_port(ap);
+		ata_eh_about_to_do(ap, NULL, ATA_EH_RESET_MASK);
+		rc = ata_do_reset(ap, reset, classes, deadline);
 
-	/*
-	 * Make sure onlineness and classification result correspond.
-	 * Hotplug could have happened during reset and some
-	 * controllers fail to wait while a drive is spinning up after
-	 * being hotplugged causing misdetection.  By cross checking
-	 * link on/offlineness and classification result, those
-	 * conditions can be reliably detected and retried.
-	 */
-	nr_unknown = 0;
-	ata_for_each_dev(dev, link, ALL) {
-		if (ata_phys_link_online(ata_dev_phys_link(dev))) {
-			if (classes[dev->devno] == ATA_DEV_UNKNOWN) {
-				ata_dev_printk(dev, KERN_DEBUG, "link online "
-					       "but device misclassifed\n");
-				classes[dev->devno] = ATA_DEV_NONE;
-				nr_unknown++;
-			}
-		} else if (ata_phys_link_offline(ata_dev_phys_link(dev))) {
-			if (ata_class_enabled(classes[dev->devno]))
-				ata_dev_printk(dev, KERN_DEBUG, "link offline, "
-					       "clearing class %d to NONE\n",
-					       classes[dev->devno]);
-			classes[dev->devno] = ATA_DEV_NONE;
-		} else if (classes[dev->devno] == ATA_DEV_UNKNOWN) {
-			ata_dev_printk(dev, KERN_DEBUG, "link status unknown, "
-				       "clearing UNKNOWN to NONE\n");
-			classes[dev->devno] = ATA_DEV_NONE;
+		if (rc == 0 && classify && classes[0] == ATA_DEV_UNKNOWN &&
+		    !(ap->flags & ATA_FLAG_ASSUME_ATA)) {
+			ata_port_printk(ap, KERN_ERR,
+					"classification failed\n");
+			rc = -EINVAL;
+			goto out;
 		}
 	}
 
-	if (classify && nr_unknown) {
-		if (try < max_tries) {
-			ata_link_printk(link, KERN_WARNING, "link online but "
-					"%d devices misclassified, retrying\n",
-					nr_unknown);
-			failed_link = link;
-			rc = -EAGAIN;
-			goto fail;
-		}
-		ata_link_printk(link, KERN_WARNING,
-				"link online but %d devices misclassified, "
-				"device detection might fail\n", nr_unknown);
-	}
-
-	/* reset successful, schedule revalidation */
-	ata_eh_done(link, NULL, ATA_EH_RESET);
-	if (slave)
-		ata_eh_done(slave, NULL, ATA_EH_RESET);
-	ehc->last_reset = jiffies;	/* update to completion time */
-	ehc->i.action |= ATA_EH_REVALIDATE;
+	/* if we skipped follow-up srst, clear rc */
+	if (rc == -EAGAIN)
+		rc = 0;
 
-	rc = 0;
- out:
-	/* clear hotplug flag */
-	ehc->i.flags &= ~ATA_EHI_HOTPLUGGED;
-	if (slave)
-		sehc->i.flags &= ~ATA_EHI_HOTPLUGGED;
+	if (rc && try < ARRAY_SIZE(ata_eh_reset_timeouts)) {
+		unsigned long now = jiffies;
 
-	spin_lock_irqsave(ap->lock, flags);
-	ap->pflags &= ~ATA_PFLAG_RESETTING;
-	spin_unlock_irqrestore(ap->lock, flags);
+		if (time_before(now, deadline)) {
+			unsigned long delta = deadline - jiffies;
 
-	return rc;
+			ata_port_printk(ap, KERN_WARNING, "reset failed "
+				"(errno=%d), retrying in %u secs\n",
+				rc, (jiffies_to_msecs(delta) + 999) / 1000);
 
- fail:
-	/* if SCR isn't accessible on a fan-out port, PMP needs to be reset */
-	if (!ata_is_host_link(link) &&
-	    sata_scr_read(link, SCR_STATUS, &sstatus))
-		rc = -ERESTART;
+			schedule_timeout_uninterruptible(delta);
+		}
 
-	if (rc == -ERESTART || try >= max_tries)
-		goto out;
+		if (rc == -EPIPE ||
+		    try == ARRAY_SIZE(ata_eh_reset_timeouts) - 1)
+			sata_down_spd_limit(ap);
+		if (hardreset)
+			reset = hardreset;
+		goto retry;
+	}
 
-	now = jiffies;
-	if (time_before(now, deadline)) {
-		unsigned long delta = deadline - now;
-
-		ata_link_printk(failed_link, KERN_WARNING,
-			"reset failed (errno=%d), retrying in %u secs\n",
-			rc, DIV_ROUND_UP(jiffies_to_msecs(delta), 1000));
-
-		while (delta)
-			delta = schedule_timeout_uninterruptible(delta);
-	}
-
-	if (try == max_tries - 1) {
-		sata_down_spd_limit(link, 0);
-		if (slave)
-			sata_down_spd_limit(slave, 0);
-	} else if (rc == -EPIPE)
-		sata_down_spd_limit(failed_link, 0);
+	if (rc == 0) {
+		u32 sstatus;
 
-	if (hardreset)
-		reset = hardreset;
-	goto retry;
-}
+		/* After the reset, the device state is PIO 0 and the
+		 * controller state is undefined.  Record the mode.
+		 */
+		for (i = 0; i < ata_port_max_devices(ap); i++) {
+			struct ata_device *dev = &ap->device[i];
 
-static inline void ata_eh_pull_park_action(struct ata_port *ap)
-{
-	struct ata_link *link;
-	struct ata_device *dev;
-	unsigned long flags;
+			dev->pio_mode = XFER_PIO_0;
 
-	/*
-	 * This function can be thought of as an extended version of
-	 * ata_eh_about_to_do() specially crafted to accommodate the
-	 * requirements of ATA_EH_PARK handling. Since the EH thread
-	 * does not leave the do {} while () loop in ata_eh_recover as
-	 * long as the timeout for a park request to *one* device on
-	 * the port has not expired, and since we still want to pick
-	 * up park requests to other devices on the same port or
-	 * timeout updates for the same device, we have to pull
-	 * ATA_EH_PARK actions from eh_info into eh_context.i
-	 * ourselves at the beginning of each pass over the loop.
-	 *
-	 * Additionally, all write accesses to &ap->park_req_pending
-	 * through INIT_COMPLETION() (see below) or complete_all()
-	 * (see ata_scsi_park_store()) are protected by the host lock.
-	 * As a result we have that park_req_pending.done is zero on
-	 * exit from this function, i.e. when ATA_EH_PARK actions for
-	 * *all* devices on port ap have been pulled into the
-	 * respective eh_context structs. If, and only if,
-	 * park_req_pending.done is non-zero by the time we reach
-	 * wait_for_completion_timeout(), another ATA_EH_PARK action
-	 * has been scheduled for at least one of the devices on port
-	 * ap and we have to cycle over the do {} while () loop in
-	 * ata_eh_recover() again.
-	 */
+			if (ata_port_offline(ap))
+				continue;
 
-	spin_lock_irqsave(ap->lock, flags);
-	INIT_COMPLETION(ap->park_req_pending);
-	ata_for_each_link(link, ap, EDGE) {
-		ata_for_each_dev(dev, link, ALL) {
-			struct ata_eh_info *ehi = &link->eh_info;
-
-			link->eh_context.i.dev_action[dev->devno] |=
-				ehi->dev_action[dev->devno] & ATA_EH_PARK;
-			ata_eh_clear_action(link, dev, ehi, ATA_EH_PARK);
+			if (ap->flags & ATA_FLAG_ASSUME_ATA)
+				classes[dev->devno] = ATA_DEV_ATA;
 		}
-	}
-	spin_unlock_irqrestore(ap->lock, flags);
-}
 
-static void ata_eh_park_issue_cmd(struct ata_device *dev, int park)
-{
-	struct ata_eh_context *ehc = &dev->link->eh_context;
-	struct ata_taskfile tf;
-	unsigned int err_mask;
+		/* record current link speed */
+		if (sata_scr_read(ap, SCR_STATUS, &sstatus) == 0)
+			ap->sata_spd = (sstatus >> 4) & 0xf;
 
-	ata_tf_init(dev, &tf);
-	if (park) {
-		ehc->unloaded_mask |= 1 << dev->devno;
-		tf.command = ATA_CMD_IDLEIMMEDIATE;
-		tf.feature = 0x44;
-		tf.lbal = 0x4c;
-		tf.lbam = 0x4e;
-		tf.lbah = 0x55;
-	} else {
-		ehc->unloaded_mask &= ~(1 << dev->devno);
-		tf.command = ATA_CMD_CHK_POWER;
-	}
+		if (postreset)
+			postreset(ap, classes);
 
-	tf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_ISADDR;
-	tf.protocol |= ATA_PROT_NODATA;
-	err_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);
-	if (park && (err_mask || tf.lbal != 0xc4)) {
-		ata_dev_printk(dev, KERN_ERR, "head unload failed!\n");
-		ehc->unloaded_mask &= ~(1 << dev->devno);
+		/* reset successful, schedule revalidation */
+		ata_eh_done(ap, NULL, ehc->i.action & ATA_EH_RESET_MASK);
+		ehc->i.action |= ATA_EH_REVALIDATE;
 	}
+ out:
+	/* clear hotplug flag */
+	ehc->i.flags &= ~ATA_EHI_HOTPLUGGED;
+	return rc;
 }
 
-static int ata_eh_revalidate_and_attach(struct ata_link *link,
+static int ata_eh_revalidate_and_attach(struct ata_port *ap,
 					struct ata_device **r_failed_dev)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_eh_context *ehc = &link->eh_context;
+	struct ata_eh_context *ehc = &ap->eh_context;
 	struct ata_device *dev;
 	unsigned int new_mask = 0;
 	unsigned long flags;
-	int rc = 0;
+	int i, rc = 0;
 
 	DPRINTK("ENTER\n");
 
@@ -2910,28 +1961,27 @@
 	 * be done backwards such that PDIAG- is released by the slave
 	 * device before the master device is identified.
 	 */
-	ata_for_each_dev(dev, link, ALL_REVERSE) {
-		unsigned int action = ata_eh_dev_action(dev);
-		unsigned int readid_flags = 0;
+	for (i = ATA_MAX_DEVICES - 1; i >= 0; i--) {
+		unsigned int action, readid_flags = 0;
+
+		dev = &ap->device[i];
+		action = ata_eh_dev_action(dev);
 
 		if (ehc->i.flags & ATA_EHI_DID_RESET)
 			readid_flags |= ATA_READID_POSTRESET;
 
 		if ((action & ATA_EH_REVALIDATE) && ata_dev_enabled(dev)) {
-			WARN_ON(dev->class == ATA_DEV_PMP);
-
-			if (ata_phys_link_offline(ata_dev_phys_link(dev))) {
+			if (ata_port_offline(ap)) {
 				rc = -EIO;
 				goto err;
 			}
 
-			ata_eh_about_to_do(link, dev, ATA_EH_REVALIDATE);
-			rc = ata_dev_revalidate(dev, ehc->classes[dev->devno],
-						readid_flags);
+			ata_eh_about_to_do(ap, dev, ATA_EH_REVALIDATE);
+			rc = ata_dev_revalidate(dev, readid_flags);
 			if (rc)
 				goto err;
 
-			ata_eh_done(link, dev, ATA_EH_REVALIDATE);
+			ata_eh_done(ap, dev, ATA_EH_REVALIDATE);
 
 			/* Configuration may have changed, reconfigure
 			 * transfer mode.
@@ -2943,69 +1993,47 @@
 		} else if (dev->class == ATA_DEV_UNKNOWN &&
 			   ehc->tries[dev->devno] &&
 			   ata_class_enabled(ehc->classes[dev->devno])) {
-			/* Temporarily set dev->class, it will be
-			 * permanently set once all configurations are
-			 * complete.  This is necessary because new
-			 * device configuration is done in two
-			 * separate loops.
-			 */
 			dev->class = ehc->classes[dev->devno];
 
-			if (dev->class == ATA_DEV_PMP)
-				rc = sata_pmp_attach(dev);
-			else
-				rc = ata_dev_read_id(dev, &dev->class,
-						     readid_flags, dev->id);
-
-			/* read_id might have changed class, store and reset */
-			ehc->classes[dev->devno] = dev->class;
-			dev->class = ATA_DEV_UNKNOWN;
-
+			rc = ata_dev_read_id(dev, &dev->class, readid_flags,
+					     dev->id);
 			switch (rc) {
 			case 0:
-				/* clear error info accumulated during probe */
-				ata_ering_clear(&dev->ering);
-				new_mask |= 1 << dev->devno;
+				new_mask |= 1 << i;
 				break;
 			case -ENOENT:
 				/* IDENTIFY was issued to non-existent
 				 * device.  No need to reset.  Just
-				 * thaw and ignore the device.
+				 * thaw and kill the device.
 				 */
 				ata_eh_thaw_port(ap);
+				dev->class = ATA_DEV_UNKNOWN;
 				break;
 			default:
+				dev->class = ATA_DEV_UNKNOWN;
 				goto err;
 			}
 		}
 	}
 
 	/* PDIAG- should have been released, ask cable type if post-reset */
-	if ((ehc->i.flags & ATA_EHI_DID_RESET) && ata_is_host_link(link)) {
-		if (ap->ops->cable_detect)
-			ap->cbl = ap->ops->cable_detect(ap);
-		ata_force_cbl(ap);
-	}
+	if ((ehc->i.flags & ATA_EHI_DID_RESET) && ap->ops->cable_detect)
+		ap->cbl = ap->ops->cable_detect(ap);
 
 	/* Configure new devices forward such that user doesn't see
 	 * device detection messages backwards.
 	 */
-	ata_for_each_dev(dev, link, ALL) {
-		if (!(new_mask & (1 << dev->devno)))
-			continue;
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		dev = &ap->device[i];
 
-		dev->class = ehc->classes[dev->devno];
-
-		if (dev->class == ATA_DEV_PMP)
+		if (!(new_mask & (1 << i)))
 			continue;
 
 		ehc->i.flags |= ATA_EHI_PRINTINFO;
 		rc = ata_dev_configure(dev);
 		ehc->i.flags &= ~ATA_EHI_PRINTINFO;
-		if (rc) {
-			dev->class = ATA_DEV_UNKNOWN;
+		if (rc)
 			goto err;
-		}
 
 		spin_lock_irqsave(ap->lock, flags);
 		ap->pflags |= ATA_PFLAG_SCSI_HOTPLUG;
@@ -3023,151 +2051,40 @@
 	return rc;
 }
 
-/**
- *	ata_set_mode - Program timings and issue SET FEATURES - XFER
- *	@link: link on which timings will be programmed
- *	@r_failed_dev: out parameter for failed device
- *
- *	Set ATA device disk transfer mode (PIO3, UDMA6, etc.).  If
- *	ata_set_mode() fails, pointer to the failing device is
- *	returned in @r_failed_dev.
- *
- *	LOCKING:
- *	PCI/etc. bus probe sem.
- *
- *	RETURNS:
- *	0 on success, negative errno otherwise
- */
-int ata_set_mode(struct ata_link *link, struct ata_device **r_failed_dev)
-{
-	struct ata_port *ap = link->ap;
-	struct ata_device *dev;
-	int rc;
-
-	/* if data transfer is verified, clear DUBIOUS_XFER on ering top */
-	ata_for_each_dev(dev, link, ENABLED) {
-		if (!(dev->flags & ATA_DFLAG_DUBIOUS_XFER)) {
-			struct ata_ering_entry *ent;
-
-			ent = ata_ering_top(&dev->ering);
-			if (ent)
-				ent->eflags &= ~ATA_EFLAG_DUBIOUS_XFER;
-		}
-	}
-
-	/* has private set_mode? */
-	if (ap->ops->set_mode)
-		rc = ap->ops->set_mode(link, r_failed_dev);
-	else
-		rc = ata_do_set_mode(link, r_failed_dev);
-
-	/* if transfer mode has changed, set DUBIOUS_XFER on device */
-	ata_for_each_dev(dev, link, ENABLED) {
-		struct ata_eh_context *ehc = &link->eh_context;
-		u8 saved_xfer_mode = ehc->saved_xfer_mode[dev->devno];
-		u8 saved_ncq = !!(ehc->saved_ncq_enabled & (1 << dev->devno));
-
-		if (dev->xfer_mode != saved_xfer_mode ||
-		    ata_ncq_enabled(dev) != saved_ncq)
-			dev->flags |= ATA_DFLAG_DUBIOUS_XFER;
-	}
-
-	return rc;
-}
-
-/**
- *	atapi_eh_clear_ua - Clear ATAPI UNIT ATTENTION after reset
- *	@dev: ATAPI device to clear UA for
- *
- *	Resets and other operations can make an ATAPI device raise
- *	UNIT ATTENTION which causes the next operation to fail.  This
- *	function clears UA.
- *
- *	LOCKING:
- *	EH context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-static int atapi_eh_clear_ua(struct ata_device *dev)
+static int ata_port_nr_enabled(struct ata_port *ap)
 {
-	int i;
-
-	for (i = 0; i < ATA_EH_UA_TRIES; i++) {
-		u8 *sense_buffer = dev->link->ap->sector_buf;
-		u8 sense_key = 0;
-		unsigned int err_mask;
-
-		err_mask = atapi_eh_tur(dev, &sense_key);
-		if (err_mask != 0 && err_mask != AC_ERR_DEV) {
-			ata_dev_printk(dev, KERN_WARNING, "TEST_UNIT_READY "
-				"failed (err_mask=0x%x)\n", err_mask);
-			return -EIO;
-		}
-
-		if (!err_mask || sense_key != UNIT_ATTENTION)
-			return 0;
+	int i, cnt = 0;
 
-		err_mask = atapi_eh_request_sense(dev, sense_buffer, sense_key);
-		if (err_mask) {
-			ata_dev_printk(dev, KERN_WARNING, "failed to clear "
-				"UNIT ATTENTION (err_mask=0x%x)\n", err_mask);
-			return -EIO;
-		}
-	}
-
-	ata_dev_printk(dev, KERN_WARNING,
-		"UNIT ATTENTION persists after %d tries\n", ATA_EH_UA_TRIES);
-
-	return 0;
-}
-
-static int ata_link_nr_enabled(struct ata_link *link)
-{
-	struct ata_device *dev;
-	int cnt = 0;
-
-	ata_for_each_dev(dev, link, ENABLED)
-		cnt++;
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		if (ata_dev_enabled(&ap->device[i]))
+			cnt++;
 	return cnt;
 }
 
-static int ata_link_nr_vacant(struct ata_link *link)
+static int ata_port_nr_vacant(struct ata_port *ap)
 {
-	struct ata_device *dev;
-	int cnt = 0;
+	int i, cnt = 0;
 
-	ata_for_each_dev(dev, link, ALL)
-		if (dev->class == ATA_DEV_UNKNOWN)
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		if (ap->device[i].class == ATA_DEV_UNKNOWN)
 			cnt++;
 	return cnt;
 }
 
-static int ata_eh_skip_recovery(struct ata_link *link)
+static int ata_eh_skip_recovery(struct ata_port *ap)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_eh_context *ehc = &link->eh_context;
-	struct ata_device *dev;
-
-	/* skip disabled links */
-	if (link->flags & ATA_LFLAG_DISABLED)
-		return 1;
-
-	/* skip if explicitly requested */
-	if (ehc->i.flags & ATA_EHI_NO_RECOVERY)
-		return 1;
-
-	/* thaw frozen port and recover failed devices */
-	if ((ap->pflags & ATA_PFLAG_FROZEN) || ata_link_nr_enabled(link))
-		return 0;
+	struct ata_eh_context *ehc = &ap->eh_context;
+	int i;
 
-	/* reset at least once if reset is requested */
-	if ((ehc->i.action & ATA_EH_RESET) &&
-	    !(ehc->i.flags & ATA_EHI_DID_RESET))
+	/* thaw frozen port, resume link and recover failed devices */
+	if ((ap->pflags & ATA_PFLAG_FROZEN) ||
+	    (ehc->i.flags & ATA_EHI_RESUME_LINK) || ata_port_nr_enabled(ap))
 		return 0;
 
 	/* skip if class codes for all vacant slots are ATA_DEV_NONE */
-	ata_for_each_dev(dev, link, ALL) {
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+
 		if (dev->class == ATA_DEV_UNKNOWN &&
 		    ehc->classes[dev->devno] != ATA_DEV_NONE)
 			return 0;
@@ -3176,67 +2093,12 @@
 	return 1;
 }
 
-static int ata_count_probe_trials_cb(struct ata_ering_entry *ent, void *void_arg)
-{
-	u64 interval = msecs_to_jiffies(ATA_EH_PROBE_TRIAL_INTERVAL);
-	u64 now = get_jiffies_64();
-	int *trials = void_arg;
-
-	if (ent->timestamp < now - min(now, interval))
-		return -1;
-
-	(*trials)++;
-	return 0;
-}
-
-static int ata_eh_schedule_probe(struct ata_device *dev)
-{
-	struct ata_eh_context *ehc = &dev->link->eh_context;
-	struct ata_link *link = ata_dev_phys_link(dev);
-	int trials = 0;
-
-	if (!(ehc->i.probe_mask & (1 << dev->devno)) ||
-	    (ehc->did_probe_mask & (1 << dev->devno)))
-		return 0;
-
-	ata_eh_detach_dev(dev);
-	ata_dev_init(dev);
-	ehc->did_probe_mask |= (1 << dev->devno);
-	ehc->i.action |= ATA_EH_RESET;
-	ehc->saved_xfer_mode[dev->devno] = 0;
-	ehc->saved_ncq_enabled &= ~(1 << dev->devno);
-
-	/* Record and count probe trials on the ering.  The specific
-	 * error mask used is irrelevant.  Because a successful device
-	 * detection clears the ering, this count accumulates only if
-	 * there are consecutive failed probes.
-	 *
-	 * If the count is equal to or higher than ATA_EH_PROBE_TRIALS
-	 * in the last ATA_EH_PROBE_TRIAL_INTERVAL, link speed is
-	 * forced to 1.5Gbps.
-	 *
-	 * This is to work around cases where failed link speed
-	 * negotiation results in device misdetection leading to
-	 * infinite DEVXCHG or PHRDY CHG events.
-	 */
-	ata_ering_record(&dev->ering, 0, AC_ERR_OTHER);
-	ata_ering_map(&dev->ering, ata_count_probe_trials_cb, &trials);
-
-	if (trials > ATA_EH_PROBE_TRIALS)
-		sata_down_spd_limit(link, 1);
-
-	return 1;
-}
-
-static int ata_eh_handle_dev_fail(struct ata_device *dev, int err)
+static void ata_eh_handle_dev_fail(struct ata_device *dev, int err)
 {
-	struct ata_eh_context *ehc = &dev->link->eh_context;
+	struct ata_port *ap = dev->ap;
+	struct ata_eh_context *ehc = &ap->eh_context;
 
-	/* -EAGAIN from EH routine indicates retry without prejudice.
-	 * The requester is responsible for ensuring forward progress.
-	 */
-	if (err != -EAGAIN)
-		ehc->tries[dev->devno]--;
+	ehc->tries[dev->devno]--;
 
 	switch (err) {
 	case -ENODEV:
@@ -3250,9 +2112,8 @@
 			/* This is the last chance, better to slow
 			 * down than lose it.
 			 */
-			sata_down_spd_limit(ata_dev_phys_link(dev), 0);
-			if (dev->pio_mode > XFER_PIO_0)
-				ata_down_xfermask_limit(dev, ATA_DNXFER_PIO);
+			sata_down_spd_limit(ap);
+			ata_down_xfermask_limit(dev, ATA_DNXFER_PIO);
 		}
 	}
 
@@ -3261,20 +2122,25 @@
 		ata_dev_disable(dev);
 
 		/* detach if offline */
-		if (ata_phys_link_offline(ata_dev_phys_link(dev)))
+		if (ata_port_offline(ap))
 			ata_eh_detach_dev(dev);
 
-		/* schedule probe if necessary */
-		if (ata_eh_schedule_probe(dev)) {
+		/* probe if requested */
+		if ((ehc->i.probe_mask & (1 << dev->devno)) &&
+		    !(ehc->did_probe_mask & (1 << dev->devno))) {
+			ata_eh_detach_dev(dev);
+			ata_dev_init(dev);
+
 			ehc->tries[dev->devno] = ATA_EH_DEV_TRIES;
-			memset(ehc->cmd_timeout_idx[dev->devno], 0,
-			       sizeof(ehc->cmd_timeout_idx[dev->devno]));
+			ehc->did_probe_mask |= (1 << dev->devno);
+			ehc->i.action |= ATA_EH_SOFTRESET;
 		}
-
-		return 1;
 	} else {
-		ehc->i.action |= ATA_EH_RESET;
-		return 0;
+		/* soft didn't work?  be haaaaard */
+		if (ehc->i.flags & ATA_EHI_DID_RESET)
+			ehc->i.action |= ATA_EH_HARDRESET;
+		else
+			ehc->i.action |= ATA_EH_SOFTRESET;
 	}
 }
 
@@ -3285,13 +2151,12 @@
  *	@softreset: softreset method (can be NULL)
  *	@hardreset: hardreset method (can be NULL)
  *	@postreset: postreset method (can be NULL)
- *	@r_failed_link: out parameter for failed link
  *
  *	This is the alpha and omega, eum and yang, heart and soul of
  *	libata exception handling.  On entry, actions required to
- *	recover each link and hotplug requests are recorded in the
- *	link's eh_context.  This function executes all the operations
- *	with appropriate retrials and fallbacks to resurrect failed
+ *	recover the port and hotplug requests are recorded in
+ *	eh_context.  This function executes all the operations with
+ *	appropriate retrials and fallbacks to resurrect failed
  *	devices, detach goners and greet newcomers.
  *
  *	LOCKING:
@@ -3300,204 +2165,103 @@
  *	RETURNS:
  *	0 on success, -errno on failure.
  */
-int ata_eh_recover(struct ata_port *ap, ata_prereset_fn_t prereset,
-		   ata_reset_fn_t softreset, ata_reset_fn_t hardreset,
-		   ata_postreset_fn_t postreset,
-		   struct ata_link **r_failed_link)
+static int ata_eh_recover(struct ata_port *ap, ata_prereset_fn_t prereset,
+			  ata_reset_fn_t softreset, ata_reset_fn_t hardreset,
+			  ata_postreset_fn_t postreset)
 {
-	struct ata_link *link;
+	struct ata_eh_context *ehc = &ap->eh_context;
 	struct ata_device *dev;
-	int nr_failed_devs;
-	int rc;
-	unsigned long flags, deadline;
+	int i, rc;
 
 	DPRINTK("ENTER\n");
 
 	/* prep for recovery */
-	ata_for_each_link(link, ap, EDGE) {
-		struct ata_eh_context *ehc = &link->eh_context;
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		dev = &ap->device[i];
 
-		/* re-enable link? */
-		if (ehc->i.action & ATA_EH_ENABLE_LINK) {
-			ata_eh_about_to_do(link, NULL, ATA_EH_ENABLE_LINK);
-			spin_lock_irqsave(ap->lock, flags);
-			link->flags &= ~ATA_LFLAG_DISABLED;
-			spin_unlock_irqrestore(ap->lock, flags);
-			ata_eh_done(link, NULL, ATA_EH_ENABLE_LINK);
-		}
+		ehc->tries[dev->devno] = ATA_EH_DEV_TRIES;
 
-		ata_for_each_dev(dev, link, ALL) {
-			if (link->flags & ATA_LFLAG_NO_RETRY)
-				ehc->tries[dev->devno] = 1;
-			else
-				ehc->tries[dev->devno] = ATA_EH_DEV_TRIES;
+		/* collect port action mask recorded in dev actions */
+		ehc->i.action |= ehc->i.dev_action[i] & ~ATA_EH_PERDEV_MASK;
+		ehc->i.dev_action[i] &= ATA_EH_PERDEV_MASK;
 
-			/* collect port action mask recorded in dev actions */
-			ehc->i.action |= ehc->i.dev_action[dev->devno] &
-					 ~ATA_EH_PERDEV_MASK;
-			ehc->i.dev_action[dev->devno] &= ATA_EH_PERDEV_MASK;
-
-			/* process hotplug request */
-			if (dev->flags & ATA_DFLAG_DETACH)
-				ata_eh_detach_dev(dev);
-
-			/* schedule probe if necessary */
-			if (!ata_dev_enabled(dev))
-				ata_eh_schedule_probe(dev);
+		/* process hotplug request */
+		if (dev->flags & ATA_DFLAG_DETACH)
+			ata_eh_detach_dev(dev);
+
+		if (!ata_dev_enabled(dev) &&
+		    ((ehc->i.probe_mask & (1 << dev->devno)) &&
+		     !(ehc->did_probe_mask & (1 << dev->devno)))) {
+			ata_eh_detach_dev(dev);
+			ata_dev_init(dev);
+			ehc->did_probe_mask |= (1 << dev->devno);
+			ehc->i.action |= ATA_EH_SOFTRESET;
 		}
 	}
 
  retry:
 	rc = 0;
-	nr_failed_devs = 0;
 
 	/* if UNLOADING, finish immediately */
 	if (ap->pflags & ATA_PFLAG_UNLOADING)
 		goto out;
 
-	/* prep for EH */
-	ata_for_each_link(link, ap, EDGE) {
-		struct ata_eh_context *ehc = &link->eh_context;
-
-		/* skip EH if possible. */
-		if (ata_eh_skip_recovery(link))
-			ehc->i.action = 0;
+	/* skip EH if possible. */
+	if (ata_eh_skip_recovery(ap))
+		ehc->i.action = 0;
 
-		ata_for_each_dev(dev, link, ALL)
-			ehc->classes[dev->devno] = ATA_DEV_UNKNOWN;
-	}
+	for (i = 0; i < ATA_MAX_DEVICES; i++)
+		ehc->classes[i] = ATA_DEV_UNKNOWN;
 
 	/* reset */
-	ata_for_each_link(link, ap, EDGE) {
-		struct ata_eh_context *ehc = &link->eh_context;
-
-		if (!(ehc->i.action & ATA_EH_RESET))
-			continue;
+	if (ehc->i.action & ATA_EH_RESET_MASK) {
+		ata_eh_freeze_port(ap);
 
-		rc = ata_eh_reset(link, ata_link_nr_vacant(link),
-				  prereset, softreset, hardreset, postreset);
+		rc = ata_eh_reset(ap, ata_port_nr_vacant(ap), prereset,
+				  softreset, hardreset, postreset);
 		if (rc) {
-			ata_link_printk(link, KERN_ERR,
+			ata_port_printk(ap, KERN_ERR,
 					"reset failed, giving up\n");
 			goto out;
 		}
-	}
-
-	do {
-		unsigned long now;
-
-		/*
-		 * clears ATA_EH_PARK in eh_info and resets
-		 * ap->park_req_pending
-		 */
-		ata_eh_pull_park_action(ap);
-
-		deadline = jiffies;
-		ata_for_each_link(link, ap, EDGE) {
-			ata_for_each_dev(dev, link, ALL) {
-				struct ata_eh_context *ehc = &link->eh_context;
-				unsigned long tmp;
-
-				if (dev->class != ATA_DEV_ATA)
-					continue;
-				if (!(ehc->i.dev_action[dev->devno] &
-				      ATA_EH_PARK))
-					continue;
-				tmp = dev->unpark_deadline;
-				if (time_before(deadline, tmp))
-					deadline = tmp;
-				else if (time_before_eq(tmp, jiffies))
-					continue;
-				if (ehc->unloaded_mask & (1 << dev->devno))
-					continue;
-
-				ata_eh_park_issue_cmd(dev, 1);
-			}
-		}
-
-		now = jiffies;
-		if (time_before_eq(deadline, now))
-			break;
 
-		deadline = wait_for_completion_timeout(&ap->park_req_pending,
-						       deadline - now);
-	} while (deadline);
-	ata_for_each_link(link, ap, EDGE) {
-		ata_for_each_dev(dev, link, ALL) {
-			if (!(link->eh_context.unloaded_mask &
-			      (1 << dev->devno)))
-				continue;
-
-			ata_eh_park_issue_cmd(dev, 0);
-			ata_eh_done(link, dev, ATA_EH_PARK);
-		}
+		ata_eh_thaw_port(ap);
 	}
 
-	/* the rest */
-	ata_for_each_link(link, ap, EDGE) {
-		struct ata_eh_context *ehc = &link->eh_context;
+	/* revalidate existing devices and attach new ones */
+	rc = ata_eh_revalidate_and_attach(ap, &dev);
+	if (rc)
+		goto dev_fail;
 
-		/* revalidate existing devices and attach new ones */
-		rc = ata_eh_revalidate_and_attach(link, &dev);
+	/* configure transfer mode if necessary */
+	if (ehc->i.flags & ATA_EHI_SETMODE) {
+		rc = ata_set_mode(ap, &dev);
 		if (rc)
 			goto dev_fail;
+		ehc->i.flags &= ~ATA_EHI_SETMODE;
+	}
 
-		/* if PMP got attached, return, pmp EH will take care of it */
-		if (link->device->class == ATA_DEV_PMP) {
-			ehc->i.action = 0;
-			return 0;
-		}
-
-		/* configure transfer mode if necessary */
-		if (ehc->i.flags & ATA_EHI_SETMODE) {
-			rc = ata_set_mode(link, &dev);
-			if (rc)
-				goto dev_fail;
-			ehc->i.flags &= ~ATA_EHI_SETMODE;
-		}
+	goto out;
 
-		/* If reset has been issued, clear UA to avoid
-		 * disrupting the current users of the device.
-		 */
-		if (ehc->i.flags & ATA_EHI_DID_RESET) {
-			ata_for_each_dev(dev, link, ALL) {
-				if (dev->class != ATA_DEV_ATAPI)
-					continue;
-				rc = atapi_eh_clear_ua(dev);
-				if (rc)
-					goto dev_fail;
-			}
-		}
+ dev_fail:
+	ata_eh_handle_dev_fail(dev, rc);
 
-		/* configure link power saving */
-		if (ehc->i.action & ATA_EH_LPM)
-			ata_for_each_dev(dev, link, ALL)
-				ata_dev_enable_pm(dev, ap->pm_policy);
-
-		/* this link is okay now */
-		ehc->i.flags = 0;
-		continue;
-
-dev_fail:
-		nr_failed_devs++;
-		ata_eh_handle_dev_fail(dev, rc);
-
-		if (ap->pflags & ATA_PFLAG_FROZEN) {
-			/* PMP reset requires working host port.
-			 * Can't retry if it's frozen.
-			 */
-			if (sata_pmp_attached(ap))
-				goto out;
-			break;
-		}
+	if (ata_port_nr_enabled(ap)) {
+		ata_port_printk(ap, KERN_WARNING, "failed to recover some "
+				"devices, retrying in 5 secs\n");
+		ssleep(5);
+	} else {
+		/* no device left, repeat fast */
+		msleep(500);
 	}
 
-	if (nr_failed_devs)
-		goto retry;
+	goto retry;
 
  out:
-	if (rc && r_failed_link)
-		*r_failed_link = link;
+	if (rc) {
+		for (i = 0; i < ATA_MAX_DEVICES; i++)
+			ata_dev_disable(&ap->device[i]);
+	}
 
 	DPRINTK("EXIT, rc=%d\n", rc);
 	return rc;
@@ -3513,7 +2277,7 @@
  *	LOCKING:
  *	None.
  */
-void ata_eh_finish(struct ata_port *ap)
+static void ata_eh_finish(struct ata_port *ap)
 {
 	int tag;
 
@@ -3529,10 +2293,10 @@
 			 * generate sense data in this function,
 			 * considering both err_mask and tf.
 			 */
-			if (qc->flags & ATA_QCFLAG_RETRY)
-				ata_eh_qc_retry(qc);
-			else
+			if (qc->err_mask & AC_ERR_INVALID)
 				ata_eh_qc_complete(qc);
+			else
+				ata_eh_qc_retry(qc);
 		} else {
 			if (qc->flags & ATA_QCFLAG_SENSE_VALID) {
 				ata_eh_qc_complete(qc);
@@ -3543,16 +2307,11 @@
 			}
 		}
 	}
-
-	/* make sure nr_active_links is zero after EH */
-	WARN_ON(ap->nr_active_links);
-	ap->nr_active_links = 0;
 }
 
 /**
  *	ata_do_eh - do standard error handling
  *	@ap: host port to handle error for
- *
  *	@prereset: prereset method (can be NULL)
  *	@softreset: softreset method (can be NULL)
  *	@hardreset: hardreset method (can be NULL)
@@ -3567,43 +2326,12 @@
 	       ata_reset_fn_t softreset, ata_reset_fn_t hardreset,
 	       ata_postreset_fn_t postreset)
 {
-	struct ata_device *dev;
-	int rc;
-
 	ata_eh_autopsy(ap);
 	ata_eh_report(ap);
-
-	rc = ata_eh_recover(ap, prereset, softreset, hardreset, postreset,
-			    NULL);
-	if (rc) {
-		ata_for_each_dev(dev, &ap->link, ALL)
-			ata_dev_disable(dev);
-	}
-
+	ata_eh_recover(ap, prereset, softreset, hardreset, postreset);
 	ata_eh_finish(ap);
 }
 
-/**
- *	ata_std_error_handler - standard error handler
- *	@ap: host port to handle error for
- *
- *	Standard error handler
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- */
-void ata_std_error_handler(struct ata_port *ap)
-{
-	struct ata_port_operations *ops = ap->ops;
-	ata_reset_fn_t hardreset = ops->hardreset;
-
-	/* ignore built-in hardreset if SCR access is not available */
-	if (ata_is_builtin_hardreset(hardreset) && !sata_scr_valid(&ap->link))
-		hardreset = NULL;
-
-	ata_do_eh(ap, ops->prereset, ops->softreset, hardreset, ops->postreset);
-}
-
 #ifdef CONFIG_PM
 /**
  *	ata_eh_handle_port_suspend - perform port suspend operation
@@ -3641,7 +2369,6 @@
 	if (ap->ops->port_suspend)
 		rc = ap->ops->port_suspend(ap, ap->pm_mesg);
 
-	ata_acpi_set_state(ap, PMSG_SUSPEND);
  out:
 	/* report result */
 	spin_lock_irqsave(ap->lock, flags);
@@ -3673,8 +2400,6 @@
  */
 static void ata_eh_handle_port_resume(struct ata_port *ap)
 {
-	struct ata_link *link;
-	struct ata_device *dev;
 	unsigned long flags;
 	int rc = 0;
 
@@ -3689,19 +2414,6 @@
 
 	WARN_ON(!(ap->pflags & ATA_PFLAG_SUSPENDED));
 
-	/*
-	 * Error timestamps are in jiffies which doesn't run while
-	 * suspended and PHY events during resume isn't too uncommon.
-	 * When the two are combined, it can lead to unnecessary speed
-	 * downs if the machine is suspended and resumed repeatedly.
-	 * Clear error history.
-	 */
-	ata_for_each_link(link, ap, HOST_FIRST)
-		ata_for_each_dev(dev, link, ALL)
-			ata_ering_clear(&dev->ering);
-
-	ata_acpi_set_state(ap, PMSG_ON);
-
 	if (ap->ops->port_resume)
 		rc = ap->ops->port_resume(ap);
 
diff -Nur linux-sh4/drivers/ata.org/libata.h linux-sh4/drivers/ata/libata.h
--- linux-sh4/drivers/ata.org/libata.h	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/libata.h	2012-01-15 06:30:14.000000000 -0800
@@ -29,7 +29,6 @@
 #define __LIBATA_H__
 
 #define DRV_NAME	"libata"
-#define DRV_VERSION	"3.00"	/* must be exactly four chars */
 
 struct ata_scsi_args {
 	struct ata_device	*dev;
@@ -38,17 +37,6 @@
 	void			(*done)(struct scsi_cmnd *);
 };
 
-static inline int ata_is_builtin_hardreset(ata_reset_fn_t reset)
-{
-	if (reset == sata_std_hardreset)
-		return 1;
-#ifdef CONFIG_ATA_SFF
-	if (reset == sata_sff_hardreset)
-		return 1;
-#endif
-	return 0;
-}
-
 /* libata-core.c */
 enum {
 	/* flags for ata_dev_read_id() */
@@ -66,78 +54,59 @@
 
 extern unsigned int ata_print_id;
 extern struct workqueue_struct *ata_aux_wq;
-extern int atapi_passthru16;
+extern int atapi_enabled;
+extern int atapi_dmadir;
 extern int libata_fua;
 extern int libata_noacpi;
-extern int libata_allow_tpm;
-extern struct ata_link *ata_dev_phys_link(struct ata_device *dev);
-extern void ata_force_cbl(struct ata_port *ap);
-extern u64 ata_tf_to_lba(const struct ata_taskfile *tf);
-extern u64 ata_tf_to_lba48(const struct ata_taskfile *tf);
 extern struct ata_queued_cmd *ata_qc_new_init(struct ata_device *dev);
 extern int ata_build_rw_tf(struct ata_taskfile *tf, struct ata_device *dev,
 			   u64 block, u32 n_block, unsigned int tf_flags,
 			   unsigned int tag);
 extern u64 ata_tf_read_block(struct ata_taskfile *tf, struct ata_device *dev);
+extern void ata_dev_disable(struct ata_device *dev);
 extern void ata_port_flush_task(struct ata_port *ap);
 extern unsigned ata_exec_internal(struct ata_device *dev,
 				  struct ata_taskfile *tf, const u8 *cdb,
-				  int dma_dir, void *buf, unsigned int buflen,
-				  unsigned long timeout);
+				  int dma_dir, void *buf, unsigned int buflen);
 extern unsigned ata_exec_internal_sg(struct ata_device *dev,
 				     struct ata_taskfile *tf, const u8 *cdb,
 				     int dma_dir, struct scatterlist *sg,
-				     unsigned int n_elem, unsigned long timeout);
+				     unsigned int n_elem);
 extern unsigned int ata_do_simple_cmd(struct ata_device *dev, u8 cmd);
-extern int ata_wait_ready(struct ata_link *link, unsigned long deadline,
-			  int (*check_ready)(struct ata_link *link));
 extern int ata_dev_read_id(struct ata_device *dev, unsigned int *p_class,
 			   unsigned int flags, u16 *id);
 extern int ata_dev_reread_id(struct ata_device *dev, unsigned int readid_flags);
-extern int ata_dev_revalidate(struct ata_device *dev, unsigned int new_class,
-			      unsigned int readid_flags);
+extern int ata_dev_revalidate(struct ata_device *dev, unsigned int readid_flags);
 extern int ata_dev_configure(struct ata_device *dev);
-extern int sata_down_spd_limit(struct ata_link *link, u32 spd_limit);
+extern int sata_down_spd_limit(struct ata_port *ap);
+extern int sata_set_spd_needed(struct ata_port *ap);
 extern int ata_down_xfermask_limit(struct ata_device *dev, unsigned int sel);
+extern int ata_set_mode(struct ata_port *ap, struct ata_device **r_failed_dev);
 extern void ata_sg_clean(struct ata_queued_cmd *qc);
 extern void ata_qc_free(struct ata_queued_cmd *qc);
 extern void ata_qc_issue(struct ata_queued_cmd *qc);
 extern void __ata_qc_complete(struct ata_queued_cmd *qc);
-extern int atapi_check_dma(struct ata_queued_cmd *qc);
+extern int ata_check_atapi_dma(struct ata_queued_cmd *qc);
+extern void ata_dev_select(struct ata_port *ap, unsigned int device,
+                           unsigned int wait, unsigned int can_sleep);
 extern void swap_buf_le16(u16 *buf, unsigned int buf_words);
-extern bool ata_phys_link_online(struct ata_link *link);
-extern bool ata_phys_link_offline(struct ata_link *link);
+extern int ata_flush_cache(struct ata_device *dev);
 extern void ata_dev_init(struct ata_device *dev);
-extern void ata_link_init(struct ata_port *ap, struct ata_link *link, int pmp);
-extern int sata_link_init_spd(struct ata_link *link);
 extern int ata_task_ioctl(struct scsi_device *scsidev, void __user *arg);
 extern int ata_cmd_ioctl(struct scsi_device *scsidev, void __user *arg);
 extern struct ata_port *ata_port_alloc(struct ata_host *host);
-extern void ata_dev_enable_pm(struct ata_device *dev, enum link_pm policy);
-extern void ata_lpm_schedule(struct ata_port *ap, enum link_pm);
 
 /* libata-acpi.c */
 #ifdef CONFIG_ATA_ACPI
-extern unsigned int ata_acpi_gtf_filter;
-
-extern void ata_acpi_associate_sata_port(struct ata_port *ap);
 extern void ata_acpi_associate(struct ata_host *host);
-extern void ata_acpi_dissociate(struct ata_host *host);
 extern int ata_acpi_on_suspend(struct ata_port *ap);
 extern void ata_acpi_on_resume(struct ata_port *ap);
-extern int ata_acpi_on_devcfg(struct ata_device *dev);
-extern void ata_acpi_on_disable(struct ata_device *dev);
-extern void ata_acpi_set_state(struct ata_port *ap, pm_message_t state);
+extern int ata_acpi_on_devcfg(struct ata_device *adev);
 #else
-static inline void ata_acpi_associate_sata_port(struct ata_port *ap) { }
 static inline void ata_acpi_associate(struct ata_host *host) { }
-static inline void ata_acpi_dissociate(struct ata_host *host) { }
 static inline int ata_acpi_on_suspend(struct ata_port *ap) { return 0; }
 static inline void ata_acpi_on_resume(struct ata_port *ap) { }
-static inline int ata_acpi_on_devcfg(struct ata_device *dev) { return 0; }
-static inline void ata_acpi_on_disable(struct ata_device *dev) { }
-static inline void ata_acpi_set_state(struct ata_port *ap,
-				      pm_message_t state) { }
+static inline int ata_acpi_on_devcfg(struct ata_device *adev) { return 0; }
 #endif
 
 /* libata-scsi.c */
@@ -152,60 +121,14 @@
 extern int ata_bus_probe(struct ata_port *ap);
 
 /* libata-eh.c */
-extern unsigned long ata_internal_cmd_timeout(struct ata_device *dev, u8 cmd);
-extern void ata_internal_cmd_timed_out(struct ata_device *dev, u8 cmd);
 extern enum blk_eh_timer_return ata_scsi_timed_out(struct scsi_cmnd *cmd);
 extern void ata_scsi_error(struct Scsi_Host *host);
 extern void ata_port_wait_eh(struct ata_port *ap);
 extern void ata_eh_fastdrain_timerfn(unsigned long arg);
 extern void ata_qc_schedule_eh(struct ata_queued_cmd *qc);
-extern void ata_dev_disable(struct ata_device *dev);
-extern void ata_eh_detach_dev(struct ata_device *dev);
-extern void ata_eh_about_to_do(struct ata_link *link, struct ata_device *dev,
-			       unsigned int action);
-extern void ata_eh_done(struct ata_link *link, struct ata_device *dev,
-			unsigned int action);
-extern void ata_eh_autopsy(struct ata_port *ap);
-const char *ata_get_cmd_descript(u8 command);
-extern void ata_eh_report(struct ata_port *ap);
-extern int ata_eh_reset(struct ata_link *link, int classify,
-			ata_prereset_fn_t prereset, ata_reset_fn_t softreset,
-			ata_reset_fn_t hardreset, ata_postreset_fn_t postreset);
-extern int ata_set_mode(struct ata_link *link, struct ata_device **r_failed_dev);
-extern int ata_eh_recover(struct ata_port *ap, ata_prereset_fn_t prereset,
-			  ata_reset_fn_t softreset, ata_reset_fn_t hardreset,
-			  ata_postreset_fn_t postreset,
-			  struct ata_link **r_failed_disk);
-extern void ata_eh_finish(struct ata_port *ap);
-
-/* libata-pmp.c */
-#ifdef CONFIG_SATA_PMP
-extern int sata_pmp_scr_read(struct ata_link *link, int reg, u32 *val);
-extern int sata_pmp_scr_write(struct ata_link *link, int reg, u32 val);
-extern int sata_pmp_attach(struct ata_device *dev);
-#else /* CONFIG_SATA_PMP */
-static inline int sata_pmp_scr_read(struct ata_link *link, int reg, u32 *val)
-{
-	return -EINVAL;
-}
-
-static inline int sata_pmp_scr_write(struct ata_link *link, int reg, u32 val)
-{
-	return -EINVAL;
-}
-
-static inline int sata_pmp_attach(struct ata_device *dev)
-{
-	return -EINVAL;
-}
-#endif /* CONFIG_SATA_PMP */
 
 /* libata-sff.c */
-#ifdef CONFIG_ATA_SFF
-extern void ata_dev_select(struct ata_port *ap, unsigned int device,
-                           unsigned int wait, unsigned int can_sleep);
 extern u8 ata_irq_on(struct ata_port *ap);
-extern void ata_pio_task(struct work_struct *work);
-#endif /* CONFIG_ATA_SFF */
+
 
 #endif /* __LIBATA_H__ */
diff -Nur linux-sh4/drivers/ata.org/libata-pmp.c linux-sh4/drivers/ata/libata-pmp.c
--- linux-sh4/drivers/ata.org/libata-pmp.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/libata-pmp.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,1022 +0,0 @@
-/*
- * libata-pmp.c - libata port multiplier support
- *
- * Copyright (c) 2007  SUSE Linux Products GmbH
- * Copyright (c) 2007  Tejun Heo <teheo@suse.de>
- *
- * This file is released under the GPLv2.
- */
-
-#include <linux/kernel.h>
-#include <linux/libata.h>
-#include "libata.h"
-
-const struct ata_port_operations sata_pmp_port_ops = {
-	.inherits		= &sata_port_ops,
-	.pmp_prereset		= ata_std_prereset,
-	.pmp_hardreset		= sata_std_hardreset,
-	.pmp_postreset		= ata_std_postreset,
-	.error_handler		= sata_pmp_error_handler,
-};
-
-/**
- *	sata_pmp_read - read PMP register
- *	@link: link to read PMP register for
- *	@reg: register to read
- *	@r_val: resulting value
- *
- *	Read PMP register.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, AC_ERR_* mask on failure.
- */
-static unsigned int sata_pmp_read(struct ata_link *link, int reg, u32 *r_val)
-{
-	struct ata_port *ap = link->ap;
-	struct ata_device *pmp_dev = ap->link.device;
-	struct ata_taskfile tf;
-	unsigned int err_mask;
-
-	ata_tf_init(pmp_dev, &tf);
-	tf.command = ATA_CMD_PMP_READ;
-	tf.protocol = ATA_PROT_NODATA;
-	tf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE | ATA_TFLAG_LBA48;
-	tf.feature = reg;
-	tf.device = link->pmp;
-
-	err_mask = ata_exec_internal(pmp_dev, &tf, NULL, DMA_NONE, NULL, 0,
-				     SATA_PMP_RW_TIMEOUT);
-	if (err_mask)
-		return err_mask;
-
-	*r_val = tf.nsect | tf.lbal << 8 | tf.lbam << 16 | tf.lbah << 24;
-	return 0;
-}
-
-/**
- *	sata_pmp_write - write PMP register
- *	@link: link to write PMP register for
- *	@reg: register to write
- *	@r_val: value to write
- *
- *	Write PMP register.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, AC_ERR_* mask on failure.
- */
-static unsigned int sata_pmp_write(struct ata_link *link, int reg, u32 val)
-{
-	struct ata_port *ap = link->ap;
-	struct ata_device *pmp_dev = ap->link.device;
-	struct ata_taskfile tf;
-
-	ata_tf_init(pmp_dev, &tf);
-	tf.command = ATA_CMD_PMP_WRITE;
-	tf.protocol = ATA_PROT_NODATA;
-	tf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE | ATA_TFLAG_LBA48;
-	tf.feature = reg;
-	tf.device = link->pmp;
-	tf.nsect = val & 0xff;
-	tf.lbal = (val >> 8) & 0xff;
-	tf.lbam = (val >> 16) & 0xff;
-	tf.lbah = (val >> 24) & 0xff;
-
-	return ata_exec_internal(pmp_dev, &tf, NULL, DMA_NONE, NULL, 0,
-				 SATA_PMP_RW_TIMEOUT);
-}
-
-/**
- *	sata_pmp_qc_defer_cmd_switch - qc_defer for command switching PMP
- *	@qc: ATA command in question
- *
- *	A host which has command switching PMP support cannot issue
- *	commands to multiple links simultaneously.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
- *	RETURNS:
- *	ATA_DEFER_* if deferring is needed, 0 otherwise.
- */
-int sata_pmp_qc_defer_cmd_switch(struct ata_queued_cmd *qc)
-{
-	struct ata_link *link = qc->dev->link;
-	struct ata_port *ap = link->ap;
-
-	if (ap->excl_link == NULL || ap->excl_link == link) {
-		if (ap->nr_active_links == 0 || ata_link_active(link)) {
-			qc->flags |= ATA_QCFLAG_CLEAR_EXCL;
-			return ata_std_qc_defer(qc);
-		}
-
-		ap->excl_link = link;
-	}
-
-	return ATA_DEFER_PORT;
-}
-
-/**
- *	sata_pmp_scr_read - read PSCR
- *	@link: ATA link to read PSCR for
- *	@reg: PSCR to read
- *	@r_val: resulting value
- *
- *	Read PSCR @reg into @r_val for @link, to be called from
- *	ata_scr_read().
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-int sata_pmp_scr_read(struct ata_link *link, int reg, u32 *r_val)
-{
-	unsigned int err_mask;
-
-	if (reg > SATA_PMP_PSCR_CONTROL)
-		return -EINVAL;
-
-	err_mask = sata_pmp_read(link, reg, r_val);
-	if (err_mask) {
-		ata_link_printk(link, KERN_WARNING, "failed to read SCR %d "
-				"(Emask=0x%x)\n", reg, err_mask);
-		return -EIO;
-	}
-	return 0;
-}
-
-/**
- *	sata_pmp_scr_write - write PSCR
- *	@link: ATA link to write PSCR for
- *	@reg: PSCR to write
- *	@val: value to be written
- *
- *	Write @val to PSCR @reg for @link, to be called from
- *	ata_scr_write() and ata_scr_write_flush().
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-int sata_pmp_scr_write(struct ata_link *link, int reg, u32 val)
-{
-	unsigned int err_mask;
-
-	if (reg > SATA_PMP_PSCR_CONTROL)
-		return -EINVAL;
-
-	err_mask = sata_pmp_write(link, reg, val);
-	if (err_mask) {
-		ata_link_printk(link, KERN_WARNING, "failed to write SCR %d "
-				"(Emask=0x%x)\n", reg, err_mask);
-		return -EIO;
-	}
-	return 0;
-}
-
-/**
- *	sata_pmp_read_gscr - read GSCR block of SATA PMP
- *	@dev: PMP device
- *	@gscr: buffer to read GSCR block into
- *
- *	Read selected PMP GSCRs from the PMP at @dev.  This will serve
- *	as configuration and identification info for the PMP.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-static int sata_pmp_read_gscr(struct ata_device *dev, u32 *gscr)
-{
-	static const int gscr_to_read[] = { 0, 1, 2, 32, 33, 64, 96 };
-	int i;
-
-	for (i = 0; i < ARRAY_SIZE(gscr_to_read); i++) {
-		int reg = gscr_to_read[i];
-		unsigned int err_mask;
-
-		err_mask = sata_pmp_read(dev->link, reg, &gscr[reg]);
-		if (err_mask) {
-			ata_dev_printk(dev, KERN_ERR, "failed to read PMP "
-				"GSCR[%d] (Emask=0x%x)\n", reg, err_mask);
-			return -EIO;
-		}
-	}
-
-	return 0;
-}
-
-static const char *sata_pmp_spec_rev_str(const u32 *gscr)
-{
-	u32 rev = gscr[SATA_PMP_GSCR_REV];
-
-	if (rev & (1 << 3))
-		return "1.2";
-	if (rev & (1 << 2))
-		return "1.1";
-	if (rev & (1 << 1))
-		return "1.0";
-	return "<unknown>";
-}
-
-static int sata_pmp_configure(struct ata_device *dev, int print_info)
-{
-	struct ata_port *ap = dev->link->ap;
-	u32 *gscr = dev->gscr;
-	unsigned int err_mask = 0;
-	const char *reason;
-	int nr_ports, rc;
-
-	nr_ports = sata_pmp_gscr_ports(gscr);
-
-	if (nr_ports <= 0 || nr_ports > SATA_PMP_MAX_PORTS) {
-		rc = -EINVAL;
-		reason = "invalid nr_ports";
-		goto fail;
-	}
-
-	if ((ap->flags & ATA_FLAG_AN) &&
-	    (gscr[SATA_PMP_GSCR_FEAT] & SATA_PMP_FEAT_NOTIFY))
-		dev->flags |= ATA_DFLAG_AN;
-
-	/* monitor SERR_PHYRDY_CHG on fan-out ports */
-	err_mask = sata_pmp_write(dev->link, SATA_PMP_GSCR_ERROR_EN,
-				  SERR_PHYRDY_CHG);
-	if (err_mask) {
-		rc = -EIO;
-		reason = "failed to write GSCR_ERROR_EN";
-		goto fail;
-	}
-
-	if (print_info) {
-		ata_dev_printk(dev, KERN_INFO, "Port Multiplier %s, "
-			       "0x%04x:0x%04x r%d, %d ports, feat 0x%x/0x%x\n",
-			       sata_pmp_spec_rev_str(gscr),
-			       sata_pmp_gscr_vendor(gscr),
-			       sata_pmp_gscr_devid(gscr),
-			       sata_pmp_gscr_rev(gscr),
-			       nr_ports, gscr[SATA_PMP_GSCR_FEAT_EN],
-			       gscr[SATA_PMP_GSCR_FEAT]);
-
-		if (!(dev->flags & ATA_DFLAG_AN))
-			ata_dev_printk(dev, KERN_INFO,
-				"Asynchronous notification not supported, "
-				"hotplug won't\n         work on fan-out "
-				"ports. Use warm-plug instead.\n");
-	}
-
-	return 0;
-
- fail:
-	ata_dev_printk(dev, KERN_ERR,
-		       "failed to configure Port Multiplier (%s, Emask=0x%x)\n",
-		       reason, err_mask);
-	return rc;
-}
-
-static int sata_pmp_init_links(struct ata_port *ap, int nr_ports)
-{
-	struct ata_link *pmp_link = ap->pmp_link;
-	int i;
-
-	if (!pmp_link) {
-		pmp_link = kzalloc(sizeof(pmp_link[0]) * SATA_PMP_MAX_PORTS,
-				   GFP_NOIO);
-		if (!pmp_link)
-			return -ENOMEM;
-
-		for (i = 0; i < SATA_PMP_MAX_PORTS; i++)
-			ata_link_init(ap, &pmp_link[i], i);
-
-		ap->pmp_link = pmp_link;
-	}
-
-	for (i = 0; i < nr_ports; i++) {
-		struct ata_link *link = &pmp_link[i];
-		struct ata_eh_context *ehc = &link->eh_context;
-
-		link->flags = 0;
-		ehc->i.probe_mask |= ATA_ALL_DEVICES;
-		ehc->i.action |= ATA_EH_RESET;
-	}
-
-	return 0;
-}
-
-static void sata_pmp_quirks(struct ata_port *ap)
-{
-	u32 *gscr = ap->link.device->gscr;
-	u16 vendor = sata_pmp_gscr_vendor(gscr);
-	u16 devid = sata_pmp_gscr_devid(gscr);
-	struct ata_link *link;
-
-	if (vendor == 0x1095 && devid == 0x3726) {
-		/* sil3726 quirks */
-		ata_for_each_link(link, ap, EDGE) {
-			/* Class code report is unreliable and SRST
-			 * times out under certain configurations.
-			 */
-			if (link->pmp < 5)
-				link->flags |= ATA_LFLAG_NO_SRST |
-					       ATA_LFLAG_ASSUME_ATA;
-
-			/* port 5 is for SEMB device and it doesn't like SRST */
-			if (link->pmp == 5)
-				link->flags |= ATA_LFLAG_NO_SRST |
-					       ATA_LFLAG_ASSUME_SEMB;
-		}
-	} else if (vendor == 0x1095 && devid == 0x4723) {
-		/* sil4723 quirks */
-		ata_for_each_link(link, ap, EDGE) {
-			/* class code report is unreliable */
-			if (link->pmp < 2)
-				link->flags |= ATA_LFLAG_ASSUME_ATA;
-
-			/* the config device at port 2 locks up on SRST */
-			if (link->pmp == 2)
-				link->flags |= ATA_LFLAG_NO_SRST |
-					       ATA_LFLAG_ASSUME_ATA;
-		}
-	} else if (vendor == 0x1095 && devid == 0x4726) {
-		/* sil4726 quirks */
-		ata_for_each_link(link, ap, EDGE) {
-			/* Class code report is unreliable and SRST
-			 * times out under certain configurations.
-			 * Config device can be at port 0 or 5 and
-			 * locks up on SRST.
-			 */
-			if (link->pmp <= 5)
-				link->flags |= ATA_LFLAG_NO_SRST |
-					       ATA_LFLAG_ASSUME_ATA;
-
-			/* Port 6 is for SEMB device which doesn't
-			 * like SRST either.
-			 */
-			if (link->pmp == 6)
-				link->flags |= ATA_LFLAG_NO_SRST |
-					       ATA_LFLAG_ASSUME_SEMB;
-		}
-	} else if (vendor == 0x1095 && (devid == 0x5723 || devid == 0x5733 ||
-					devid == 0x5734 || devid == 0x5744)) {
-		/* sil5723/5744 quirks */
-
-		/* sil5723/5744 has either two or three downstream
-		 * ports depending on operation mode.  The last port
-		 * is empty if any actual IO device is available or
-		 * occupied by a pseudo configuration device
-		 * otherwise.  Don't try hard to recover it.
-		 */
-		ap->pmp_link[ap->nr_pmp_links - 1].flags |= ATA_LFLAG_NO_RETRY;
-	}
-}
-
-/**
- *	sata_pmp_attach - attach a SATA PMP device
- *	@dev: SATA PMP device to attach
- *
- *	Configure and attach SATA PMP device @dev.  This function is
- *	also responsible for allocating and initializing PMP links.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-int sata_pmp_attach(struct ata_device *dev)
-{
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
-	unsigned long flags;
-	struct ata_link *tlink;
-	int rc;
-
-	/* is it hanging off the right place? */
-	if (!sata_pmp_supported(ap)) {
-		ata_dev_printk(dev, KERN_ERR,
-			       "host does not support Port Multiplier\n");
-		return -EINVAL;
-	}
-
-	if (!ata_is_host_link(link)) {
-		ata_dev_printk(dev, KERN_ERR,
-			       "Port Multipliers cannot be nested\n");
-		return -EINVAL;
-	}
-
-	if (dev->devno) {
-		ata_dev_printk(dev, KERN_ERR,
-			       "Port Multiplier must be the first device\n");
-		return -EINVAL;
-	}
-
-	WARN_ON(link->pmp != 0);
-	link->pmp = SATA_PMP_CTRL_PORT;
-
-	/* read GSCR block */
-	rc = sata_pmp_read_gscr(dev, dev->gscr);
-	if (rc)
-		goto fail;
-
-	/* config PMP */
-	rc = sata_pmp_configure(dev, 1);
-	if (rc)
-		goto fail;
-
-	rc = sata_pmp_init_links(ap, sata_pmp_gscr_ports(dev->gscr));
-	if (rc) {
-		ata_dev_printk(dev, KERN_INFO,
-			       "failed to initialize PMP links\n");
-		goto fail;
-	}
-
-	/* attach it */
-	spin_lock_irqsave(ap->lock, flags);
-	WARN_ON(ap->nr_pmp_links);
-	ap->nr_pmp_links = sata_pmp_gscr_ports(dev->gscr);
-	spin_unlock_irqrestore(ap->lock, flags);
-
-	sata_pmp_quirks(ap);
-
-	if (ap->ops->pmp_attach)
-		ap->ops->pmp_attach(ap);
-
-	ata_for_each_link(tlink, ap, EDGE)
-		sata_link_init_spd(tlink);
-
-	ata_acpi_associate_sata_port(ap);
-
-	return 0;
-
- fail:
-	link->pmp = 0;
-	return rc;
-}
-
-/**
- *	sata_pmp_detach - detach a SATA PMP device
- *	@dev: SATA PMP device to detach
- *
- *	Detach SATA PMP device @dev.  This function is also
- *	responsible for deconfiguring PMP links.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- */
-static void sata_pmp_detach(struct ata_device *dev)
-{
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
-	struct ata_link *tlink;
-	unsigned long flags;
-
-	ata_dev_printk(dev, KERN_INFO, "Port Multiplier detaching\n");
-
-	WARN_ON(!ata_is_host_link(link) || dev->devno ||
-		link->pmp != SATA_PMP_CTRL_PORT);
-
-	if (ap->ops->pmp_detach)
-		ap->ops->pmp_detach(ap);
-
-	ata_for_each_link(tlink, ap, EDGE)
-		ata_eh_detach_dev(tlink->device);
-
-	spin_lock_irqsave(ap->lock, flags);
-	ap->nr_pmp_links = 0;
-	link->pmp = 0;
-	spin_unlock_irqrestore(ap->lock, flags);
-
-	ata_acpi_associate_sata_port(ap);
-}
-
-/**
- *	sata_pmp_same_pmp - does new GSCR matches the configured PMP?
- *	@dev: PMP device to compare against
- *	@new_gscr: GSCR block of the new device
- *
- *	Compare @new_gscr against @dev and determine whether @dev is
- *	the PMP described by @new_gscr.
- *
- *	LOCKING:
- *	None.
- *
- *	RETURNS:
- *	1 if @dev matches @new_gscr, 0 otherwise.
- */
-static int sata_pmp_same_pmp(struct ata_device *dev, const u32 *new_gscr)
-{
-	const u32 *old_gscr = dev->gscr;
-	u16 old_vendor, new_vendor, old_devid, new_devid;
-	int old_nr_ports, new_nr_ports;
-
-	old_vendor = sata_pmp_gscr_vendor(old_gscr);
-	new_vendor = sata_pmp_gscr_vendor(new_gscr);
-	old_devid = sata_pmp_gscr_devid(old_gscr);
-	new_devid = sata_pmp_gscr_devid(new_gscr);
-	old_nr_ports = sata_pmp_gscr_ports(old_gscr);
-	new_nr_ports = sata_pmp_gscr_ports(new_gscr);
-
-	if (old_vendor != new_vendor) {
-		ata_dev_printk(dev, KERN_INFO, "Port Multiplier "
-			       "vendor mismatch '0x%x' != '0x%x'\n",
-			       old_vendor, new_vendor);
-		return 0;
-	}
-
-	if (old_devid != new_devid) {
-		ata_dev_printk(dev, KERN_INFO, "Port Multiplier "
-			       "device ID mismatch '0x%x' != '0x%x'\n",
-			       old_devid, new_devid);
-		return 0;
-	}
-
-	if (old_nr_ports != new_nr_ports) {
-		ata_dev_printk(dev, KERN_INFO, "Port Multiplier "
-			       "nr_ports mismatch '0x%x' != '0x%x'\n",
-			       old_nr_ports, new_nr_ports);
-		return 0;
-	}
-
-	return 1;
-}
-
-/**
- *	sata_pmp_revalidate - revalidate SATA PMP
- *	@dev: PMP device to revalidate
- *	@new_class: new class code
- *
- *	Re-read GSCR block and make sure @dev is still attached to the
- *	port and properly configured.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno otherwise.
- */
-static int sata_pmp_revalidate(struct ata_device *dev, unsigned int new_class)
-{
-	struct ata_link *link = dev->link;
-	struct ata_port *ap = link->ap;
-	u32 *gscr = (void *)ap->sector_buf;
-	int rc;
-
-	DPRINTK("ENTER\n");
-
-	ata_eh_about_to_do(link, NULL, ATA_EH_REVALIDATE);
-
-	if (!ata_dev_enabled(dev)) {
-		rc = -ENODEV;
-		goto fail;
-	}
-
-	/* wrong class? */
-	if (ata_class_enabled(new_class) && new_class != ATA_DEV_PMP) {
-		rc = -ENODEV;
-		goto fail;
-	}
-
-	/* read GSCR */
-	rc = sata_pmp_read_gscr(dev, gscr);
-	if (rc)
-		goto fail;
-
-	/* is the pmp still there? */
-	if (!sata_pmp_same_pmp(dev, gscr)) {
-		rc = -ENODEV;
-		goto fail;
-	}
-
-	memcpy(dev->gscr, gscr, sizeof(gscr[0]) * SATA_PMP_GSCR_DWORDS);
-
-	rc = sata_pmp_configure(dev, 0);
-	if (rc)
-		goto fail;
-
-	ata_eh_done(link, NULL, ATA_EH_REVALIDATE);
-
-	DPRINTK("EXIT, rc=0\n");
-	return 0;
-
- fail:
-	ata_dev_printk(dev, KERN_ERR,
-		       "PMP revalidation failed (errno=%d)\n", rc);
-	DPRINTK("EXIT, rc=%d\n", rc);
-	return rc;
-}
-
-/**
- *	sata_pmp_revalidate_quick - revalidate SATA PMP quickly
- *	@dev: PMP device to revalidate
- *
- *	Make sure the attached PMP is accessible.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno otherwise.
- */
-static int sata_pmp_revalidate_quick(struct ata_device *dev)
-{
-	unsigned int err_mask;
-	u32 prod_id;
-
-	err_mask = sata_pmp_read(dev->link, SATA_PMP_GSCR_PROD_ID, &prod_id);
-	if (err_mask) {
-		ata_dev_printk(dev, KERN_ERR, "failed to read PMP product ID "
-			       "(Emask=0x%x)\n", err_mask);
-		return -EIO;
-	}
-
-	if (prod_id != dev->gscr[SATA_PMP_GSCR_PROD_ID]) {
-		ata_dev_printk(dev, KERN_ERR, "PMP product ID mismatch\n");
-		/* something weird is going on, request full PMP recovery */
-		return -EIO;
-	}
-
-	return 0;
-}
-
-/**
- *	sata_pmp_eh_recover_pmp - recover PMP
- *	@ap: ATA port PMP is attached to
- *	@prereset: prereset method (can be NULL)
- *	@softreset: softreset method
- *	@hardreset: hardreset method
- *	@postreset: postreset method (can be NULL)
- *
- *	Recover PMP attached to @ap.  Recovery procedure is somewhat
- *	similar to that of ata_eh_recover() except that reset should
- *	always be performed in hard->soft sequence and recovery
- *	failure results in PMP detachment.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-static int sata_pmp_eh_recover_pmp(struct ata_port *ap,
-		ata_prereset_fn_t prereset, ata_reset_fn_t softreset,
-		ata_reset_fn_t hardreset, ata_postreset_fn_t postreset)
-{
-	struct ata_link *link = &ap->link;
-	struct ata_eh_context *ehc = &link->eh_context;
-	struct ata_device *dev = link->device;
-	int tries = ATA_EH_PMP_TRIES;
-	int detach = 0, rc = 0;
-	int reval_failed = 0;
-
-	DPRINTK("ENTER\n");
-
-	if (dev->flags & ATA_DFLAG_DETACH) {
-		detach = 1;
-		goto fail;
-	}
-
- retry:
-	ehc->classes[0] = ATA_DEV_UNKNOWN;
-
-	if (ehc->i.action & ATA_EH_RESET) {
-		struct ata_link *tlink;
-
-		/* reset */
-		rc = ata_eh_reset(link, 0, prereset, softreset, hardreset,
-				  postreset);
-		if (rc) {
-			ata_link_printk(link, KERN_ERR,
-					"failed to reset PMP, giving up\n");
-			goto fail;
-		}
-
-		/* PMP is reset, SErrors cannot be trusted, scan all */
-		ata_for_each_link(tlink, ap, EDGE) {
-			struct ata_eh_context *ehc = &tlink->eh_context;
-
-			ehc->i.probe_mask |= ATA_ALL_DEVICES;
-			ehc->i.action |= ATA_EH_RESET;
-		}
-	}
-
-	/* If revalidation is requested, revalidate and reconfigure;
-	 * otherwise, do quick revalidation.
-	 */
-	if (ehc->i.action & ATA_EH_REVALIDATE)
-		rc = sata_pmp_revalidate(dev, ehc->classes[0]);
-	else
-		rc = sata_pmp_revalidate_quick(dev);
-
-	if (rc) {
-		tries--;
-
-		if (rc == -ENODEV) {
-			ehc->i.probe_mask |= ATA_ALL_DEVICES;
-			detach = 1;
-			/* give it just two more chances */
-			tries = min(tries, 2);
-		}
-
-		if (tries) {
-			/* consecutive revalidation failures? speed down */
-			if (reval_failed)
-				sata_down_spd_limit(link, 0);
-			else
-				reval_failed = 1;
-
-			ehc->i.action |= ATA_EH_RESET;
-			goto retry;
-		} else {
-			ata_dev_printk(dev, KERN_ERR, "failed to recover PMP "
-				       "after %d tries, giving up\n",
-				       ATA_EH_PMP_TRIES);
-			goto fail;
-		}
-	}
-
-	/* okay, PMP resurrected */
-	ehc->i.flags = 0;
-
-	DPRINTK("EXIT, rc=0\n");
-	return 0;
-
- fail:
-	sata_pmp_detach(dev);
-	if (detach)
-		ata_eh_detach_dev(dev);
-	else
-		ata_dev_disable(dev);
-
-	DPRINTK("EXIT, rc=%d\n", rc);
-	return rc;
-}
-
-static int sata_pmp_eh_handle_disabled_links(struct ata_port *ap)
-{
-	struct ata_link *link;
-	unsigned long flags;
-	int rc;
-
-	spin_lock_irqsave(ap->lock, flags);
-
-	ata_for_each_link(link, ap, EDGE) {
-		if (!(link->flags & ATA_LFLAG_DISABLED))
-			continue;
-
-		spin_unlock_irqrestore(ap->lock, flags);
-
-		/* Some PMPs require hardreset sequence to get
-		 * SError.N working.
-		 */
-		sata_link_hardreset(link, sata_deb_timing_normal,
-				ata_deadline(jiffies, ATA_TMOUT_INTERNAL_QUICK),
-				NULL, NULL);
-
-		/* unconditionally clear SError.N */
-		rc = sata_scr_write(link, SCR_ERROR, SERR_PHYRDY_CHG);
-		if (rc) {
-			ata_link_printk(link, KERN_ERR, "failed to clear "
-					"SError.N (errno=%d)\n", rc);
-			return rc;
-		}
-
-		spin_lock_irqsave(ap->lock, flags);
-	}
-
-	spin_unlock_irqrestore(ap->lock, flags);
-
-	return 0;
-}
-
-static int sata_pmp_handle_link_fail(struct ata_link *link, int *link_tries)
-{
-	struct ata_port *ap = link->ap;
-	unsigned long flags;
-
-	if (link_tries[link->pmp] && --link_tries[link->pmp])
-		return 1;
-
-	/* disable this link */
-	if (!(link->flags & ATA_LFLAG_DISABLED)) {
-		ata_link_printk(link, KERN_WARNING,
-			"failed to recover link after %d tries, disabling\n",
-			ATA_EH_PMP_LINK_TRIES);
-
-		spin_lock_irqsave(ap->lock, flags);
-		link->flags |= ATA_LFLAG_DISABLED;
-		spin_unlock_irqrestore(ap->lock, flags);
-	}
-
-	ata_dev_disable(link->device);
-	link->eh_context.i.action = 0;
-
-	return 0;
-}
-
-/**
- *	sata_pmp_eh_recover - recover PMP-enabled port
- *	@ap: ATA port to recover
- *
- *	Drive EH recovery operation for PMP enabled port @ap.  This
- *	function recovers host and PMP ports with proper retrials and
- *	fallbacks.  Actual recovery operations are performed using
- *	ata_eh_recover() and sata_pmp_eh_recover_pmp().
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno on failure.
- */
-static int sata_pmp_eh_recover(struct ata_port *ap)
-{
-	struct ata_port_operations *ops = ap->ops;
-	int pmp_tries, link_tries[SATA_PMP_MAX_PORTS];
-	struct ata_link *pmp_link = &ap->link;
-	struct ata_device *pmp_dev = pmp_link->device;
-	struct ata_eh_context *pmp_ehc = &pmp_link->eh_context;
-	u32 *gscr = pmp_dev->gscr;
-	struct ata_link *link;
-	struct ata_device *dev;
-	unsigned int err_mask;
-	u32 gscr_error, sntf;
-	int cnt, rc;
-
-	pmp_tries = ATA_EH_PMP_TRIES;
-	ata_for_each_link(link, ap, EDGE)
-		link_tries[link->pmp] = ATA_EH_PMP_LINK_TRIES;
-
- retry:
-	/* PMP attached? */
-	if (!sata_pmp_attached(ap)) {
-		rc = ata_eh_recover(ap, ops->prereset, ops->softreset,
-				    ops->hardreset, ops->postreset, NULL);
-		if (rc) {
-			ata_for_each_dev(dev, &ap->link, ALL)
-				ata_dev_disable(dev);
-			return rc;
-		}
-
-		if (pmp_dev->class != ATA_DEV_PMP)
-			return 0;
-
-		/* new PMP online */
-		ata_for_each_link(link, ap, EDGE)
-			link_tries[link->pmp] = ATA_EH_PMP_LINK_TRIES;
-
-		/* fall through */
-	}
-
-	/* recover pmp */
-	rc = sata_pmp_eh_recover_pmp(ap, ops->prereset, ops->softreset,
-				     ops->hardreset, ops->postreset);
-	if (rc)
-		goto pmp_fail;
-
-	/* PHY event notification can disturb reset and other recovery
-	 * operations.  Turn it off.
-	 */
-	if (gscr[SATA_PMP_GSCR_FEAT_EN] & SATA_PMP_FEAT_NOTIFY) {
-		gscr[SATA_PMP_GSCR_FEAT_EN] &= ~SATA_PMP_FEAT_NOTIFY;
-
-		err_mask = sata_pmp_write(pmp_link, SATA_PMP_GSCR_FEAT_EN,
-					  gscr[SATA_PMP_GSCR_FEAT_EN]);
-		if (err_mask) {
-			ata_link_printk(pmp_link, KERN_WARNING,
-				"failed to disable NOTIFY (err_mask=0x%x)\n",
-				err_mask);
-			goto pmp_fail;
-		}
-	}
-
-	/* handle disabled links */
-	rc = sata_pmp_eh_handle_disabled_links(ap);
-	if (rc)
-		goto pmp_fail;
-
-	/* recover links */
-	rc = ata_eh_recover(ap, ops->pmp_prereset, ops->pmp_softreset,
-			    ops->pmp_hardreset, ops->pmp_postreset, &link);
-	if (rc)
-		goto link_fail;
-
-	/* Connection status might have changed while resetting other
-	 * links, check SATA_PMP_GSCR_ERROR before returning.
-	 */
-
-	/* clear SNotification */
-	rc = sata_scr_read(&ap->link, SCR_NOTIFICATION, &sntf);
-	if (rc == 0)
-		sata_scr_write(&ap->link, SCR_NOTIFICATION, sntf);
-
-	/* enable notification */
-	if (pmp_dev->flags & ATA_DFLAG_AN) {
-		gscr[SATA_PMP_GSCR_FEAT_EN] |= SATA_PMP_FEAT_NOTIFY;
-
-		err_mask = sata_pmp_write(pmp_link, SATA_PMP_GSCR_FEAT_EN,
-					  gscr[SATA_PMP_GSCR_FEAT_EN]);
-		if (err_mask) {
-			ata_dev_printk(pmp_dev, KERN_ERR, "failed to write "
-				       "PMP_FEAT_EN (Emask=0x%x)\n", err_mask);
-			rc = -EIO;
-			goto pmp_fail;
-		}
-	}
-
-	/* check GSCR_ERROR */
-	err_mask = sata_pmp_read(pmp_link, SATA_PMP_GSCR_ERROR, &gscr_error);
-	if (err_mask) {
-		ata_dev_printk(pmp_dev, KERN_ERR, "failed to read "
-			       "PMP_GSCR_ERROR (Emask=0x%x)\n", err_mask);
-		rc = -EIO;
-		goto pmp_fail;
-	}
-
-	cnt = 0;
-	ata_for_each_link(link, ap, EDGE) {
-		if (!(gscr_error & (1 << link->pmp)))
-			continue;
-
-		if (sata_pmp_handle_link_fail(link, link_tries)) {
-			ata_ehi_hotplugged(&link->eh_context.i);
-			cnt++;
-		} else {
-			ata_link_printk(link, KERN_WARNING,
-				"PHY status changed but maxed out on retries, "
-				"giving up\n");
-			ata_link_printk(link, KERN_WARNING,
-				"Manully issue scan to resume this link\n");
-		}
-	}
-
-	if (cnt) {
-		ata_port_printk(ap, KERN_INFO, "PMP SError.N set for some "
-				"ports, repeating recovery\n");
-		goto retry;
-	}
-
-	return 0;
-
- link_fail:
-	if (sata_pmp_handle_link_fail(link, link_tries)) {
-		pmp_ehc->i.action |= ATA_EH_RESET;
-		goto retry;
-	}
-
-	/* fall through */
- pmp_fail:
-	/* Control always ends up here after detaching PMP.  Shut up
-	 * and return if we're unloading.
-	 */
-	if (ap->pflags & ATA_PFLAG_UNLOADING)
-		return rc;
-
-	if (!sata_pmp_attached(ap))
-		goto retry;
-
-	if (--pmp_tries) {
-		pmp_ehc->i.action |= ATA_EH_RESET;
-		goto retry;
-	}
-
-	ata_port_printk(ap, KERN_ERR,
-			"failed to recover PMP after %d tries, giving up\n",
-			ATA_EH_PMP_TRIES);
-	sata_pmp_detach(pmp_dev);
-	ata_dev_disable(pmp_dev);
-
-	return rc;
-}
-
-/**
- *	sata_pmp_error_handler - do standard error handling for PMP-enabled host
- *	@ap: host port to handle error for
- *
- *	Perform standard error handling sequence for PMP-enabled host
- *	@ap.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- */
-void sata_pmp_error_handler(struct ata_port *ap)
-{
-	ata_eh_autopsy(ap);
-	ata_eh_report(ap);
-	sata_pmp_eh_recover(ap);
-	ata_eh_finish(ap);
-}
-
-EXPORT_SYMBOL_GPL(sata_pmp_port_ops);
-EXPORT_SYMBOL_GPL(sata_pmp_qc_defer_cmd_switch);
-EXPORT_SYMBOL_GPL(sata_pmp_error_handler);
diff -Nur linux-sh4/drivers/ata.org/libata-scsi.c linux-sh4/drivers/ata/libata-scsi.c
--- linux-sh4/drivers/ata.org/libata-scsi.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/libata-scsi.c	2012-01-15 06:30:14.000000000 -0800
@@ -45,22 +45,18 @@
 #include <scsi/scsi_transport.h>
 #include <linux/libata.h>
 #include <linux/hdreg.h>
-#include <linux/uaccess.h>
-#include <linux/suspend.h>
+#include <asm/uaccess.h>
+#include <linux/cdrom.h>
 
 #include "libata.h"
 
-#define SECTOR_SIZE		512
-#define ATA_SCSI_RBUF_SIZE	4096
-
-static DEFINE_SPINLOCK(ata_scsi_rbuf_lock);
-static u8 ata_scsi_rbuf[ATA_SCSI_RBUF_SIZE];
+#define SECTOR_SIZE	512
 
 typedef unsigned int (*ata_xlat_func_t)(struct ata_queued_cmd *qc);
 
-static struct ata_device *__ata_scsi_find_dev(struct ata_port *ap,
+static struct ata_device * __ata_scsi_find_dev(struct ata_port *ap,
 					const struct scsi_device *scsidev);
-static struct ata_device *ata_scsi_find_dev(struct ata_port *ap,
+static struct ata_device * ata_scsi_find_dev(struct ata_port *ap,
 					    const struct scsi_device *scsidev);
 static int ata_scsi_user_scan(struct Scsi_Host *shost, unsigned int channel,
 			      unsigned int id, unsigned int lun);
@@ -76,10 +72,11 @@
 #define ALL_SUB_MPAGES 0xff
 
 
-static const u8 def_rw_recovery_mpage[RW_RECOVERY_MPAGE_LEN] = {
+static const u8 def_rw_recovery_mpage[] = {
 	RW_RECOVERY_MPAGE,
 	RW_RECOVERY_MPAGE_LEN - 2,
-	(1 << 7),	/* AWRE */
+	(1 << 7) |	/* AWRE, sat-r06 say it shall be 0 */
+	    (1 << 6),	/* ARRE (auto read reallocation) */
 	0,		/* read retry count */
 	0, 0, 0, 0,
 	0,		/* write retry count */
@@ -114,267 +111,34 @@
 	.user_scan		= ata_scsi_user_scan,
 };
 
+/**
+ *	ata_scsi_set_sense - Set SCSI sense data and status
+ *	@cmd: SCSI request to be handled
+ *	@sk: SCSI-defined sense key
+ *	@asc: SCSI-defined additional sense code
+ *	@ascq: SCSI-defined additional sense code qualifier
+ *
+ *	Helper function that builds a valid fixed format, current
+ *	response code and the given sense key (sk), additional sense
+ *	code (asc) and additional sense code qualifier (ascq) with
+ *	a SCSI command status of %SAM_STAT_CHECK_CONDITION and
+ *	DRIVER_SENSE set in the upper bits of scsi_cmnd::result .
+ *
+ *	LOCKING:
+ *	Not required
+ */
 
-static const struct {
-	enum link_pm	value;
-	const char	*name;
-} link_pm_policy[] = {
-	{ NOT_AVAILABLE, "max_performance" },
-	{ MIN_POWER, "min_power" },
-	{ MAX_PERFORMANCE, "max_performance" },
-	{ MEDIUM_POWER, "medium_power" },
-};
-
-static const char *ata_scsi_lpm_get(enum link_pm policy)
-{
-	int i;
-
-	for (i = 0; i < ARRAY_SIZE(link_pm_policy); i++)
-		if (link_pm_policy[i].value == policy)
-			return link_pm_policy[i].name;
-
-	return NULL;
-}
-
-static ssize_t ata_scsi_lpm_put(struct device *dev,
-				struct device_attribute *attr,
-				const char *buf, size_t count)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-	enum link_pm policy = 0;
-	int i;
-
-	/*
-	 * we are skipping array location 0 on purpose - this
-	 * is because a value of NOT_AVAILABLE is displayed
-	 * to the user as max_performance, but when the user
-	 * writes "max_performance", they actually want the
-	 * value to match MAX_PERFORMANCE.
-	 */
-	for (i = 1; i < ARRAY_SIZE(link_pm_policy); i++) {
-		const int len = strlen(link_pm_policy[i].name);
-		if (strncmp(link_pm_policy[i].name, buf, len) == 0 &&
-		   buf[len] == '\n') {
-			policy = link_pm_policy[i].value;
-			break;
-		}
-	}
-	if (!policy)
-		return -EINVAL;
-
-	ata_lpm_schedule(ap, policy);
-	return count;
-}
-
-static ssize_t
-ata_scsi_lpm_show(struct device *dev, struct device_attribute *attr, char *buf)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-	const char *policy =
-		ata_scsi_lpm_get(ap->pm_policy);
-
-	if (!policy)
-		return -EINVAL;
-
-	return snprintf(buf, 23, "%s\n", policy);
-}
-DEVICE_ATTR(link_power_management_policy, S_IRUGO | S_IWUSR,
-		ata_scsi_lpm_show, ata_scsi_lpm_put);
-EXPORT_SYMBOL_GPL(dev_attr_link_power_management_policy);
-
-static ssize_t ata_scsi_park_show(struct device *device,
-				  struct device_attribute *attr, char *buf)
-{
-	struct scsi_device *sdev = to_scsi_device(device);
-	struct ata_port *ap;
-	struct ata_link *link;
-	struct ata_device *dev;
-	unsigned long flags, now;
-	unsigned int uninitialized_var(msecs);
-	int rc = 0;
-
-	ap = ata_shost_to_port(sdev->host);
-
-	spin_lock_irqsave(ap->lock, flags);
-	dev = ata_scsi_find_dev(ap, sdev);
-	if (!dev) {
-		rc = -ENODEV;
-		goto unlock;
-	}
-	if (dev->flags & ATA_DFLAG_NO_UNLOAD) {
-		rc = -EOPNOTSUPP;
-		goto unlock;
-	}
-
-	link = dev->link;
-	now = jiffies;
-	if (ap->pflags & ATA_PFLAG_EH_IN_PROGRESS &&
-	    link->eh_context.unloaded_mask & (1 << dev->devno) &&
-	    time_after(dev->unpark_deadline, now))
-		msecs = jiffies_to_msecs(dev->unpark_deadline - now);
-	else
-		msecs = 0;
-
-unlock:
-	spin_unlock_irq(ap->lock);
-
-	return rc ? rc : snprintf(buf, 20, "%u\n", msecs);
-}
-
-static ssize_t ata_scsi_park_store(struct device *device,
-				   struct device_attribute *attr,
-				   const char *buf, size_t len)
-{
-	struct scsi_device *sdev = to_scsi_device(device);
-	struct ata_port *ap;
-	struct ata_device *dev;
-	long int input;
-	unsigned long flags;
-	int rc;
-
-	rc = strict_strtol(buf, 10, &input);
-	if (rc || input < -2)
-		return -EINVAL;
-	if (input > ATA_TMOUT_MAX_PARK) {
-		rc = -EOVERFLOW;
-		input = ATA_TMOUT_MAX_PARK;
-	}
-
-	ap = ata_shost_to_port(sdev->host);
-
-	spin_lock_irqsave(ap->lock, flags);
-	dev = ata_scsi_find_dev(ap, sdev);
-	if (unlikely(!dev)) {
-		rc = -ENODEV;
-		goto unlock;
-	}
-	if (dev->class != ATA_DEV_ATA) {
-		rc = -EOPNOTSUPP;
-		goto unlock;
-	}
-
-	if (input >= 0) {
-		if (dev->flags & ATA_DFLAG_NO_UNLOAD) {
-			rc = -EOPNOTSUPP;
-			goto unlock;
-		}
-
-		dev->unpark_deadline = ata_deadline(jiffies, input);
-		dev->link->eh_info.dev_action[dev->devno] |= ATA_EH_PARK;
-		ata_port_schedule_eh(ap);
-		complete(&ap->park_req_pending);
-	} else {
-		switch (input) {
-		case -1:
-			dev->flags &= ~ATA_DFLAG_NO_UNLOAD;
-			break;
-		case -2:
-			dev->flags |= ATA_DFLAG_NO_UNLOAD;
-			break;
-		}
-	}
-unlock:
-	spin_unlock_irqrestore(ap->lock, flags);
-
-	return rc ? rc : len;
-}
-DEVICE_ATTR(unload_heads, S_IRUGO | S_IWUSR,
-	    ata_scsi_park_show, ata_scsi_park_store);
-EXPORT_SYMBOL_GPL(dev_attr_unload_heads);
-
-static void ata_scsi_set_sense(struct scsi_cmnd *cmd, u8 sk, u8 asc, u8 ascq)
+void ata_scsi_set_sense(struct scsi_cmnd *cmd, u8 sk, u8 asc, u8 ascq)
 {
 	cmd->result = (DRIVER_SENSE << 24) | SAM_STAT_CHECK_CONDITION;
 
-	scsi_build_sense_buffer(0, cmd->sense_buffer, sk, asc, ascq);
-}
-
-static ssize_t
-ata_scsi_em_message_store(struct device *dev, struct device_attribute *attr,
-			  const char *buf, size_t count)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-	if (ap->ops->em_store && (ap->flags & ATA_FLAG_EM))
-		return ap->ops->em_store(ap, buf, count);
-	return -EINVAL;
-}
-
-static ssize_t
-ata_scsi_em_message_show(struct device *dev, struct device_attribute *attr,
-			 char *buf)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-
-	if (ap->ops->em_show && (ap->flags & ATA_FLAG_EM))
-		return ap->ops->em_show(ap, buf);
-	return -EINVAL;
-}
-DEVICE_ATTR(em_message, S_IRUGO | S_IWUSR,
-		ata_scsi_em_message_show, ata_scsi_em_message_store);
-EXPORT_SYMBOL_GPL(dev_attr_em_message);
-
-static ssize_t
-ata_scsi_em_message_type_show(struct device *dev, struct device_attribute *attr,
-			      char *buf)
-{
-	struct Scsi_Host *shost = class_to_shost(dev);
-	struct ata_port *ap = ata_shost_to_port(shost);
-
-	return snprintf(buf, 23, "%d\n", ap->em_message_type);
+	cmd->sense_buffer[0] = 0x70;	/* fixed format, current */
+	cmd->sense_buffer[2] = sk;
+	cmd->sense_buffer[7] = 18 - 8;	/* additional sense length */
+	cmd->sense_buffer[12] = asc;
+	cmd->sense_buffer[13] = ascq;
 }
-DEVICE_ATTR(em_message_type, S_IRUGO,
-		  ata_scsi_em_message_type_show, NULL);
-EXPORT_SYMBOL_GPL(dev_attr_em_message_type);
-
-static ssize_t
-ata_scsi_activity_show(struct device *dev, struct device_attribute *attr,
-		char *buf)
-{
-	struct scsi_device *sdev = to_scsi_device(dev);
-	struct ata_port *ap = ata_shost_to_port(sdev->host);
-	struct ata_device *atadev = ata_scsi_find_dev(ap, sdev);
 
-	if (ap->ops->sw_activity_show && (ap->flags & ATA_FLAG_SW_ACTIVITY))
-		return ap->ops->sw_activity_show(atadev, buf);
-	return -EINVAL;
-}
-
-static ssize_t
-ata_scsi_activity_store(struct device *dev, struct device_attribute *attr,
-	const char *buf, size_t count)
-{
-	struct scsi_device *sdev = to_scsi_device(dev);
-	struct ata_port *ap = ata_shost_to_port(sdev->host);
-	struct ata_device *atadev = ata_scsi_find_dev(ap, sdev);
-	enum sw_activity val;
-	int rc;
-
-	if (ap->ops->sw_activity_store && (ap->flags & ATA_FLAG_SW_ACTIVITY)) {
-		val = simple_strtoul(buf, NULL, 0);
-		switch (val) {
-		case OFF: case BLINK_ON: case BLINK_OFF:
-			rc = ap->ops->sw_activity_store(atadev, val);
-			if (!rc)
-				return count;
-			else
-				return rc;
-		}
-	}
-	return -EINVAL;
-}
-DEVICE_ATTR(sw_activity, S_IWUSR | S_IRUGO, ata_scsi_activity_show,
-			ata_scsi_activity_store);
-EXPORT_SYMBOL_GPL(dev_attr_sw_activity);
-
-struct device_attribute *ata_common_sdev_attrs[] = {
-	&dev_attr_unload_heads,
-	NULL
-};
-EXPORT_SYMBOL_GPL(ata_common_sdev_attrs);
 
 static void ata_scsi_invalid_field(struct scsi_cmnd *cmd,
 				   void (*done)(struct scsi_cmnd *))
@@ -415,7 +179,6 @@
 
 /**
  *	ata_get_identity - Handler for HDIO_GET_IDENTITY ioctl
- *	@ap: target port
  *	@sdev: SCSI device to get identify data for
  *	@arg: User buffer area for identify data
  *
@@ -425,9 +188,9 @@
  *	RETURNS:
  *	Zero on success, negative errno on error.
  */
-static int ata_get_identity(struct ata_port *ap, struct scsi_device *sdev,
-			    void __user *arg)
+static int ata_get_identity(struct scsi_device *sdev, void __user *arg)
 {
+	struct ata_port *ap = ata_shost_to_port(sdev->host);
 	struct ata_device *dev = ata_scsi_find_dev(ap, sdev);
 	u16 __user *dst = arg;
 	char buf[40];
@@ -495,7 +258,7 @@
 
 		scsi_cmd[1]  = (4 << 1); /* PIO Data-in */
 		scsi_cmd[2]  = 0x0e;     /* no off.line or cc, read from dev,
-					    block count in sector count field */
+		                            block count in sector count field */
 		data_dir = DMA_FROM_DEVICE;
 	} else {
 		scsi_cmd[1]  = (3 << 1); /* Non-data */
@@ -506,7 +269,7 @@
 	scsi_cmd[0] = ATA_16;
 
 	scsi_cmd[4] = args[2];
-	if (args[0] == ATA_CMD_SMART) { /* hack -- ide driver does this too */
+	if (args[0] == ATA_CMD_SMART) { /* hack -- ide driver does this too... */
 		scsi_cmd[6]  = args[3];
 		scsi_cmd[8]  = args[1];
 		scsi_cmd[10] = 0x4f;
@@ -519,7 +282,7 @@
 	/* Good values for timeout and retries?  Values below
 	   from scsi_ioctl_send_command() for default case... */
 	cmd_result = scsi_execute(scsidev, scsi_cmd, data_dir, argbuf, argsize,
-				  sensebuf, (10*HZ), 5, 0, NULL);
+	                          sensebuf, (10*HZ), 5, 0, NULL);
 
 	if (driver_byte(cmd_result) == DRIVER_SENSE) {/* sense data available */
 		u8 *desc = sensebuf + 8;
@@ -530,18 +293,18 @@
 		if (cmd_result & SAM_STAT_CHECK_CONDITION) {
 			struct scsi_sense_hdr sshdr;
 			scsi_normalize_sense(sensebuf, SCSI_SENSE_BUFFERSIZE,
-					     &sshdr);
-			if (sshdr.sense_key == 0 &&
-			    sshdr.asc == 0 && sshdr.ascq == 0)
+			                      &sshdr);
+			if (sshdr.sense_key==0 &&
+			    sshdr.asc==0 && sshdr.ascq==0)
 				cmd_result &= ~SAM_STAT_CHECK_CONDITION;
 		}
 
 		/* Send userspace a few ATA registers (same as drivers/ide) */
-		if (sensebuf[0] == 0x72 &&	/* format is "descriptor" */
-		    desc[0] == 0x09) {		/* code is "ATA Descriptor" */
-			args[0] = desc[13];	/* status */
-			args[1] = desc[3];	/* error */
-			args[2] = desc[5];	/* sector count (0:7) */
+		if (sensebuf[0] == 0x72 &&     /* format is "descriptor" */
+		    desc[0] == 0x09 ) {        /* code is "ATA Descriptor" */
+			args[0] = desc[13];    /* status */
+			args[1] = desc[3];     /* error */
+			args[2] = desc[5];     /* sector count (0:7) */
 			if (copy_to_user(arg, args, sizeof(args)))
 				rc = -EFAULT;
 		}
@@ -617,8 +380,8 @@
 			struct scsi_sense_hdr sshdr;
 			scsi_normalize_sense(sensebuf, SCSI_SENSE_BUFFERSIZE,
 						&sshdr);
-			if (sshdr.sense_key == 0 &&
-				sshdr.asc == 0 && sshdr.ascq == 0)
+			if (sshdr.sense_key==0 &&
+				sshdr.asc==0 && sshdr.ascq==0)
 				cmd_result &= ~SAM_STAT_CHECK_CONDITION;
 		}
 
@@ -647,48 +410,25 @@
 	return rc;
 }
 
-static int ata_ioc32(struct ata_port *ap)
-{
-	if (ap->flags & ATA_FLAG_PIO_DMA)
-		return 1;
-	if (ap->pflags & ATA_PFLAG_PIO32)
-		return 1;
-	return 0;
-}
-
-int ata_sas_scsi_ioctl(struct ata_port *ap, struct scsi_device *scsidev,
-		     int cmd, void __user *arg)
+int ata_scsi_ioctl(struct scsi_device *scsidev, int cmd, void __user *arg)
 {
 	int val = -EINVAL, rc = -EINVAL;
-	unsigned long flags;
 
 	switch (cmd) {
 	case ATA_IOC_GET_IO32:
-		spin_lock_irqsave(ap->lock, flags);
-		val = ata_ioc32(ap);
-		spin_unlock_irqrestore(ap->lock, flags);
+		val = 0;
 		if (copy_to_user(arg, &val, 1))
 			return -EFAULT;
 		return 0;
 
 	case ATA_IOC_SET_IO32:
 		val = (unsigned long) arg;
-		rc = 0;
-		spin_lock_irqsave(ap->lock, flags);
-		if (ap->pflags & ATA_PFLAG_PIO32CHANGE) {
-			if (val)
-				ap->pflags |= ATA_PFLAG_PIO32;
-			else
-				ap->pflags &= ~ATA_PFLAG_PIO32;
-		} else {
-			if (val != ata_ioc32(ap))
-				rc = -EINVAL;
-		}
-		spin_unlock_irqrestore(ap->lock, flags);
-		return rc;
+		if (val != 0)
+			return -EINVAL;
+		return 0;
 
 	case HDIO_GET_IDENTITY:
-		return ata_get_identity(ap, scsidev, arg);
+		return ata_get_identity(scsidev, arg);
 
 	case HDIO_DRIVE_CMD:
 		if (!capable(CAP_SYS_ADMIN) || !capable(CAP_SYS_RAWIO))
@@ -707,14 +447,6 @@
 
 	return rc;
 }
-EXPORT_SYMBOL_GPL(ata_sas_scsi_ioctl);
-
-int ata_scsi_ioctl(struct scsi_device *scsidev, int cmd, void __user *arg)
-{
-	return ata_sas_scsi_ioctl(ata_shost_to_port(scsidev->host),
-				scsidev, cmd, arg);
-}
-EXPORT_SYMBOL_GPL(ata_scsi_ioctl);
 
 /**
  *	ata_scsi_qc_new - acquire new ata_queued_cmd reference
@@ -747,7 +479,7 @@
 		qc->scsicmd = cmd;
 		qc->scsidone = done;
 
-		qc->sg = scsi_sglist(cmd);
+		qc->__sg = scsi_sglist(cmd);
 		qc->n_elem = scsi_sg_count(cmd);
 	} else {
 		cmd->result = (DID_OK << 16) | (QUEUE_FULL << 1);
@@ -757,14 +489,6 @@
 	return qc;
 }
 
-static void ata_qc_set_pc_nbytes(struct ata_queued_cmd *qc)
-{
-	struct scsi_cmnd *scmd = qc->scsicmd;
-
-	qc->extrabytes = scmd->request->extra_len;
-	qc->nbytes = scsi_bufflen(scmd) + qc->extrabytes;
-}
-
 /**
  *	ata_dump_status - user friendly display of error info
  *	@id: id of the port in question
@@ -1055,13 +779,42 @@
 {
 	sdev->use_10_for_rw = 1;
 	sdev->use_10_for_ms = 1;
+}
 
-	/* Schedule policy is determined by ->qc_defer() callback and
-	 * it needs to see every deferred qc.  Set dev_blocked to 1 to
-	 * prevent SCSI midlayer from automatically deferring
-	 * requests.
-	 */
-	sdev->max_device_blocked = 1;
+/**
+ *	atapi_cmd_type - Determine ATAPI command type from SCSI opcode
+ *	@opcode: SCSI opcode
+ *
+ *	Determine ATAPI command type from @opcode.
+ *
+ *	LOCKING:
+ *	None.
+ *
+ *	RETURNS:
+ *	ATAPI_{READ|WRITE|READ_CD|PASS_THRU|MISC}
+ */
+int atapi_cmd_type(u8 opcode)
+{
+	switch (opcode) {
+	case GPCMD_READ_10:
+	case GPCMD_READ_12:
+		return ATAPI_READ;
+
+	case GPCMD_WRITE_10:
+	case GPCMD_WRITE_12:
+	case GPCMD_WRITE_AND_VERIFY_10:
+		return ATAPI_WRITE;
+
+	case GPCMD_READ_CD:
+	case GPCMD_READ_CD_MSF:
+		return ATAPI_READ_CD;
+
+	case ATA_16:
+	case ATA_12:
+		/* fall thru */
+	default:
+		return ATAPI_MISC;
+	}
 }
 
 /**
@@ -1090,22 +843,23 @@
 	return atapi_cmd_type(rq->cmd[0]) == ATAPI_MISC;
 }
 
-static int ata_scsi_dev_config(struct scsi_device *sdev,
-			       struct ata_device *dev)
+static void ata_scsi_dev_config(struct scsi_device *sdev,
+				struct ata_device *dev)
 {
-	if (!ata_id_has_unload(dev->id))
-		dev->flags |= ATA_DFLAG_NO_UNLOAD;
-
 	/* configure max sectors */
 	blk_queue_max_sectors(sdev->request_queue, dev->max_sectors);
 
-	sdev->sector_size = ATA_SECT_SIZE;
-
+	/* SATA DMA transfers must be multiples of 4 byte, so
+	 * we need to pad ATAPI transfers using an extra sg.
+	 * Decrement max hw segments accordingly.
+	 */
 	if (dev->class == ATA_DEV_ATAPI) {
 		struct request_queue *q = sdev->request_queue;
 		void *buf;
 
-		/* set DMA padding */
+		/* set the min alignment and padding */
+		blk_queue_update_dma_alignment(sdev->request_queue,
+					       ATA_DMA_PAD_SZ - 1);
 		blk_queue_update_dma_pad(sdev->request_queue,
 					 ATA_DMA_PAD_SZ - 1);
 
@@ -1114,32 +868,12 @@
 		if (!buf) {
 			ata_dev_printk(dev, KERN_ERR,
 				       "drain buffer allocation failed\n");
-			return -ENOMEM;
+			return;
 		}
 
 		blk_queue_dma_drain(q, atapi_drain_needed, buf, ATAPI_MAX_DRAIN);
-	} else {
-		sdev->manage_start_stop = 1;
 	}
 
-	/*
-	 * ata_pio_sectors() expects buffer for each sector to not cross
-	 * page boundary.  Enforce it by requiring buffers to be sector
-	 * aligned, which works iff sector_size is not larger than
-	 * PAGE_SIZE.  ATAPI devices also need the alignment as
-	 * IDENTIFY_PACKET is executed as ATA_PROT_PIO.
-	 */
-	if (sdev->sector_size > PAGE_SIZE)
-		ata_dev_printk(dev, KERN_WARNING,
-			"sector_size=%u > PAGE_SIZE, PIO may malfunction\n",
-			sdev->sector_size);
-
-	blk_queue_update_dma_alignment(sdev->request_queue,
-				       sdev->sector_size - 1);
-
-	if (dev->flags & ATA_DFLAG_AN)
-		set_bit(SDEV_EVT_MEDIA_CHANGE, sdev->supported_events);
-
 	if (dev->flags & ATA_DFLAG_NCQ) {
 		int depth;
 
@@ -1147,8 +881,6 @@
 		depth = min(ATA_MAX_QUEUE - 1, depth);
 		scsi_adjust_queue_depth(sdev, MSG_SIMPLE_TAG, depth);
 	}
-
-	return 0;
 }
 
 /**
@@ -1167,14 +899,17 @@
 {
 	struct ata_port *ap = ata_shost_to_port(sdev->host);
 	struct ata_device *dev = __ata_scsi_find_dev(ap, sdev);
-	int rc = 0;
 
 	ata_scsi_sdev_config(sdev);
 
+	blk_queue_max_phys_segments(sdev->request_queue, LIBATA_MAX_PRD);
+
+	sdev->manage_start_stop = 1;
+
 	if (dev)
-		rc = ata_scsi_dev_config(sdev, dev);
+		ata_scsi_dev_config(sdev, dev);
 
-	return rc;
+	return 0;	/* scsi layer doesn't check return value, sigh */
 }
 
 /**
@@ -1194,7 +929,6 @@
 void ata_scsi_slave_destroy(struct scsi_device *sdev)
 {
 	struct ata_port *ap = ata_shost_to_port(sdev->host);
-	struct request_queue *q = sdev->request_queue;
 	unsigned long flags;
 	struct ata_device *dev;
 
@@ -1210,10 +944,6 @@
 		ata_port_schedule_eh(ap);
 	}
 	spin_unlock_irqrestore(ap->lock, flags);
-
-	kfree(q->dma_drain_buffer);
-	q->dma_drain_buffer = NULL;
-	q->dma_drain_size = 0;
 }
 
 /**
@@ -1265,6 +995,23 @@
 	return queue_depth;
 }
 
+/* XXX: for spindown warning */
+static void ata_delayed_done_timerfn(unsigned long arg)
+{
+	struct scsi_cmnd *scmd = (void *)arg;
+
+	scmd->scsi_done(scmd);
+}
+
+/* XXX: for spindown warning */
+static void ata_delayed_done(struct scsi_cmnd *scmd)
+{
+	static struct timer_list timer;
+
+	setup_timer(&timer, ata_delayed_done_timerfn, (unsigned long)scmd);
+	mod_timer(&timer, jiffies + 5 * HZ);
+}
+
 /**
  *	ata_scsi_start_stop_xlat - Translate SCSI START STOP UNIT command
  *	@qc: Storage for translated ATA taskfile
@@ -1298,7 +1045,6 @@
 		goto invalid_fld;       /* LOEJ bit set not supported */
 	if (((cdb[4] >> 4) & 0xf) != 0)
 		goto invalid_fld;       /* power conditions not supported */
-
 	if (cdb[4] & 0x1) {
 		tf->nsect = 1;	/* 1 sector, lba=0 */
 
@@ -1318,16 +1064,32 @@
 
 		tf->command = ATA_CMD_VERIFY;	/* READ VERIFY */
 	} else {
-		/* Some odd clown BIOSen issue spindown on power off (ACPI S4
-		 * or S5) causing some drives to spin up and down again.
+		/* XXX: This is for backward compatibility, will be
+		 * removed.  Read Documentation/feature-removal-schedule.txt
+		 * for more info.
 		 */
-		if ((qc->ap->flags & ATA_FLAG_NO_POWEROFF_SPINDOWN) &&
-		    system_state == SYSTEM_POWER_OFF)
-			goto skip;
-
-		if ((qc->ap->flags & ATA_FLAG_NO_HIBERNATE_SPINDOWN) &&
-		     system_entering_hibernation())
-			goto skip;
+		if ((qc->dev->flags & ATA_DFLAG_SPUNDOWN) &&
+		    (system_state == SYSTEM_HALT ||
+		     system_state == SYSTEM_POWER_OFF)) {
+			static unsigned long warned = 0;
+
+			if (!test_and_set_bit(0, &warned)) {
+				ata_dev_printk(qc->dev, KERN_WARNING,
+					"DISK MIGHT NOT BE SPUN DOWN PROPERLY. "
+					"UPDATE SHUTDOWN UTILITY\n");
+				ata_dev_printk(qc->dev, KERN_WARNING,
+					"For more info, visit "
+					"http://linux-ata.org/shutdown.html\n");
+
+				/* ->scsi_done is not used, use it for
+				 * delayed completion.
+				 */
+				scmd->scsi_done = qc->scsidone;
+				qc->scsidone = ata_delayed_done;
+			}
+			scmd->result = SAM_STAT_GOOD;
+			return 1;
+		}
 
 		/* Issue ATA STANDBY IMMEDIATE command */
 		tf->command = ATA_CMD_STANDBYNOW1;
@@ -1342,13 +1104,10 @@
 
 	return 0;
 
- invalid_fld:
+invalid_fld:
 	ata_scsi_set_sense(scmd, ILLEGAL_REQUEST, 0x24, 0x0);
 	/* "Invalid field in cbd" */
 	return 1;
- skip:
-	scmd->result = SAM_STAT_GOOD;
-	return 1;
 }
 
 
@@ -1377,9 +1136,6 @@
 	else
 		tf->command = ATA_CMD_FLUSH;
 
-	/* flush is critical for IO integrity, consider it an IO command */
-	qc->flags |= ATA_QCFLAG_IO;
-
 	return 0;
 }
 
@@ -1703,7 +1459,29 @@
 	struct ata_port *ap = qc->ap;
 	struct scsi_cmnd *cmd = qc->scsicmd;
 	u8 *cdb = cmd->cmnd;
-	int need_sense = (qc->err_mask != 0);
+ 	int need_sense = (qc->err_mask != 0);
+
+	/* We snoop the SET_FEATURES - Write Cache ON/OFF command, and
+	 * schedule EH_REVALIDATE operation to update the IDENTIFY DEVICE
+	 * cache
+	 */
+	if (ap->ops->error_handler && !need_sense) {
+		switch (qc->tf.command) {
+		case ATA_CMD_SET_FEATURES:
+			if ((qc->tf.feature == SETFEATURES_WC_ON) ||
+			    (qc->tf.feature == SETFEATURES_WC_OFF)) {
+				ap->eh_info.action |= ATA_EH_REVALIDATE;
+				ata_port_schedule_eh(ap);
+			}
+			break;
+
+		case ATA_CMD_INIT_DEV_PARAMS: /* CHS translation changed */
+		case ATA_CMD_SET_MULTI: /* multi_count changed */
+			ap->eh_info.action |= ATA_EH_REVALIDATE;
+			ata_port_schedule_eh(ap);
+			break;
+		}
+	}
 
 	/* For ATA pass thru (SAT) commands, generate a sense block if
 	 * user mandated it or if there's an error.  Note that if we
@@ -1713,7 +1491,7 @@
 	 * was no error, SK, ASC and ASCQ will all be zero.
 	 */
 	if (((cdb[0] == ATA_16) || (cdb[0] == ATA_12)) &&
-	    ((cdb[2] & 0x20) || need_sense)) {
+ 	    ((cdb[2] & 0x20) || need_sense)) {
 		ata_gen_passthru_sense(qc);
 	} else {
 		if (!need_sense) {
@@ -1729,6 +1507,14 @@
 		}
 	}
 
+	/* XXX: track spindown state for spindown skipping and warning */
+	if (unlikely(qc->tf.command == ATA_CMD_STANDBY ||
+		     qc->tf.command == ATA_CMD_STANDBYNOW1))
+		qc->dev->flags |= ATA_DFLAG_SPUNDOWN;
+	else if (likely(system_state != SYSTEM_HALT &&
+			system_state != SYSTEM_POWER_OFF))
+		qc->dev->flags &= ~ATA_DFLAG_SPUNDOWN;
+
 	if (need_sense && !ap->ops->error_handler)
 		ata_dump_status(ap->print_id, &qc->result_tf);
 
@@ -1738,6 +1524,37 @@
 }
 
 /**
+ *	ata_scmd_need_defer - Check whether we need to defer scmd
+ *	@dev: ATA device to which the command is addressed
+ *	@is_io: Is the command IO (and thus possibly NCQ)?
+ *
+ *	NCQ and non-NCQ commands cannot run together.  As upper layer
+ *	only knows the queue depth, we are responsible for maintaining
+ *	exclusion.  This function checks whether a new command can be
+ *	issued to @dev.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ *	RETURNS:
+ *	1 if deferring is needed, 0 otherwise.
+ */
+static int ata_scmd_need_defer(struct ata_device *dev, int is_io)
+{
+	struct ata_port *ap = dev->ap;
+	int is_ncq = is_io && ata_ncq_enabled(dev);
+
+	if (is_ncq) {
+		if (!ata_tag_valid(ap->active_tag))
+			return 0;
+	} else {
+		if (!ata_tag_valid(ap->active_tag) && !ap->sactive)
+			return 0;
+	}
+	return 1;
+}
+
+/**
  *	ata_scsi_translate - Translate then issue SCSI command to ATA device
  *	@dev: ATA device to which the command is addressed
  *	@cmd: SCSI command to execute
@@ -1768,12 +1585,14 @@
 			      void (*done)(struct scsi_cmnd *),
 			      ata_xlat_func_t xlat_func)
 {
-	struct ata_port *ap = dev->link->ap;
 	struct ata_queued_cmd *qc;
-	int rc;
+	int is_io = xlat_func == ata_scsi_rw_xlat;
 
 	VPRINTK("ENTER\n");
 
+	if (unlikely(ata_scmd_need_defer(dev, is_io)))
+		goto defer;
+
 	qc = ata_scsi_qc_new(dev, cmd, done);
 	if (!qc)
 		goto err_mem;
@@ -1787,6 +1606,11 @@
 			goto err_did;
 		}
 
+		/*if (cmd->use_sg)
+			ata_sg_init(qc, cmd->request_buffer, cmd->use_sg);
+		else
+			ata_sg_init_one(qc, cmd->request_buffer,
+					cmd->request_bufflen);*/
 		ata_sg_init(qc, scsi_sglist(cmd), scsi_sg_count(cmd));
 
 		qc->dma_dir = cmd->sc_data_direction;
@@ -1797,11 +1621,6 @@
 	if (xlat_func(qc))
 		goto early_finish;
 
-	if (ap->ops->qc_defer) {
-		if ((rc = ap->ops->qc_defer(qc)))
-			goto defer;
-	}
-
 	/* select device, send command to hardware */
 	ata_qc_issue(qc);
 
@@ -1809,7 +1628,7 @@
 	return 0;
 
 early_finish:
-	ata_qc_free(qc);
+        ata_qc_free(qc);
 	qc->scsidone(cmd);
 	DPRINTK("EXIT - early finish (good or error)\n");
 	return 0;
@@ -1823,28 +1642,29 @@
 	return 0;
 
 defer:
-	ata_qc_free(qc);
 	DPRINTK("EXIT - defer\n");
-	if (rc == ATA_DEFER_LINK)
-		return SCSI_MLQUEUE_DEVICE_BUSY;
-	else
-		return SCSI_MLQUEUE_HOST_BUSY;
+	return SCSI_MLQUEUE_DEVICE_BUSY;
 }
 
+#define ATA_SCSI_RBUF_SIZE	4096
+
+static DEFINE_SPINLOCK(ata_scsi_rbuf_lock);
+static u8 ata_scsi_rbuf[ATA_SCSI_RBUF_SIZE];
+
 /**
  *	ata_scsi_rbuf_get - Map response buffer.
  *	@cmd: SCSI command containing buffer to be mapped.
- *	@flags: unsigned long variable to store irq enable status
- *	@copy_in: copy in from user buffer
+ *	@buf_out: Pointer to mapped area.
  *
- *	Prepare buffer for simulated SCSI commands.
+ *	Maps buffer contained within SCSI command @cmd.
  *
  *	LOCKING:
- *	spin_lock_irqsave(ata_scsi_rbuf_lock) on success
+ *	spin_lock_irqsave(host lock)
  *
  *	RETURNS:
- *	Pointer to response buffer.
+ *	Length of response buffer.
  */
+
 static void *ata_scsi_rbuf_get(struct scsi_cmnd *cmd, bool copy_in,
 			       unsigned long *flags)
 {
@@ -1860,15 +1680,14 @@
 /**
  *	ata_scsi_rbuf_put - Unmap response buffer.
  *	@cmd: SCSI command containing buffer to be unmapped.
- *	@copy_out: copy out result
- *	@flags: @flags passed to ata_scsi_rbuf_get()
+ *	@buf: buffer to unmap
  *
- *	Returns rbuf buffer.  The result is copied to @cmd's buffer if
- *	@copy_back is true.
+ *	Unmaps response buffer contained within @cmd.
  *
  *	LOCKING:
- *	Unlocks ata_scsi_rbuf_lock.
+ *	spin_lock_irqsave(host lock)
  */
+
 static inline void ata_scsi_rbuf_put(struct scsi_cmnd *cmd, bool copy_out,
 				     unsigned long *flags)
 {
@@ -1893,6 +1712,7 @@
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
+
 static void ata_scsi_rbuf_fill(struct ata_scsi_args *args,
 		unsigned int (*actor)(struct ata_scsi_args *args, u8 *rbuf))
 {
@@ -1911,9 +1731,26 @@
 }
 
 /**
+ *	ATA_SCSI_RBUF_SET - helper to set values in SCSI response buffer
+ *	@idx: byte index into SCSI response buffer
+ *	@val: value to set
+ *
+ *	To be used by SCSI command simulator functions.  This macros
+ *	expects two local variables, u8 *rbuf and unsigned int buflen,
+ *	are in scope.
+ *
+ *	LOCKING:
+ *	None.
+ */
+#define ATA_SCSI_RBUF_SET(idx, val) do { \
+		if ((idx) < buflen) rbuf[(idx)] = (u8)(val); \
+	} while (0)
+
+/**
  *	ata_scsiop_inq_std - Simulate INQUIRY command
  *	@args: device IDENTIFY data / SCSI command of interest.
  *	@rbuf: Response buffer, to which simulated SCSI cmd output is sent.
+ *	@buflen: Response buffer length.
  *
  *	Returns standard device identification data associated
  *	with non-VPD INQUIRY command output.
@@ -1921,7 +1758,8 @@
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
-static unsigned int ata_scsiop_inq_std(struct ata_scsi_args *args, u8 *rbuf)
+
+unsigned int ata_scsiop_inq_std(struct ata_scsi_args *args, u8 *rbuf)
 {
 	const u8 versions[] = {
 		0x60,	/* SAM-3 (no version claimed) */
@@ -1963,13 +1801,15 @@
  *	ata_scsiop_inq_00 - Simulate INQUIRY VPD page 0, list of pages
  *	@args: device IDENTIFY data / SCSI command of interest.
  *	@rbuf: Response buffer, to which simulated SCSI cmd output is sent.
+ *	@buflen: Response buffer length.
  *
  *	Returns list of inquiry VPD pages available.
  *
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
-static unsigned int ata_scsiop_inq_00(struct ata_scsi_args *args, u8 *rbuf)
+
+unsigned int ata_scsiop_inq_00(struct ata_scsi_args *args, u8 *rbuf)
 {
 	const u8 pages[] = {
 		0x00,	/* page 0x00, this page */
@@ -1988,13 +1828,15 @@
  *	ata_scsiop_inq_80 - Simulate INQUIRY VPD page 80, device serial number
  *	@args: device IDENTIFY data / SCSI command of interest.
  *	@rbuf: Response buffer, to which simulated SCSI cmd output is sent.
+ *	@buflen: Response buffer length.
  *
  *	Returns ATA device serial number.
  *
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
-static unsigned int ata_scsiop_inq_80(struct ata_scsi_args *args, u8 *rbuf)
+
+unsigned int ata_scsiop_inq_80(struct ata_scsi_args *args, u8 *rbuf)
 {
 	const u8 hdr[] = {
 		0,
@@ -2013,6 +1855,7 @@
  *	ata_scsiop_inq_83 - Simulate INQUIRY VPD page 83, device identity
  *	@args: device IDENTIFY data / SCSI command of interest.
  *	@rbuf: Response buffer, to which simulated SCSI cmd output is sent.
+ *	@buflen: Response buffer length.
  *
  *	Yields two logical unit device identification designators:
  *	 - vendor specific ASCII containing the ATA serial number
@@ -2022,7 +1865,8 @@
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
-static unsigned int ata_scsiop_inq_83(struct ata_scsi_args *args, u8 *rbuf)
+
+unsigned int ata_scsiop_inq_83(struct ata_scsi_args *args, u8 *rbuf)
 {
 	const int sat_model_serial_desc_len = 68;
 	int num;
@@ -2079,7 +1923,7 @@
 
 	memcpy(&rbuf[8], "linux   ", 8);
 	memcpy(&rbuf[16], "libata          ", 16);
-	memcpy(&rbuf[32], DRV_VERSION, 4);
+	memcpy(&rbuf[32], "XXXX", 4);
 	ata_id_string(args->id, &rbuf[32], ATA_ID_FW_REV, 4);
 
 	/* we don't store the ATA device signature, so we fake it */
@@ -2097,24 +1941,11 @@
 	return 0;
 }
 
-static unsigned int ata_scsiop_inq_b1(struct ata_scsi_args *args, u8 *rbuf)
-{
-	int form_factor = ata_id_form_factor(args->id);
-	int media_rotation_rate = ata_id_rotation_rate(args->id);
-
-	rbuf[1] = 0xb1;
-	rbuf[3] = 0x3c;
-	rbuf[4] = media_rotation_rate >> 8;
-	rbuf[5] = media_rotation_rate;
-	rbuf[7] = form_factor;
-
-	return 0;
-}
-
 /**
  *	ata_scsiop_noop - Command handler that simply returns success.
  *	@args: device IDENTIFY data / SCSI command of interest.
  *	@rbuf: Response buffer, to which simulated SCSI cmd output is sent.
+ *	@buflen: Response buffer length.
  *
  *	No operation.  Simply returns success to caller, to indicate
  *	that the caller should successfully complete this SCSI command.
@@ -2122,16 +1953,46 @@
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
-static unsigned int ata_scsiop_noop(struct ata_scsi_args *args, u8 *rbuf)
+
+unsigned int ata_scsiop_noop(struct ata_scsi_args *args, u8 *rbuf)
 {
 	VPRINTK("ENTER\n");
 	return 0;
 }
 
 /**
+ *	ata_msense_push - Push data onto MODE SENSE data output buffer
+ *	@ptr_io: (input/output) Location to store more output data
+ *	@last: End of output data buffer
+ *	@buf: Pointer to BLOB being added to output buffer
+ *	@buflen: Length of BLOB
+ *
+ *	Store MODE SENSE data on an output buffer.
+ *
+ *	LOCKING:
+ *	None.
+ */
+
+static void ata_msense_push(u8 **ptr_io, const u8 *last,
+			    const u8 *buf, unsigned int buflen)
+{
+	u8 *ptr = *ptr_io;
+
+	if ((ptr + buflen - 1) > last)
+		return;
+
+	memcpy(ptr, buf, buflen);
+
+	ptr += buflen;
+
+	*ptr_io = ptr;
+}
+
+/**
  *	ata_msense_caching - Simulate MODE SENSE caching info page
  *	@id: device IDENTIFY data
- *	@buf: output buffer
+ *	@ptr_io: (input/output) Location to store more output data
+ *	@last: End of output data buffer
  *
  *	Generate a caching info page, which conditionally indicates
  *	write caching to the SCSI layer, depending on device
@@ -2140,6 +2001,7 @@
  *	LOCKING:
  *	None.
  */
+
 static unsigned int ata_msense_caching(u16 *id, u8 *buf)
 {
 	memcpy(buf, def_cache_mpage, sizeof(def_cache_mpage));
@@ -2152,13 +2014,16 @@
 
 /**
  *	ata_msense_ctl_mode - Simulate MODE SENSE control mode page
- *	@buf: output buffer
+ *	@dev: Device associated with this MODE SENSE command
+ *	@ptr_io: (input/output) Location to store more output data
+ *	@last: End of output data buffer
  *
  *	Generate a generic MODE SENSE control mode page.
  *
  *	LOCKING:
  *	None.
  */
+
 static unsigned int ata_msense_ctl_mode(u8 *buf)
 {
 	memcpy(buf, def_control_mpage, sizeof(def_control_mpage));
@@ -2167,13 +2032,16 @@
 
 /**
  *	ata_msense_rw_recovery - Simulate MODE SENSE r/w error recovery page
- *	@buf: output buffer
+ *	@dev: Device associated with this MODE SENSE command
+ *	@ptr_io: (input/output) Location to store more output data
+ *	@last: End of output data buffer
  *
  *	Generate a generic MODE SENSE r/w error recovery page.
  *
  *	LOCKING:
  *	None.
  */
+
 static unsigned int ata_msense_rw_recovery(u8 *buf)
 {
 	memcpy(buf, def_rw_recovery_mpage, sizeof(def_rw_recovery_mpage));
@@ -2208,6 +2076,7 @@
  *	ata_scsiop_mode_sense - Simulate MODE SENSE 6, 10 commands
  *	@args: device IDENTIFY data / SCSI command of interest.
  *	@rbuf: Response buffer, to which simulated SCSI cmd output is sent.
+ *	@buflen: Response buffer length.
  *
  *	Simulate MODE SENSE commands. Assume this is invoked for direct
  *	access devices (e.g. disks) only. There should be no block
@@ -2216,7 +2085,8 @@
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
-static unsigned int ata_scsiop_mode_sense(struct ata_scsi_args *args, u8 *rbuf)
+
+unsigned int ata_scsiop_mode_sense(struct ata_scsi_args *args, u8 *rbuf)
 {
 	struct ata_device *dev = args->dev;
 	u8 *scsicmd = args->cmd->cmnd, *p = rbuf;
@@ -2326,13 +2196,14 @@
  *	ata_scsiop_read_cap - Simulate READ CAPACITY[ 16] commands
  *	@args: device IDENTIFY data / SCSI command of interest.
  *	@rbuf: Response buffer, to which simulated SCSI cmd output is sent.
+ *	@buflen: Response buffer length.
  *
  *	Simulate READ CAPACITY commands.
  *
  *	LOCKING:
  *	None.
  */
-static unsigned int ata_scsiop_read_cap(struct ata_scsi_args *args, u8 *rbuf)
+unsigned int ata_scsiop_read_cap(struct ata_scsi_args *args, u8 *rbuf)
 {
 	struct ata_device *dev = args->dev;
 	u64 last_lba = dev->n_sectors - 1; /* LBA of the last block */
@@ -2395,13 +2266,15 @@
  *	ata_scsiop_report_luns - Simulate REPORT LUNS command
  *	@args: device IDENTIFY data / SCSI command of interest.
  *	@rbuf: Response buffer, to which simulated SCSI cmd output is sent.
+ *	@buflen: Response buffer length.
  *
  *	Simulate REPORT LUNS command.
  *
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
-static unsigned int ata_scsiop_report_luns(struct ata_scsi_args *args, u8 *rbuf)
+
+unsigned int ata_scsiop_report_luns(struct ata_scsi_args *args, u8 *rbuf)
 {
 	VPRINTK("ENTER\n");
 	rbuf[3] = 8;	/* just one lun, LUN 0, size 8 bytes */
@@ -2409,6 +2282,29 @@
 	return 0;
 }
 
+/**
+ *	ata_scsi_badcmd - End a SCSI request with an error
+ *	@cmd: SCSI request to be handled
+ *	@done: SCSI command completion function
+ *	@asc: SCSI-defined additional sense code
+ *	@ascq: SCSI-defined additional sense code qualifier
+ *
+ *	Helper function that completes a SCSI command with
+ *	%SAM_STAT_CHECK_CONDITION, with a sense key %ILLEGAL_REQUEST
+ *	and the specified additional sense codes.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ */
+
+void ata_scsi_badcmd(struct scsi_cmnd *cmd, void (*done)(struct scsi_cmnd *), u8 asc, u8 ascq)
+{
+	DPRINTK("ENTER\n");
+	ata_scsi_set_sense(cmd, ILLEGAL_REQUEST, asc, ascq);
+
+	done(cmd);
+}
+
 static void atapi_sense_complete(struct ata_queued_cmd *qc)
 {
 	if (qc->err_mask && ((qc->err_mask & AC_ERR_DEV) == 0)) {
@@ -2438,12 +2334,9 @@
 	DPRINTK("ATAPI request sense\n");
 
 	/* FIXME: is this needed? */
-	memset(cmd->sense_buffer, 0, SCSI_SENSE_BUFFERSIZE);
+	memset(cmd->sense_buffer, 0, sizeof(cmd->sense_buffer));
 
-#ifdef CONFIG_ATA_SFF
-	if (ap->ops->sff_tf_read)
-		ap->ops->sff_tf_read(ap, &qc->tf);
-#endif
+	ap->ops->tf_read(ap, &qc->tf);
 
 	/* fill these in, for the case where they are -not- overwritten */
 	cmd->sense_buffer[0] = 0x70;
@@ -2451,9 +2344,7 @@
 
 	ata_qc_reinit(qc);
 
-	/* setup sg table and init transfer direction */
-	sg_init_one(&qc->sgent, cmd->sense_buffer, SCSI_SENSE_BUFFERSIZE);
-	ata_sg_init(qc, &qc->sgent, 1);
+	ata_sg_init_one(qc, cmd->sense_buffer, sizeof(cmd->sense_buffer));
 	qc->dma_dir = DMA_FROM_DEVICE;
 
 	memset(&qc->cdb, 0, qc->dev->cdb_len);
@@ -2464,12 +2355,12 @@
 	qc->tf.command = ATA_CMD_PACKET;
 
 	if (ata_pio_use_silly(ap)) {
-		qc->tf.protocol = ATAPI_PROT_DMA;
+		qc->tf.protocol = ATA_PROT_ATAPI_DMA;
 		qc->tf.feature |= ATAPI_PKT_DMA;
 	} else {
-		qc->tf.protocol = ATAPI_PROT_PIO;
-		qc->tf.lbam = SCSI_SENSE_BUFFERSIZE;
-		qc->tf.lbah = 0;
+		qc->tf.protocol = ATA_PROT_ATAPI;
+		qc->tf.lbam = (8 * 1024) & 0xff;
+		qc->tf.lbah = (8 * 1024) >> 8;
 	}
 	qc->nbytes = SCSI_SENSE_BUFFERSIZE;
 
@@ -2565,6 +2456,14 @@
 	qc->scsidone(cmd);
 	ata_qc_free(qc);
 }
+
+static void ata_qc_set_pc_nbytes(struct ata_queued_cmd *qc)
+{
+	struct scsi_cmnd *scmd = qc->scsicmd;
+
+	qc->nbytes = scsi_bufflen(scmd) + scmd->request->extra_len;
+}
+
 /**
  *	atapi_xlat - Initialize PACKET taskfile
  *	@qc: command structure to be initialized
@@ -2579,9 +2478,8 @@
 {
 	struct scsi_cmnd *scmd = qc->scsicmd;
 	struct ata_device *dev = qc->dev;
+	int using_pio = (dev->flags & ATA_DFLAG_PIO);
 	int nodata = (scmd->sc_data_direction == DMA_NONE);
-	int using_pio = !nodata && (dev->flags & ATA_DFLAG_PIO);
-	unsigned int nbytes;
 
 	memset(qc->cdb, 0, dev->cdb_len);
 	memcpy(qc->cdb, scmd->cmnd, scmd->cmd_len);
@@ -2598,97 +2496,75 @@
 	ata_qc_set_pc_nbytes(qc);
 
 	/* check whether ATAPI DMA is safe */
-	if (!nodata && !using_pio && atapi_check_dma(qc))
+	if (!using_pio && ata_check_atapi_dma(qc))
 		using_pio = 1;
 
-	/* Some controller variants snoop this value for Packet
-	 * transfers to do state machine and FIFO management.  Thus we
-	 * want to set it properly, and for DMA where it is
-	 * effectively meaningless.
-	 */
-	nbytes = min(ata_qc_raw_nbytes(qc), (unsigned int)63 * 1024);
-
-	/* Most ATAPI devices which honor transfer chunk size don't
-	 * behave according to the spec when odd chunk size which
-	 * matches the transfer length is specified.  If the number of
-	 * bytes to transfer is 2n+1.  According to the spec, what
-	 * should happen is to indicate that 2n+1 is going to be
-	 * transferred and transfer 2n+2 bytes where the last byte is
-	 * padding.
-	 *
-	 * In practice, this doesn't happen.  ATAPI devices first
-	 * indicate and transfer 2n bytes and then indicate and
-	 * transfer 2 bytes where the last byte is padding.
-	 *
-	 * This inconsistency confuses several controllers which
-	 * perform PIO using DMA such as Intel AHCIs and sil3124/32.
-	 * These controllers use actual number of transferred bytes to
-	 * update DMA poitner and transfer of 4n+2 bytes make those
-	 * controller push DMA pointer by 4n+4 bytes because SATA data
-	 * FISes are aligned to 4 bytes.  This causes data corruption
-	 * and buffer overrun.
-	 *
-	 * Always setting nbytes to even number solves this problem
-	 * because then ATAPI devices don't have to split data at 2n
-	 * boundaries.
-	 */
-	if (nbytes & 0x1)
-		nbytes++;
-
-	qc->tf.lbam = (nbytes & 0xFF);
-	qc->tf.lbah = (nbytes >> 8);
-
-	if (nodata)
-		qc->tf.protocol = ATAPI_PROT_NODATA;
-	else if (using_pio)
-		qc->tf.protocol = ATAPI_PROT_PIO;
-	else {
+	if (using_pio || nodata) {
+		/* no data, or PIO data xfer */
+		if (nodata)
+			qc->tf.protocol = ATA_PROT_ATAPI_NODATA;
+		else
+			qc->tf.protocol = ATA_PROT_ATAPI;
+		qc->tf.lbam = (8 * 1024) & 0xff;
+		qc->tf.lbah = (8 * 1024) >> 8;
+	} else {
 		/* DMA data xfer */
-		qc->tf.protocol = ATAPI_PROT_DMA;
+		qc->tf.protocol = ATA_PROT_ATAPI_DMA;
 		qc->tf.feature |= ATAPI_PKT_DMA;
 
-		if ((dev->flags & ATA_DFLAG_DMADIR) &&
-		    (scmd->sc_data_direction != DMA_TO_DEVICE))
+		if (atapi_dmadir && (scmd->sc_data_direction != DMA_TO_DEVICE))
 			/* some SATA bridges need us to indicate data xfer direction */
 			qc->tf.feature |= ATAPI_DMADIR;
 	}
 
-
-	/* FIXME: We need to translate 0x05 READ_BLOCK_LIMITS to a MODE_SENSE
-	   as ATAPI tape drives don't get this right otherwise */
 	return 0;
 }
 
-static struct ata_device *ata_find_dev(struct ata_port *ap, int devno)
+static struct ata_device * ata_find_dev(struct ata_port *ap, int id)
 {
-	if (!sata_pmp_attached(ap)) {
-		if (likely(devno < ata_link_max_devices(&ap->link)))
-			return &ap->link.device[devno];
-	} else {
-		if (likely(devno < ap->nr_pmp_links))
-			return &ap->pmp_link[devno].device[0];
-	}
-
+	if (likely(id < ATA_MAX_DEVICES))
+		return &ap->device[id];
 	return NULL;
 }
 
-static struct ata_device *__ata_scsi_find_dev(struct ata_port *ap,
-					      const struct scsi_device *scsidev)
+static struct ata_device * __ata_scsi_find_dev(struct ata_port *ap,
+					const struct scsi_device *scsidev)
 {
-	int devno;
-
 	/* skip commands not addressed to targets we simulate */
-	if (!sata_pmp_attached(ap)) {
-		if (unlikely(scsidev->channel || scsidev->lun))
-			return NULL;
-		devno = scsidev->id;
-	} else {
-		if (unlikely(scsidev->id || scsidev->lun))
-			return NULL;
-		devno = scsidev->channel;
+	if (unlikely(scsidev->channel || scsidev->lun))
+		return NULL;
+
+	return ata_find_dev(ap, scsidev->id);
+}
+
+/**
+ *	ata_scsi_dev_enabled - determine if device is enabled
+ *	@dev: ATA device
+ *
+ *	Determine if commands should be sent to the specified device.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ *	RETURNS:
+ *	0 if commands are not allowed / 1 if commands are allowed
+ */
+
+static int ata_scsi_dev_enabled(struct ata_device *dev)
+{
+	if (unlikely(!ata_dev_enabled(dev)))
+		return 0;
+
+	if (!atapi_enabled || (dev->ap->flags & ATA_FLAG_NO_ATAPI)) {
+		if (unlikely(dev->class == ATA_DEV_ATAPI)) {
+			ata_dev_printk(dev, KERN_WARNING,
+				       "WARNING: ATAPI is %s, device ignored.\n",
+				       atapi_enabled ? "not supported with this driver" : "disabled");
+			return 0;
+		}
 	}
 
-	return ata_find_dev(ap, devno);
+	return 1;
 }
 
 /**
@@ -2712,7 +2588,7 @@
 {
 	struct ata_device *dev = __ata_scsi_find_dev(ap, scsidev);
 
-	if (unlikely(!dev || !ata_dev_enabled(dev)))
+	if (unlikely(!dev || !ata_scsi_dev_enabled(dev)))
 		return NULL;
 
 	return dev;
@@ -2729,27 +2605,27 @@
 ata_scsi_map_proto(u8 byte1)
 {
 	switch((byte1 & 0x1e) >> 1) {
-	case 3:		/* Non-data */
-		return ATA_PROT_NODATA;
+		case 3:		/* Non-data */
+			return ATA_PROT_NODATA;
 
-	case 6:		/* DMA */
-	case 10:	/* UDMA Data-in */
-	case 11:	/* UDMA Data-Out */
-		return ATA_PROT_DMA;
-
-	case 4:		/* PIO Data-in */
-	case 5:		/* PIO Data-out */
-		return ATA_PROT_PIO;
-
-	case 0:		/* Hard Reset */
-	case 1:		/* SRST */
-	case 8:		/* Device Diagnostic */
-	case 9:		/* Device Reset */
-	case 7:		/* DMA Queued */
-	case 12:	/* FPDMA */
-	case 15:	/* Return Response Info */
-	default:	/* Reserved */
-		break;
+		case 6:		/* DMA */
+		case 10:	/* UDMA Data-in */
+		case 11:	/* UDMA Data-Out */
+			return ATA_PROT_DMA;
+
+		case 4:		/* PIO Data-in */
+		case 5:		/* PIO Data-out */
+			return ATA_PROT_PIO;
+
+		case 0:		/* Hard Reset */
+		case 1:		/* SRST */
+		case 8:		/* Device Diagnostic */
+		case 9:		/* Device Reset */
+		case 7:		/* DMA Queued */
+		case 12:	/* FPDMA */
+		case 15:	/* Return Response Info */
+		default:	/* Reserved */
+			break;
 	}
 
 	return ATA_PROT_UNKNOWN;
@@ -2774,6 +2650,10 @@
 	if ((tf->protocol = ata_scsi_map_proto(cdb[1])) == ATA_PROT_UNKNOWN)
 		goto invalid_fld;
 
+	/* We may not issue DMA commands if no DMA mode is set */
+	if (tf->protocol == ATA_PROT_DMA && dev->dma_mode == 0)
+		goto invalid_fld;
+
 	/*
 	 * 12 and 16 byte CDBs use different offsets to
 	 * provide the various register values.
@@ -2823,41 +2703,6 @@
 	tf->device = dev->devno ?
 		tf->device | ATA_DEV1 : tf->device & ~ATA_DEV1;
 
-	/* READ/WRITE LONG use a non-standard sect_size */
-	qc->sect_size = ATA_SECT_SIZE;
-	switch (tf->command) {
-	case ATA_CMD_READ_LONG:
-	case ATA_CMD_READ_LONG_ONCE:
-	case ATA_CMD_WRITE_LONG:
-	case ATA_CMD_WRITE_LONG_ONCE:
-		if (tf->protocol != ATA_PROT_PIO || tf->nsect != 1)
-			goto invalid_fld;
-		qc->sect_size = scsi_bufflen(scmd);
-	}
-
-	/*
-	 * Set flags so that all registers will be written, pass on
-	 * write indication (used for PIO/DMA setup), result TF is
-	 * copied back and we don't whine too much about its failure.
-	 */
-	tf->flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;
-	if (scmd->sc_data_direction == DMA_TO_DEVICE)
-		tf->flags |= ATA_TFLAG_WRITE;
-
-	qc->flags |= ATA_QCFLAG_RESULT_TF | ATA_QCFLAG_QUIET;
-
-	/*
-	 * Set transfer length.
-	 *
-	 * TODO: find out if we need to do more here to
-	 *       cover scatter/gather case.
-	 */
-	ata_qc_set_pc_nbytes(qc);
-
-	/* We may not issue DMA commands if no DMA mode is set */
-	if (tf->protocol == ATA_PROT_DMA && dev->dma_mode == 0)
-		goto invalid_fld;
-
 	/* sanity check for pio multi commands */
 	if ((cdb[1] & 0xe0) && !is_multi_taskfile(tf))
 		goto invalid_fld;
@@ -2874,6 +2719,18 @@
 				       multi_count);
 	}
 
+	/* READ/WRITE LONG use a non-standard sect_size */
+	qc->sect_size = ATA_SECT_SIZE;
+	switch (tf->command) {
+	case ATA_CMD_READ_LONG:
+	case ATA_CMD_READ_LONG_ONCE:
+	case ATA_CMD_WRITE_LONG:
+	case ATA_CMD_WRITE_LONG_ONCE:
+		if (tf->protocol != ATA_PROT_PIO || tf->nsect != 1)
+			goto invalid_fld;
+		qc->sect_size = scsi_bufflen(scmd);
+	}
+
 	/*
 	 * Filter SET_FEATURES - XFER MODE command -- otherwise,
 	 * SET_FEATURES - XFER MODE must be preceded/succeeded
@@ -2881,27 +2738,30 @@
 	 * controller (i.e. the reason for ->set_piomode(),
 	 * ->set_dmamode(), and ->post_set_mode() hooks).
 	 */
-	if (tf->command == ATA_CMD_SET_FEATURES &&
-	    tf->feature == SETFEATURES_XFER)
+	if ((tf->command == ATA_CMD_SET_FEATURES)
+	 && (tf->feature == SETFEATURES_XFER))
 		goto invalid_fld;
 
 	/*
-	 * Filter TPM commands by default. These provide an
-	 * essentially uncontrolled encrypted "back door" between
-	 * applications and the disk. Set libata.allow_tpm=1 if you
-	 * have a real reason for wanting to use them. This ensures
-	 * that installed software cannot easily mess stuff up without
-	 * user intent. DVR type users will probably ship with this enabled
-	 * for movie content management.
+	 * Set flags so that all registers will be written,
+	 * and pass on write indication (used for PIO/DMA
+	 * setup.)
+	 */
+	tf->flags |= (ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE);
+
+	if (scmd->sc_data_direction == DMA_TO_DEVICE)
+		tf->flags |= ATA_TFLAG_WRITE;
+
+	/*
+	 * Set transfer length.
 	 *
-	 * Note that for ATA8 we can issue a DCS change and DCS freeze lock
-	 * for this and should do in future but that it is not sufficient as
-	 * DCS is an optional feature set. Thus we also do the software filter
-	 * so that we comply with the TC consortium stated goal that the user
-	 * can turn off TC features of their system.
+	 * TODO: find out if we need to do more here to
+	 *       cover scatter/gather case.
 	 */
-	if (tf->command >= 0x5C && tf->command <= 0x5F && !libata_allow_tpm)
-		goto invalid_fld;
+	qc->nbytes = scsi_bufflen(scmd);
+
+	/* request result TF */
+	qc->flags |= ATA_QCFLAG_RESULT_TF;
 
 	return 0;
 
@@ -2983,49 +2843,28 @@
 				      void (*done)(struct scsi_cmnd *),
 				      struct ata_device *dev)
 {
-	u8 scsi_op = scmd->cmnd[0];
-	ata_xlat_func_t xlat_func;
 	int rc = 0;
 
-	if (dev->class == ATA_DEV_ATA) {
-		if (unlikely(!scmd->cmd_len || scmd->cmd_len > dev->cdb_len))
-			goto bad_cdb_len;
-
-		xlat_func = ata_get_xlat_func(dev, scsi_op);
-	} else {
-		if (unlikely(!scmd->cmd_len))
-			goto bad_cdb_len;
-
-		xlat_func = NULL;
-		if (likely((scsi_op != ATA_16) || !atapi_passthru16)) {
-			/* relay SCSI command to ATAPI device */
-			int len = COMMAND_SIZE(scsi_op);
-			if (unlikely(len > scmd->cmd_len || len > dev->cdb_len))
-				goto bad_cdb_len;
-
-			xlat_func = atapi_xlat;
-		} else {
-			/* ATA_16 passthru, treat as an ATA command */
-			if (unlikely(scmd->cmd_len > 16))
-				goto bad_cdb_len;
-
-			xlat_func = ata_get_xlat_func(dev, scsi_op);
-		}
+	if (unlikely(!scmd->cmd_len || scmd->cmd_len > dev->cdb_len)) {
+		DPRINTK("bad CDB len=%u, max=%u\n",
+			scmd->cmd_len, dev->cdb_len);
+		scmd->result = DID_ERROR << 16;
+		done(scmd);
+		return 0;
 	}
 
-	if (xlat_func)
-		rc = ata_scsi_translate(dev, scmd, done, xlat_func);
-	else
-		ata_scsi_simulate(dev, scmd, done);
+	if (dev->class == ATA_DEV_ATA) {
+		ata_xlat_func_t xlat_func = ata_get_xlat_func(dev,
+							      scmd->cmnd[0]);
 
-	return rc;
+		if (xlat_func)
+			rc = ata_scsi_translate(dev, scmd, done, xlat_func);
+		else
+			ata_scsi_simulate(dev, scmd, done);
+	} else
+		rc = ata_scsi_translate(dev, scmd, done, atapi_xlat);
 
- bad_cdb_len:
-	DPRINTK("bad CDB len=%u, scsi_op=0x%02x, max=%u\n",
-		scmd->cmd_len, scsi_op, dev->cdb_len);
-	scmd->result = DID_ERROR << 16;
-	done(scmd);
-	return 0;
+	return rc;
 }
 
 /**
@@ -3075,6 +2914,20 @@
 	return rc;
 }
 
+static unsigned int ata_scsiop_inq_b1(struct ata_scsi_args *args, u8 *rbuf)
+{
+	int form_factor = ata_id_form_factor(args->id);
+	int media_rotation_rate = ata_id_rotation_rate(args->id);
+
+	rbuf[1] = 0xb1;
+	rbuf[3] = 0x3c;
+	rbuf[4] = media_rotation_rate >> 8;
+	rbuf[5] = media_rotation_rate;
+	rbuf[7] = form_factor;
+
+	return 0;
+}
+
 /**
  *	ata_scsi_simulate - simulate SCSI command on ATA device
  *	@dev: the target device
@@ -3218,13 +3071,6 @@
 		shost->max_channel = 1;
 		shost->max_cmd_len = 16;
 
-		/* Schedule policy is determined by ->qc_defer()
-		 * callback and it needs to see every deferred qc.
-		 * Set host_blocked to 1 to prevent SCSI midlayer from
-		 * automatically deferring requests.
-		 */
-		shost->max_host_blocked = 1;
-
 		rc = scsi_add_host(ap->scsi_host, ap->host->dev);
 		if (rc)
 			goto err_add;
@@ -3248,32 +3094,25 @@
 {
 	int tries = 5;
 	struct ata_device *last_failed_dev = NULL;
-	struct ata_link *link;
 	struct ata_device *dev;
+	unsigned int i;
 
 	if (ap->flags & ATA_FLAG_DISABLED)
 		return;
 
  repeat:
-	ata_for_each_link(link, ap, EDGE) {
-		ata_for_each_dev(dev, link, ENABLED) {
-			struct scsi_device *sdev;
-			int channel = 0, id = 0;
-
-			if (dev->sdev)
-				continue;
-
-			if (ata_is_host_link(link))
-				id = dev->devno;
-			else
-				channel = link->pmp;
-
-			sdev = __scsi_add_device(ap->scsi_host, channel, id, 0,
-						 NULL);
-			if (!IS_ERR(sdev)) {
-				dev->sdev = sdev;
-				scsi_device_put(sdev);
-			}
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct scsi_device *sdev;
+
+		dev = &ap->device[i];
+
+		if (!ata_dev_enabled(dev) || dev->sdev)
+			continue;
+
+		sdev = __scsi_add_device(ap->scsi_host, 0, i, 0, NULL);
+		if (!IS_ERR(sdev)) {
+			dev->sdev = sdev;
+			scsi_device_put(sdev);
 		}
 	}
 
@@ -3281,14 +3120,12 @@
 	 * failure occurred, scan would have failed silently.  Check
 	 * whether all devices are attached.
 	 */
-	ata_for_each_link(link, ap, EDGE) {
-		ata_for_each_dev(dev, link, ENABLED) {
-			if (!dev->sdev)
-				goto exit_loop;
-		}
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		dev = &ap->device[i];
+		if (ata_dev_enabled(dev) && !dev->sdev)
+			break;
 	}
- exit_loop:
-	if (!link)
+	if (i == ATA_MAX_DEVICES)
 		return;
 
 	/* we're missing some SCSI devices */
@@ -3355,7 +3192,7 @@
  */
 static void ata_scsi_remove_dev(struct ata_device *dev)
 {
-	struct ata_port *ap = dev->link->ap;
+	struct ata_port *ap = dev->ap;
 	struct scsi_device *sdev;
 	unsigned long flags;
 
@@ -3402,42 +3239,6 @@
 	}
 }
 
-static void ata_scsi_handle_link_detach(struct ata_link *link)
-{
-	struct ata_port *ap = link->ap;
-	struct ata_device *dev;
-
-	ata_for_each_dev(dev, link, ALL) {
-		unsigned long flags;
-
-		if (!(dev->flags & ATA_DFLAG_DETACHED))
-			continue;
-
-		spin_lock_irqsave(ap->lock, flags);
-		dev->flags &= ~ATA_DFLAG_DETACHED;
-		spin_unlock_irqrestore(ap->lock, flags);
-
-		ata_scsi_remove_dev(dev);
-	}
-}
-
-/**
- *	ata_scsi_media_change_notify - send media change event
- *	@dev: Pointer to the disk device with media change event
- *
- *	Tell the block layer to send a media change notification
- *	event.
- *
- * 	LOCKING:
- * 	spin_lock_irqsave(host lock)
- */
-void ata_scsi_media_change_notify(struct ata_device *dev)
-{
-	if (dev->sdev)
-		sdev_evt_send_simple(dev->sdev, SDEV_EVT_MEDIA_CHANGE,
-				     GFP_ATOMIC);
-}
-
 /**
  *	ata_scsi_hotplug - SCSI part of hotplug
  *	@work: Pointer to ATA port to perform SCSI hotplug on
@@ -3463,14 +3264,20 @@
 
 	DPRINTK("ENTER\n");
 
-	/* Unplug detached devices.  We cannot use link iterator here
-	 * because PMP links have to be scanned even if PMP is
-	 * currently not attached.  Iterate manually.
-	 */
-	ata_scsi_handle_link_detach(&ap->link);
-	if (ap->pmp_link)
-		for (i = 0; i < SATA_PMP_MAX_PORTS; i++)
-			ata_scsi_handle_link_detach(&ap->pmp_link[i]);
+	/* unplug detached devices */
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+		unsigned long flags;
+
+		if (!(dev->flags & ATA_DFLAG_DETACHED))
+			continue;
+
+		spin_lock_irqsave(ap->lock, flags);
+		dev->flags &= ~ATA_DFLAG_DETACHED;
+		spin_unlock_irqrestore(ap->lock, flags);
+
+		ata_scsi_remove_dev(dev);
+	}
 
 	/* scan for new ones */
 	ata_scsi_scan_host(ap, 0);
@@ -3499,41 +3306,27 @@
 {
 	struct ata_port *ap = ata_shost_to_port(shost);
 	unsigned long flags;
-	int devno, rc = 0;
+	int rc = 0;
 
 	if (!ap->ops->error_handler)
 		return -EOPNOTSUPP;
 
-	if (lun != SCAN_WILD_CARD && lun)
+	if ((channel != SCAN_WILD_CARD && channel != 0) ||
+	    (lun != SCAN_WILD_CARD && lun != 0))
 		return -EINVAL;
 
-	if (!sata_pmp_attached(ap)) {
-		if (channel != SCAN_WILD_CARD && channel)
-			return -EINVAL;
-		devno = id;
-	} else {
-		if (id != SCAN_WILD_CARD && id)
-			return -EINVAL;
-		devno = channel;
-	}
-
 	spin_lock_irqsave(ap->lock, flags);
 
-	if (devno == SCAN_WILD_CARD) {
-		struct ata_link *link;
-
-		ata_for_each_link(link, ap, EDGE) {
-			struct ata_eh_info *ehi = &link->eh_info;
-			ehi->probe_mask |= ATA_ALL_DEVICES;
-			ehi->action |= ATA_EH_RESET;
-		}
+	if (id == SCAN_WILD_CARD) {
+		ap->eh_info.probe_mask |= (1 << ATA_MAX_DEVICES) - 1;
+		ap->eh_info.action |= ATA_EH_SOFTRESET;
 	} else {
-		struct ata_device *dev = ata_find_dev(ap, devno);
+		struct ata_device *dev = ata_find_dev(ap, id);
 
 		if (dev) {
-			struct ata_eh_info *ehi = &dev->link->eh_info;
-			ehi->probe_mask |= 1 << dev->devno;
-			ehi->action |= ATA_EH_RESET;
+			ap->eh_info.probe_mask |= 1 << dev->devno;
+			ap->eh_info.action |= ATA_EH_SOFTRESET;
+			ap->eh_info.flags |= ATA_EHI_RESUME_LINK;
 		} else
 			rc = -EINVAL;
 	}
@@ -3564,26 +3357,24 @@
 {
 	struct ata_port *ap =
 		container_of(work, struct ata_port, scsi_rescan_task);
-	struct ata_link *link;
-	struct ata_device *dev;
 	unsigned long flags;
+	unsigned int i;
 
 	spin_lock_irqsave(ap->lock, flags);
 
-	ata_for_each_link(link, ap, EDGE) {
-		ata_for_each_dev(dev, link, ENABLED) {
-			struct scsi_device *sdev = dev->sdev;
-
-			if (!sdev)
-				continue;
-			if (scsi_device_get(sdev))
-				continue;
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+		struct scsi_device *sdev = dev->sdev;
 
-			spin_unlock_irqrestore(ap->lock, flags);
-			scsi_rescan_device(&(sdev->sdev_gendev));
-			scsi_device_put(sdev);
-			spin_lock_irqsave(ap->lock, flags);
-		}
+		if (!ata_dev_enabled(dev) || !sdev)
+			continue;
+		if (scsi_device_get(sdev))
+			continue;
+
+		spin_unlock_irqrestore(ap->lock, flags);
+		scsi_rescan_device(&(sdev->sdev_gendev));
+		scsi_device_put(sdev);
+		spin_lock_irqsave(ap->lock, flags);
 	}
 
 	spin_unlock_irqrestore(ap->lock, flags);
@@ -3630,7 +3421,7 @@
  *	@ap: Port to initialize
  *
  *	Called just after data structures for each port are
- *	initialized.
+ *	initialized.  Allocates DMA pad.
  *
  *	May be used as the port_start() entry in ata_port_operations.
  *
@@ -3639,7 +3430,7 @@
  */
 int ata_sas_port_start(struct ata_port *ap)
 {
-	return 0;
+	return ata_pad_alloc(ap, ap->dev);
 }
 EXPORT_SYMBOL_GPL(ata_sas_port_start);
 
@@ -3647,6 +3438,8 @@
  *	ata_port_stop - Undo ata_sas_port_start()
  *	@ap: Port to shut down
  *
+ *	Frees the DMA pad.
+ *
  *	May be used as the port_stop() entry in ata_port_operations.
  *
  *	LOCKING:
@@ -3655,6 +3448,7 @@
 
 void ata_sas_port_stop(struct ata_port *ap)
 {
+	ata_pad_free(ap, ap->dev);
 }
 EXPORT_SYMBOL_GPL(ata_sas_port_stop);
 
@@ -3708,7 +3502,7 @@
 int ata_sas_slave_configure(struct scsi_device *sdev, struct ata_port *ap)
 {
 	ata_scsi_sdev_config(sdev);
-	ata_scsi_dev_config(sdev, ap->link.device);
+	ata_scsi_dev_config(sdev, ap->device);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(ata_sas_slave_configure);
@@ -3731,8 +3525,8 @@
 
 	ata_scsi_dump_cdb(ap, cmd);
 
-	if (likely(ata_dev_enabled(ap->link.device)))
-		rc = __ata_scsi_queuecmd(cmd, done, ap->link.device);
+	if (likely(ata_scsi_dev_enabled(ap->device)))
+		rc = __ata_scsi_queuecmd(cmd, done, ap->device);
 	else {
 		cmd->result = (DID_BAD_TARGET << 16);
 		done(cmd);
diff -Nur linux-sh4/drivers/ata.org/libata-sff.c linux-sh4/drivers/ata/libata-sff.c
--- linux-sh4/drivers/ata.org/libata-sff.c	2012-03-10 00:25:26.000000000 -0800
+++ linux-sh4/drivers/ata/libata-sff.c	2012-01-15 06:30:15.000000000 -0800
@@ -35,207 +35,189 @@
 #include <linux/kernel.h>
 #include <linux/pci.h>
 #include <linux/libata.h>
-#include <linux/highmem.h>
 
 #include "libata.h"
 
-const struct ata_port_operations ata_sff_port_ops = {
-	.inherits		= &ata_base_port_ops,
+/**
+ *	ata_irq_on - Enable interrupts on a port.
+ *	@ap: Port on which interrupts are enabled.
+ *
+ *	Enable interrupts on a legacy IDE device using MMIO or PIO,
+ *	wait for idle, clear any pending interrupts.
+ *
+ *	LOCKING:
+ *	Inherited from caller.
+ */
+u8 ata_irq_on(struct ata_port *ap)
+{
+	struct ata_ioports *ioaddr = &ap->ioaddr;
+	u8 tmp;
+
+	ap->ctl &= ~ATA_NIEN;
+	ap->last_ctl = ap->ctl;
+
+	iowrite8(ap->ctl, ioaddr->ctl_addr);
+	tmp = ata_wait_idle(ap);
+
+	ap->ops->irq_clear(ap);
+
+	return tmp;
+}
 
-	.qc_prep		= ata_sff_qc_prep,
-	.qc_issue		= ata_sff_qc_issue,
-	.qc_fill_rtf		= ata_sff_qc_fill_rtf,
-
-	.freeze			= ata_sff_freeze,
-	.thaw			= ata_sff_thaw,
-	.prereset		= ata_sff_prereset,
-	.softreset		= ata_sff_softreset,
-	.hardreset		= sata_sff_hardreset,
-	.postreset		= ata_sff_postreset,
-	.drain_fifo		= ata_sff_drain_fifo,
-	.error_handler		= ata_sff_error_handler,
-	.post_internal_cmd	= ata_sff_post_internal_cmd,
-
-	.sff_dev_select		= ata_sff_dev_select,
-	.sff_check_status	= ata_sff_check_status,
-	.sff_tf_load		= ata_sff_tf_load,
-	.sff_tf_read		= ata_sff_tf_read,
-	.sff_exec_command	= ata_sff_exec_command,
-	.sff_data_xfer		= ata_sff_data_xfer,
-	.sff_irq_on		= ata_sff_irq_on,
-	.sff_irq_clear		= ata_sff_irq_clear,
-
-	.lost_interrupt		= ata_sff_lost_interrupt,
-
-	.port_start		= ata_sff_port_start,
-};
-EXPORT_SYMBOL_GPL(ata_sff_port_ops);
-
-const struct ata_port_operations ata_bmdma_port_ops = {
-	.inherits		= &ata_sff_port_ops,
-
-	.mode_filter		= ata_bmdma_mode_filter,
-
-	.bmdma_setup		= ata_bmdma_setup,
-	.bmdma_start		= ata_bmdma_start,
-	.bmdma_stop		= ata_bmdma_stop,
-	.bmdma_status		= ata_bmdma_status,
-};
-EXPORT_SYMBOL_GPL(ata_bmdma_port_ops);
-
-const struct ata_port_operations ata_bmdma32_port_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-
-	.sff_data_xfer		= ata_sff_data_xfer32,
-	.port_start		= ata_sff_port_start32,
-};
-EXPORT_SYMBOL_GPL(ata_bmdma32_port_ops);
+u8 ata_dummy_irq_on (struct ata_port *ap) 	{ return 0; }
 
 /**
- *	ata_fill_sg - Fill PCI IDE PRD table
- *	@qc: Metadata associated with taskfile to be transferred
+ *	ata_irq_ack - Acknowledge a device interrupt.
+ *	@ap: Port on which interrupts are enabled.
  *
- *	Fill PCI IDE PRD (scatter-gather) table with segments
- *	associated with the current disk command.
+ *	Wait up to 10 ms for legacy IDE device to become idle (BUSY
+ *	or BUSY+DRQ clear).  Obtain dma status and port status from
+ *	device.  Clear the interrupt.  Return port status.
  *
  *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
  */
-static void ata_fill_sg(struct ata_queued_cmd *qc)
+
+u8 ata_irq_ack(struct ata_port *ap, unsigned int chk_drq)
 {
-	struct ata_port *ap = qc->ap;
-	struct scatterlist *sg;
-	unsigned int si, pi;
+	unsigned int bits = chk_drq ? ATA_BUSY | ATA_DRQ : ATA_BUSY;
+	u8 host_stat = 0, post_stat = 0, status;
 
-	pi = 0;
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		u32 addr, offset;
-		u32 sg_len, len;
-
-		/* determine if physical DMA addr spans 64K boundary.
-		 * Note h/w doesn't support 64-bit, so we unconditionally
-		 * truncate dma_addr_t to u32.
-		 */
-		addr = (u32) sg_dma_address(sg);
-		sg_len = sg_dma_len(sg);
+	status = ata_busy_wait(ap, bits, 1000);
+	if (status & bits)
+		if (ata_msg_err(ap))
+			printk(KERN_ERR "abnormal status 0x%X\n", status);
 
-		while (sg_len) {
-			offset = addr & 0xffff;
-			len = sg_len;
-			if ((offset + sg_len) > 0x10000)
-				len = 0x10000 - offset;
-
-			ap->prd[pi].addr = cpu_to_le32(addr);
-			ap->prd[pi].flags_len = cpu_to_le32(len & 0xffff);
-			VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", pi, addr, len);
-
-			pi++;
-			sg_len -= len;
-			addr += len;
-		}
-	}
+	if (ap->ioaddr.bmdma_addr) {
+		/* get controller status; clear intr, err bits */
+		host_stat = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
+		iowrite8(host_stat | ATA_DMA_INTR | ATA_DMA_ERR,
+			 ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
 
-	ap->prd[pi - 1].flags_len |= cpu_to_le32(ATA_PRD_EOT);
+		post_stat = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
+	}
+	if (ata_msg_intr(ap))
+		printk(KERN_INFO "%s: irq ack: host_stat 0x%X, new host_stat 0x%X, drv_stat 0x%X\n",
+			__FUNCTION__,
+			host_stat, post_stat, status);
+	return status;
 }
 
+u8 ata_dummy_irq_ack(struct ata_port *ap, unsigned int chk_drq) { return 0; }
+
 /**
- *	ata_fill_sg_dumb - Fill PCI IDE PRD table
- *	@qc: Metadata associated with taskfile to be transferred
+ *	ata_tf_load - send taskfile registers to host controller
+ *	@ap: Port to which output is sent
+ *	@tf: ATA taskfile register set
  *
- *	Fill PCI IDE PRD (scatter-gather) table with segments
- *	associated with the current disk command. Perform the fill
- *	so that we avoid writing any length 64K records for
- *	controllers that don't follow the spec.
+ *	Outputs ATA taskfile to standard ATA host controller.
  *
  *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
+ *	Inherited from caller.
  */
-static void ata_fill_sg_dumb(struct ata_queued_cmd *qc)
+
+void ata_tf_load(struct ata_port *ap, const struct ata_taskfile *tf)
 {
-	struct ata_port *ap = qc->ap;
-	struct scatterlist *sg;
-	unsigned int si, pi;
+	struct ata_ioports *ioaddr = &ap->ioaddr;
+	unsigned int is_addr = tf->flags & ATA_TFLAG_ISADDR;
 
-	pi = 0;
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		u32 addr, offset;
-		u32 sg_len, len, blen;
-
-		/* determine if physical DMA addr spans 64K boundary.
-		 * Note h/w doesn't support 64-bit, so we unconditionally
-		 * truncate dma_addr_t to u32.
-		 */
-		addr = (u32) sg_dma_address(sg);
-		sg_len = sg_dma_len(sg);
+	if (tf->ctl != ap->last_ctl) {
+		iowrite8(tf->ctl, ioaddr->ctl_addr);
+		ap->last_ctl = tf->ctl;
+		ata_wait_idle(ap);
+	}
 
-		while (sg_len) {
-			offset = addr & 0xffff;
-			len = sg_len;
-			if ((offset + sg_len) > 0x10000)
-				len = 0x10000 - offset;
-
-			blen = len & 0xffff;
-			ap->prd[pi].addr = cpu_to_le32(addr);
-			if (blen == 0) {
-				/* Some PATA chipsets like the CS5530 can't
-				   cope with 0x0000 meaning 64K as the spec
-				   says */
-				ap->prd[pi].flags_len = cpu_to_le32(0x8000);
-				blen = 0x8000;
-				ap->prd[++pi].addr = cpu_to_le32(addr + 0x8000);
-			}
-			ap->prd[pi].flags_len = cpu_to_le32(blen);
-			VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", pi, addr, len);
-
-			pi++;
-			sg_len -= len;
-			addr += len;
-		}
+	if (is_addr && (tf->flags & ATA_TFLAG_LBA48)) {
+		iowrite8(tf->hob_feature, ioaddr->feature_addr);
+		iowrite8(tf->hob_nsect, ioaddr->nsect_addr);
+		iowrite8(tf->hob_lbal, ioaddr->lbal_addr);
+		iowrite8(tf->hob_lbam, ioaddr->lbam_addr);
+		iowrite8(tf->hob_lbah, ioaddr->lbah_addr);
+		VPRINTK("hob: feat 0x%X nsect 0x%X, lba 0x%X 0x%X 0x%X\n",
+			tf->hob_feature,
+			tf->hob_nsect,
+			tf->hob_lbal,
+			tf->hob_lbam,
+			tf->hob_lbah);
+	}
+
+	if (is_addr) {
+		iowrite8(tf->feature, ioaddr->feature_addr);
+		iowrite8(tf->nsect, ioaddr->nsect_addr);
+		iowrite8(tf->lbal, ioaddr->lbal_addr);
+		iowrite8(tf->lbam, ioaddr->lbam_addr);
+		iowrite8(tf->lbah, ioaddr->lbah_addr);
+		VPRINTK("feat 0x%X nsect 0x%X lba 0x%X 0x%X 0x%X\n",
+			tf->feature,
+			tf->nsect,
+			tf->lbal,
+			tf->lbam,
+			tf->lbah);
+	}
+
+	if (tf->flags & ATA_TFLAG_DEVICE) {
+		iowrite8(tf->device, ioaddr->device_addr);
+		VPRINTK("device 0x%X\n", tf->device);
 	}
 
-	ap->prd[pi - 1].flags_len |= cpu_to_le32(ATA_PRD_EOT);
+	ata_wait_idle(ap);
 }
 
 /**
- *	ata_sff_qc_prep - Prepare taskfile for submission
- *	@qc: Metadata associated with taskfile to be prepared
+ *	ata_exec_command - issue ATA command to host controller
+ *	@ap: port to which command is being issued
+ *	@tf: ATA taskfile register set
  *
- *	Prepare ATA taskfile for submission.
+ *	Issues ATA command, with proper synchronization with interrupt
+ *	handler / other threads.
  *
  *	LOCKING:
  *	spin_lock_irqsave(host lock)
  */
-void ata_sff_qc_prep(struct ata_queued_cmd *qc)
+void ata_exec_command(struct ata_port *ap, const struct ata_taskfile *tf)
 {
-	if (!(qc->flags & ATA_QCFLAG_DMAMAP))
-		return;
+	DPRINTK("ata%u: cmd 0x%X\n", ap->print_id, tf->command);
 
-	ata_fill_sg(qc);
+	iowrite8(tf->command, ap->ioaddr.command_addr);
+	ata_pause(ap);
 }
-EXPORT_SYMBOL_GPL(ata_sff_qc_prep);
 
 /**
- *	ata_sff_dumb_qc_prep - Prepare taskfile for submission
- *	@qc: Metadata associated with taskfile to be prepared
+ *	ata_tf_read - input device's ATA taskfile shadow registers
+ *	@ap: Port from which input is read
+ *	@tf: ATA taskfile register set for storing input
  *
- *	Prepare ATA taskfile for submission.
+ *	Reads ATA taskfile registers for currently-selected device
+ *	into @tf.
  *
  *	LOCKING:
- *	spin_lock_irqsave(host lock)
+ *	Inherited from caller.
  */
-void ata_sff_dumb_qc_prep(struct ata_queued_cmd *qc)
+void ata_tf_read(struct ata_port *ap, struct ata_taskfile *tf)
 {
-	if (!(qc->flags & ATA_QCFLAG_DMAMAP))
-		return;
+	struct ata_ioports *ioaddr = &ap->ioaddr;
+
+	tf->command = ata_check_status(ap);
+	tf->feature = ioread8(ioaddr->error_addr);
+	tf->nsect = ioread8(ioaddr->nsect_addr);
+	tf->lbal = ioread8(ioaddr->lbal_addr);
+	tf->lbam = ioread8(ioaddr->lbam_addr);
+	tf->lbah = ioread8(ioaddr->lbah_addr);
+	tf->device = ioread8(ioaddr->device_addr);
 
-	ata_fill_sg_dumb(qc);
+	if (tf->flags & ATA_TFLAG_LBA48) {
+		iowrite8(tf->ctl | ATA_HOB, ioaddr->ctl_addr);
+		tf->hob_feature = ioread8(ioaddr->error_addr);
+		tf->hob_nsect = ioread8(ioaddr->nsect_addr);
+		tf->hob_lbal = ioread8(ioaddr->lbal_addr);
+		tf->hob_lbam = ioread8(ioaddr->lbam_addr);
+		tf->hob_lbah = ioread8(ioaddr->lbah_addr);
+		iowrite8(tf->ctl, ioaddr->ctl_addr);
+		ap->last_ctl = tf->ctl;
+	}
 }
-EXPORT_SYMBOL_GPL(ata_sff_dumb_qc_prep);
 
 /**
- *	ata_sff_check_status - Read device status reg & clear interrupt
+ *	ata_check_status - Read device status reg & clear interrupt
  *	@ap: port where the device is
  *
  *	Reads ATA taskfile status register for currently-selected device
@@ -245,14 +227,13 @@
  *	LOCKING:
  *	Inherited from caller.
  */
-u8 ata_sff_check_status(struct ata_port *ap)
+u8 ata_check_status(struct ata_port *ap)
 {
 	return ioread8(ap->ioaddr.status_addr);
 }
-EXPORT_SYMBOL_GPL(ata_sff_check_status);
 
 /**
- *	ata_sff_altstatus - Read device alternate status reg
+ *	ata_altstatus - Read device alternate status reg
  *	@ap: port where the device is
  *
  *	Reads ATA taskfile alternate status register for
@@ -264,2054 +245,207 @@
  *	LOCKING:
  *	Inherited from caller.
  */
-static u8 ata_sff_altstatus(struct ata_port *ap)
+u8 ata_altstatus(struct ata_port *ap)
 {
-	if (ap->ops->sff_check_altstatus)
-		return ap->ops->sff_check_altstatus(ap);
+	if (ap->ops->check_altstatus)
+		return ap->ops->check_altstatus(ap);
 
 	return ioread8(ap->ioaddr.altstatus_addr);
 }
 
 /**
- *	ata_sff_irq_status - Check if the device is busy
- *	@ap: port where the device is
- *
- *	Determine if the port is currently busy. Uses altstatus
- *	if available in order to avoid clearing shared IRQ status
- *	when finding an IRQ source. Non ctl capable devices don't
- *	share interrupt lines fortunately for us.
+ *	ata_bmdma_setup - Set up PCI IDE BMDMA transaction
+ *	@qc: Info associated with this ATA transaction.
  *
  *	LOCKING:
- *	Inherited from caller.
+ *	spin_lock_irqsave(host lock)
  */
-static u8 ata_sff_irq_status(struct ata_port *ap)
+void ata_bmdma_setup(struct ata_queued_cmd *qc)
 {
-	u8 status;
+	struct ata_port *ap = qc->ap;
+	unsigned int rw = (qc->tf.flags & ATA_TFLAG_WRITE);
+	u8 dmactl;
 
-	if (ap->ops->sff_check_altstatus || ap->ioaddr.altstatus_addr) {
-		status = ata_sff_altstatus(ap);
-		/* Not us: We are busy */
-		if (status & ATA_BUSY)
-			return status;
-	}
-	/* Clear INTRQ latch */
-	status = ap->ops->sff_check_status(ap);
-	return status;
-}
+	/* load PRD table addr. */
+	mb();	/* make sure PRD table writes are visible to controller */
+	iowrite32(ap->prd_dma, ap->ioaddr.bmdma_addr + ATA_DMA_TABLE_OFS);
 
-/**
- *	ata_sff_sync - Flush writes
- *	@ap: Port to wait for.
- *
- *	CAUTION:
- *	If we have an mmio device with no ctl and no altstatus
- *	method this will fail. No such devices are known to exist.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
+	/* specify data direction, triple-check start bit is clear */
+	dmactl = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
+	dmactl &= ~(ATA_DMA_WR | ATA_DMA_START);
+	if (!rw)
+		dmactl |= ATA_DMA_WR;
+	iowrite8(dmactl, ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
 
-static void ata_sff_sync(struct ata_port *ap)
-{
-	if (ap->ops->sff_check_altstatus)
-		ap->ops->sff_check_altstatus(ap);
-	else if (ap->ioaddr.altstatus_addr)
-		ioread8(ap->ioaddr.altstatus_addr);
+	/* issue r/w command */
+	ap->ops->exec_command(ap, &qc->tf);
 }
 
 /**
- *	ata_sff_pause		-	Flush writes and wait 400nS
- *	@ap: Port to pause for.
- *
- *	CAUTION:
- *	If we have an mmio device with no ctl and no altstatus
- *	method this will fail. No such devices are known to exist.
+ *	ata_bmdma_start - Start a PCI IDE BMDMA transaction
+ *	@qc: Info associated with this ATA transaction.
  *
  *	LOCKING:
- *	Inherited from caller.
+ *	spin_lock_irqsave(host lock)
  */
-
-void ata_sff_pause(struct ata_port *ap)
+void ata_bmdma_start (struct ata_queued_cmd *qc)
 {
-	ata_sff_sync(ap);
-	ndelay(400);
-}
-EXPORT_SYMBOL_GPL(ata_sff_pause);
+	struct ata_port *ap = qc->ap;
+	u8 dmactl;
 
-/**
- *	ata_sff_dma_pause	-	Pause before commencing DMA
- *	@ap: Port to pause for.
- *
- *	Perform I/O fencing and ensure sufficient cycle delays occur
- *	for the HDMA1:0 transition
- */
+	/* start host DMA transaction */
+	dmactl = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
+	iowrite8(dmactl | ATA_DMA_START, ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
 
-void ata_sff_dma_pause(struct ata_port *ap)
-{
-	if (ap->ops->sff_check_altstatus || ap->ioaddr.altstatus_addr) {
-		/* An altstatus read will cause the needed delay without
-		   messing up the IRQ status */
-		ata_sff_altstatus(ap);
-		return;
-	}
-	/* There are no DMA controllers without ctl. BUG here to ensure
-	   we never violate the HDMA1:0 transition timing and risk
-	   corruption. */
-	BUG();
+	/* Strictly, one may wish to issue an ioread8() here, to
+	 * flush the mmio write.  However, control also passes
+	 * to the hardware at this point, and it will interrupt
+	 * us when we are to resume control.  So, in effect,
+	 * we don't care when the mmio write flushes.
+	 * Further, a read of the DMA status register _immediately_
+	 * following the write may not be what certain flaky hardware
+	 * is expected, so I think it is best to not add a readb()
+	 * without first all the MMIO ATA cards/mobos.
+	 * Or maybe I'm just being paranoid.
+	 *
+	 * FIXME: The posting of this write means I/O starts are
+	 * unneccessarily delayed for MMIO
+	 */
 }
-EXPORT_SYMBOL_GPL(ata_sff_dma_pause);
 
 /**
- *	ata_sff_busy_sleep - sleep until BSY clears, or timeout
- *	@ap: port containing status register to be polled
- *	@tmout_pat: impatience timeout in msecs
- *	@tmout: overall timeout in msecs
+ *	ata_bmdma_irq_clear - Clear PCI IDE BMDMA interrupt.
+ *	@ap: Port associated with this ATA transaction.
  *
- *	Sleep until ATA Status register bit BSY clears,
- *	or a timeout occurs.
+ *	Clear interrupt and error flags in DMA status register.
  *
- *	LOCKING:
- *	Kernel thread context (may sleep).
+ *	May be used as the irq_clear() entry in ata_port_operations.
  *
- *	RETURNS:
- *	0 on success, -errno otherwise.
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
  */
-int ata_sff_busy_sleep(struct ata_port *ap,
-		       unsigned long tmout_pat, unsigned long tmout)
+void ata_bmdma_irq_clear(struct ata_port *ap)
 {
-	unsigned long timer_start, timeout;
-	u8 status;
-
-	status = ata_sff_busy_wait(ap, ATA_BUSY, 300);
-	timer_start = jiffies;
-	timeout = ata_deadline(timer_start, tmout_pat);
-	while (status != 0xff && (status & ATA_BUSY) &&
-	       time_before(jiffies, timeout)) {
-		msleep(50);
-		status = ata_sff_busy_wait(ap, ATA_BUSY, 3);
-	}
-
-	if (status != 0xff && (status & ATA_BUSY))
-		ata_port_printk(ap, KERN_WARNING,
-				"port is slow to respond, please be patient "
-				"(Status 0x%x)\n", status);
-
-	timeout = ata_deadline(timer_start, tmout);
-	while (status != 0xff && (status & ATA_BUSY) &&
-	       time_before(jiffies, timeout)) {
-		msleep(50);
-		status = ap->ops->sff_check_status(ap);
-	}
-
-	if (status == 0xff)
-		return -ENODEV;
-
-	if (status & ATA_BUSY) {
-		ata_port_printk(ap, KERN_ERR, "port failed to respond "
-				"(%lu secs, Status 0x%x)\n",
-				DIV_ROUND_UP(tmout, 1000), status);
-		return -EBUSY;
-	}
-
-	return 0;
-}
-EXPORT_SYMBOL_GPL(ata_sff_busy_sleep);
+	void __iomem *mmio = ap->ioaddr.bmdma_addr;
 
-static int ata_sff_check_ready(struct ata_link *link)
-{
-	u8 status = link->ap->ops->sff_check_status(link->ap);
+	if (!mmio)
+		return;
 
-	return ata_check_ready(status);
+	iowrite8(ioread8(mmio + ATA_DMA_STATUS), mmio + ATA_DMA_STATUS);
 }
 
 /**
- *	ata_sff_wait_ready - sleep until BSY clears, or timeout
- *	@link: SFF link to wait ready status for
- *	@deadline: deadline jiffies for the operation
+ *	ata_bmdma_status - Read PCI IDE BMDMA status
+ *	@ap: Port associated with this ATA transaction.
  *
- *	Sleep until ATA Status register bit BSY clears, or timeout
- *	occurs.
+ *	Read and return BMDMA status register.
  *
- *	LOCKING:
- *	Kernel thread context (may sleep).
+ *	May be used as the bmdma_status() entry in ata_port_operations.
  *
- *	RETURNS:
- *	0 on success, -errno otherwise.
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
  */
-int ata_sff_wait_ready(struct ata_link *link, unsigned long deadline)
+u8 ata_bmdma_status(struct ata_port *ap)
 {
-	return ata_wait_ready(link, deadline, ata_sff_check_ready);
+	return ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
 }
-EXPORT_SYMBOL_GPL(ata_sff_wait_ready);
 
 /**
- *	ata_sff_dev_select - Select device 0/1 on ATA bus
- *	@ap: ATA channel to manipulate
- *	@device: ATA device (numbered from zero) to select
+ *	ata_bmdma_stop - Stop PCI IDE BMDMA transfer
+ *	@qc: Command we are ending DMA for
  *
- *	Use the method defined in the ATA specification to
- *	make either device 0, or device 1, active on the
- *	ATA channel.  Works with both PIO and MMIO.
+ *	Clears the ATA_DMA_START flag in the dma control register
  *
- *	May be used as the dev_select() entry in ata_port_operations.
+ *	May be used as the bmdma_stop() entry in ata_port_operations.
  *
  *	LOCKING:
- *	caller.
+ *	spin_lock_irqsave(host lock)
  */
-void ata_sff_dev_select(struct ata_port *ap, unsigned int device)
+void ata_bmdma_stop(struct ata_queued_cmd *qc)
 {
-	u8 tmp;
+	struct ata_port *ap = qc->ap;
+	void __iomem *mmio = ap->ioaddr.bmdma_addr;
 
-	if (device == 0)
-		tmp = ATA_DEVICE_OBS;
-	else
-		tmp = ATA_DEVICE_OBS | ATA_DEV1;
+	/* clear start/stop bit */
+	iowrite8(ioread8(mmio + ATA_DMA_CMD) & ~ATA_DMA_START,
+		 mmio + ATA_DMA_CMD);
 
-	iowrite8(tmp, ap->ioaddr.device_addr);
-	ata_sff_pause(ap);	/* needed; also flushes, for mmio */
+	/* one-PIO-cycle guaranteed wait, per spec, for HDMA1:0 transition */
+	ata_altstatus(ap);        /* dummy read */
 }
-EXPORT_SYMBOL_GPL(ata_sff_dev_select);
 
 /**
- *	ata_dev_select - Select device 0/1 on ATA bus
- *	@ap: ATA channel to manipulate
- *	@device: ATA device (numbered from zero) to select
- *	@wait: non-zero to wait for Status register BSY bit to clear
- *	@can_sleep: non-zero if context allows sleeping
- *
- *	Use the method defined in the ATA specification to
- *	make either device 0, or device 1, active on the
- *	ATA channel.
+ *	ata_bmdma_freeze - Freeze BMDMA controller port
+ *	@ap: port to freeze
  *
- *	This is a high-level version of ata_sff_dev_select(), which
- *	additionally provides the services of inserting the proper
- *	pauses and status polling, where needed.
+ *	Freeze BMDMA controller port.
  *
  *	LOCKING:
- *	caller.
+ *	Inherited from caller.
  */
-void ata_dev_select(struct ata_port *ap, unsigned int device,
-			   unsigned int wait, unsigned int can_sleep)
+void ata_bmdma_freeze(struct ata_port *ap)
 {
-	if (ata_msg_probe(ap))
-		ata_port_printk(ap, KERN_INFO, "ata_dev_select: ENTER, "
-				"device %u, wait %u\n", device, wait);
+	struct ata_ioports *ioaddr = &ap->ioaddr;
 
-	if (wait)
-		ata_wait_idle(ap);
+	ap->ctl |= ATA_NIEN;
+	ap->last_ctl = ap->ctl;
+
+	iowrite8(ap->ctl, ioaddr->ctl_addr);
 
-	ap->ops->sff_dev_select(ap, device);
+	/* Under certain circumstances, some controllers raise IRQ on
+	 * ATA_NIEN manipulation.  Also, many controllers fail to mask
+	 * previously pending IRQ on ATA_NIEN assertion.  Clear it.
+	 */
+	ata_chk_status(ap);
 
-	if (wait) {
-		if (can_sleep && ap->link.device[device].class == ATA_DEV_ATAPI)
-			msleep(150);
-		ata_wait_idle(ap);
-	}
+	ap->ops->irq_clear(ap);
 }
 
 /**
- *	ata_sff_irq_on - Enable interrupts on a port.
- *	@ap: Port on which interrupts are enabled.
+ *	ata_bmdma_thaw - Thaw BMDMA controller port
+ *	@ap: port to thaw
  *
- *	Enable interrupts on a legacy IDE device using MMIO or PIO,
- *	wait for idle, clear any pending interrupts.
+ *	Thaw BMDMA controller port.
  *
  *	LOCKING:
  *	Inherited from caller.
  */
-u8 ata_sff_irq_on(struct ata_port *ap)
+void ata_bmdma_thaw(struct ata_port *ap)
 {
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	u8 tmp;
-
-	ap->ctl &= ~ATA_NIEN;
-	ap->last_ctl = ap->ctl;
-
-	if (ioaddr->ctl_addr)
-		iowrite8(ap->ctl, ioaddr->ctl_addr);
-	tmp = ata_wait_idle(ap);
-
-	ap->ops->sff_irq_clear(ap);
-
-	return tmp;
+	/* clear & re-enable interrupts */
+	ata_chk_status(ap);
+	ap->ops->irq_clear(ap);
+	ap->ops->irq_on(ap);
 }
-EXPORT_SYMBOL_GPL(ata_sff_irq_on);
 
 /**
- *	ata_sff_irq_clear - Clear PCI IDE BMDMA interrupt.
- *	@ap: Port associated with this ATA transaction.
+ *	ata_bmdma_drive_eh - Perform EH with given methods for BMDMA controller
+ *	@ap: port to handle error for
+ *	@prereset: prereset method (can be NULL)
+ *	@softreset: softreset method (can be NULL)
+ *	@hardreset: hardreset method (can be NULL)
+ *	@postreset: postreset method (can be NULL)
  *
- *	Clear interrupt and error flags in DMA status register.
+ *	Handle error for ATA BMDMA controller.  It can handle both
+ *	PATA and SATA controllers.  Many controllers should be able to
+ *	use this EH as-is or with some added handling before and
+ *	after.
  *
- *	May be used as the irq_clear() entry in ata_port_operations.
+ *	This function is intended to be used for constructing
+ *	->error_handler callback by low level drivers.
  *
  *	LOCKING:
- *	spin_lock_irqsave(host lock)
+ *	Kernel thread context (may sleep)
  */
-void ata_sff_irq_clear(struct ata_port *ap)
+void ata_bmdma_drive_eh(struct ata_port *ap, ata_prereset_fn_t prereset,
+			ata_reset_fn_t softreset, ata_reset_fn_t hardreset,
+			ata_postreset_fn_t postreset)
 {
-	void __iomem *mmio = ap->ioaddr.bmdma_addr;
-
-	if (!mmio)
-		return;
-
-	iowrite8(ioread8(mmio + ATA_DMA_STATUS), mmio + ATA_DMA_STATUS);
-}
-EXPORT_SYMBOL_GPL(ata_sff_irq_clear);
-
-/**
- *	ata_sff_tf_load - send taskfile registers to host controller
- *	@ap: Port to which output is sent
- *	@tf: ATA taskfile register set
- *
- *	Outputs ATA taskfile to standard ATA host controller.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-void ata_sff_tf_load(struct ata_port *ap, const struct ata_taskfile *tf)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	unsigned int is_addr = tf->flags & ATA_TFLAG_ISADDR;
-
-	if (tf->ctl != ap->last_ctl) {
-		if (ioaddr->ctl_addr)
-			iowrite8(tf->ctl, ioaddr->ctl_addr);
-		ap->last_ctl = tf->ctl;
-		ata_wait_idle(ap);
-	}
-
-	if (is_addr && (tf->flags & ATA_TFLAG_LBA48)) {
-		WARN_ON_ONCE(!ioaddr->ctl_addr);
-		iowrite8(tf->hob_feature, ioaddr->feature_addr);
-		iowrite8(tf->hob_nsect, ioaddr->nsect_addr);
-		iowrite8(tf->hob_lbal, ioaddr->lbal_addr);
-		iowrite8(tf->hob_lbam, ioaddr->lbam_addr);
-		iowrite8(tf->hob_lbah, ioaddr->lbah_addr);
-		VPRINTK("hob: feat 0x%X nsect 0x%X, lba 0x%X 0x%X 0x%X\n",
-			tf->hob_feature,
-			tf->hob_nsect,
-			tf->hob_lbal,
-			tf->hob_lbam,
-			tf->hob_lbah);
-	}
-
-	if (is_addr) {
-		iowrite8(tf->feature, ioaddr->feature_addr);
-		iowrite8(tf->nsect, ioaddr->nsect_addr);
-		iowrite8(tf->lbal, ioaddr->lbal_addr);
-		iowrite8(tf->lbam, ioaddr->lbam_addr);
-		iowrite8(tf->lbah, ioaddr->lbah_addr);
-		VPRINTK("feat 0x%X nsect 0x%X lba 0x%X 0x%X 0x%X\n",
-			tf->feature,
-			tf->nsect,
-			tf->lbal,
-			tf->lbam,
-			tf->lbah);
-	}
-
-	if (tf->flags & ATA_TFLAG_DEVICE) {
-		iowrite8(tf->device, ioaddr->device_addr);
-		VPRINTK("device 0x%X\n", tf->device);
-	}
-
-	ata_wait_idle(ap);
-}
-EXPORT_SYMBOL_GPL(ata_sff_tf_load);
-
-/**
- *	ata_sff_tf_read - input device's ATA taskfile shadow registers
- *	@ap: Port from which input is read
- *	@tf: ATA taskfile register set for storing input
- *
- *	Reads ATA taskfile registers for currently-selected device
- *	into @tf. Assumes the device has a fully SFF compliant task file
- *	layout and behaviour. If you device does not (eg has a different
- *	status method) then you will need to provide a replacement tf_read
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-void ata_sff_tf_read(struct ata_port *ap, struct ata_taskfile *tf)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-
-	tf->command = ata_sff_check_status(ap);
-	tf->feature = ioread8(ioaddr->error_addr);
-	tf->nsect = ioread8(ioaddr->nsect_addr);
-	tf->lbal = ioread8(ioaddr->lbal_addr);
-	tf->lbam = ioread8(ioaddr->lbam_addr);
-	tf->lbah = ioread8(ioaddr->lbah_addr);
-	tf->device = ioread8(ioaddr->device_addr);
-
-	if (tf->flags & ATA_TFLAG_LBA48) {
-		if (likely(ioaddr->ctl_addr)) {
-			iowrite8(tf->ctl | ATA_HOB, ioaddr->ctl_addr);
-			tf->hob_feature = ioread8(ioaddr->error_addr);
-			tf->hob_nsect = ioread8(ioaddr->nsect_addr);
-			tf->hob_lbal = ioread8(ioaddr->lbal_addr);
-			tf->hob_lbam = ioread8(ioaddr->lbam_addr);
-			tf->hob_lbah = ioread8(ioaddr->lbah_addr);
-			iowrite8(tf->ctl, ioaddr->ctl_addr);
-			ap->last_ctl = tf->ctl;
-		} else
-			WARN_ON_ONCE(1);
-	}
-}
-EXPORT_SYMBOL_GPL(ata_sff_tf_read);
-
-/**
- *	ata_sff_exec_command - issue ATA command to host controller
- *	@ap: port to which command is being issued
- *	@tf: ATA taskfile register set
- *
- *	Issues ATA command, with proper synchronization with interrupt
- *	handler / other threads.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- */
-void ata_sff_exec_command(struct ata_port *ap, const struct ata_taskfile *tf)
-{
-	DPRINTK("ata%u: cmd 0x%X\n", ap->print_id, tf->command);
-
-	iowrite8(tf->command, ap->ioaddr.command_addr);
-	ata_sff_pause(ap);
-}
-EXPORT_SYMBOL_GPL(ata_sff_exec_command);
-
-/**
- *	ata_tf_to_host - issue ATA taskfile to host controller
- *	@ap: port to which command is being issued
- *	@tf: ATA taskfile register set
- *
- *	Issues ATA taskfile register set to ATA host controller,
- *	with proper synchronization with interrupt handler and
- *	other threads.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- */
-static inline void ata_tf_to_host(struct ata_port *ap,
-				  const struct ata_taskfile *tf)
-{
-	ap->ops->sff_tf_load(ap, tf);
-	ap->ops->sff_exec_command(ap, tf);
-}
-
-/**
- *	ata_sff_data_xfer - Transfer data by PIO
- *	@dev: device to target
- *	@buf: data buffer
- *	@buflen: buffer length
- *	@rw: read/write
- *
- *	Transfer data from/to the device data register by PIO.
- *
- *	LOCKING:
- *	Inherited from caller.
- *
- *	RETURNS:
- *	Bytes consumed.
- */
-unsigned int ata_sff_data_xfer(struct ata_device *dev, unsigned char *buf,
-			       unsigned int buflen, int rw)
-{
-	struct ata_port *ap = dev->link->ap;
-	void __iomem *data_addr = ap->ioaddr.data_addr;
-	unsigned int words = buflen >> 1;
-
-	/* Transfer multiple of 2 bytes */
-	if (rw == READ)
-		ioread16_rep(data_addr, buf, words);
-	else
-		iowrite16_rep(data_addr, buf, words);
-
-	/* Transfer trailing byte, if any. */
-	if (unlikely(buflen & 0x01)) {
-		unsigned char pad[2];
-
-		/* Point buf to the tail of buffer */
-		buf += buflen - 1;
-
-		/*
-		 * Use io*16_rep() accessors here as well to avoid pointlessly
-		 * swapping bytes to and fro on the big endian machines...
-		 */
-		if (rw == READ) {
-			ioread16_rep(data_addr, pad, 1);
-			*buf = pad[0];
-		} else {
-			pad[0] = *buf;
-			iowrite16_rep(data_addr, pad, 1);
-		}
-		words++;
-	}
-
-	return words << 1;
-}
-EXPORT_SYMBOL_GPL(ata_sff_data_xfer);
-
-/**
- *	ata_sff_data_xfer32 - Transfer data by PIO
- *	@dev: device to target
- *	@buf: data buffer
- *	@buflen: buffer length
- *	@rw: read/write
- *
- *	Transfer data from/to the device data register by PIO using 32bit
- *	I/O operations.
- *
- *	LOCKING:
- *	Inherited from caller.
- *
- *	RETURNS:
- *	Bytes consumed.
- */
-
-unsigned int ata_sff_data_xfer32(struct ata_device *dev, unsigned char *buf,
-			       unsigned int buflen, int rw)
-{
-	struct ata_port *ap = dev->link->ap;
-	void __iomem *data_addr = ap->ioaddr.data_addr;
-	unsigned int words = buflen >> 2;
-	int slop = buflen & 3;
-	
-	if (!(ap->pflags & ATA_PFLAG_PIO32))
-		return ata_sff_data_xfer(dev, buf, buflen, rw);
-
-	/* Transfer multiple of 4 bytes */
-	if (rw == READ)
-		ioread32_rep(data_addr, buf, words);
-	else
-		iowrite32_rep(data_addr, buf, words);
-
-	/* Transfer trailing bytes, if any */
-	if (unlikely(slop)) {
-		unsigned char pad[4];
-
-		/* Point buf to the tail of buffer */
-		buf += buflen - slop;
-
-		/*
-		 * Use io*_rep() accessors here as well to avoid pointlessly
-		 * swapping bytes to and fro on the big endian machines...
-		 */
-		if (rw == READ) {
-			if (slop < 3)
-				ioread16_rep(data_addr, pad, 1);
-			else
-				ioread32_rep(data_addr, pad, 1);
-			memcpy(buf, pad, slop);
-		} else {
-			memcpy(pad, buf, slop);
-			if (slop < 3)
-				iowrite16_rep(data_addr, pad, 1);
-			else
-				iowrite32_rep(data_addr, pad, 1);
-		}
-	}
-	return (buflen + 1) & ~1;
-}
-EXPORT_SYMBOL_GPL(ata_sff_data_xfer32);
-
-/**
- *	ata_sff_data_xfer_noirq - Transfer data by PIO
- *	@dev: device to target
- *	@buf: data buffer
- *	@buflen: buffer length
- *	@rw: read/write
- *
- *	Transfer data from/to the device data register by PIO. Do the
- *	transfer with interrupts disabled.
- *
- *	LOCKING:
- *	Inherited from caller.
- *
- *	RETURNS:
- *	Bytes consumed.
- */
-unsigned int ata_sff_data_xfer_noirq(struct ata_device *dev, unsigned char *buf,
-				     unsigned int buflen, int rw)
-{
-	unsigned long flags;
-	unsigned int consumed;
-
-	local_irq_save(flags);
-	consumed = ata_sff_data_xfer(dev, buf, buflen, rw);
-	local_irq_restore(flags);
-
-	return consumed;
-}
-EXPORT_SYMBOL_GPL(ata_sff_data_xfer_noirq);
-
-/**
- *	ata_pio_sector - Transfer a sector of data.
- *	@qc: Command on going
- *
- *	Transfer qc->sect_size bytes of data from/to the ATA device.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static void ata_pio_sector(struct ata_queued_cmd *qc)
-{
-	int do_write = (qc->tf.flags & ATA_TFLAG_WRITE);
-	struct ata_port *ap = qc->ap;
-	struct page *page;
-	unsigned int offset;
-	unsigned char *buf;
-
-	if (qc->curbytes == qc->nbytes - qc->sect_size)
-		ap->hsm_task_state = HSM_ST_LAST;
-
-	page = sg_page(qc->cursg);
-	offset = qc->cursg->offset + qc->cursg_ofs;
-
-	/* get the current page and offset */
-	page = nth_page(page, (offset >> PAGE_SHIFT));
-	offset %= PAGE_SIZE;
-
-	DPRINTK("data %s\n", qc->tf.flags & ATA_TFLAG_WRITE ? "write" : "read");
-
-	if (PageHighMem(page)) {
-		unsigned long flags;
-
-		/* FIXME: use a bounce buffer */
-		local_irq_save(flags);
-		buf = kmap_atomic(page, KM_IRQ0);
-
-		/* do the actual data transfer */
-		ap->ops->sff_data_xfer(qc->dev, buf + offset, qc->sect_size,
-				       do_write);
-
-		kunmap_atomic(buf, KM_IRQ0);
-		local_irq_restore(flags);
-	} else {
-		buf = page_address(page);
-		ap->ops->sff_data_xfer(qc->dev, buf + offset, qc->sect_size,
-				       do_write);
-	}
-
-	if (!do_write && !PageSlab(page))
-		flush_dcache_page(page);
-
-	qc->curbytes += qc->sect_size;
-	qc->cursg_ofs += qc->sect_size;
-
-	if (qc->cursg_ofs == qc->cursg->length) {
-		qc->cursg = sg_next(qc->cursg);
-		qc->cursg_ofs = 0;
-	}
-}
-
-/**
- *	ata_pio_sectors - Transfer one or many sectors.
- *	@qc: Command on going
- *
- *	Transfer one or many sectors of data from/to the
- *	ATA device for the DRQ request.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static void ata_pio_sectors(struct ata_queued_cmd *qc)
-{
-	if (is_multi_taskfile(&qc->tf)) {
-		/* READ/WRITE MULTIPLE */
-		unsigned int nsect;
-
-		WARN_ON_ONCE(qc->dev->multi_count == 0);
-
-		nsect = min((qc->nbytes - qc->curbytes) / qc->sect_size,
-			    qc->dev->multi_count);
-		while (nsect--)
-			ata_pio_sector(qc);
-	} else
-		ata_pio_sector(qc);
-
-	ata_sff_sync(qc->ap); /* flush */
-}
-
-/**
- *	atapi_send_cdb - Write CDB bytes to hardware
- *	@ap: Port to which ATAPI device is attached.
- *	@qc: Taskfile currently active
- *
- *	When device has indicated its readiness to accept
- *	a CDB, this function is called.  Send the CDB.
- *
- *	LOCKING:
- *	caller.
- */
-static void atapi_send_cdb(struct ata_port *ap, struct ata_queued_cmd *qc)
-{
-	/* send SCSI cdb */
-	DPRINTK("send cdb\n");
-	WARN_ON_ONCE(qc->dev->cdb_len < 12);
-
-	ap->ops->sff_data_xfer(qc->dev, qc->cdb, qc->dev->cdb_len, 1);
-	ata_sff_sync(ap);
-	/* FIXME: If the CDB is for DMA do we need to do the transition delay
-	   or is bmdma_start guaranteed to do it ? */
-	switch (qc->tf.protocol) {
-	case ATAPI_PROT_PIO:
-		ap->hsm_task_state = HSM_ST;
-		break;
-	case ATAPI_PROT_NODATA:
-		ap->hsm_task_state = HSM_ST_LAST;
-		break;
-	case ATAPI_PROT_DMA:
-		ap->hsm_task_state = HSM_ST_LAST;
-		/* initiate bmdma */
-		ap->ops->bmdma_start(qc);
-		break;
-	}
-}
-
-/**
- *	__atapi_pio_bytes - Transfer data from/to the ATAPI device.
- *	@qc: Command on going
- *	@bytes: number of bytes
- *
- *	Transfer Transfer data from/to the ATAPI device.
- *
- *	LOCKING:
- *	Inherited from caller.
- *
- */
-static int __atapi_pio_bytes(struct ata_queued_cmd *qc, unsigned int bytes)
-{
-	int rw = (qc->tf.flags & ATA_TFLAG_WRITE) ? WRITE : READ;
-	struct ata_port *ap = qc->ap;
-	struct ata_device *dev = qc->dev;
-	struct ata_eh_info *ehi = &dev->link->eh_info;
-	struct scatterlist *sg;
-	struct page *page;
-	unsigned char *buf;
-	unsigned int offset, count, consumed;
-
-next_sg:
-	sg = qc->cursg;
-	if (unlikely(!sg)) {
-		ata_ehi_push_desc(ehi, "unexpected or too much trailing data "
-				  "buf=%u cur=%u bytes=%u",
-				  qc->nbytes, qc->curbytes, bytes);
-		return -1;
-	}
-
-	page = sg_page(sg);
-	offset = sg->offset + qc->cursg_ofs;
-
-	/* get the current page and offset */
-	page = nth_page(page, (offset >> PAGE_SHIFT));
-	offset %= PAGE_SIZE;
-
-	/* don't overrun current sg */
-	count = min(sg->length - qc->cursg_ofs, bytes);
-
-	/* don't cross page boundaries */
-	count = min(count, (unsigned int)PAGE_SIZE - offset);
-
-	DPRINTK("data %s\n", qc->tf.flags & ATA_TFLAG_WRITE ? "write" : "read");
-
-	if (PageHighMem(page)) {
-		unsigned long flags;
-
-		/* FIXME: use bounce buffer */
-		local_irq_save(flags);
-		buf = kmap_atomic(page, KM_IRQ0);
-
-		/* do the actual data transfer */
-		consumed = ap->ops->sff_data_xfer(dev,  buf + offset,
-								count, rw);
-
-		kunmap_atomic(buf, KM_IRQ0);
-		local_irq_restore(flags);
-	} else {
-		buf = page_address(page);
-		consumed = ap->ops->sff_data_xfer(dev,  buf + offset,
-								count, rw);
-	}
-
-	bytes -= min(bytes, consumed);
-	qc->curbytes += count;
-	qc->cursg_ofs += count;
-
-	if (qc->cursg_ofs == sg->length) {
-		qc->cursg = sg_next(qc->cursg);
-		qc->cursg_ofs = 0;
-	}
-
-	/*
-	 * There used to be a  WARN_ON_ONCE(qc->cursg && count != consumed);
-	 * Unfortunately __atapi_pio_bytes doesn't know enough to do the WARN
-	 * check correctly as it doesn't know if it is the last request being
-	 * made. Somebody should implement a proper sanity check.
-	 */
-	if (bytes)
-		goto next_sg;
-	return 0;
-}
-
-/**
- *	atapi_pio_bytes - Transfer data from/to the ATAPI device.
- *	@qc: Command on going
- *
- *	Transfer Transfer data from/to the ATAPI device.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static void atapi_pio_bytes(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct ata_device *dev = qc->dev;
-	struct ata_eh_info *ehi = &dev->link->eh_info;
-	unsigned int ireason, bc_lo, bc_hi, bytes;
-	int i_write, do_write = (qc->tf.flags & ATA_TFLAG_WRITE) ? 1 : 0;
-
-	/* Abuse qc->result_tf for temp storage of intermediate TF
-	 * here to save some kernel stack usage.
-	 * For normal completion, qc->result_tf is not relevant. For
-	 * error, qc->result_tf is later overwritten by ata_qc_complete().
-	 * So, the correctness of qc->result_tf is not affected.
-	 */
-	ap->ops->sff_tf_read(ap, &qc->result_tf);
-	ireason = qc->result_tf.nsect;
-	bc_lo = qc->result_tf.lbam;
-	bc_hi = qc->result_tf.lbah;
-	bytes = (bc_hi << 8) | bc_lo;
-
-	/* shall be cleared to zero, indicating xfer of data */
-	if (unlikely(ireason & (1 << 0)))
-		goto atapi_check;
-
-	/* make sure transfer direction matches expected */
-	i_write = ((ireason & (1 << 1)) == 0) ? 1 : 0;
-	if (unlikely(do_write != i_write))
-		goto atapi_check;
-
-	if (unlikely(!bytes))
-		goto atapi_check;
-
-	VPRINTK("ata%u: xfering %d bytes\n", ap->print_id, bytes);
-
-	if (unlikely(__atapi_pio_bytes(qc, bytes)))
-		goto err_out;
-	ata_sff_sync(ap); /* flush */
-
-	return;
-
- atapi_check:
-	ata_ehi_push_desc(ehi, "ATAPI check failed (ireason=0x%x bytes=%u)",
-			  ireason, bytes);
- err_out:
-	qc->err_mask |= AC_ERR_HSM;
-	ap->hsm_task_state = HSM_ST_ERR;
-}
-
-/**
- *	ata_hsm_ok_in_wq - Check if the qc can be handled in the workqueue.
- *	@ap: the target ata_port
- *	@qc: qc on going
- *
- *	RETURNS:
- *	1 if ok in workqueue, 0 otherwise.
- */
-static inline int ata_hsm_ok_in_wq(struct ata_port *ap,
-						struct ata_queued_cmd *qc)
-{
-	if (qc->tf.flags & ATA_TFLAG_POLLING)
-		return 1;
-
-	if (ap->hsm_task_state == HSM_ST_FIRST) {
-		if (qc->tf.protocol == ATA_PROT_PIO &&
-		   (qc->tf.flags & ATA_TFLAG_WRITE))
-		    return 1;
-
-		if (ata_is_atapi(qc->tf.protocol) &&
-		   !(qc->dev->flags & ATA_DFLAG_CDB_INTR))
-			return 1;
-	}
-
-	return 0;
-}
-
-/**
- *	ata_hsm_qc_complete - finish a qc running on standard HSM
- *	@qc: Command to complete
- *	@in_wq: 1 if called from workqueue, 0 otherwise
- *
- *	Finish @qc which is running on standard HSM.
- *
- *	LOCKING:
- *	If @in_wq is zero, spin_lock_irqsave(host lock).
- *	Otherwise, none on entry and grabs host lock.
- */
-static void ata_hsm_qc_complete(struct ata_queued_cmd *qc, int in_wq)
-{
-	struct ata_port *ap = qc->ap;
-	unsigned long flags;
-
-	if (ap->ops->error_handler) {
-		if (in_wq) {
-			spin_lock_irqsave(ap->lock, flags);
-
-			/* EH might have kicked in while host lock is
-			 * released.
-			 */
-			qc = ata_qc_from_tag(ap, qc->tag);
-			if (qc) {
-				if (likely(!(qc->err_mask & AC_ERR_HSM))) {
-					ap->ops->sff_irq_on(ap);
-					ata_qc_complete(qc);
-				} else
-					ata_port_freeze(ap);
-			}
-
-			spin_unlock_irqrestore(ap->lock, flags);
-		} else {
-			if (likely(!(qc->err_mask & AC_ERR_HSM)))
-				ata_qc_complete(qc);
-			else
-				ata_port_freeze(ap);
-		}
-	} else {
-		if (in_wq) {
-			spin_lock_irqsave(ap->lock, flags);
-			ap->ops->sff_irq_on(ap);
-			ata_qc_complete(qc);
-			spin_unlock_irqrestore(ap->lock, flags);
-		} else
-			ata_qc_complete(qc);
-	}
-}
-
-/**
- *	ata_sff_hsm_move - move the HSM to the next state.
- *	@ap: the target ata_port
- *	@qc: qc on going
- *	@status: current device status
- *	@in_wq: 1 if called from workqueue, 0 otherwise
- *
- *	RETURNS:
- *	1 when poll next status needed, 0 otherwise.
- */
-int ata_sff_hsm_move(struct ata_port *ap, struct ata_queued_cmd *qc,
-		     u8 status, int in_wq)
-{
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	unsigned long flags = 0;
-	int poll_next;
-
-	WARN_ON_ONCE((qc->flags & ATA_QCFLAG_ACTIVE) == 0);
-
-	/* Make sure ata_sff_qc_issue() does not throw things
-	 * like DMA polling into the workqueue. Notice that
-	 * in_wq is not equivalent to (qc->tf.flags & ATA_TFLAG_POLLING).
-	 */
-	WARN_ON_ONCE(in_wq != ata_hsm_ok_in_wq(ap, qc));
-
-fsm_start:
-	DPRINTK("ata%u: protocol %d task_state %d (dev_stat 0x%X)\n",
-		ap->print_id, qc->tf.protocol, ap->hsm_task_state, status);
-
-	switch (ap->hsm_task_state) {
-	case HSM_ST_FIRST:
-		/* Send first data block or PACKET CDB */
-
-		/* If polling, we will stay in the work queue after
-		 * sending the data. Otherwise, interrupt handler
-		 * takes over after sending the data.
-		 */
-		poll_next = (qc->tf.flags & ATA_TFLAG_POLLING);
-
-		/* check device status */
-		if (unlikely((status & ATA_DRQ) == 0)) {
-			/* handle BSY=0, DRQ=0 as error */
-			if (likely(status & (ATA_ERR | ATA_DF)))
-				/* device stops HSM for abort/error */
-				qc->err_mask |= AC_ERR_DEV;
-			else {
-				/* HSM violation. Let EH handle this */
-				ata_ehi_push_desc(ehi,
-					"ST_FIRST: !(DRQ|ERR|DF)");
-				qc->err_mask |= AC_ERR_HSM;
-			}
-
-			ap->hsm_task_state = HSM_ST_ERR;
-			goto fsm_start;
-		}
-
-		/* Device should not ask for data transfer (DRQ=1)
-		 * when it finds something wrong.
-		 * We ignore DRQ here and stop the HSM by
-		 * changing hsm_task_state to HSM_ST_ERR and
-		 * let the EH abort the command or reset the device.
-		 */
-		if (unlikely(status & (ATA_ERR | ATA_DF))) {
-			/* Some ATAPI tape drives forget to clear the ERR bit
-			 * when doing the next command (mostly request sense).
-			 * We ignore ERR here to workaround and proceed sending
-			 * the CDB.
-			 */
-			if (!(qc->dev->horkage & ATA_HORKAGE_STUCK_ERR)) {
-				ata_ehi_push_desc(ehi, "ST_FIRST: "
-					"DRQ=1 with device error, "
-					"dev_stat 0x%X", status);
-				qc->err_mask |= AC_ERR_HSM;
-				ap->hsm_task_state = HSM_ST_ERR;
-				goto fsm_start;
-			}
-		}
-
-		/* Send the CDB (atapi) or the first data block (ata pio out).
-		 * During the state transition, interrupt handler shouldn't
-		 * be invoked before the data transfer is complete and
-		 * hsm_task_state is changed. Hence, the following locking.
-		 */
-		if (in_wq)
-			spin_lock_irqsave(ap->lock, flags);
-
-		if (qc->tf.protocol == ATA_PROT_PIO) {
-			/* PIO data out protocol.
-			 * send first data block.
-			 */
-
-			/* ata_pio_sectors() might change the state
-			 * to HSM_ST_LAST. so, the state is changed here
-			 * before ata_pio_sectors().
-			 */
-			ap->hsm_task_state = HSM_ST;
-			ata_pio_sectors(qc);
-		} else
-			/* send CDB */
-			atapi_send_cdb(ap, qc);
-
-		if (in_wq)
-			spin_unlock_irqrestore(ap->lock, flags);
-
-		/* if polling, ata_pio_task() handles the rest.
-		 * otherwise, interrupt handler takes over from here.
-		 */
-		break;
-
-	case HSM_ST:
-		/* complete command or read/write the data register */
-		if (qc->tf.protocol == ATAPI_PROT_PIO) {
-			/* ATAPI PIO protocol */
-			if ((status & ATA_DRQ) == 0) {
-				/* No more data to transfer or device error.
-				 * Device error will be tagged in HSM_ST_LAST.
-				 */
-				ap->hsm_task_state = HSM_ST_LAST;
-				goto fsm_start;
-			}
-
-			/* Device should not ask for data transfer (DRQ=1)
-			 * when it finds something wrong.
-			 * We ignore DRQ here and stop the HSM by
-			 * changing hsm_task_state to HSM_ST_ERR and
-			 * let the EH abort the command or reset the device.
-			 */
-			if (unlikely(status & (ATA_ERR | ATA_DF))) {
-				ata_ehi_push_desc(ehi, "ST-ATAPI: "
-					"DRQ=1 with device error, "
-					"dev_stat 0x%X", status);
-				qc->err_mask |= AC_ERR_HSM;
-				ap->hsm_task_state = HSM_ST_ERR;
-				goto fsm_start;
-			}
-
-			atapi_pio_bytes(qc);
-
-			if (unlikely(ap->hsm_task_state == HSM_ST_ERR))
-				/* bad ireason reported by device */
-				goto fsm_start;
-
-		} else {
-			/* ATA PIO protocol */
-			if (unlikely((status & ATA_DRQ) == 0)) {
-				/* handle BSY=0, DRQ=0 as error */
-				if (likely(status & (ATA_ERR | ATA_DF))) {
-					/* device stops HSM for abort/error */
-					qc->err_mask |= AC_ERR_DEV;
-
-					/* If diagnostic failed and this is
-					 * IDENTIFY, it's likely a phantom
-					 * device.  Mark hint.
-					 */
-					if (qc->dev->horkage &
-					    ATA_HORKAGE_DIAGNOSTIC)
-						qc->err_mask |=
-							AC_ERR_NODEV_HINT;
-				} else {
-					/* HSM violation. Let EH handle this.
-					 * Phantom devices also trigger this
-					 * condition.  Mark hint.
-					 */
-					ata_ehi_push_desc(ehi, "ST-ATA: "
-						"DRQ=0 without device error, "
-						"dev_stat 0x%X", status);
-					qc->err_mask |= AC_ERR_HSM |
-							AC_ERR_NODEV_HINT;
-				}
-
-				ap->hsm_task_state = HSM_ST_ERR;
-				goto fsm_start;
-			}
-
-			/* For PIO reads, some devices may ask for
-			 * data transfer (DRQ=1) alone with ERR=1.
-			 * We respect DRQ here and transfer one
-			 * block of junk data before changing the
-			 * hsm_task_state to HSM_ST_ERR.
-			 *
-			 * For PIO writes, ERR=1 DRQ=1 doesn't make
-			 * sense since the data block has been
-			 * transferred to the device.
-			 */
-			if (unlikely(status & (ATA_ERR | ATA_DF))) {
-				/* data might be corrputed */
-				qc->err_mask |= AC_ERR_DEV;
-
-				if (!(qc->tf.flags & ATA_TFLAG_WRITE)) {
-					ata_pio_sectors(qc);
-					status = ata_wait_idle(ap);
-				}
-
-				if (status & (ATA_BUSY | ATA_DRQ)) {
-					ata_ehi_push_desc(ehi, "ST-ATA: "
-						"BUSY|DRQ persists on ERR|DF, "
-						"dev_stat 0x%X", status);
-					qc->err_mask |= AC_ERR_HSM;
-				}
-
-				/* There are oddball controllers with
-				 * status register stuck at 0x7f and
-				 * lbal/m/h at zero which makes it
-				 * pass all other presence detection
-				 * mechanisms we have.  Set NODEV_HINT
-				 * for it.  Kernel bz#7241.
-				 */
-				if (status == 0x7f)
-					qc->err_mask |= AC_ERR_NODEV_HINT;
-
-				/* ata_pio_sectors() might change the
-				 * state to HSM_ST_LAST. so, the state
-				 * is changed after ata_pio_sectors().
-				 */
-				ap->hsm_task_state = HSM_ST_ERR;
-				goto fsm_start;
-			}
-
-			ata_pio_sectors(qc);
-
-			if (ap->hsm_task_state == HSM_ST_LAST &&
-			    (!(qc->tf.flags & ATA_TFLAG_WRITE))) {
-				/* all data read */
-				status = ata_wait_idle(ap);
-				goto fsm_start;
-			}
-		}
-
-		poll_next = 1;
-		break;
-
-	case HSM_ST_LAST:
-		if (unlikely(!ata_ok(status))) {
-			qc->err_mask |= __ac_err_mask(status);
-			ap->hsm_task_state = HSM_ST_ERR;
-			goto fsm_start;
-		}
-
-		/* no more data to transfer */
-		DPRINTK("ata%u: dev %u command complete, drv_stat 0x%x\n",
-			ap->print_id, qc->dev->devno, status);
-
-		WARN_ON_ONCE(qc->err_mask & (AC_ERR_DEV | AC_ERR_HSM));
-
-		ap->hsm_task_state = HSM_ST_IDLE;
-
-		/* complete taskfile transaction */
-		ata_hsm_qc_complete(qc, in_wq);
-
-		poll_next = 0;
-		break;
-
-	case HSM_ST_ERR:
-		ap->hsm_task_state = HSM_ST_IDLE;
-
-		/* complete taskfile transaction */
-		ata_hsm_qc_complete(qc, in_wq);
-
-		poll_next = 0;
-		break;
-	default:
-		poll_next = 0;
-		BUG();
-	}
-
-	return poll_next;
-}
-EXPORT_SYMBOL_GPL(ata_sff_hsm_move);
-
-void ata_pio_task(struct work_struct *work)
-{
-	struct ata_port *ap =
-		container_of(work, struct ata_port, port_task.work);
-	struct ata_queued_cmd *qc = ap->port_task_data;
-	u8 status;
-	int poll_next;
-
-fsm_start:
-	WARN_ON_ONCE(ap->hsm_task_state == HSM_ST_IDLE);
-
-	/*
-	 * This is purely heuristic.  This is a fast path.
-	 * Sometimes when we enter, BSY will be cleared in
-	 * a chk-status or two.  If not, the drive is probably seeking
-	 * or something.  Snooze for a couple msecs, then
-	 * chk-status again.  If still busy, queue delayed work.
-	 */
-	status = ata_sff_busy_wait(ap, ATA_BUSY, 5);
-	if (status & ATA_BUSY) {
-		msleep(2);
-		status = ata_sff_busy_wait(ap, ATA_BUSY, 10);
-		if (status & ATA_BUSY) {
-			ata_pio_queue_task(ap, qc, ATA_SHORT_PAUSE);
-			return;
-		}
-	}
-
-	/* move the HSM */
-	poll_next = ata_sff_hsm_move(ap, qc, status, 1);
-
-	/* another command or interrupt handler
-	 * may be running at this point.
-	 */
-	if (poll_next)
-		goto fsm_start;
-}
-
-/**
- *	ata_sff_qc_issue - issue taskfile to device in proto-dependent manner
- *	@qc: command to issue to device
- *
- *	Using various libata functions and hooks, this function
- *	starts an ATA command.  ATA commands are grouped into
- *	classes called "protocols", and issuing each type of protocol
- *	is slightly different.
- *
- *	May be used as the qc_issue() entry in ata_port_operations.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
- *	RETURNS:
- *	Zero on success, AC_ERR_* mask on failure
- */
-unsigned int ata_sff_qc_issue(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-
-	/* Use polling pio if the LLD doesn't handle
-	 * interrupt driven pio and atapi CDB interrupt.
-	 */
-	if (ap->flags & ATA_FLAG_PIO_POLLING) {
-		switch (qc->tf.protocol) {
-		case ATA_PROT_PIO:
-		case ATA_PROT_NODATA:
-		case ATAPI_PROT_PIO:
-		case ATAPI_PROT_NODATA:
-			qc->tf.flags |= ATA_TFLAG_POLLING;
-			break;
-		case ATAPI_PROT_DMA:
-			if (qc->dev->flags & ATA_DFLAG_CDB_INTR)
-				/* see ata_dma_blacklisted() */
-				BUG();
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* select the device */
-	ata_dev_select(ap, qc->dev->devno, 1, 0);
-
-	/* start the command */
-	switch (qc->tf.protocol) {
-	case ATA_PROT_NODATA:
-		if (qc->tf.flags & ATA_TFLAG_POLLING)
-			ata_qc_set_polling(qc);
-
-		ata_tf_to_host(ap, &qc->tf);
-		ap->hsm_task_state = HSM_ST_LAST;
-
-		if (qc->tf.flags & ATA_TFLAG_POLLING)
-			ata_pio_queue_task(ap, qc, 0);
-
-		break;
-
-	case ATA_PROT_DMA:
-		WARN_ON_ONCE(qc->tf.flags & ATA_TFLAG_POLLING);
-
-		ap->ops->sff_tf_load(ap, &qc->tf);  /* load tf registers */
-		ap->ops->bmdma_setup(qc);	    /* set up bmdma */
-		ap->ops->bmdma_start(qc);	    /* initiate bmdma */
-		ap->hsm_task_state = HSM_ST_LAST;
-		break;
-
-	case ATA_PROT_PIO:
-		if (qc->tf.flags & ATA_TFLAG_POLLING)
-			ata_qc_set_polling(qc);
-
-		ata_tf_to_host(ap, &qc->tf);
-
-		if (qc->tf.flags & ATA_TFLAG_WRITE) {
-			/* PIO data out protocol */
-			ap->hsm_task_state = HSM_ST_FIRST;
-			ata_pio_queue_task(ap, qc, 0);
-
-			/* always send first data block using
-			 * the ata_pio_task() codepath.
-			 */
-		} else {
-			/* PIO data in protocol */
-			ap->hsm_task_state = HSM_ST;
-
-			if (qc->tf.flags & ATA_TFLAG_POLLING)
-				ata_pio_queue_task(ap, qc, 0);
-
-			/* if polling, ata_pio_task() handles the rest.
-			 * otherwise, interrupt handler takes over from here.
-			 */
-		}
-
-		break;
-
-	case ATAPI_PROT_PIO:
-	case ATAPI_PROT_NODATA:
-		if (qc->tf.flags & ATA_TFLAG_POLLING)
-			ata_qc_set_polling(qc);
-
-		ata_tf_to_host(ap, &qc->tf);
-
-		ap->hsm_task_state = HSM_ST_FIRST;
-
-		/* send cdb by polling if no cdb interrupt */
-		if ((!(qc->dev->flags & ATA_DFLAG_CDB_INTR)) ||
-		    (qc->tf.flags & ATA_TFLAG_POLLING))
-			ata_pio_queue_task(ap, qc, 0);
-		break;
-
-	case ATAPI_PROT_DMA:
-		WARN_ON_ONCE(qc->tf.flags & ATA_TFLAG_POLLING);
-
-		ap->ops->sff_tf_load(ap, &qc->tf);  /* load tf registers */
-		ap->ops->bmdma_setup(qc);	    /* set up bmdma */
-		ap->hsm_task_state = HSM_ST_FIRST;
-
-		/* send cdb by polling if no cdb interrupt */
-		if (!(qc->dev->flags & ATA_DFLAG_CDB_INTR))
-			ata_pio_queue_task(ap, qc, 0);
-		break;
-
-	default:
-		WARN_ON_ONCE(1);
-		return AC_ERR_SYSTEM;
-	}
-
-	return 0;
-}
-EXPORT_SYMBOL_GPL(ata_sff_qc_issue);
-
-/**
- *	ata_sff_qc_fill_rtf - fill result TF using ->sff_tf_read
- *	@qc: qc to fill result TF for
- *
- *	@qc is finished and result TF needs to be filled.  Fill it
- *	using ->sff_tf_read.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
- *	RETURNS:
- *	true indicating that result TF is successfully filled.
- */
-bool ata_sff_qc_fill_rtf(struct ata_queued_cmd *qc)
-{
-	qc->ap->ops->sff_tf_read(qc->ap, &qc->result_tf);
-	return true;
-}
-EXPORT_SYMBOL_GPL(ata_sff_qc_fill_rtf);
-
-/**
- *	ata_sff_host_intr - Handle host interrupt for given (port, task)
- *	@ap: Port on which interrupt arrived (possibly...)
- *	@qc: Taskfile currently active in engine
- *
- *	Handle host interrupt for given queued command.  Currently,
- *	only DMA interrupts are handled.  All other commands are
- *	handled via polling with interrupts disabled (nIEN bit).
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
- *	RETURNS:
- *	One if interrupt was handled, zero if not (shared irq).
- */
-unsigned int ata_sff_host_intr(struct ata_port *ap,
-				      struct ata_queued_cmd *qc)
-{
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	u8 status, host_stat = 0;
-
-	VPRINTK("ata%u: protocol %d task_state %d\n",
-		ap->print_id, qc->tf.protocol, ap->hsm_task_state);
-
-	/* Check whether we are expecting interrupt in this state */
-	switch (ap->hsm_task_state) {
-	case HSM_ST_FIRST:
-		/* Some pre-ATAPI-4 devices assert INTRQ
-		 * at this state when ready to receive CDB.
-		 */
-
-		/* Check the ATA_DFLAG_CDB_INTR flag is enough here.
-		 * The flag was turned on only for atapi devices.  No
-		 * need to check ata_is_atapi(qc->tf.protocol) again.
-		 */
-		if (!(qc->dev->flags & ATA_DFLAG_CDB_INTR))
-			goto idle_irq;
-		break;
-	case HSM_ST_LAST:
-		if (qc->tf.protocol == ATA_PROT_DMA ||
-		    qc->tf.protocol == ATAPI_PROT_DMA) {
-			/* check status of DMA engine */
-			host_stat = ap->ops->bmdma_status(ap);
-			VPRINTK("ata%u: host_stat 0x%X\n",
-				ap->print_id, host_stat);
-
-			/* if it's not our irq... */
-			if (!(host_stat & ATA_DMA_INTR))
-				goto idle_irq;
-
-			/* before we do anything else, clear DMA-Start bit */
-			ap->ops->bmdma_stop(qc);
-
-			if (unlikely(host_stat & ATA_DMA_ERR)) {
-				/* error when transfering data to/from memory */
-				qc->err_mask |= AC_ERR_HOST_BUS;
-				ap->hsm_task_state = HSM_ST_ERR;
-			}
-		}
-		break;
-	case HSM_ST:
-		break;
-	default:
-		goto idle_irq;
-	}
-
-
-	/* check main status, clearing INTRQ if needed */
-	status = ata_sff_irq_status(ap);
-	if (status & ATA_BUSY)
-		goto idle_irq;
-
-	/* ack bmdma irq events */
-	ap->ops->sff_irq_clear(ap);
-
-	ata_sff_hsm_move(ap, qc, status, 0);
-
-	if (unlikely(qc->err_mask) && (qc->tf.protocol == ATA_PROT_DMA ||
-				       qc->tf.protocol == ATAPI_PROT_DMA))
-		ata_ehi_push_desc(ehi, "BMDMA stat 0x%x", host_stat);
-
-	return 1;	/* irq handled */
-
-idle_irq:
-	ap->stats.idle_irq++;
-
-#ifdef ATA_IRQ_TRAP
-	if ((ap->stats.idle_irq % 1000) == 0) {
-		ap->ops->sff_check_status(ap);
-		ap->ops->sff_irq_clear(ap);
-		ata_port_printk(ap, KERN_WARNING, "irq trap\n");
-		return 1;
-	}
-#endif
-	return 0;	/* irq not handled */
-}
-EXPORT_SYMBOL_GPL(ata_sff_host_intr);
-
-/**
- *	ata_sff_interrupt - Default ATA host interrupt handler
- *	@irq: irq line (unused)
- *	@dev_instance: pointer to our ata_host information structure
- *
- *	Default interrupt handler for PCI IDE devices.  Calls
- *	ata_sff_host_intr() for each port that is not disabled.
- *
- *	LOCKING:
- *	Obtains host lock during operation.
- *
- *	RETURNS:
- *	IRQ_NONE or IRQ_HANDLED.
- */
-irqreturn_t ata_sff_interrupt(int irq, void *dev_instance)
-{
-	struct ata_host *host = dev_instance;
-	unsigned int i;
-	unsigned int handled = 0;
-	unsigned long flags;
-
-	/* TODO: make _irqsave conditional on x86 PCI IDE legacy mode */
-	spin_lock_irqsave(&host->lock, flags);
-
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap;
-
-		ap = host->ports[i];
-		if (ap &&
-		    !(ap->flags & ATA_FLAG_DISABLED)) {
-			struct ata_queued_cmd *qc;
-
-			qc = ata_qc_from_tag(ap, ap->link.active_tag);
-			if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)) &&
-			    (qc->flags & ATA_QCFLAG_ACTIVE))
-				handled |= ata_sff_host_intr(ap, qc);
-		}
-	}
-
-	spin_unlock_irqrestore(&host->lock, flags);
-
-	return IRQ_RETVAL(handled);
-}
-EXPORT_SYMBOL_GPL(ata_sff_interrupt);
-
-/**
- *	ata_sff_lost_interrupt	-	Check for an apparent lost interrupt
- *	@ap: port that appears to have timed out
- *
- *	Called from the libata error handlers when the core code suspects
- *	an interrupt has been lost. If it has complete anything we can and
- *	then return. Interface must support altstatus for this faster
- *	recovery to occur.
- *
- *	Locking:
- *	Caller holds host lock
- */
-
-void ata_sff_lost_interrupt(struct ata_port *ap)
-{
-	u8 status;
-	struct ata_queued_cmd *qc;
-
-	/* Only one outstanding command per SFF channel */
-	qc = ata_qc_from_tag(ap, ap->link.active_tag);
-	/* Check we have a live one.. */
-	if (qc == NULL ||  !(qc->flags & ATA_QCFLAG_ACTIVE))
-		return;
-	/* We cannot lose an interrupt on a polled command */
-	if (qc->tf.flags & ATA_TFLAG_POLLING)
-		return;
-	/* See if the controller thinks it is still busy - if so the command
-	   isn't a lost IRQ but is still in progress */
-	status = ata_sff_altstatus(ap);
-	if (status & ATA_BUSY)
-		return;
-
-	/* There was a command running, we are no longer busy and we have
-	   no interrupt. */
-	ata_port_printk(ap, KERN_WARNING, "lost interrupt (Status 0x%x)\n",
-								status);
-	/* Run the host interrupt logic as if the interrupt had not been
-	   lost */
-	ata_sff_host_intr(ap, qc);
-}
-EXPORT_SYMBOL_GPL(ata_sff_lost_interrupt);
-
-/**
- *	ata_sff_freeze - Freeze SFF controller port
- *	@ap: port to freeze
- *
- *	Freeze BMDMA controller port.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-void ata_sff_freeze(struct ata_port *ap)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-
-	ap->ctl |= ATA_NIEN;
-	ap->last_ctl = ap->ctl;
-
-	if (ioaddr->ctl_addr)
-		iowrite8(ap->ctl, ioaddr->ctl_addr);
-
-	/* Under certain circumstances, some controllers raise IRQ on
-	 * ATA_NIEN manipulation.  Also, many controllers fail to mask
-	 * previously pending IRQ on ATA_NIEN assertion.  Clear it.
-	 */
-	ap->ops->sff_check_status(ap);
-
-	ap->ops->sff_irq_clear(ap);
-}
-EXPORT_SYMBOL_GPL(ata_sff_freeze);
-
-/**
- *	ata_sff_thaw - Thaw SFF controller port
- *	@ap: port to thaw
- *
- *	Thaw SFF controller port.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-void ata_sff_thaw(struct ata_port *ap)
-{
-	/* clear & re-enable interrupts */
-	ap->ops->sff_check_status(ap);
-	ap->ops->sff_irq_clear(ap);
-	ap->ops->sff_irq_on(ap);
-}
-EXPORT_SYMBOL_GPL(ata_sff_thaw);
-
-/**
- *	ata_sff_prereset - prepare SFF link for reset
- *	@link: SFF link to be reset
- *	@deadline: deadline jiffies for the operation
- *
- *	SFF link @link is about to be reset.  Initialize it.  It first
- *	calls ata_std_prereset() and wait for !BSY if the port is
- *	being softreset.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep)
- *
- *	RETURNS:
- *	0 on success, -errno otherwise.
- */
-int ata_sff_prereset(struct ata_link *link, unsigned long deadline)
-{
-	struct ata_eh_context *ehc = &link->eh_context;
-	int rc;
-
-	rc = ata_std_prereset(link, deadline);
-	if (rc)
-		return rc;
-
-	/* if we're about to do hardreset, nothing more to do */
-	if (ehc->i.action & ATA_EH_HARDRESET)
-		return 0;
-
-	/* wait for !BSY if we don't know that no device is attached */
-	if (!ata_link_offline(link)) {
-		rc = ata_sff_wait_ready(link, deadline);
-		if (rc && rc != -ENODEV) {
-			ata_link_printk(link, KERN_WARNING, "device not ready "
-					"(errno=%d), forcing hardreset\n", rc);
-			ehc->i.action |= ATA_EH_HARDRESET;
-		}
-	}
-
-	return 0;
-}
-EXPORT_SYMBOL_GPL(ata_sff_prereset);
-
-/**
- *	ata_devchk - PATA device presence detection
- *	@ap: ATA channel to examine
- *	@device: Device to examine (starting at zero)
- *
- *	This technique was originally described in
- *	Hale Landis's ATADRVR (www.ata-atapi.com), and
- *	later found its way into the ATA/ATAPI spec.
- *
- *	Write a pattern to the ATA shadow registers,
- *	and if a device is present, it will respond by
- *	correctly storing and echoing back the
- *	ATA shadow register contents.
- *
- *	LOCKING:
- *	caller.
- */
-static unsigned int ata_devchk(struct ata_port *ap, unsigned int device)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	u8 nsect, lbal;
-
-	ap->ops->sff_dev_select(ap, device);
-
-	iowrite8(0x55, ioaddr->nsect_addr);
-	iowrite8(0xaa, ioaddr->lbal_addr);
-
-	iowrite8(0xaa, ioaddr->nsect_addr);
-	iowrite8(0x55, ioaddr->lbal_addr);
-
-	iowrite8(0x55, ioaddr->nsect_addr);
-	iowrite8(0xaa, ioaddr->lbal_addr);
-
-	nsect = ioread8(ioaddr->nsect_addr);
-	lbal = ioread8(ioaddr->lbal_addr);
-
-	if ((nsect == 0x55) && (lbal == 0xaa))
-		return 1;	/* we found a device */
-
-	return 0;		/* nothing found */
-}
-
-/**
- *	ata_sff_dev_classify - Parse returned ATA device signature
- *	@dev: ATA device to classify (starting at zero)
- *	@present: device seems present
- *	@r_err: Value of error register on completion
- *
- *	After an event -- SRST, E.D.D., or SATA COMRESET -- occurs,
- *	an ATA/ATAPI-defined set of values is placed in the ATA
- *	shadow registers, indicating the results of device detection
- *	and diagnostics.
- *
- *	Select the ATA device, and read the values from the ATA shadow
- *	registers.  Then parse according to the Error register value,
- *	and the spec-defined values examined by ata_dev_classify().
- *
- *	LOCKING:
- *	caller.
- *
- *	RETURNS:
- *	Device type - %ATA_DEV_ATA, %ATA_DEV_ATAPI or %ATA_DEV_NONE.
- */
-unsigned int ata_sff_dev_classify(struct ata_device *dev, int present,
-				  u8 *r_err)
-{
-	struct ata_port *ap = dev->link->ap;
-	struct ata_taskfile tf;
-	unsigned int class;
-	u8 err;
-
-	ap->ops->sff_dev_select(ap, dev->devno);
-
-	memset(&tf, 0, sizeof(tf));
-
-	ap->ops->sff_tf_read(ap, &tf);
-	err = tf.feature;
-	if (r_err)
-		*r_err = err;
-
-	/* see if device passed diags: continue and warn later */
-	if (err == 0)
-		/* diagnostic fail : do nothing _YET_ */
-		dev->horkage |= ATA_HORKAGE_DIAGNOSTIC;
-	else if (err == 1)
-		/* do nothing */ ;
-	else if ((dev->devno == 0) && (err == 0x81))
-		/* do nothing */ ;
-	else
-		return ATA_DEV_NONE;
-
-	/* determine if device is ATA or ATAPI */
-	class = ata_dev_classify(&tf);
-
-	if (class == ATA_DEV_UNKNOWN) {
-		/* If the device failed diagnostic, it's likely to
-		 * have reported incorrect device signature too.
-		 * Assume ATA device if the device seems present but
-		 * device signature is invalid with diagnostic
-		 * failure.
-		 */
-		if (present && (dev->horkage & ATA_HORKAGE_DIAGNOSTIC))
-			class = ATA_DEV_ATA;
-		else
-			class = ATA_DEV_NONE;
-	} else if ((class == ATA_DEV_ATA) &&
-		   (ap->ops->sff_check_status(ap) == 0))
-		class = ATA_DEV_NONE;
-
-	return class;
-}
-EXPORT_SYMBOL_GPL(ata_sff_dev_classify);
-
-/**
- *	ata_sff_wait_after_reset - wait for devices to become ready after reset
- *	@link: SFF link which is just reset
- *	@devmask: mask of present devices
- *	@deadline: deadline jiffies for the operation
- *
- *	Wait devices attached to SFF @link to become ready after
- *	reset.  It contains preceding 150ms wait to avoid accessing TF
- *	status register too early.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep).
- *
- *	RETURNS:
- *	0 on success, -ENODEV if some or all of devices in @devmask
- *	don't seem to exist.  -errno on other errors.
- */
-int ata_sff_wait_after_reset(struct ata_link *link, unsigned int devmask,
-			     unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	unsigned int dev0 = devmask & (1 << 0);
-	unsigned int dev1 = devmask & (1 << 1);
-	int rc, ret = 0;
-
-	msleep(ATA_WAIT_AFTER_RESET);
-
-	/* always check readiness of the master device */
-	rc = ata_sff_wait_ready(link, deadline);
-	/* -ENODEV means the odd clown forgot the D7 pulldown resistor
-	 * and TF status is 0xff, bail out on it too.
-	 */
-	if (rc)
-		return rc;
-
-	/* if device 1 was found in ata_devchk, wait for register
-	 * access briefly, then wait for BSY to clear.
-	 */
-	if (dev1) {
-		int i;
-
-		ap->ops->sff_dev_select(ap, 1);
-
-		/* Wait for register access.  Some ATAPI devices fail
-		 * to set nsect/lbal after reset, so don't waste too
-		 * much time on it.  We're gonna wait for !BSY anyway.
-		 */
-		for (i = 0; i < 2; i++) {
-			u8 nsect, lbal;
-
-			nsect = ioread8(ioaddr->nsect_addr);
-			lbal = ioread8(ioaddr->lbal_addr);
-			if ((nsect == 1) && (lbal == 1))
-				break;
-			msleep(50);	/* give drive a breather */
-		}
-
-		rc = ata_sff_wait_ready(link, deadline);
-		if (rc) {
-			if (rc != -ENODEV)
-				return rc;
-			ret = rc;
-		}
-	}
-
-	/* is all this really necessary? */
-	ap->ops->sff_dev_select(ap, 0);
-	if (dev1)
-		ap->ops->sff_dev_select(ap, 1);
-	if (dev0)
-		ap->ops->sff_dev_select(ap, 0);
-
-	return ret;
-}
-EXPORT_SYMBOL_GPL(ata_sff_wait_after_reset);
-
-static int ata_bus_softreset(struct ata_port *ap, unsigned int devmask,
-			     unsigned long deadline)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-
-	DPRINTK("ata%u: bus reset via SRST\n", ap->print_id);
-
-	/* software reset.  causes dev0 to be selected */
-	iowrite8(ap->ctl, ioaddr->ctl_addr);
-	udelay(20);	/* FIXME: flush */
-	iowrite8(ap->ctl | ATA_SRST, ioaddr->ctl_addr);
-	udelay(20);	/* FIXME: flush */
-	iowrite8(ap->ctl, ioaddr->ctl_addr);
-	ap->last_ctl = ap->ctl;
-
-	/* wait the port to become ready */
-	return ata_sff_wait_after_reset(&ap->link, devmask, deadline);
-}
-
-/**
- *	ata_sff_softreset - reset host port via ATA SRST
- *	@link: ATA link to reset
- *	@classes: resulting classes of attached devices
- *	@deadline: deadline jiffies for the operation
- *
- *	Reset host port using ATA SRST.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep)
- *
- *	RETURNS:
- *	0 on success, -errno otherwise.
- */
-int ata_sff_softreset(struct ata_link *link, unsigned int *classes,
-		      unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	unsigned int slave_possible = ap->flags & ATA_FLAG_SLAVE_POSS;
-	unsigned int devmask = 0;
-	int rc;
-	u8 err;
-
-	DPRINTK("ENTER\n");
-
-	/* determine if device 0/1 are present */
-	if (ata_devchk(ap, 0))
-		devmask |= (1 << 0);
-	if (slave_possible && ata_devchk(ap, 1))
-		devmask |= (1 << 1);
-
-	/* select device 0 again */
-	ap->ops->sff_dev_select(ap, 0);
-
-	/* issue bus reset */
-	DPRINTK("about to softreset, devmask=%x\n", devmask);
-	rc = ata_bus_softreset(ap, devmask, deadline);
-	/* if link is occupied, -ENODEV too is an error */
-	if (rc && (rc != -ENODEV || sata_scr_valid(link))) {
-		ata_link_printk(link, KERN_ERR, "SRST failed (errno=%d)\n", rc);
-		return rc;
-	}
-
-	/* determine by signature whether we have ATA or ATAPI devices */
-	classes[0] = ata_sff_dev_classify(&link->device[0],
-					  devmask & (1 << 0), &err);
-	if (slave_possible && err != 0x81)
-		classes[1] = ata_sff_dev_classify(&link->device[1],
-						  devmask & (1 << 1), &err);
-
-	DPRINTK("EXIT, classes[0]=%u [1]=%u\n", classes[0], classes[1]);
-	return 0;
-}
-EXPORT_SYMBOL_GPL(ata_sff_softreset);
-
-/**
- *	sata_sff_hardreset - reset host port via SATA phy reset
- *	@link: link to reset
- *	@class: resulting class of attached device
- *	@deadline: deadline jiffies for the operation
- *
- *	SATA phy-reset host port using DET bits of SControl register,
- *	wait for !BSY and classify the attached device.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep)
- *
- *	RETURNS:
- *	0 on success, -errno otherwise.
- */
-int sata_sff_hardreset(struct ata_link *link, unsigned int *class,
-		       unsigned long deadline)
-{
-	struct ata_eh_context *ehc = &link->eh_context;
-	const unsigned long *timing = sata_ehc_deb_timing(ehc);
-	bool online;
-	int rc;
-
-	rc = sata_link_hardreset(link, timing, deadline, &online,
-				 ata_sff_check_ready);
-	if (online)
-		*class = ata_sff_dev_classify(link->device, 1, NULL);
-
-	DPRINTK("EXIT, class=%u\n", *class);
-	return rc;
-}
-EXPORT_SYMBOL_GPL(sata_sff_hardreset);
-
-/**
- *	ata_sff_postreset - SFF postreset callback
- *	@link: the target SFF ata_link
- *	@classes: classes of attached devices
- *
- *	This function is invoked after a successful reset.  It first
- *	calls ata_std_postreset() and performs SFF specific postreset
- *	processing.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep)
- */
-void ata_sff_postreset(struct ata_link *link, unsigned int *classes)
-{
-	struct ata_port *ap = link->ap;
-	unsigned int slave_possible = ap->flags & ATA_FLAG_SLAVE_POSS;
-
-	ata_std_postreset(link, classes);
-
-	/* is double-select really necessary? */
-	if (classes[0] != ATA_DEV_NONE)
-		ap->ops->sff_dev_select(ap, 1);
-	if (classes[1] != ATA_DEV_NONE && slave_possible)
-		ap->ops->sff_dev_select(ap, 0);
-
-	/* bail out if no device is present */
-	if (classes[0] == ATA_DEV_NONE &&
-	    (!slave_possible || classes[1] == ATA_DEV_NONE)) {
-		DPRINTK("EXIT, no device\n");
-		return;
-	}
-
-	/* set up device control */
-	if (ap->ioaddr.ctl_addr) {
-		iowrite8(ap->ctl, ap->ioaddr.ctl_addr);
-		ap->last_ctl = ap->ctl;
-	}
-}
-EXPORT_SYMBOL_GPL(ata_sff_postreset);
-
-/**
- *	ata_sff_drain_fifo - Stock FIFO drain logic for SFF controllers
- *	@qc: command
- *
- *	Drain the FIFO and device of any stuck data following a command
- *	failing to complete. In some cases this is neccessary before a
- *	reset will recover the device.
- *
- */
-
-void ata_sff_drain_fifo(struct ata_queued_cmd *qc)
-{
-	int count;
-	struct ata_port *ap;
-
-	/* We only need to flush incoming data when a command was running */
-	if (qc == NULL || qc->dma_dir == DMA_TO_DEVICE)
-		return;
-
-	ap = qc->ap;
-	/* Drain up to 64K of data before we give up this recovery method */
-	for (count = 0; (ap->ops->sff_check_status(ap) & ATA_DRQ)
-						&& count < 32768; count++)
-		ioread16(ap->ioaddr.data_addr);
-
-	/* Can become DEBUG later */
-	if (count)
-		ata_port_printk(ap, KERN_DEBUG,
-			"drained %d bytes to clear DRQ.\n", count);
-
-}
-EXPORT_SYMBOL_GPL(ata_sff_drain_fifo);
-
-/**
- *	ata_sff_error_handler - Stock error handler for BMDMA controller
- *	@ap: port to handle error for
- *
- *	Stock error handler for SFF controller.  It can handle both
- *	PATA and SATA controllers.  Many controllers should be able to
- *	use this EH as-is or with some added handling before and
- *	after.
- *
- *	LOCKING:
- *	Kernel thread context (may sleep)
- */
-void ata_sff_error_handler(struct ata_port *ap)
-{
-	ata_reset_fn_t softreset = ap->ops->softreset;
-	ata_reset_fn_t hardreset = ap->ops->hardreset;
 	struct ata_queued_cmd *qc;
 	unsigned long flags;
 	int thaw = 0;
 
-	qc = __ata_qc_from_tag(ap, ap->link.active_tag);
+	qc = __ata_qc_from_tag(ap, ap->active_tag);
 	if (qc && !(qc->flags & ATA_QCFLAG_FAILED))
 		qc = NULL;
 
@@ -2320,9 +454,8 @@
 
 	ap->hsm_task_state = HSM_ST_IDLE;
 
-	if (ap->ioaddr.bmdma_addr &&
-	    qc && (qc->tf.protocol == ATA_PROT_DMA ||
-		   qc->tf.protocol == ATAPI_PROT_DMA)) {
+	if (qc && (qc->tf.protocol == ATA_PROT_DMA ||
+		   qc->tf.protocol == ATA_PROT_ATAPI_DMA)) {
 		u8 host_stat;
 
 		host_stat = ap->ops->bmdma_status(ap);
@@ -2332,379 +465,101 @@
 		 * really a timeout event, adjust error mask and
 		 * cancel frozen state.
 		 */
-		if (qc->err_mask == AC_ERR_TIMEOUT
-						&& (host_stat & ATA_DMA_ERR)) {
+		if (qc->err_mask == AC_ERR_TIMEOUT && (host_stat & ATA_DMA_ERR)) {
 			qc->err_mask = AC_ERR_HOST_BUS;
 			thaw = 1;
 		}
 
-		ap->ops->bmdma_stop(qc);
-	}
-
-	ata_sff_sync(ap);		/* FIXME: We don't need this */
-	ap->ops->sff_check_status(ap);
-	ap->ops->sff_irq_clear(ap);
-	/* We *MUST* do FIFO draining before we issue a reset as several
-	 * devices helpfully clear their internal state and will lock solid
-	 * if we touch the data port post reset. Pass qc in case anyone wants
-	 *  to do different PIO/DMA recovery or has per command fixups
-	 */
-	if (ap->ops->drain_fifo)
-		ap->ops->drain_fifo(qc);
-
-	spin_unlock_irqrestore(ap->lock, flags);
-
-	if (thaw)
-		ata_eh_thaw_port(ap);
-
-	/* PIO and DMA engines have been stopped, perform recovery */
-
-	/* Ignore ata_sff_softreset if ctl isn't accessible and
-	 * built-in hardresets if SCR access isn't available.
-	 */
-	if (softreset == ata_sff_softreset && !ap->ioaddr.ctl_addr)
-		softreset = NULL;
-	if (ata_is_builtin_hardreset(hardreset) && !sata_scr_valid(&ap->link))
-		hardreset = NULL;
-
-	ata_do_eh(ap, ap->ops->prereset, softreset, hardreset,
-		  ap->ops->postreset);
-}
-EXPORT_SYMBOL_GPL(ata_sff_error_handler);
-
-/**
- *	ata_sff_post_internal_cmd - Stock post_internal_cmd for SFF controller
- *	@qc: internal command to clean up
- *
- *	LOCKING:
- *	Kernel thread context (may sleep)
- */
-void ata_sff_post_internal_cmd(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	unsigned long flags;
-
-	spin_lock_irqsave(ap->lock, flags);
-
-	ap->hsm_task_state = HSM_ST_IDLE;
-
-	if (ap->ioaddr.bmdma_addr)
-		ata_bmdma_stop(qc);
-
-	spin_unlock_irqrestore(ap->lock, flags);
-}
-EXPORT_SYMBOL_GPL(ata_sff_post_internal_cmd);
-
-/**
- *	ata_sff_port_start - Set port up for dma.
- *	@ap: Port to initialize
- *
- *	Called just after data structures for each port are
- *	initialized.  Allocates space for PRD table if the device
- *	is DMA capable SFF.
- *
- *	May be used as the port_start() entry in ata_port_operations.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-int ata_sff_port_start(struct ata_port *ap)
-{
-	if (ap->ioaddr.bmdma_addr)
-		return ata_port_start(ap);
-	return 0;
-}
-EXPORT_SYMBOL_GPL(ata_sff_port_start);
-
-/**
- *	ata_sff_port_start32 - Set port up for dma.
- *	@ap: Port to initialize
- *
- *	Called just after data structures for each port are
- *	initialized.  Allocates space for PRD table if the device
- *	is DMA capable SFF.
- *
- *	May be used as the port_start() entry in ata_port_operations for
- *	devices that are capable of 32bit PIO.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-int ata_sff_port_start32(struct ata_port *ap)
-{
-	ap->pflags |= ATA_PFLAG_PIO32 | ATA_PFLAG_PIO32CHANGE;
-	if (ap->ioaddr.bmdma_addr)
-		return ata_port_start(ap);
-	return 0;
-}
-EXPORT_SYMBOL_GPL(ata_sff_port_start32);
-
-/**
- *	ata_sff_std_ports - initialize ioaddr with standard port offsets.
- *	@ioaddr: IO address structure to be initialized
- *
- *	Utility function which initializes data_addr, error_addr,
- *	feature_addr, nsect_addr, lbal_addr, lbam_addr, lbah_addr,
- *	device_addr, status_addr, and command_addr to standard offsets
- *	relative to cmd_addr.
- *
- *	Does not set ctl_addr, altstatus_addr, bmdma_addr, or scr_addr.
- */
-void ata_sff_std_ports(struct ata_ioports *ioaddr)
-{
-	ioaddr->data_addr = ioaddr->cmd_addr + ATA_REG_DATA;
-	ioaddr->error_addr = ioaddr->cmd_addr + ATA_REG_ERR;
-	ioaddr->feature_addr = ioaddr->cmd_addr + ATA_REG_FEATURE;
-	ioaddr->nsect_addr = ioaddr->cmd_addr + ATA_REG_NSECT;
-	ioaddr->lbal_addr = ioaddr->cmd_addr + ATA_REG_LBAL;
-	ioaddr->lbam_addr = ioaddr->cmd_addr + ATA_REG_LBAM;
-	ioaddr->lbah_addr = ioaddr->cmd_addr + ATA_REG_LBAH;
-	ioaddr->device_addr = ioaddr->cmd_addr + ATA_REG_DEVICE;
-	ioaddr->status_addr = ioaddr->cmd_addr + ATA_REG_STATUS;
-	ioaddr->command_addr = ioaddr->cmd_addr + ATA_REG_CMD;
-}
-EXPORT_SYMBOL_GPL(ata_sff_std_ports);
-
-unsigned long ata_bmdma_mode_filter(struct ata_device *adev,
-				    unsigned long xfer_mask)
-{
-	/* Filter out DMA modes if the device has been configured by
-	   the BIOS as PIO only */
-
-	if (adev->link->ap->ioaddr.bmdma_addr == NULL)
-		xfer_mask &= ~(ATA_MASK_MWDMA | ATA_MASK_UDMA);
-	return xfer_mask;
-}
-EXPORT_SYMBOL_GPL(ata_bmdma_mode_filter);
-
-/**
- *	ata_bmdma_setup - Set up PCI IDE BMDMA transaction
- *	@qc: Info associated with this ATA transaction.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- */
-void ata_bmdma_setup(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	unsigned int rw = (qc->tf.flags & ATA_TFLAG_WRITE);
-	u8 dmactl;
-
-	/* load PRD table addr. */
-	mb();	/* make sure PRD table writes are visible to controller */
-	iowrite32(ap->prd_dma, ap->ioaddr.bmdma_addr + ATA_DMA_TABLE_OFS);
-
-	/* specify data direction, triple-check start bit is clear */
-	dmactl = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
-	dmactl &= ~(ATA_DMA_WR | ATA_DMA_START);
-	if (!rw)
-		dmactl |= ATA_DMA_WR;
-	iowrite8(dmactl, ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
-
-	/* issue r/w command */
-	ap->ops->sff_exec_command(ap, &qc->tf);
-}
-EXPORT_SYMBOL_GPL(ata_bmdma_setup);
-
-/**
- *	ata_bmdma_start - Start a PCI IDE BMDMA transaction
- *	@qc: Info associated with this ATA transaction.
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- */
-void ata_bmdma_start(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	u8 dmactl;
-
-	/* start host DMA transaction */
-	dmactl = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
-	iowrite8(dmactl | ATA_DMA_START, ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
+		ap->ops->bmdma_stop(qc);
+	}
 
-	/* Strictly, one may wish to issue an ioread8() here, to
-	 * flush the mmio write.  However, control also passes
-	 * to the hardware at this point, and it will interrupt
-	 * us when we are to resume control.  So, in effect,
-	 * we don't care when the mmio write flushes.
-	 * Further, a read of the DMA status register _immediately_
-	 * following the write may not be what certain flaky hardware
-	 * is expected, so I think it is best to not add a readb()
-	 * without first all the MMIO ATA cards/mobos.
-	 * Or maybe I'm just being paranoid.
-	 *
-	 * FIXME: The posting of this write means I/O starts are
-	 * unneccessarily delayed for MMIO
-	 */
+	ata_altstatus(ap);
+	ata_chk_status(ap);
+	ap->ops->irq_clear(ap);
+
+	spin_unlock_irqrestore(ap->lock, flags);
+
+	if (thaw)
+		ata_eh_thaw_port(ap);
+
+	/* PIO and DMA engines have been stopped, perform recovery */
+	ata_do_eh(ap, prereset, softreset, hardreset, postreset);
 }
-EXPORT_SYMBOL_GPL(ata_bmdma_start);
 
 /**
- *	ata_bmdma_stop - Stop PCI IDE BMDMA transfer
- *	@qc: Command we are ending DMA for
- *
- *	Clears the ATA_DMA_START flag in the dma control register
+ *	ata_bmdma_error_handler - Stock error handler for BMDMA controller
+ *	@ap: port to handle error for
  *
- *	May be used as the bmdma_stop() entry in ata_port_operations.
+ *	Stock error handler for BMDMA controller.
  *
  *	LOCKING:
- *	spin_lock_irqsave(host lock)
+ *	Kernel thread context (may sleep)
  */
-void ata_bmdma_stop(struct ata_queued_cmd *qc)
+void ata_bmdma_error_handler(struct ata_port *ap)
 {
-	struct ata_port *ap = qc->ap;
-	void __iomem *mmio = ap->ioaddr.bmdma_addr;
+	ata_reset_fn_t hardreset;
 
-	/* clear start/stop bit */
-	iowrite8(ioread8(mmio + ATA_DMA_CMD) & ~ATA_DMA_START,
-		 mmio + ATA_DMA_CMD);
+	hardreset = NULL;
+	if (sata_scr_valid(ap))
+		hardreset = sata_std_hardreset;
 
-	/* one-PIO-cycle guaranteed wait, per spec, for HDMA1:0 transition */
-	ata_sff_dma_pause(ap);
+	ata_bmdma_drive_eh(ap, ata_std_prereset, ata_std_softreset, hardreset,
+			   ata_std_postreset);
 }
-EXPORT_SYMBOL_GPL(ata_bmdma_stop);
 
 /**
- *	ata_bmdma_status - Read PCI IDE BMDMA status
- *	@ap: Port associated with this ATA transaction.
- *
- *	Read and return BMDMA status register.
- *
- *	May be used as the bmdma_status() entry in ata_port_operations.
+ *	ata_bmdma_post_internal_cmd - Stock post_internal_cmd for
+ *				      BMDMA controller
+ *	@qc: internal command to clean up
  *
  *	LOCKING:
- *	spin_lock_irqsave(host lock)
+ *	Kernel thread context (may sleep)
  */
-u8 ata_bmdma_status(struct ata_port *ap)
+void ata_bmdma_post_internal_cmd(struct ata_queued_cmd *qc)
 {
-	return ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
+	if (qc->ap->ioaddr.bmdma_addr)
+		ata_bmdma_stop(qc);
 }
-EXPORT_SYMBOL_GPL(ata_bmdma_status);
 
 /**
- *	ata_bus_reset - reset host port and associated ATA channel
- *	@ap: port to reset
- *
- *	This is typically the first time we actually start issuing
- *	commands to the ATA channel.  We wait for BSY to clear, then
- *	issue EXECUTE DEVICE DIAGNOSTIC command, polling for its
- *	result.  Determine what devices, if any, are on the channel
- *	by looking at the device 0/1 error register.  Look at the signature
- *	stored in each device's taskfile registers, to determine if
- *	the device is ATA or ATAPI.
+ *	ata_sff_port_start - Set port up for dma.
+ *	@ap: Port to initialize
  *
- *	LOCKING:
- *	PCI/etc. bus probe sem.
- *	Obtains host lock.
+ *	Called just after data structures for each port are
+ *	initialized.  Allocates space for PRD table if the device
+ *	is DMA capable SFF.
  *
- *	SIDE EFFECTS:
- *	Sets ATA_FLAG_DISABLED if bus reset fails.
+ *	May be used as the port_start() entry in ata_port_operations.
  *
- *	DEPRECATED:
- *	This function is only for drivers which still use old EH and
- *	will be removed soon.
+ *	LOCKING:
+ *	Inherited from caller.
  */
-void ata_bus_reset(struct ata_port *ap)
-{
-	struct ata_device *device = ap->link.device;
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	unsigned int slave_possible = ap->flags & ATA_FLAG_SLAVE_POSS;
-	u8 err;
-	unsigned int dev0, dev1 = 0, devmask = 0;
-	int rc;
-
-	DPRINTK("ENTER, host %u, port %u\n", ap->print_id, ap->port_no);
-
-	/* determine if device 0/1 are present */
-	if (ap->flags & ATA_FLAG_SATA_RESET)
-		dev0 = 1;
-	else {
-		dev0 = ata_devchk(ap, 0);
-		if (slave_possible)
-			dev1 = ata_devchk(ap, 1);
-	}
-
-	if (dev0)
-		devmask |= (1 << 0);
-	if (dev1)
-		devmask |= (1 << 1);
-
-	/* select device 0 again */
-	ap->ops->sff_dev_select(ap, 0);
-
-	/* issue bus reset */
-	if (ap->flags & ATA_FLAG_SRST) {
-		rc = ata_bus_softreset(ap, devmask,
-				       ata_deadline(jiffies, 40000));
-		if (rc && rc != -ENODEV)
-			goto err_out;
-	}
-
-	/*
-	 * determine by signature whether we have ATA or ATAPI devices
-	 */
-	device[0].class = ata_sff_dev_classify(&device[0], dev0, &err);
-	if ((slave_possible) && (err != 0x81))
-		device[1].class = ata_sff_dev_classify(&device[1], dev1, &err);
-
-	/* is double-select really necessary? */
-	if (device[1].class != ATA_DEV_NONE)
-		ap->ops->sff_dev_select(ap, 1);
-	if (device[0].class != ATA_DEV_NONE)
-		ap->ops->sff_dev_select(ap, 0);
-
-	/* if no devices were detected, disable this port */
-	if ((device[0].class == ATA_DEV_NONE) &&
-	    (device[1].class == ATA_DEV_NONE))
-		goto err_out;
-
-	if (ap->flags & (ATA_FLAG_SATA_RESET | ATA_FLAG_SRST)) {
-		/* set up device control for ATA_FLAG_SATA_RESET */
-		iowrite8(ap->ctl, ioaddr->ctl_addr);
-		ap->last_ctl = ap->ctl;
-	}
-
-	DPRINTK("EXIT\n");
-	return;
-
-err_out:
-	ata_port_printk(ap, KERN_ERR, "disabling port\n");
-	ata_port_disable(ap);
 
-	DPRINTK("EXIT\n");
+int ata_sff_port_start(struct ata_port *ap)
+{
+	if (ap->ioaddr.bmdma_addr)
+		return ata_port_start(ap);
+	return 0;
 }
-EXPORT_SYMBOL_GPL(ata_bus_reset);
 
 #ifdef CONFIG_PCI
 
-/**
- *	ata_pci_bmdma_clear_simplex -	attempt to kick device out of simplex
- *	@pdev: PCI device
- *
- *	Some PCI ATA devices report simplex mode but in fact can be told to
- *	enter non simplex mode. This implements the necessary logic to
- *	perform the task on such devices. Calling it on other devices will
- *	have -undefined- behaviour.
- */
-int ata_pci_bmdma_clear_simplex(struct pci_dev *pdev)
+static int ata_resources_present(struct pci_dev *pdev, int port)
 {
-	unsigned long bmdma = pci_resource_start(pdev, 4);
-	u8 simplex;
-
-	if (bmdma == 0)
-		return -ENOENT;
+	int i;
 
-	simplex = inb(bmdma + 0x02);
-	outb(simplex & 0x60, bmdma + 0x02);
-	simplex = inb(bmdma + 0x02);
-	if (simplex & 0x80)
-		return -EOPNOTSUPP;
-	return 0;
+	/* Check the PCI resources for this channel are enabled */
+	port = port * 2;
+	for (i = 0; i < 2; i ++) {
+		if (pci_resource_start(pdev, port + i) == 0 ||
+		    pci_resource_len(pdev, port + i) == 0)
+			return 0;
+	}
+	return 1;
 }
-EXPORT_SYMBOL_GPL(ata_pci_bmdma_clear_simplex);
 
 /**
- *	ata_pci_bmdma_init - acquire PCI BMDMA resources and init ATA host
+ *	ata_pci_init_bmdma - acquire PCI BMDMA resources and init ATA host
  *	@host: target ATA host
  *
  *	Acquire PCI BMDMA resources and initialize @host accordingly.
@@ -2715,7 +570,7 @@
  *	RETURNS:
  *	0 on success, -errno otherwise.
  */
-int ata_pci_bmdma_init(struct ata_host *host)
+int ata_pci_init_bmdma(struct ata_host *host)
 {
 	struct device *gdev = host->dev;
 	struct pci_dev *pdev = to_pci_dev(gdev);
@@ -2734,7 +589,7 @@
 		return rc;
 
 	/* request and iomap DMA region */
-	rc = pcim_iomap_regions(pdev, 1 << 4, dev_driver_string(gdev));
+	rc = pcim_iomap_regions(pdev, 1 << 4, DRV_NAME);
 	if (rc) {
 		dev_printk(KERN_ERR, gdev, "failed to request/iomap BAR4\n");
 		return -ENOMEM;
@@ -2752,31 +607,13 @@
 		if ((!(ap->flags & ATA_FLAG_IGN_SIMPLEX)) &&
 		    (ioread8(bmdma + 2) & 0x80))
 			host->flags |= ATA_HOST_SIMPLEX;
-
-		ata_port_desc(ap, "bmdma 0x%llx",
-		    (unsigned long long)pci_resource_start(pdev, 4) + 8 * i);
 	}
 
 	return 0;
 }
-EXPORT_SYMBOL_GPL(ata_pci_bmdma_init);
-
-static int ata_resources_present(struct pci_dev *pdev, int port)
-{
-	int i;
-
-	/* Check the PCI resources for this channel are enabled */
-	port = port * 2;
-	for (i = 0; i < 2; i++) {
-		if (pci_resource_start(pdev, port + i) == 0 ||
-		    pci_resource_len(pdev, port + i) == 0)
-			return 0;
-	}
-	return 1;
-}
 
 /**
- *	ata_pci_sff_init_host - acquire native PCI ATA resources and init host
+ *	ata_pci_init_sff_host - acquire native PCI ATA resources and init host
  *	@host: target ATA host
  *
  *	Acquire native PCI ATA resources for @host and initialize the
@@ -2794,7 +631,7 @@
  *	0 if at least one port is initialized, -ENODEV if no port is
  *	available.
  */
-int ata_pci_sff_init_host(struct ata_host *host)
+int ata_pci_init_sff_host(struct ata_host *host)
 {
 	struct device *gdev = host->dev;
 	struct pci_dev *pdev = to_pci_dev(gdev);
@@ -2819,8 +656,7 @@
 			continue;
 		}
 
-		rc = pcim_iomap_regions(pdev, 0x3 << base,
-					dev_driver_string(gdev));
+		rc = pcim_iomap_regions(pdev, 0x3 << base, DRV_NAME);
 		if (rc) {
 			dev_printk(KERN_WARNING, gdev,
 				   "failed to request/iomap BARs for port %d "
@@ -2836,11 +672,7 @@
 		ap->ioaddr.altstatus_addr =
 		ap->ioaddr.ctl_addr = (void __iomem *)
 			((unsigned long)iomap[base + 1] | ATA_PCI_CTL_OFS);
-		ata_sff_std_ports(&ap->ioaddr);
-
-		ata_port_desc(ap, "cmd 0x%llx ctl 0x%llx",
-			(unsigned long long)pci_resource_start(pdev, base),
-			(unsigned long long)pci_resource_start(pdev, base + 1));
+		ata_std_ports(&ap->ioaddr);
 
 		mask |= 1 << i;
 	}
@@ -2852,10 +684,9 @@
 
 	return 0;
 }
-EXPORT_SYMBOL_GPL(ata_pci_sff_init_host);
 
 /**
- *	ata_pci_sff_prepare_host - helper to prepare native PCI ATA host
+ *	ata_pci_prepare_sff_host - helper to prepare native PCI ATA host
  *	@pdev: target PCI device
  *	@ppi: array of port_info, must be enough for two ports
  *	@r_host: out argument for the initialized ATA host
@@ -2869,8 +700,8 @@
  *	RETURNS:
  *	0 on success, -errno otherwise.
  */
-int ata_pci_sff_prepare_host(struct pci_dev *pdev,
-			     const struct ata_port_info * const *ppi,
+int ata_pci_prepare_sff_host(struct pci_dev *pdev,
+			     const struct ata_port_info * const * ppi,
 			     struct ata_host **r_host)
 {
 	struct ata_host *host;
@@ -2887,12 +718,12 @@
 		goto err_out;
 	}
 
-	rc = ata_pci_sff_init_host(host);
+	rc = ata_pci_init_sff_host(host);
 	if (rc)
 		goto err_out;
 
 	/* init DMA related stuff */
-	rc = ata_pci_bmdma_init(host);
+	rc = ata_pci_init_bmdma(host);
 	if (rc)
 		goto err_bmdma;
 
@@ -2900,119 +731,22 @@
 	*r_host = host;
 	return 0;
 
-err_bmdma:
+ err_bmdma:
 	/* This is necessary because PCI and iomap resources are
 	 * merged and releasing the top group won't release the
 	 * acquired resources if some of those have been acquired
 	 * before entering this function.
 	 */
 	pcim_iounmap_regions(pdev, 0xf);
-err_out:
+ err_out:
 	devres_release_group(&pdev->dev, NULL);
 	return rc;
 }
-EXPORT_SYMBOL_GPL(ata_pci_sff_prepare_host);
-
-/**
- *	ata_pci_sff_activate_host - start SFF host, request IRQ and register it
- *	@host: target SFF ATA host
- *	@irq_handler: irq_handler used when requesting IRQ(s)
- *	@sht: scsi_host_template to use when registering the host
- *
- *	This is the counterpart of ata_host_activate() for SFF ATA
- *	hosts.  This separate helper is necessary because SFF hosts
- *	use two separate interrupts in legacy mode.
- *
- *	LOCKING:
- *	Inherited from calling layer (may sleep).
- *
- *	RETURNS:
- *	0 on success, -errno otherwise.
- */
-int ata_pci_sff_activate_host(struct ata_host *host,
-			      irq_handler_t irq_handler,
-			      struct scsi_host_template *sht)
-{
-	struct device *dev = host->dev;
-	struct pci_dev *pdev = to_pci_dev(dev);
-	const char *drv_name = dev_driver_string(host->dev);
-	int legacy_mode = 0, rc;
-
-	rc = ata_host_start(host);
-	if (rc)
-		return rc;
-
-	if ((pdev->class >> 8) == PCI_CLASS_STORAGE_IDE) {
-		u8 tmp8, mask;
-
-		/* TODO: What if one channel is in native mode ... */
-		pci_read_config_byte(pdev, PCI_CLASS_PROG, &tmp8);
-		mask = (1 << 2) | (1 << 0);
-		if ((tmp8 & mask) != mask)
-			legacy_mode = 1;
-#if defined(CONFIG_NO_ATA_LEGACY)
-		/* Some platforms with PCI limits cannot address compat
-		   port space. In that case we punt if their firmware has
-		   left a device in compatibility mode */
-		if (legacy_mode) {
-			printk(KERN_ERR "ata: Compatibility mode ATA is not supported on this platform, skipping.\n");
-			return -EOPNOTSUPP;
-		}
-#endif
-	}
-
-	if (!devres_open_group(dev, NULL, GFP_KERNEL))
-		return -ENOMEM;
-
-	if (!legacy_mode && pdev->irq) {
-		rc = devm_request_irq(dev, pdev->irq, irq_handler,
-				      IRQF_SHARED, drv_name, host);
-		if (rc)
-			goto out;
-
-		ata_port_desc(host->ports[0], "irq %d", pdev->irq);
-		ata_port_desc(host->ports[1], "irq %d", pdev->irq);
-	} else if (legacy_mode) {
-		if (!ata_port_is_dummy(host->ports[0])) {
-			rc = devm_request_irq(dev, ATA_PRIMARY_IRQ(pdev),
-					      irq_handler, IRQF_SHARED,
-					      drv_name, host);
-			if (rc)
-				goto out;
-
-			ata_port_desc(host->ports[0], "irq %d",
-				      ATA_PRIMARY_IRQ(pdev));
-		}
-
-		if (!ata_port_is_dummy(host->ports[1])) {
-			rc = devm_request_irq(dev, ATA_SECONDARY_IRQ(pdev),
-					      irq_handler, IRQF_SHARED,
-					      drv_name, host);
-			if (rc)
-				goto out;
-
-			ata_port_desc(host->ports[1], "irq %d",
-				      ATA_SECONDARY_IRQ(pdev));
-		}
-	}
-
-	rc = ata_host_register(host, sht);
-out:
-	if (rc == 0)
-		devres_remove_group(dev, NULL);
-	else
-		devres_release_group(dev, NULL);
-
-	return rc;
-}
-EXPORT_SYMBOL_GPL(ata_pci_sff_activate_host);
 
 /**
- *	ata_pci_sff_init_one - Initialize/register PCI IDE host controller
+ *	ata_pci_init_one - Initialize/register PCI IDE host controller
  *	@pdev: Controller to be initialized
  *	@ppi: array of port_info, must be enough for two ports
- *	@sht: scsi_host_template to use when registering the host
- *	@host_priv: host private_data
  *
  *	This is a helper function which can be called from a driver's
  *	xxx_init_one() probe function if the hardware uses traditional
@@ -3032,13 +766,14 @@
  *	RETURNS:
  *	Zero on success, negative on errno-based value on error.
  */
-int ata_pci_sff_init_one(struct pci_dev *pdev,
-			 const struct ata_port_info * const *ppi,
-			 struct scsi_host_template *sht, void *host_priv)
+int ata_pci_init_one(struct pci_dev *pdev,
+		     const struct ata_port_info * const * ppi)
 {
 	struct device *dev = &pdev->dev;
 	const struct ata_port_info *pi = NULL;
 	struct ata_host *host = NULL;
+	u8 mask;
+	int legacy_mode = 0;
 	int i, rc;
 
 	DPRINTK("ENTER\n");
@@ -3060,26 +795,124 @@
 	if (!devres_open_group(dev, NULL, GFP_KERNEL))
 		return -ENOMEM;
 
+	/* FIXME: Really for ATA it isn't safe because the device may be
+	   multi-purpose and we want to leave it alone if it was already
+	   enabled. Secondly for shared use as Arjan says we want refcounting
+
+	   Checking dev->is_enabled is insufficient as this is not set at
+	   boot for the primary video which is BIOS enabled
+	  */
+
 	rc = pcim_enable_device(pdev);
 	if (rc)
-		goto out;
+		goto err_out;
+
+	if ((pdev->class >> 8) == PCI_CLASS_STORAGE_IDE) {
+		u8 tmp8;
+
+		/* TODO: What if one channel is in native mode ... */
+		pci_read_config_byte(pdev, PCI_CLASS_PROG, &tmp8);
+		mask = (1 << 2) | (1 << 0);
+		if ((tmp8 & mask) != mask)
+			legacy_mode = 1;
+#if defined(CONFIG_NO_ATA_LEGACY)
+		/* Some platforms with PCI limits cannot address compat
+		   port space. In that case we punt if their firmware has
+		   left a device in compatibility mode */
+		if (legacy_mode) {
+			printk(KERN_ERR "ata: Compatibility mode ATA is not supported on this platform, skipping.\n");
+			rc = -EOPNOTSUPP;
+			goto err_out;
+		}
+#endif
+	}
 
-	/* prepare and activate SFF host */
-	rc = ata_pci_sff_prepare_host(pdev, ppi, &host);
+	/* prepare host */
+	rc = ata_pci_prepare_sff_host(pdev, ppi, &host);
 	if (rc)
-		goto out;
-	host->private_data = host_priv;
+		goto err_out;
 
 	pci_set_master(pdev);
-	rc = ata_pci_sff_activate_host(host, ata_sff_interrupt, sht);
-out:
-	if (rc == 0)
-		devres_remove_group(&pdev->dev, NULL);
-	else
-		devres_release_group(&pdev->dev, NULL);
 
+	/* start host and request IRQ */
+	rc = ata_host_start(host);
+	if (rc)
+		goto err_out;
+
+	if (!legacy_mode) {
+		rc = devm_request_irq(dev, pdev->irq, pi->port_ops->irq_handler,
+				      IRQF_SHARED, DRV_NAME, host);
+		if (rc)
+			goto err_out;
+		host->irq = pdev->irq;
+	} else {
+		if (!ata_port_is_dummy(host->ports[0])) {
+			host->irq = ATA_PRIMARY_IRQ(pdev);
+			rc = devm_request_irq(dev, host->irq,
+					      pi->port_ops->irq_handler,
+					      IRQF_SHARED, DRV_NAME, host);
+			if (rc)
+				goto err_out;
+		}
+
+		if (!ata_port_is_dummy(host->ports[1])) {
+			host->irq2 = ATA_SECONDARY_IRQ(pdev);
+			rc = devm_request_irq(dev, host->irq2,
+					      pi->port_ops->irq_handler,
+					      IRQF_SHARED, DRV_NAME, host);
+			if (rc)
+				goto err_out;
+		}
+	}
+
+	/* register */
+	rc = ata_host_register(host, pi->sht);
+	if (rc)
+		goto err_out;
+
+	devres_remove_group(dev, NULL);
+	return 0;
+
+err_out:
+	devres_release_group(dev, NULL);
 	return rc;
 }
-EXPORT_SYMBOL_GPL(ata_pci_sff_init_one);
+
+/**
+ *	ata_pci_clear_simplex	-	attempt to kick device out of simplex
+ *	@pdev: PCI device
+ *
+ *	Some PCI ATA devices report simplex mode but in fact can be told to
+ *	enter non simplex mode. This implements the neccessary logic to
+ *	perform the task on such devices. Calling it on other devices will
+ *	have -undefined- behaviour.
+ */
+
+int ata_pci_clear_simplex(struct pci_dev *pdev)
+{
+	unsigned long bmdma = pci_resource_start(pdev, 4);
+	u8 simplex;
+
+	if (bmdma == 0)
+		return -ENOENT;
+
+	simplex = inb(bmdma + 0x02);
+	outb(simplex & 0x60, bmdma + 0x02);
+	simplex = inb(bmdma + 0x02);
+	if (simplex & 0x80)
+		return -EOPNOTSUPP;
+	return 0;
+}
+
+unsigned long ata_pci_default_filter(struct ata_device *adev, unsigned long xfer_mask)
+{
+	/* Filter out DMA modes if the device has been configured by
+	   the BIOS as PIO only */
+
+	if (adev->ap->ioaddr.bmdma_addr == 0)
+		xfer_mask &= ~(ATA_MASK_MWDMA | ATA_MASK_UDMA);
+	return xfer_mask;
+}
 
 #endif /* CONFIG_PCI */
+
diff -Nur linux-sh4/drivers/ata.org/Makefile linux-sh4/drivers/ata/Makefile
--- linux-sh4/drivers/ata.org/Makefile	2012-03-10 00:25:26.000000000 -0800
+++ linux-sh4/drivers/ata/Makefile	2012-01-15 06:30:15.000000000 -0800
@@ -17,21 +17,17 @@
 obj-$(CONFIG_SATA_MV)		+= sata_mv.o
 obj-$(CONFIG_SATA_INIC162X)	+= sata_inic162x.o
 obj-$(CONFIG_PDC_ADMA)		+= pdc_adma.o
-obj-$(CONFIG_SATA_FSL)		+= sata_fsl.o
 obj-$(CONFIG_SATA_STM)		+= sata_stm.o
 
 obj-$(CONFIG_PATA_ALI)		+= pata_ali.o
 obj-$(CONFIG_PATA_AMD)		+= pata_amd.o
 obj-$(CONFIG_PATA_ARTOP)	+= pata_artop.o
-obj-$(CONFIG_PATA_ATP867X)	+= pata_atp867x.o
-obj-$(CONFIG_PATA_AT32)		+= pata_at32.o
 obj-$(CONFIG_PATA_ATIIXP)	+= pata_atiixp.o
 obj-$(CONFIG_PATA_CMD640_PCI)	+= pata_cmd640.o
 obj-$(CONFIG_PATA_CMD64X)	+= pata_cmd64x.o
 obj-$(CONFIG_PATA_CS5520)	+= pata_cs5520.o
 obj-$(CONFIG_PATA_CS5530)	+= pata_cs5530.o
 obj-$(CONFIG_PATA_CS5535)	+= pata_cs5535.o
-obj-$(CONFIG_PATA_CS5536)	+= pata_cs5536.o
 obj-$(CONFIG_PATA_CYPRESS)	+= pata_cypress.o
 obj-$(CONFIG_PATA_EFAR)		+= pata_efar.o
 obj-$(CONFIG_PATA_HPT366)	+= pata_hpt366.o
@@ -43,23 +39,18 @@
 obj-$(CONFIG_PATA_IT8213)	+= pata_it8213.o
 obj-$(CONFIG_PATA_JMICRON)	+= pata_jmicron.o
 obj-$(CONFIG_PATA_NETCELL)	+= pata_netcell.o
-obj-$(CONFIG_PATA_NINJA32)	+= pata_ninja32.o
 obj-$(CONFIG_PATA_NS87410)	+= pata_ns87410.o
-obj-$(CONFIG_PATA_NS87415)	+= pata_ns87415.o
 obj-$(CONFIG_PATA_OPTI)		+= pata_opti.o
 obj-$(CONFIG_PATA_OPTIDMA)	+= pata_optidma.o
 obj-$(CONFIG_PATA_MPC52xx)	+= pata_mpc52xx.o
 obj-$(CONFIG_PATA_MARVELL)	+= pata_marvell.o
 obj-$(CONFIG_PATA_MPIIX)	+= pata_mpiix.o
 obj-$(CONFIG_PATA_OLDPIIX)	+= pata_oldpiix.o
-obj-$(CONFIG_PATA_PALMLD)	+= pata_palmld.o
 obj-$(CONFIG_PATA_PCMCIA)	+= pata_pcmcia.o
 obj-$(CONFIG_PATA_PDC2027X)	+= pata_pdc2027x.o
 obj-$(CONFIG_PATA_PDC_OLD)	+= pata_pdc202xx_old.o
 obj-$(CONFIG_PATA_QDI)		+= pata_qdi.o
 obj-$(CONFIG_PATA_RADISYS)	+= pata_radisys.o
-obj-$(CONFIG_PATA_RB532)	+= pata_rb532_cf.o
-obj-$(CONFIG_PATA_RDC)		+= pata_rdc.o
 obj-$(CONFIG_PATA_RZ1000)	+= pata_rz1000.o
 obj-$(CONFIG_PATA_SC1200)	+= pata_sc1200.o
 obj-$(CONFIG_PATA_SERVERWORKS)	+= pata_serverworks.o
@@ -71,21 +62,12 @@
 obj-$(CONFIG_PATA_TRIFLEX)	+= pata_triflex.o
 obj-$(CONFIG_PATA_IXP4XX_CF)	+= pata_ixp4xx_cf.o
 obj-$(CONFIG_PATA_SCC)		+= pata_scc.o
-obj-$(CONFIG_PATA_SCH)		+= pata_sch.o
-obj-$(CONFIG_PATA_BF54X)	+= pata_bf54x.o
-obj-$(CONFIG_PATA_OCTEON_CF)	+= pata_octeon_cf.o
 obj-$(CONFIG_PATA_PLATFORM)	+= pata_platform.o
-obj-$(CONFIG_PATA_AT91)	+= pata_at91.o
-obj-$(CONFIG_PATA_OF_PLATFORM)	+= pata_of_platform.o
 obj-$(CONFIG_PATA_ICSIDE)	+= pata_icside.o
-# Should be last but two libata driver
-obj-$(CONFIG_PATA_ACPI)		+= pata_acpi.o
 # Should be last but one libata driver
 obj-$(CONFIG_ATA_GENERIC)	+= ata_generic.o
 # Should be last libata driver
 obj-$(CONFIG_PATA_LEGACY)	+= pata_legacy.o
 
-libata-objs	:= libata-core.o libata-scsi.o libata-eh.o
-libata-$(CONFIG_ATA_SFF)	+= libata-sff.o
-libata-$(CONFIG_SATA_PMP)	+= libata-pmp.o
+libata-objs	:= libata-core.o libata-scsi.o libata-sff.o libata-eh.o
 libata-$(CONFIG_ATA_ACPI)	+= libata-acpi.o
diff -Nur linux-sh4/drivers/ata.org/pata_acpi.c linux-sh4/drivers/ata/pata_acpi.c
--- linux-sh4/drivers/ata.org/pata_acpi.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_acpi.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,299 +0,0 @@
-/*
- *	ACPI PATA driver
- *
- *	(c) 2007 Red Hat
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <linux/delay.h>
-#include <linux/device.h>
-#include <scsi/scsi_host.h>
-#include <acpi/acpi_bus.h>
-
-#include <linux/libata.h>
-#include <linux/ata.h>
-
-#define DRV_NAME	"pata_acpi"
-#define DRV_VERSION	"0.2.3"
-
-struct pata_acpi {
-	struct ata_acpi_gtm gtm;
-	void *last;
-	unsigned long mask[2];
-};
-
-/**
- *	pacpi_pre_reset	-	check for 40/80 pin
- *	@ap: Port
- *	@deadline: deadline jiffies for the operation
- *
- *	Perform the PATA port setup we need.
- */
-
-static int pacpi_pre_reset(struct ata_link *link, unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	struct pata_acpi *acpi = ap->private_data;
-	if (ap->acpi_handle == NULL || ata_acpi_gtm(ap, &acpi->gtm) < 0)
-		return -ENODEV;
-
-	return ata_sff_prereset(link, deadline);
-}
-
-/**
- *	pacpi_cable_detect	-	cable type detection
- *	@ap: port to detect
- *
- *	Perform device specific cable detection
- */
-
-static int pacpi_cable_detect(struct ata_port *ap)
-{
-	struct pata_acpi *acpi = ap->private_data;
-
-	if ((acpi->mask[0] | acpi->mask[1]) & (0xF8 << ATA_SHIFT_UDMA))
-		return ATA_CBL_PATA80;
-	else
-		return ATA_CBL_PATA40;
-}
-
-/**
- *	pacpi_discover_modes	-	filter non ACPI modes
- *	@adev: ATA device
- *	@mask: proposed modes
- *
- *	Try the modes available and see which ones the ACPI method will
- *	set up sensibly. From this we get a mask of ACPI modes we can use
- */
-
-static unsigned long pacpi_discover_modes(struct ata_port *ap, struct ata_device *adev)
-{
-	struct pata_acpi *acpi = ap->private_data;
-	struct ata_acpi_gtm probe;
-	unsigned int xfer_mask;
-
-	probe = acpi->gtm;
-
-	ata_acpi_gtm(ap, &probe);
-
-	xfer_mask = ata_acpi_gtm_xfermask(adev, &probe);
-
-	if (xfer_mask & (0xF8 << ATA_SHIFT_UDMA))
-		ap->cbl = ATA_CBL_PATA80;
-
-	return xfer_mask;
-}
-
-/**
- *	pacpi_mode_filter	-	mode filter for ACPI
- *	@adev: device
- *	@mask: mask of valid modes
- *
- *	Filter the valid mode list according to our own specific rules, in
- *	this case the list of discovered valid modes obtained by ACPI probing
- */
-
-static unsigned long pacpi_mode_filter(struct ata_device *adev, unsigned long mask)
-{
-	struct pata_acpi *acpi = adev->link->ap->private_data;
-	return ata_bmdma_mode_filter(adev, mask & acpi->mask[adev->devno]);
-}
-
-/**
- *	pacpi_set_piomode	-	set initial PIO mode data
- *	@ap: ATA interface
- *	@adev: ATA device
- */
-
-static void pacpi_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	int unit = adev->devno;
-	struct pata_acpi *acpi = ap->private_data;
-	const struct ata_timing *t;
-
-	if (!(acpi->gtm.flags & 0x10))
-		unit = 0;
-
-	/* Now stuff the nS values into the structure */
-	t = ata_timing_find_mode(adev->pio_mode);
-	acpi->gtm.drive[unit].pio = t->cycle;
-	ata_acpi_stm(ap, &acpi->gtm);
-	/* See what mode we actually got */
-	ata_acpi_gtm(ap, &acpi->gtm);
-}
-
-/**
- *	pacpi_set_dmamode	-	set initial DMA mode data
- *	@ap: ATA interface
- *	@adev: ATA device
- */
-
-static void pacpi_set_dmamode(struct ata_port *ap, struct ata_device *adev)
-{
-	int unit = adev->devno;
-	struct pata_acpi *acpi = ap->private_data;
-	const struct ata_timing *t;
-
-	if (!(acpi->gtm.flags & 0x10))
-		unit = 0;
-
-	/* Now stuff the nS values into the structure */
-	t = ata_timing_find_mode(adev->dma_mode);
-	if (adev->dma_mode >= XFER_UDMA_0) {
-		acpi->gtm.drive[unit].dma = t->udma;
-		acpi->gtm.flags |= (1 << (2 * unit));
-	} else {
-		acpi->gtm.drive[unit].dma = t->cycle;
-		acpi->gtm.flags &= ~(1 << (2 * unit));
-	}
-	ata_acpi_stm(ap, &acpi->gtm);
-	/* See what mode we actually got */
-	ata_acpi_gtm(ap, &acpi->gtm);
-}
-
-/**
- *	pacpi_qc_issue	-	command issue
- *	@qc: command pending
- *
- *	Called when the libata layer is about to issue a command. We wrap
- *	this interface so that we can load the correct ATA timings if
- *	neccessary.
- */
-
-static unsigned int pacpi_qc_issue(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct ata_device *adev = qc->dev;
-	struct pata_acpi *acpi = ap->private_data;
-
-	if (acpi->gtm.flags & 0x10)
-		return ata_sff_qc_issue(qc);
-
-	if (adev != acpi->last) {
-		pacpi_set_piomode(ap, adev);
-		if (ata_dma_enabled(adev))
-			pacpi_set_dmamode(ap, adev);
-		acpi->last = adev;
-	}
-	return ata_sff_qc_issue(qc);
-}
-
-/**
- *	pacpi_port_start	-	port setup
- *	@ap: ATA port being set up
- *
- *	Use the port_start hook to maintain private control structures
- */
-
-static int pacpi_port_start(struct ata_port *ap)
-{
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	struct pata_acpi *acpi;
-
-	int ret;
-
-	if (ap->acpi_handle == NULL)
-		return -ENODEV;
-
-	acpi = ap->private_data = devm_kzalloc(&pdev->dev, sizeof(struct pata_acpi), GFP_KERNEL);
-	if (ap->private_data == NULL)
-		return -ENOMEM;
-	acpi->mask[0] = pacpi_discover_modes(ap, &ap->link.device[0]);
-	acpi->mask[1] = pacpi_discover_modes(ap, &ap->link.device[1]);
-	ret = ata_sff_port_start(ap);
-	if (ret < 0)
-		return ret;
-
-	return ret;
-}
-
-static struct scsi_host_template pacpi_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations pacpi_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.qc_issue		= pacpi_qc_issue,
-	.cable_detect		= pacpi_cable_detect,
-	.mode_filter		= pacpi_mode_filter,
-	.set_piomode		= pacpi_set_piomode,
-	.set_dmamode		= pacpi_set_dmamode,
-	.prereset		= pacpi_pre_reset,
-	.port_start		= pacpi_port_start,
-};
-
-
-/**
- *	pacpi_init_one - Register ACPI ATA PCI device with kernel services
- *	@pdev: PCI device to register
- *	@ent: Entry in pacpi_pci_tbl matching with @pdev
- *
- *	Called from kernel PCI layer.
- *
- *	LOCKING:
- *	Inherited from PCI layer (may sleep).
- *
- *	RETURNS:
- *	Zero on success, or -ERRNO value.
- */
-
-static int pacpi_init_one (struct pci_dev *pdev, const struct pci_device_id *id)
-{
-	static const struct ata_port_info info = {
-		.flags		= ATA_FLAG_SLAVE_POSS | ATA_FLAG_SRST,
-
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask 	= ATA_UDMA6,
-
-		.port_ops	= &pacpi_ops,
-	};
-	const struct ata_port_info *ppi[] = { &info, NULL };
-	if (pdev->vendor == PCI_VENDOR_ID_ATI) {
-		int rc = pcim_enable_device(pdev);
-		if (rc < 0)
-			return rc;
-		pcim_pin_device(pdev);
-	}
-	return ata_pci_sff_init_one(pdev, ppi, &pacpi_sht, NULL);
-}
-
-static const struct pci_device_id pacpi_pci_tbl[] = {
-	{ PCI_ANY_ID,		PCI_ANY_ID,			   PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_STORAGE_IDE << 8, 0xFFFFFF00UL, 1},
-	{ }	/* terminate list */
-};
-
-static struct pci_driver pacpi_pci_driver = {
-	.name			= DRV_NAME,
-	.id_table		= pacpi_pci_tbl,
-	.probe			= pacpi_init_one,
-	.remove			= ata_pci_remove_one,
-#ifdef CONFIG_PM
-	.suspend		= ata_pci_device_suspend,
-	.resume			= ata_pci_device_resume,
-#endif
-};
-
-static int __init pacpi_init(void)
-{
-	return pci_register_driver(&pacpi_pci_driver);
-}
-
-static void __exit pacpi_exit(void)
-{
-	pci_unregister_driver(&pacpi_pci_driver);
-}
-
-module_init(pacpi_init);
-module_exit(pacpi_exit);
-
-MODULE_AUTHOR("Alan Cox");
-MODULE_DESCRIPTION("SCSI low-level driver for ATA in ACPI mode");
-MODULE_LICENSE("GPL");
-MODULE_DEVICE_TABLE(pci, pacpi_pci_tbl);
-MODULE_VERSION(DRV_VERSION);
-
diff -Nur linux-sh4/drivers/ata.org/pata_ali.c linux-sh4/drivers/ata/pata_ali.c
--- linux-sh4/drivers/ata.org/pata_ali.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_ali.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_ali.c 	- ALI 15x3 PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  * based in part upon
  * linux/drivers/ide/pci/alim15x3.c		Version 0.17	2003/01/02
@@ -19,9 +20,7 @@
  *
  *  TODO/CHECK
  *	Cannot have ATAPI on both master & slave for rev < c2 (???) but
- *	otherwise should do atapi DMA (For now for old we do PIO only for
- *	ATAPI)
- *	Review Sunblade workaround.
+ *	otherwise should do atapi DMA.
  */
 
 #include <linux/kernel.h>
@@ -35,19 +34,13 @@
 #include <linux/dmi.h>
 
 #define DRV_NAME "pata_ali"
-#define DRV_VERSION "0.7.8"
-
-static int ali_atapi_dma = 0;
-module_param_named(atapi_dma, ali_atapi_dma, int, 0644);
-MODULE_PARM_DESC(atapi_dma, "Enable ATAPI DMA (0=disable, 1=enable)");
-
-static struct pci_dev *ali_isa_bridge;
+#define DRV_VERSION "0.7.5"
 
 /*
  *	Cable special cases
  */
 
-static const struct dmi_system_id cable_dmi_table[] = {
+static struct dmi_system_id cable_dmi_table[] = {
 	{
 		.ident = "HP Pavilion N5430",
 		.matches = {
@@ -70,9 +63,6 @@
 	/* Fujitsu P2000 */
 	if (pdev->subsystem_vendor == 0x10CF && pdev->subsystem_device == 0x10AF)
 	   	return 1;
-	/* Mitac 8317 (Winbook-A) and relatives */
-	if (pdev->subsystem_vendor == 0x1071 && pdev->subsystem_device == 0x8317)
-		return 1;
 	/* Systems by DMI */
 	if (dmi_check_system(cable_dmi_table))
 		return 1;
@@ -124,7 +114,7 @@
 	ata_id_c_string(adev->id, model_num, ATA_ID_PROD, sizeof(model_num));
 	if (strstr(model_num, "WDC"))
 		return mask &= ~ATA_MASK_UDMA;
-	return ata_bmdma_mode_filter(adev, mask);
+	return ata_pci_default_filter(adev, mask);
 }
 
 /**
@@ -151,7 +141,8 @@
 
 	pci_read_config_byte(pdev, pio_fifo, &fifo);
 	fifo &= ~(0x0F << shift);
-	fifo |= (on << shift);
+	if (on)
+		fifo |= (on << shift);
 	pci_write_config_byte(pdev, pio_fifo, fifo);
 }
 
@@ -179,11 +170,11 @@
 	u8 udma;
 
 	if (t != NULL) {
-		t->setup = clamp_val(t->setup, 1, 8) & 7;
-		t->act8b = clamp_val(t->act8b, 1, 8) & 7;
-		t->rec8b = clamp_val(t->rec8b, 1, 16) & 15;
-		t->active = clamp_val(t->active, 1, 8) & 7;
-		t->recover = clamp_val(t->recover, 1, 16) & 15;
+		t->setup = FIT(t->setup, 1, 8) & 7;
+		t->act8b = FIT(t->act8b, 1, 8) & 7;
+		t->rec8b = FIT(t->rec8b, 1, 16) & 15;
+		t->active = FIT(t->active, 1, 8) & 7;
+		t->recover = FIT(t->recover, 1, 16) & 15;
 
 		pci_write_config_byte(pdev, cas, t->setup);
 		pci_write_config_byte(pdev, cbt, (t->act8b << 4) | t->rec8b);
@@ -276,27 +267,6 @@
 }
 
 /**
- *	ali_warn_atapi_dma	-	Warn about ATAPI DMA disablement
- *	@adev: Device
- *
- *	Whine about ATAPI DMA disablement if @adev is an ATAPI device.
- *	Can be used as ->dev_config.
- */
-
-static void ali_warn_atapi_dma(struct ata_device *adev)
-{
-	struct ata_eh_context *ehc = &adev->link->eh_context;
-	int print_info = ehc->i.flags & ATA_EHI_PRINTINFO;
-
-	if (print_info && adev->class == ATA_DEV_ATAPI && !ali_atapi_dma) {
-		ata_dev_printk(adev, KERN_WARNING,
-			       "WARNING: ATAPI DMA disabled for reliability issues.  It can be enabled\n");
-		ata_dev_printk(adev, KERN_WARNING,
-			       "WARNING: via pata_ali.atapi_dma modparam or corresponding sysfs node.\n");
-	}
-}
-
-/**
  *	ali_lock_sectors	-	Keep older devices to 255 sector mode
  *	@adev: Device
  *
@@ -310,55 +280,24 @@
 static void ali_lock_sectors(struct ata_device *adev)
 {
 	adev->max_sectors = 255;
-	ali_warn_atapi_dma(adev);
-}
-
-/**
- *	ali_check_atapi_dma	-	DMA check for most ALi controllers
- *	@adev: Device
- *
- *	Called to decide whether commands should be sent by DMA or PIO
- */
-
-static int ali_check_atapi_dma(struct ata_queued_cmd *qc)
-{
-	if (!ali_atapi_dma) {
-		/* FIXME: pata_ali can't do ATAPI DMA reliably but the
-		 * IDE alim15x3 driver can.  I tried lots of things
-		 * but couldn't find what the actual difference was.
-		 * If you got an idea, please write it to
-		 * linux-ide@vger.kernel.org and cc htejun@gmail.com.
-		 *
-		 * Disable ATAPI DMA for now.
-		 */
-		return -EOPNOTSUPP;
-	}
-
-	/* If its not a media command, its not worth it */
-	if (atapi_cmd_type(qc->cdb[0]) == ATAPI_MISC)
-		return -EOPNOTSUPP;
-	return 0;
-}
-
-static void ali_c2_c3_postreset(struct ata_link *link, unsigned int *classes)
-{
-	u8 r;
-	int port_bit = 4 << link->ap->port_no;
-
-	/* If our bridge is an ALI 1533 then do the extra work */
-	if (ali_isa_bridge) {
-		/* Tristate and re-enable the bus signals */
-		pci_read_config_byte(ali_isa_bridge, 0x58, &r);
-		r &= ~port_bit;
-		pci_write_config_byte(ali_isa_bridge, 0x58, r);
-		r |= port_bit;
-		pci_write_config_byte(ali_isa_bridge, 0x58, r);
-	}
-	ata_sff_postreset(link, classes);
 }
 
 static struct scsi_host_template ali_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 /*
@@ -366,16 +305,31 @@
  */
 
 static struct ata_port_operations ali_early_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= ali_set_piomode,
-	.sff_data_xfer  = ata_sff_data_xfer32,
-};
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
 
-static const struct ata_port_operations ali_dma_base_ops = {
-	.inherits	= &ata_bmdma32_port_ops,
-	.set_piomode	= ali_set_piomode,
-	.set_dmamode	= ali_set_dmamode,
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
@@ -383,42 +337,118 @@
  *	detect
  */
 static struct ata_port_operations ali_20_port_ops = {
-	.inherits	= &ali_dma_base_ops,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
+
+	.set_piomode	= ali_set_piomode,
+	.set_dmamode	= ali_set_dmamode,
 	.mode_filter	= ali_20_filter,
-	.check_atapi_dma = ali_check_atapi_dma,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
 	.dev_config	= ali_lock_sectors,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
  *	Port operations for DMA capable ALi with cable detect
  */
 static struct ata_port_operations ali_c2_port_ops = {
-	.inherits	= &ali_dma_base_ops,
-	.check_atapi_dma = ali_check_atapi_dma,
-	.cable_detect	= ali_c2_cable_detect,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= ali_set_piomode,
+	.set_dmamode	= ali_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
 	.dev_config	= ali_lock_sectors,
-	.postreset	= ali_c2_c3_postreset,
-};
 
-/*
- *	Port operations for DMA capable ALi with cable detect
- */
-static struct ata_port_operations ali_c4_port_ops = {
-	.inherits	= &ali_dma_base_ops,
-	.check_atapi_dma = ali_check_atapi_dma,
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
 	.cable_detect	= ali_c2_cable_detect,
-	.dev_config	= ali_lock_sectors,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
  *	Port operations for DMA capable ALi with cable detect and LBA48
  */
 static struct ata_port_operations ali_c5_port_ops = {
-	.inherits	= &ali_dma_base_ops,
-	.check_atapi_dma = ali_check_atapi_dma,
-	.dev_config	= ali_warn_atapi_dma,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= ali_set_piomode,
+	.set_dmamode	= ali_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
 	.cable_detect	= ali_c2_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 
@@ -433,53 +463,54 @@
 static void ali_init_chipset(struct pci_dev *pdev)
 {
 	u8 tmp;
-	struct pci_dev *north;
+	struct pci_dev *north, *isa_bridge;
 
 	/*
 	 * The chipset revision selects the driver operations and
 	 * mode data.
 	 */
 
-	if (pdev->revision <= 0x20) {
-		pci_read_config_byte(pdev, 0x53, &tmp);
-		tmp |= 0x03;
-		pci_write_config_byte(pdev, 0x53, tmp);
-	} else {
-		pci_read_config_byte(pdev, 0x4a, &tmp);
-		pci_write_config_byte(pdev, 0x4a, tmp | 0x20);
+	if (pdev->revision >= 0x20 && pdev->revision < 0xC2) {
+		/* 1543-E/F, 1543C-C, 1543C-D, 1543C-E */
+		pci_read_config_byte(pdev, 0x4B, &tmp);
+		/* Clear CD-ROM DMA write bit */
+		tmp &= 0x7F;
+		pci_write_config_byte(pdev, 0x4B, tmp);
+	} else if (pdev->revision >= 0xC2) {
+		/* Enable cable detection logic */
 		pci_read_config_byte(pdev, 0x4B, &tmp);
-		if (pdev->revision < 0xC2)
-			/* 1543-E/F, 1543C-C, 1543C-D, 1543C-E */
-			/* Clear CD-ROM DMA write bit */
-			tmp &= 0x7F;
-		/* Cable and UDMA */
-		if (pdev->revision >= 0xc2)
-			tmp |= 0x01;
 		pci_write_config_byte(pdev, 0x4B, tmp | 0x08);
+	}
+	north = pci_get_bus_and_slot(0, PCI_DEVFN(0,0));
+	isa_bridge = pci_get_device(PCI_VENDOR_ID_AL, PCI_DEVICE_ID_AL_M1533, NULL);
+
+	if (north && north->vendor == PCI_VENDOR_ID_AL && isa_bridge) {
+		/* Configure the ALi bridge logic. For non ALi rely on BIOS.
+		   Set the south bridge enable bit */
+		pci_read_config_byte(isa_bridge, 0x79, &tmp);
+		if (pdev->revision == 0xC2)
+			pci_write_config_byte(isa_bridge, 0x79, tmp | 0x04);
+		else if (pdev->revision > 0xC2 && pdev->revision < 0xC5)
+			pci_write_config_byte(isa_bridge, 0x79, tmp | 0x02);
+	}
+	if (pdev->revision >= 0x20) {
 		/*
 		 * CD_ROM DMA on (0x53 bit 0). Enable this even if we want
 		 * to use PIO. 0x53 bit 1 (rev 20 only) - enable FIFO control
 		 * via 0x54/55.
 		 */
 		pci_read_config_byte(pdev, 0x53, &tmp);
+		if (pdev->revision <= 0x20)
+			tmp &= ~0x02;
 		if (pdev->revision >= 0xc7)
 			tmp |= 0x03;
 		else
 			tmp |= 0x01;	/* CD_ROM enable for DMA */
 		pci_write_config_byte(pdev, 0x53, tmp);
 	}
-	north = pci_get_bus_and_slot(0, PCI_DEVFN(0,0));
-	if (north && north->vendor == PCI_VENDOR_ID_AL && ali_isa_bridge) {
-		/* Configure the ALi bridge logic. For non ALi rely on BIOS.
-		   Set the south bridge enable bit */
-		pci_read_config_byte(ali_isa_bridge, 0x79, &tmp);
-		if (pdev->revision == 0xC2)
-			pci_write_config_byte(ali_isa_bridge, 0x79, tmp | 0x04);
-		else if (pdev->revision > 0xC2 && pdev->revision < 0xC5)
-			pci_write_config_byte(ali_isa_bridge, 0x79, tmp | 0x02);
-	}
+	pci_dev_put(isa_bridge);
 	pci_dev_put(north);
-	ata_pci_bmdma_clear_simplex(pdev);
+	ata_pci_clear_simplex(pdev);
 }
 /**
  *	ali_init_one		-	discovery callback
@@ -493,70 +524,68 @@
 static int ali_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info_early = {
+		.sht = &ali_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
+		.pio_mask = 0x1f,
 		.port_ops = &ali_early_port_ops
 	};
 	/* Revision 0x20 added DMA */
 	static const struct ata_port_info info_20 = {
-		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48 |
-							ATA_FLAG_IGN_SIMPLEX,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.sht = &ali_sht,
+		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.port_ops = &ali_20_port_ops
 	};
 	/* Revision 0x20 with support logic added UDMA */
 	static const struct ata_port_info info_20_udma = {
-		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48 |
-							ATA_FLAG_IGN_SIMPLEX,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA2,
+		.sht = &ali_sht,
+		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
+		.udma_mask = 0x07,	/* UDMA33 */
 		.port_ops = &ali_20_port_ops
 	};
 	/* Revision 0xC2 adds UDMA66 */
 	static const struct ata_port_info info_c2 = {
-		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48 |
-							ATA_FLAG_IGN_SIMPLEX,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.sht = &ali_sht,
+		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA4,
 		.port_ops = &ali_c2_port_ops
 	};
 	/* Revision 0xC3 is UDMA66 for now */
 	static const struct ata_port_info info_c3 = {
-		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48 |
-							ATA_FLAG_IGN_SIMPLEX,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.sht = &ali_sht,
+		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA4,
 		.port_ops = &ali_c2_port_ops
 	};
 	/* Revision 0xC4 is UDMA100 */
 	static const struct ata_port_info info_c4 = {
-		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48 |
-							ATA_FLAG_IGN_SIMPLEX,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.sht = &ali_sht,
+		.flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_PIO_LBA48,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA5,
-		.port_ops = &ali_c4_port_ops
+		.port_ops = &ali_c2_port_ops
 	};
 	/* Revision 0xC5 is UDMA133 with LBA48 DMA */
 	static const struct ata_port_info info_c5 = {
-		.flags = ATA_FLAG_SLAVE_POSS | 	ATA_FLAG_IGN_SIMPLEX,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.sht = &ali_sht,
+		.flags = ATA_FLAG_SLAVE_POSS,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA6,
 		.port_ops = &ali_c5_port_ops
 	};
 
 	const struct ata_port_info *ppi[] = { NULL, NULL };
 	u8 tmp;
-	int rc;
-
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
+	struct pci_dev *isa_bridge;
 
 	/*
 	 * The chipset revision selects the driver operations and
@@ -578,28 +607,22 @@
 
 	ali_init_chipset(pdev);
 
-	if (ali_isa_bridge && pdev->revision >= 0x20 && pdev->revision < 0xC2) {
+	isa_bridge = pci_get_device(PCI_VENDOR_ID_AL, PCI_DEVICE_ID_AL_M1533, NULL);
+	if (isa_bridge && pdev->revision >= 0x20 && pdev->revision < 0xC2) {
 		/* Are we paired with a UDMA capable chip */
-		pci_read_config_byte(ali_isa_bridge, 0x5E, &tmp);
+		pci_read_config_byte(isa_bridge, 0x5E, &tmp);
 		if ((tmp & 0x1E) == 0x12)
 	        	ppi[0] = &info_20_udma;
+		pci_dev_put(isa_bridge);
 	}
-
-	return ata_pci_sff_init_one(pdev, ppi, &ali_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 #ifdef CONFIG_PM
 static int ali_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
 	ali_init_chipset(pdev);
-	ata_host_resume(host);
-	return 0;
+	return ata_pci_device_resume(pdev);
 }
 #endif
 
@@ -623,20 +646,13 @@
 
 static int __init ali_init(void)
 {
-	int ret;
-	ali_isa_bridge = pci_get_device(PCI_VENDOR_ID_AL, PCI_DEVICE_ID_AL_M1533, NULL);
-
-	ret = pci_register_driver(&ali_pci_driver);
-	if (ret < 0)
-		pci_dev_put(ali_isa_bridge);
-	return ret;
+	return pci_register_driver(&ali_pci_driver);
 }
 
 
 static void __exit ali_exit(void)
 {
 	pci_unregister_driver(&ali_pci_driver);
-	pci_dev_put(ali_isa_bridge);
 }
 
 
diff -Nur linux-sh4/drivers/ata.org/pata_amd.c linux-sh4/drivers/ata/pata_amd.c
--- linux-sh4/drivers/ata.org/pata_amd.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_amd.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_amd.c 	- AMD PATA for new ATA layer
  *			  (C) 2005-2006 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  *  Based on pata-sil680. Errata information is taken from data sheets
  *  and the amd74xx.c driver by Vojtech Pavlik. Nvidia SATA devices are
@@ -24,7 +25,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "pata_amd"
-#define DRV_VERSION "0.4.1"
+#define DRV_VERSION "0.3.9"
 
 /**
  *	timing_setup		-	shared timing computation and load
@@ -55,9 +56,7 @@
 	u8 t;
 
 	T = 1000000000 / amd_clock;
-	UT = T;
-	if (clock >= 2)
-		UT = T / 2;
+	UT = T / min_t(int, max_t(int, clock, 1), 2);
 
 	if (ata_timing_compute(adev, speed, &at, T, UT) < 0) {
 		dev_printk(KERN_ERR, &pdev->dev, "unknown mode %d.\n", speed);
@@ -83,32 +82,32 @@
 
 	/* Configure the address set up timing */
 	pci_read_config_byte(pdev, offset + 0x0C, &t);
-	t = (t & ~(3 << ((3 - dn) << 1))) | ((clamp_val(at.setup, 1, 4) - 1) << ((3 - dn) << 1));
+	t = (t & ~(3 << ((3 - dn) << 1))) | ((FIT(at.setup, 1, 4) - 1) << ((3 - dn) << 1));
 	pci_write_config_byte(pdev, offset + 0x0C , t);
 
 	/* Configure the 8bit I/O timing */
 	pci_write_config_byte(pdev, offset + 0x0E + (1 - (dn >> 1)),
-		((clamp_val(at.act8b, 1, 16) - 1) << 4) | (clamp_val(at.rec8b, 1, 16) - 1));
+		((FIT(at.act8b, 1, 16) - 1) << 4) | (FIT(at.rec8b, 1, 16) - 1));
 
 	/* Drive timing */
 	pci_write_config_byte(pdev, offset + 0x08 + (3 - dn),
-		((clamp_val(at.active, 1, 16) - 1) << 4) | (clamp_val(at.recover, 1, 16) - 1));
+		((FIT(at.active, 1, 16) - 1) << 4) | (FIT(at.recover, 1, 16) - 1));
 
 	switch (clock) {
 		case 1:
-		t = at.udma ? (0xc0 | (clamp_val(at.udma, 2, 5) - 2)) : 0x03;
+		t = at.udma ? (0xc0 | (FIT(at.udma, 2, 5) - 2)) : 0x03;
 		break;
 
 		case 2:
-		t = at.udma ? (0xc0 | amd_cyc2udma[clamp_val(at.udma, 2, 10)]) : 0x03;
+		t = at.udma ? (0xc0 | amd_cyc2udma[FIT(at.udma, 2, 10)]) : 0x03;
 		break;
 
 		case 3:
-		t = at.udma ? (0xc0 | amd_cyc2udma[clamp_val(at.udma, 1, 10)]) : 0x03;
+		t = at.udma ? (0xc0 | amd_cyc2udma[FIT(at.udma, 1, 10)]) : 0x03;
 		break;
 
 		case 4:
-		t = at.udma ? (0xc0 | amd_cyc2udma[clamp_val(at.udma, 1, 15)]) : 0x03;
+		t = at.udma ? (0xc0 | amd_cyc2udma[FIT(at.udma, 1, 15)]) : 0x03;
 		break;
 
 		default:
@@ -116,41 +115,39 @@
 	}
 
 	/* UDMA timing */
-	if (at.udma)
-		pci_write_config_byte(pdev, offset + 0x10 + (3 - dn), t);
+	pci_write_config_byte(pdev, offset + 0x10 + (3 - dn), t);
 }
 
 /**
- *	amd_pre_reset		-	perform reset handling
- *	@link: ATA link
+ *	amd_probe_init		-	perform reset handling
+ *	@ap: ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	Reset sequence checking enable bits to see which ports are
  *	active.
  */
 
-static int amd_pre_reset(struct ata_link *link, unsigned long deadline)
+static int amd_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits amd_enable_bits[] = {
 		{ 0x40, 1, 0x02, 0x02 },
 		{ 0x40, 1, 0x01, 0x01 }
 	};
 
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	if (!pci_test_config_bits(pdev, &amd_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
 }
 
-/**
- *	amd_cable_detect	-	report cable type
- *	@ap: port
- *
- *	AMD controller/BIOS setups record the cable type in word 0x42
- */
+static void amd_error_handler(struct ata_port *ap)
+{
+	return ata_bmdma_drive_eh(ap, amd_pre_reset,
+				      ata_std_softreset, NULL,
+				      ata_std_postreset);
+}
 
 static int amd_cable_detect(struct ata_port *ap)
 {
@@ -165,40 +162,6 @@
 }
 
 /**
- *	amd_fifo_setup		-	set the PIO FIFO for ATA/ATAPI
- *	@ap: ATA interface
- *	@adev: ATA device
- *
- *	Set the PCI fifo for this device according to the devices present
- *	on the bus at this point in time. We need to turn the post write buffer
- *	off for ATAPI devices as we may need to issue a word sized write to the
- *	device as the final I/O
- */
-
-static void amd_fifo_setup(struct ata_port *ap)
-{
-	struct ata_device *adev;
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	static const u8 fifobit[2] = { 0xC0, 0x30};
-	u8 fifo = fifobit[ap->port_no];
-	u8 r;
-
-
-	ata_for_each_dev(adev, &ap->link, ENABLED) {
-		if (adev->class == ATA_DEV_ATAPI)
-			fifo = 0;
-	}
-	if (pdev->device == PCI_DEVICE_ID_AMD_VIPER_7411) /* FIFO is broken */
-		fifo = 0;
-
-	/* On the later chips the read prefetch bits become no-op bits */
-	pci_read_config_byte(pdev, 0x41, &r);
-	r &= ~fifobit[ap->port_no];
-	r |= fifo;
-	pci_write_config_byte(pdev, 0x41, r);
-}
-
-/**
  *	amd33_set_piomode	-	set initial PIO mode data
  *	@ap: ATA interface
  *	@adev: ATA device
@@ -208,25 +171,21 @@
 
 static void amd33_set_piomode(struct ata_port *ap, struct ata_device *adev)
 {
-	amd_fifo_setup(ap);
 	timing_setup(ap, adev, 0x40, adev->pio_mode, 1);
 }
 
 static void amd66_set_piomode(struct ata_port *ap, struct ata_device *adev)
 {
-	amd_fifo_setup(ap);
 	timing_setup(ap, adev, 0x40, adev->pio_mode, 2);
 }
 
 static void amd100_set_piomode(struct ata_port *ap, struct ata_device *adev)
 {
-	amd_fifo_setup(ap);
 	timing_setup(ap, adev, 0x40, adev->pio_mode, 3);
 }
 
 static void amd133_set_piomode(struct ata_port *ap, struct ata_device *adev)
 {
-	amd_fifo_setup(ap);
 	timing_setup(ap, adev, 0x40, adev->pio_mode, 4);
 }
 
@@ -259,88 +218,57 @@
 	timing_setup(ap, adev, 0x40, adev->dma_mode, 4);
 }
 
-/* Both host-side and drive-side detection results are worthless on NV
- * PATAs.  Ignore them and just follow what BIOS configured.  Both the
- * current configuration in PCI config reg and ACPI GTM result are
- * cached during driver attach and are consulted to select transfer
- * mode.
- */
-static unsigned long nv_mode_filter(struct ata_device *dev,
-				    unsigned long xfer_mask)
-{
-	static const unsigned int udma_mask_map[] =
-		{ ATA_UDMA2, ATA_UDMA1, ATA_UDMA0, 0,
-		  ATA_UDMA3, ATA_UDMA4, ATA_UDMA5, ATA_UDMA6 };
-	struct ata_port *ap = dev->link->ap;
-	char acpi_str[32] = "";
-	u32 saved_udma, udma;
-	const struct ata_acpi_gtm *gtm;
-	unsigned long bios_limit = 0, acpi_limit = 0, limit;
-
-	/* find out what BIOS configured */
-	udma = saved_udma = (unsigned long)ap->host->private_data;
-
-	if (ap->port_no == 0)
-		udma >>= 16;
-	if (dev->devno == 0)
-		udma >>= 8;
-
-	if ((udma & 0xc0) == 0xc0)
-		bios_limit = ata_pack_xfermask(0, 0, udma_mask_map[udma & 0x7]);
-
-	/* consult ACPI GTM too */
-	gtm = ata_acpi_init_gtm(ap);
-	if (gtm) {
-		acpi_limit = ata_acpi_gtm_xfermask(dev, gtm);
-
-		snprintf(acpi_str, sizeof(acpi_str), " (%u:%u:0x%x)",
-			 gtm->drive[0].dma, gtm->drive[1].dma, gtm->flags);
-	}
-
-	/* be optimistic, EH can take care of things if something goes wrong */
-	limit = bios_limit | acpi_limit;
-
-	/* If PIO or DMA isn't configured at all, don't limit.  Let EH
-	 * handle it.
-	 */
-	if (!(limit & ATA_MASK_PIO))
-		limit |= ATA_MASK_PIO;
-	if (!(limit & (ATA_MASK_MWDMA | ATA_MASK_UDMA)))
-		limit |= ATA_MASK_MWDMA | ATA_MASK_UDMA;
-	/* PIO4, MWDMA2, UDMA2 should always be supported regardless of
-	   cable detection result */
-	limit |= ata_pack_xfermask(ATA_PIO4, ATA_MWDMA2, ATA_UDMA2);
-
-	ata_port_printk(ap, KERN_DEBUG, "nv_mode_filter: 0x%lx&0x%lx->0x%lx, "
-			"BIOS=0x%lx (0x%x) ACPI=0x%lx%s\n",
-			xfer_mask, limit, xfer_mask & limit, bios_limit,
-			saved_udma, acpi_limit, acpi_str);
-
-	return xfer_mask & limit;
-}
 
 /**
  *	nv_probe_init	-	cable detection
- *	@lin: ATA link
+ *	@ap: ATA port
  *
  *	Perform cable detection. The BIOS stores this in PCI config
  *	space for us.
  */
 
-static int nv_pre_reset(struct ata_link *link, unsigned long deadline)
+static int nv_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits nv_enable_bits[] = {
 		{ 0x50, 1, 0x02, 0x02 },
 		{ 0x50, 1, 0x01, 0x01 }
 	};
 
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	if (!pci_test_config_bits(pdev, &nv_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+static void nv_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, nv_pre_reset,
+			       ata_std_softreset, NULL,
+			       ata_std_postreset);
+}
+
+static int nv_cable_detect(struct ata_port *ap)
+{
+	static const u8 bitmask[2] = {0x03, 0x0C};
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	u8 ata66;
+	u16 udma;
+	int cbl;
+
+	pci_read_config_byte(pdev, 0x52, &ata66);
+	if (ata66 & bitmask[ap->port_no])
+		cbl = ATA_CBL_PATA80;
+	else
+		cbl = ATA_CBL_PATA40;
+
+ 	/* We now have to double check because the Nvidia boxes BIOS
+ 	   doesn't always set the cable bits but does set mode bits */
+ 	pci_read_config_word(pdev, 0x62 - 2 * ap->port_no, &udma);
+ 	if ((udma & 0xC4) == 0xC4 || (udma & 0xC400) == 0xC400)
+		cbl = ATA_CBL_PATA80;
+	return cbl;
 }
 
 /**
@@ -380,221 +308,368 @@
 	timing_setup(ap, adev, 0x50, adev->dma_mode, 4);
 }
 
-static void nv_host_stop(struct ata_host *host)
-{
-	u32 udma = (unsigned long)host->private_data;
-
-	/* restore PCI config register 0x60 */
-	pci_write_config_dword(to_pci_dev(host->dev), 0x60, udma);
-}
-
 static struct scsi_host_template amd_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-static const struct ata_port_operations amd_base_port_ops = {
-	.inherits	= &ata_bmdma32_port_ops,
-	.prereset	= amd_pre_reset,
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations amd33_port_ops = {
-	.inherits	= &amd_base_port_ops,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= amd33_set_piomode,
 	.set_dmamode	= amd33_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= amd_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations amd66_port_ops = {
-	.inherits	= &amd_base_port_ops,
-	.cable_detect	= ata_cable_unknown,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= amd66_set_piomode,
 	.set_dmamode	= amd66_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= amd_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_unknown,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations amd100_port_ops = {
-	.inherits	= &amd_base_port_ops,
-	.cable_detect	= ata_cable_unknown,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= amd100_set_piomode,
 	.set_dmamode	= amd100_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= amd_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_unknown,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations amd133_port_ops = {
-	.inherits	= &amd_base_port_ops,
-	.cable_detect	= amd_cable_detect,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= amd133_set_piomode,
 	.set_dmamode	= amd133_set_dmamode,
-};
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= amd_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= amd_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
 
-static const struct ata_port_operations nv_base_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= ata_cable_ignore,
-	.mode_filter	= nv_mode_filter,
-	.prereset	= nv_pre_reset,
-	.host_stop	= nv_host_stop,
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations nv100_port_ops = {
-	.inherits	= &nv_base_port_ops,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= nv100_set_piomode,
 	.set_dmamode	= nv100_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= nv_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= nv_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations nv133_port_ops = {
-	.inherits	= &nv_base_port_ops,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= nv133_set_piomode,
 	.set_dmamode	= nv133_set_dmamode,
-};
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= nv_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= nv_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
 
-static void amd_clear_fifo(struct pci_dev *pdev)
-{
-	u8 fifo;
-	/* Disable the FIFO, the FIFO logic will re-enable it as
-	   appropriate */
-	pci_read_config_byte(pdev, 0x41, &fifo);
-	fifo &= 0x0F;
-	pci_write_config_byte(pdev, 0x41, fifo);
-}
+	.port_start	= ata_port_start,
+};
 
 static int amd_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info[10] = {
-		{	/* 0: AMD 7401 - no swdma */
+		{	/* 0: AMD 7401 */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,	/* No SWDMA */
+			.udma_mask = 0x07,	/* UDMA 33 */
 			.port_ops = &amd33_port_ops
 		},
 		{	/* 1: Early AMD7409 - no swdma */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA4,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA4,	/* UDMA 66 */
 			.port_ops = &amd66_port_ops
 		},
-		{	/* 2: AMD 7409 */
+		{	/* 2: AMD 7409, no swdma errata */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA4,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA4,	/* UDMA 66 */
 			.port_ops = &amd66_port_ops
 		},
 		{	/* 3: AMD 7411 */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA5,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA5,	/* UDMA 100 */
 			.port_ops = &amd100_port_ops
 		},
 		{	/* 4: AMD 7441 */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA5,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA5,	/* UDMA 100 */
 			.port_ops = &amd100_port_ops
 		},
-		{	/* 5: AMD 8111 - no swdma */
+		{	/* 5: AMD 8111*/
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA6,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA6,	/* UDMA 133, no swdma */
 			.port_ops = &amd133_port_ops
 		},
-		{	/* 6: AMD 8111 UDMA 100 (Serenade) - no swdma */
+		{	/* 6: AMD 8111 UDMA 100 (Serenade) */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA5,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA5,	/* UDMA 100, no swdma */
 			.port_ops = &amd133_port_ops
 		},
 		{	/* 7: Nvidia Nforce */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA5,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA5,	/* UDMA 100 */
 			.port_ops = &nv100_port_ops
 		},
-		{	/* 8: Nvidia Nforce2 and later - no swdma */
+		{	/* 8: Nvidia Nforce2 and later */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA6,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA6,	/* UDMA 133, no swdma */
 			.port_ops = &nv133_port_ops
 		},
 		{	/* 9: AMD CS5536 (Geode companion) */
+			.sht = &amd_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA5,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = ATA_UDMA5,	/* UDMA 100 */
 			.port_ops = &amd100_port_ops
 		}
 	};
 	const struct ata_port_info *ppi[] = { NULL, NULL };
 	static int printed_version;
 	int type = id->driver_data;
-	void *hpriv = NULL;
 	u8 fifo;
-	int rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
 
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
 	pci_read_config_byte(pdev, 0x41, &fifo);
 
 	/* Check for AMD7409 without swdma errata and if found adjust type */
 	if (type == 1 && pdev->revision > 0x7)
 		type = 2;
 
+	/* Check for AMD7411 */
+	if (type == 3)
+		/* FIFO is broken */
+		pci_write_config_byte(pdev, 0x41, fifo & 0x0F);
+	else
+		pci_write_config_byte(pdev, 0x41, fifo | 0xF0);
+
 	/* Serenade ? */
 	if (type == 5 && pdev->subsystem_vendor == PCI_VENDOR_ID_AMD &&
 			 pdev->subsystem_device == PCI_DEVICE_ID_AMD_SERENADE)
 		type = 6;	/* UDMA 100 only */
 
-	/*
-	 * Okay, type is determined now.  Apply type-specific workarounds.
-	 */
-	ppi[0] = &info[type];
-
 	if (type < 3)
-		ata_pci_bmdma_clear_simplex(pdev);
-	if (pdev->vendor == PCI_VENDOR_ID_AMD)
-		amd_clear_fifo(pdev);
-	/* Cable detection on Nvidia chips doesn't work too well,
-	 * cache BIOS programmed UDMA mode.
-	 */
-	if (type == 7 || type == 8) {
-		u32 udma;
-
-		pci_read_config_dword(pdev, 0x60, &udma);
-		hpriv = (void *)(unsigned long)udma;
-	}
+		ata_pci_clear_simplex(pdev);
 
 	/* And fire it up */
-	return ata_pci_sff_init_one(pdev, ppi, &amd_sht, hpriv);
+	ppi[0] = &info[type];
+	return ata_pci_init_one(pdev, ppi);
 }
 
 #ifdef CONFIG_PM
 static int amd_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
-
 	if (pdev->vendor == PCI_VENDOR_ID_AMD) {
-		amd_clear_fifo(pdev);
+		u8 fifo;
+		pci_read_config_byte(pdev, 0x41, &fifo);
+		if (pdev->device == PCI_DEVICE_ID_AMD_VIPER_7411)
+			/* FIFO is broken */
+			pci_write_config_byte(pdev, 0x41, fifo & 0x0F);
+		else
+			pci_write_config_byte(pdev, 0x41, fifo | 0xF0);
 		if (pdev->device == PCI_DEVICE_ID_AMD_VIPER_7409 ||
 		    pdev->device == PCI_DEVICE_ID_AMD_COBRA_7401)
-			ata_pci_bmdma_clear_simplex(pdev);
+		    	ata_pci_clear_simplex(pdev);
 	}
-	ata_host_resume(host);
-	return 0;
+	return ata_pci_device_resume(pdev);
 }
 #endif
 
@@ -645,7 +720,7 @@
 }
 
 MODULE_AUTHOR("Alan Cox");
-MODULE_DESCRIPTION("low-level driver for AMD and Nvidia PATA IDE");
+MODULE_DESCRIPTION("low-level driver for AMD PATA IDE");
 MODULE_LICENSE("GPL");
 MODULE_DEVICE_TABLE(pci, amd);
 MODULE_VERSION(DRV_VERSION);
diff -Nur linux-sh4/drivers/ata.org/pata_artop.c linux-sh4/drivers/ata/pata_artop.c
--- linux-sh4/drivers/ata.org/pata_artop.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_artop.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  *    pata_artop.c - ARTOP ATA controller driver
  *
- *	(C) 2006 Red Hat
+ *	(C) 2006 Red Hat <alan@redhat.com>
  *	(C) 2007 Bartlomiej Zolnierkiewicz
  *
  *    Based in part on drivers/ide/pci/aec62xx.c
@@ -12,6 +12,7 @@
  *		performance Alessandro Zummo <alessandro.zummo@towertech.it>
  *
  *	TODO
+ *	850 serialization once the core supports it
  *	Investigate no_dsc on 850R
  *	Clock detect
  */
@@ -28,7 +29,7 @@
 #include <linux/ata.h>
 
 #define DRV_NAME	"pata_artop"
-#define DRV_VERSION	"0.4.5"
+#define DRV_VERSION	"0.4.4"
 
 /*
  *	The ARTOP has 33 Mhz and "over clocked" timing tables. Until we
@@ -39,9 +40,8 @@
 
 static int clock = 0;
 
-static int artop6210_pre_reset(struct ata_link *link, unsigned long deadline)
+static int artop6210_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	const struct pci_bits artop_enable_bits[] = {
 		{ 0x4AU, 1U, 0x02UL, 0x02UL },	/* port 0 */
@@ -51,33 +51,47 @@
 	if (!pci_test_config_bits(pdev, &artop_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	artop6210_error_handler - Probe specified port on PATA host controller
+ *	@ap: Port to probe
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void artop6210_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, artop6210_pre_reset,
+				    ata_std_softreset, NULL,
+				    ata_std_postreset);
 }
 
 /**
  *	artop6260_pre_reset	-	check for 40/80 pin
- *	@link: link
+ *	@ap: Port
  *	@deadline: deadline jiffies for the operation
  *
  *	The ARTOP hardware reports the cable detect bits in register 0x49.
  *	Nothing complicated needed here.
  */
 
-static int artop6260_pre_reset(struct ata_link *link, unsigned long deadline)
+static int artop6260_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits artop_enable_bits[] = {
 		{ 0x4AU, 1U, 0x02UL, 0x02UL },	/* port 0 */
 		{ 0x4AU, 1U, 0x04UL, 0x04UL },	/* port 1 */
 	};
 
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	/* Odd numbered device ids are the units with enable bits (the -R cards) */
 	if (pdev->device % 1 && !pci_test_config_bits(pdev, &artop_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
 }
 
 /**
@@ -98,6 +112,21 @@
 }
 
 /**
+ *	artop6260_error_handler - Probe specified port on PATA host controller
+ *	@ap: Port to probe
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void artop6260_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, artop6260_pre_reset,
+				    ata_std_softreset, NULL,
+				    ata_std_postreset);
+}
+
+/**
  *	artop6210_load_piomode - Load a set of PATA PIO timings
  *	@ap: Port whose timings we are configuring
  *	@adev: Device
@@ -282,50 +311,90 @@
 	pci_write_config_byte(pdev, 0x44 + ap->port_no, ultra);
 }
 
-/**
- *	artop_6210_qc_defer	-	implement serialization
- *	@qc: command
- *
- *	Issue commands per host on this chip.
- */
-
-static int artop6210_qc_defer(struct ata_queued_cmd *qc)
-{
-	struct ata_host *host = qc->ap->host;
-	struct ata_port *alt = host->ports[1 ^ qc->ap->port_no];
-	int rc;
-
-	/* First apply the usual rules */
-	rc = ata_std_qc_defer(qc);
-	if (rc != 0)
-		return rc;
-
-	/* Now apply serialization rules. Only allow a command if the
-	   other channel state machine is idle */
-	if (alt && alt->qc_active)
-		return	ATA_DEFER_PORT;
-	return 0;
-}
-
 static struct scsi_host_template artop_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations artop6210_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.cable_detect		= ata_cable_40wire,
+static const struct ata_port_operations artop6210_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= artop6210_set_piomode,
 	.set_dmamode		= artop6210_set_dmamode,
-	.prereset		= artop6210_pre_reset,
-	.qc_defer		= artop6210_qc_defer,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= artop6210_error_handler,
+	.post_internal_cmd 	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ata_cable_40wire,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations artop6260_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.cable_detect		= artop6260_cable_detect,
+static const struct ata_port_operations artop6260_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= artop6260_set_piomode,
 	.set_dmamode		= artop6260_set_dmamode,
-	.prereset		= artop6260_pre_reset,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= artop6260_error_handler,
+	.post_internal_cmd 	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= artop6260_cable_detect,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 
@@ -347,48 +416,51 @@
 {
 	static int printed_version;
 	static const struct ata_port_info info_6210 = {
+		.sht		= &artop_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask 	= ATA_UDMA2,
 		.port_ops	= &artop6210_ops,
 	};
 	static const struct ata_port_info info_626x = {
+		.sht		= &artop_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask 	= ATA_UDMA4,
 		.port_ops	= &artop6260_ops,
 	};
 	static const struct ata_port_info info_628x = {
+		.sht		= &artop_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask 	= ATA_UDMA5,
 		.port_ops	= &artop6260_ops,
 	};
 	static const struct ata_port_info info_628x_fast = {
+		.sht		= &artop_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask 	= ATA_UDMA6,
 		.port_ops	= &artop6260_ops,
 	};
 	const struct ata_port_info *ppi[] = { NULL, NULL };
-	int rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "version " DRV_VERSION "\n");
 
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
 	if (id->driver_data == 0) {	/* 6210 variant */
 		ppi[0] = &info_6210;
+		ppi[1] = &ata_dummy_port_info;
 		/* BIOS may have left us in UDMA, clear it before libata probe */
 		pci_write_config_byte(pdev, 0x54, 0);
+		/* For the moment (also lacks dsc) */
+		printk(KERN_WARNING "ARTOP 6210 requires serialize functionality not yet supported by libata.\n");
+		printk(KERN_WARNING "Secondary ATA ports will not be activated.\n");
 	}
 	else if (id->driver_data == 1)	/* 6260 */
 		ppi[0] = &info_626x;
@@ -421,7 +493,7 @@
 
 	BUG_ON(ppi[0] == NULL);
 
-	return ata_pci_sff_init_one(pdev, ppi, &artop_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id artop_pci_tbl[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_at32.c linux-sh4/drivers/ata/pata_at32.c
--- linux-sh4/drivers/ata.org/pata_at32.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_at32.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,411 +0,0 @@
-/*
- * AVR32 SMC/CFC PATA Driver
- *
- * Copyright (C) 2007 Atmel Norway
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License version
- * 2 as published by the Free Software Foundation.
- */
-
-#define DEBUG
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/device.h>
-#include <linux/platform_device.h>
-#include <linux/delay.h>
-#include <linux/interrupt.h>
-#include <linux/irq.h>
-#include <scsi/scsi_host.h>
-#include <linux/ata.h>
-#include <linux/libata.h>
-#include <linux/err.h>
-#include <linux/io.h>
-
-#include <mach/board.h>
-#include <mach/smc.h>
-
-#define DRV_NAME "pata_at32"
-#define DRV_VERSION "0.0.3"
-
-/*
- * CompactFlash controller memory layout relative to the base address:
- *
- *	Attribute memory:  0000 0000 -> 003f ffff
- *	Common memory:	   0040 0000 -> 007f ffff
- *	I/O memory:	   0080 0000 -> 00bf ffff
- *	True IDE Mode:	   00c0 0000 -> 00df ffff
- *	Alt IDE Mode:	   00e0 0000 -> 00ff ffff
- *
- * Only True IDE and Alt True IDE mode are needed for this driver.
- *
- *	True IDE mode	  => CS0 = 0, CS1 = 1 (cmd, error, stat, etc)
- *	Alt True IDE mode => CS0 = 1, CS1 = 0 (ctl, alt_stat)
- */
-#define CF_IDE_OFFSET	  0x00c00000
-#define CF_ALT_IDE_OFFSET 0x00e00000
-#define CF_RES_SIZE	  2048
-
-/*
- * Define DEBUG_BUS if you are doing debugging of your own EBI -> PATA
- * adaptor with a logic analyzer or similar.
- */
-#undef DEBUG_BUS
-
-/*
- * ATA PIO modes
- *
- *	Name	| Mb/s	| Min cycle time | Mask
- *	--------+-------+----------------+--------
- *	Mode 0	| 3.3	| 600 ns	 | 0x01
- *	Mode 1	| 5.2	| 383 ns	 | 0x03
- *	Mode 2	| 8.3	| 240 ns	 | 0x07
- *	Mode 3	| 11.1	| 180 ns	 | 0x0f
- *	Mode 4	| 16.7	| 120 ns	 | 0x1f
- *
- * Alter PIO_MASK below according to table to set maximal PIO mode.
- */
-enum {
-  PIO_MASK = ATA_PIO4,
-};
-
-/*
- * Struct containing private information about device.
- */
-struct at32_ide_info {
-	unsigned int		irq;
-	struct resource		res_ide;
-	struct resource		res_alt;
-	void __iomem		*ide_addr;
-	void __iomem		*alt_addr;
-	unsigned int		cs;
-	struct smc_config	smc;
-};
-
-/*
- * Setup SMC for the given ATA timing.
- */
-static int pata_at32_setup_timing(struct device *dev,
-				  struct at32_ide_info *info,
-				  const struct ata_timing *ata)
-{
-	struct smc_config *smc = &info->smc;
-	struct smc_timing timing;
-
-	int active;
-	int recover;
-
-	memset(&timing, 0, sizeof(struct smc_timing));
-
-	/* Total cycle time */
-	timing.read_cycle  = ata->cyc8b;
-
-	/* DIOR <= CFIOR timings */
-	timing.nrd_setup   = ata->setup;
-	timing.nrd_pulse   = ata->act8b;
-	timing.nrd_recover = ata->rec8b;
-
-	/* Convert nanosecond timing to clock cycles */
-	smc_set_timing(smc, &timing);
-
-	/* Add one extra cycle setup due to signal ring */
-	smc->nrd_setup = smc->nrd_setup + 1;
-
-	active  = smc->nrd_setup + smc->nrd_pulse;
-	recover = smc->read_cycle - active;
-
-	/* Need at least two cycles recovery */
-	if (recover < 2)
-	  smc->read_cycle = active + 2;
-
-	/* (CS0, CS1, DIR, OE) <= (CFCE1, CFCE2, CFRNW, NCSX) timings */
-	smc->ncs_read_setup = 1;
-	smc->ncs_read_pulse = smc->read_cycle - 2;
-
-	/* Write timings same as read timings */
-	smc->write_cycle = smc->read_cycle;
-	smc->nwe_setup = smc->nrd_setup;
-	smc->nwe_pulse = smc->nrd_pulse;
-	smc->ncs_write_setup = smc->ncs_read_setup;
-	smc->ncs_write_pulse = smc->ncs_read_pulse;
-
-	/* Do some debugging output of ATA and SMC timings */
-	dev_dbg(dev, "ATA: C=%d S=%d P=%d R=%d\n",
-		ata->cyc8b, ata->setup, ata->act8b, ata->rec8b);
-
-	dev_dbg(dev, "SMC: C=%d S=%d P=%d NS=%d NP=%d\n",
-		smc->read_cycle, smc->nrd_setup, smc->nrd_pulse,
-		smc->ncs_read_setup, smc->ncs_read_pulse);
-
-	/* Finally, configure the SMC */
-	return smc_set_configuration(info->cs, smc);
-}
-
-/*
- * Procedures for libATA.
- */
-static void pata_at32_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct ata_timing timing;
-	struct at32_ide_info *info = ap->host->private_data;
-
-	int ret;
-
-	/* Compute ATA timing */
-	ret = ata_timing_compute(adev, adev->pio_mode, &timing, 1000, 0);
-	if (ret) {
-		dev_warn(ap->dev, "Failed to compute ATA timing %d\n", ret);
-		return;
-	}
-
-	/* Setup SMC to ATA timing */
-	ret = pata_at32_setup_timing(ap->dev, info, &timing);
-	if (ret) {
-		dev_warn(ap->dev, "Failed to setup ATA timing %d\n", ret);
-		return;
-	}
-}
-
-static struct scsi_host_template at32_sht = {
-	ATA_PIO_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations at32_port_ops = {
-	.inherits		= &ata_sff_port_ops,
-	.cable_detect		= ata_cable_40wire,
-	.set_piomode		= pata_at32_set_piomode,
-};
-
-static int __init pata_at32_init_one(struct device *dev,
-				     struct at32_ide_info *info)
-{
-	struct ata_host *host;
-	struct ata_port *ap;
-
-	host = ata_host_alloc(dev, 1);
-	if (!host)
-		return -ENOMEM;
-
-	ap = host->ports[0];
-
-	/* Setup ATA bindings */
-	ap->ops	     = &at32_port_ops;
-	ap->pio_mask = PIO_MASK;
-	ap->flags   |= ATA_FLAG_MMIO | ATA_FLAG_SLAVE_POSS;
-
-	/*
-	 * Since all 8-bit taskfile transfers has to go on the lower
-	 * byte of the data bus and there is a bug in the SMC that
-	 * makes it impossible to alter the bus width during runtime,
-	 * we need to hardwire the address signals as follows:
-	 *
-	 *	A_IDE(2:0) <= A_EBI(3:1)
-	 *
-	 * This makes all addresses on the EBI even, thus all data
-	 * will be on the lower byte of the data bus.  All addresses
-	 * used by libATA need to be altered according to this.
-	 */
-	ap->ioaddr.altstatus_addr = info->alt_addr + (0x06 << 1);
-	ap->ioaddr.ctl_addr	  = info->alt_addr + (0x06 << 1);
-
-	ap->ioaddr.data_addr	  = info->ide_addr + (ATA_REG_DATA << 1);
-	ap->ioaddr.error_addr	  = info->ide_addr + (ATA_REG_ERR << 1);
-	ap->ioaddr.feature_addr	  = info->ide_addr + (ATA_REG_FEATURE << 1);
-	ap->ioaddr.nsect_addr	  = info->ide_addr + (ATA_REG_NSECT << 1);
-	ap->ioaddr.lbal_addr	  = info->ide_addr + (ATA_REG_LBAL << 1);
-	ap->ioaddr.lbam_addr	  = info->ide_addr + (ATA_REG_LBAM << 1);
-	ap->ioaddr.lbah_addr	  = info->ide_addr + (ATA_REG_LBAH << 1);
-	ap->ioaddr.device_addr	  = info->ide_addr + (ATA_REG_DEVICE << 1);
-	ap->ioaddr.status_addr	  = info->ide_addr + (ATA_REG_STATUS << 1);
-	ap->ioaddr.command_addr	  = info->ide_addr + (ATA_REG_CMD << 1);
-
-	/* Set info as private data of ATA host */
-	host->private_data = info;
-
-	/* Register ATA device and return */
-	return ata_host_activate(host, info->irq, ata_sff_interrupt,
-				 IRQF_SHARED | IRQF_TRIGGER_RISING,
-				 &at32_sht);
-}
-
-/*
- * This function may come in handy for people analyzing their own
- * EBI -> PATA adaptors.
- */
-#ifdef DEBUG_BUS
-
-static void __init pata_at32_debug_bus(struct device *dev,
-				       struct at32_ide_info *info)
-{
-	const int d1 = 0xff;
-	const int d2 = 0x00;
-
-	int i;
-
-	/* Write 8-bit values (registers) */
-	iowrite8(d1, info->alt_addr + (0x06 << 1));
-	iowrite8(d2, info->alt_addr + (0x06 << 1));
-
-	for (i = 0; i < 8; i++) {
-		iowrite8(d1, info->ide_addr + (i << 1));
-		iowrite8(d2, info->ide_addr + (i << 1));
-	}
-
-	/* Write 16 bit values (data) */
-	iowrite16(d1,	   info->ide_addr);
-	iowrite16(d1 << 8, info->ide_addr);
-
-	iowrite16(d1,	   info->ide_addr);
-	iowrite16(d1 << 8, info->ide_addr);
-}
-
-#endif
-
-static int __init pata_at32_probe(struct platform_device *pdev)
-{
-	const struct ata_timing initial_timing =
-		{XFER_PIO_0, 70, 290, 240, 600, 165, 150, 600, 0};
-
-	struct device		 *dev = &pdev->dev;
-	struct at32_ide_info	 *info;
-	struct ide_platform_data *board = pdev->dev.platform_data;
-	struct resource		 *res;
-
-	int irq;
-	int ret;
-
-	if (!board)
-		return -ENXIO;
-
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	if (!res)
-		return -ENXIO;
-
-	/* Retrive IRQ */
-	irq = platform_get_irq(pdev, 0);
-	if (irq < 0)
-		return irq;
-
-	/* Setup struct containing private information */
-	info = kzalloc(sizeof(struct at32_ide_info), GFP_KERNEL);
-	if (!info)
-		return -ENOMEM;
-
-	info->irq = irq;
-	info->cs  = board->cs;
-
-	/* Request memory resources */
-	info->res_ide.start = res->start + CF_IDE_OFFSET;
-	info->res_ide.end   = info->res_ide.start + CF_RES_SIZE - 1;
-	info->res_ide.name  = "ide";
-	info->res_ide.flags = IORESOURCE_MEM;
-
-	ret = request_resource(res, &info->res_ide);
-	if (ret)
-		goto err_req_res_ide;
-
-	info->res_alt.start = res->start + CF_ALT_IDE_OFFSET;
-	info->res_alt.end   = info->res_alt.start + CF_RES_SIZE - 1;
-	info->res_alt.name  = "alt";
-	info->res_alt.flags = IORESOURCE_MEM;
-
-	ret = request_resource(res, &info->res_alt);
-	if (ret)
-		goto err_req_res_alt;
-
-	/* Setup non-timing elements of SMC */
-	info->smc.bus_width	 = 2; /* 16 bit data bus */
-	info->smc.nrd_controlled = 1; /* Sample data on rising edge of NRD */
-	info->smc.nwe_controlled = 0; /* Drive data on falling edge of NCS */
-	info->smc.nwait_mode	 = 3; /* NWAIT is in READY mode */
-	info->smc.byte_write	 = 0; /* Byte select access type */
-	info->smc.tdf_mode	 = 0; /* TDF optimization disabled */
-	info->smc.tdf_cycles	 = 0; /* No TDF wait cycles */
-
-	/* Setup SMC to ATA timing */
-	ret = pata_at32_setup_timing(dev, info, &initial_timing);
-	if (ret)
-		goto err_setup_timing;
-
-	/* Map ATA address space */
-	ret = -ENOMEM;
-	info->ide_addr = devm_ioremap(dev, info->res_ide.start, 16);
-	info->alt_addr = devm_ioremap(dev, info->res_alt.start, 16);
-	if (!info->ide_addr || !info->alt_addr)
-		goto err_ioremap;
-
-#ifdef DEBUG_BUS
-	pata_at32_debug_bus(dev, info);
-#endif
-
-	/* Setup and register ATA device */
-	ret = pata_at32_init_one(dev, info);
-	if (ret)
-		goto err_ata_device;
-
-	return 0;
-
- err_ata_device:
- err_ioremap:
- err_setup_timing:
-	release_resource(&info->res_alt);
- err_req_res_alt:
-	release_resource(&info->res_ide);
- err_req_res_ide:
-	kfree(info);
-
-	return ret;
-}
-
-static int __exit pata_at32_remove(struct platform_device *pdev)
-{
-	struct ata_host *host = platform_get_drvdata(pdev);
-	struct at32_ide_info *info;
-
-	if (!host)
-		return 0;
-
-	info = host->private_data;
-	ata_host_detach(host);
-
-	if (!info)
-		return 0;
-
-	release_resource(&info->res_ide);
-	release_resource(&info->res_alt);
-
-	kfree(info);
-
-	return 0;
-}
-
-/* work with hotplug and coldplug */
-MODULE_ALIAS("platform:at32_ide");
-
-static struct platform_driver pata_at32_driver = {
-	.remove	       = __exit_p(pata_at32_remove),
-	.driver	       = {
-		.name  = "at32_ide",
-		.owner = THIS_MODULE,
-	},
-};
-
-static int __init pata_at32_init(void)
-{
-	return platform_driver_probe(&pata_at32_driver, pata_at32_probe);
-}
-
-static void __exit pata_at32_exit(void)
-{
-	platform_driver_unregister(&pata_at32_driver);
-}
-
-module_init(pata_at32_init);
-module_exit(pata_at32_exit);
-
-MODULE_LICENSE("GPL");
-MODULE_DESCRIPTION("AVR32 SMC/CFC PATA Driver");
-MODULE_AUTHOR("Kristoffer Nyborg Gregertsen <kngregertsen@norway.atmel.com>");
-MODULE_VERSION(DRV_VERSION);
diff -Nur linux-sh4/drivers/ata.org/pata_at91.c linux-sh4/drivers/ata/pata_at91.c
--- linux-sh4/drivers/ata.org/pata_at91.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_at91.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,358 +0,0 @@
-/*
- * PATA driver for AT91SAM9260 Static Memory Controller
- * with CompactFlash interface in True IDE mode
- *
- * Copyright (C) 2009 Matyukevich Sergey
- *
- * Based on:
- *      * generic platform driver by Paul Mundt: drivers/ata/pata_platform.c
- *      * pata_at32 driver by Kristoffer Nyborg Gregertsen
- *      * at91_ide driver by Stanislaw Gruszka
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <scsi/scsi_host.h>
-#include <linux/ata.h>
-#include <linux/clk.h>
-#include <linux/libata.h>
-#include <linux/platform_device.h>
-#include <linux/ata_platform.h>
-
-#include <mach/at91sam9_smc.h>
-#include <mach/board.h>
-#include <mach/gpio.h>
-
-
-#define DRV_NAME "pata_at91"
-#define DRV_VERSION "0.1"
-
-#define CF_IDE_OFFSET	    0x00c00000
-#define CF_ALT_IDE_OFFSET   0x00e00000
-#define CF_IDE_RES_SIZE     0x08
-
-struct at91_ide_info {
-	unsigned long mode;
-	unsigned int cs;
-
-	struct clk *mck;
-
-	void __iomem *ide_addr;
-	void __iomem *alt_addr;
-};
-
-static const struct ata_timing initial_timing =
-	{XFER_PIO_0, 70, 290, 240, 600, 165, 150, 600, 0};
-
-static unsigned long calc_mck_cycles(unsigned long ns, unsigned long mck_hz)
-{
-	unsigned long mul;
-
-	/*
-	* cycles = x [nsec] * f [Hz] / 10^9 [ns in sec] =
-	*     x * (f / 1_000_000_000) =
-	*     x * ((f * 65536) / 1_000_000_000) / 65536 =
-	*     x * (((f / 10_000) * 65536) / 100_000) / 65536 =
-	*/
-
-	mul = (mck_hz / 10000) << 16;
-	mul /= 100000;
-
-	return (ns * mul + 65536) >> 16;    /* rounding */
-}
-
-static void set_smc_mode(struct at91_ide_info *info)
-{
-	at91_sys_write(AT91_SMC_MODE(info->cs), info->mode);
-	return;
-}
-
-static void set_smc_timing(struct device *dev,
-		struct at91_ide_info *info, const struct ata_timing *ata)
-{
-	unsigned long read_cycle, write_cycle, active, recover;
-	unsigned long nrd_setup, nrd_pulse, nrd_recover;
-	unsigned long nwe_setup, nwe_pulse;
-
-	unsigned long ncs_write_setup, ncs_write_pulse;
-	unsigned long ncs_read_setup, ncs_read_pulse;
-
-	unsigned long mck_hz;
-
-	read_cycle  = ata->cyc8b;
-	nrd_setup   = ata->setup;
-	nrd_pulse   = ata->act8b;
-	nrd_recover = ata->rec8b;
-
-	mck_hz = clk_get_rate(info->mck);
-
-	read_cycle  = calc_mck_cycles(read_cycle, mck_hz);
-	nrd_setup   = calc_mck_cycles(nrd_setup, mck_hz);
-	nrd_pulse   = calc_mck_cycles(nrd_pulse, mck_hz);
-	nrd_recover = calc_mck_cycles(nrd_recover, mck_hz);
-
-	active  = nrd_setup + nrd_pulse;
-	recover = read_cycle - active;
-
-	/* Need at least two cycles recovery */
-	if (recover < 2)
-		read_cycle = active + 2;
-
-	/* (CS0, CS1, DIR, OE) <= (CFCE1, CFCE2, CFRNW, NCSX) timings */
-	ncs_read_setup = 1;
-	ncs_read_pulse = read_cycle - 2;
-
-	/* Write timings same as read timings */
-	write_cycle = read_cycle;
-	nwe_setup = nrd_setup;
-	nwe_pulse = nrd_pulse;
-	ncs_write_setup = ncs_read_setup;
-	ncs_write_pulse = ncs_read_pulse;
-
-	dev_dbg(dev, "ATA timings: nrd_setup = %lu nrd_pulse = %lu nrd_cycle = %lu\n",
-			nrd_setup, nrd_pulse, read_cycle);
-	dev_dbg(dev, "ATA timings: nwe_setup = %lu nwe_pulse = %lu nwe_cycle = %lu\n",
-			nwe_setup, nwe_pulse, write_cycle);
-	dev_dbg(dev, "ATA timings: ncs_read_setup = %lu ncs_read_pulse = %lu\n",
-			ncs_read_setup, ncs_read_pulse);
-	dev_dbg(dev, "ATA timings: ncs_write_setup = %lu ncs_write_pulse = %lu\n",
-			ncs_write_setup, ncs_write_pulse);
-
-	at91_sys_write(AT91_SMC_SETUP(info->cs),
-			AT91_SMC_NWESETUP_(nwe_setup) |
-			AT91_SMC_NRDSETUP_(nrd_setup) |
-			AT91_SMC_NCS_WRSETUP_(ncs_write_setup) |
-			AT91_SMC_NCS_RDSETUP_(ncs_read_setup));
-
-	at91_sys_write(AT91_SMC_PULSE(info->cs),
-			AT91_SMC_NWEPULSE_(nwe_pulse) |
-			AT91_SMC_NRDPULSE_(nrd_pulse) |
-			AT91_SMC_NCS_WRPULSE_(ncs_write_pulse) |
-			AT91_SMC_NCS_RDPULSE_(ncs_read_pulse));
-
-	at91_sys_write(AT91_SMC_CYCLE(info->cs),
-			AT91_SMC_NWECYCLE_(write_cycle) |
-			AT91_SMC_NRDCYCLE_(read_cycle));
-
-	return;
-}
-
-static void pata_at91_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct at91_ide_info *info = ap->host->private_data;
-	struct ata_timing timing;
-	int ret;
-
-	/* Compute ATA timing and set it to SMC */
-	ret = ata_timing_compute(adev, adev->pio_mode, &timing, 1000, 0);
-	if (ret) {
-		dev_warn(ap->dev, "Failed to compute ATA timing %d, \
-				set PIO_0 timing\n", ret);
-		set_smc_timing(ap->dev, info, &initial_timing);
-	} else {
-		set_smc_timing(ap->dev, info, &timing);
-	}
-
-	/* Setup SMC mode */
-	set_smc_mode(info);
-
-	return;
-}
-
-static unsigned int pata_at91_data_xfer_noirq(struct ata_device *dev,
-		unsigned char *buf, unsigned int buflen, int rw)
-{
-	struct at91_ide_info *info = dev->link->ap->host->private_data;
-	unsigned int consumed;
-	unsigned long flags;
-	unsigned int mode;
-
-	local_irq_save(flags);
-	mode = at91_sys_read(AT91_SMC_MODE(info->cs));
-
-	/* set 16bit mode before writing data */
-	at91_sys_write(AT91_SMC_MODE(info->cs),
-			(mode & ~AT91_SMC_DBW) | AT91_SMC_DBW_16);
-
-	consumed = ata_sff_data_xfer(dev, buf, buflen, rw);
-
-	/* restore 8bit mode after data is written */
-	at91_sys_write(AT91_SMC_MODE(info->cs),
-			(mode & ~AT91_SMC_DBW) | AT91_SMC_DBW_8);
-
-	local_irq_restore(flags);
-	return consumed;
-}
-
-static struct scsi_host_template pata_at91_sht = {
-	ATA_PIO_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations pata_at91_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-
-	.sff_data_xfer	= pata_at91_data_xfer_noirq,
-	.set_piomode	= pata_at91_set_piomode,
-	.cable_detect	= ata_cable_40wire,
-	.port_start	= ATA_OP_NULL,
-};
-
-static int __devinit pata_at91_probe(struct platform_device *pdev)
-{
-	struct at91_cf_data *board = pdev->dev.platform_data;
-	struct device *dev = &pdev->dev;
-	struct at91_ide_info *info;
-	struct resource *mem_res;
-	struct ata_host *host;
-	struct ata_port *ap;
-
-	int irq_flags = 0;
-	int irq = 0;
-	int ret;
-
-	/*  get platform resources: IO/CTL memories and irq/rst pins */
-
-	if (pdev->num_resources != 1) {
-		dev_err(&pdev->dev, "invalid number of resources\n");
-		return -EINVAL;
-	}
-
-	mem_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-
-	if (!mem_res) {
-		dev_err(dev, "failed to get mem resource\n");
-		return -EINVAL;
-	}
-
-	irq = board->irq_pin;
-
-	/* init ata host */
-
-	host = ata_host_alloc(dev, 1);
-
-	if (!host)
-		return -ENOMEM;
-
-	ap = host->ports[0];
-	ap->ops = &pata_at91_port_ops;
-	ap->flags |= ATA_FLAG_SLAVE_POSS;
-	ap->pio_mask = ATA_PIO4;
-
-	if (!irq) {
-		ap->flags |= ATA_FLAG_PIO_POLLING;
-		ata_port_desc(ap, "no IRQ, using PIO polling");
-	}
-
-	info = devm_kzalloc(dev, sizeof(*info), GFP_KERNEL);
-
-	if (!info) {
-		dev_err(dev, "failed to allocate memory for private data\n");
-		return -ENOMEM;
-	}
-
-	info->mck = clk_get(NULL, "mck");
-
-	if (IS_ERR(info->mck)) {
-		dev_err(dev, "failed to get access to mck clock\n");
-		return -ENODEV;
-	}
-
-	info->cs    = board->chipselect;
-	info->mode  = AT91_SMC_READMODE | AT91_SMC_WRITEMODE |
-		AT91_SMC_EXNWMODE_READY | AT91_SMC_BAT_SELECT |
-		AT91_SMC_DBW_8 | AT91_SMC_TDF_(0);
-
-	info->ide_addr = devm_ioremap(dev,
-			mem_res->start + CF_IDE_OFFSET, CF_IDE_RES_SIZE);
-
-	if (!info->ide_addr) {
-		dev_err(dev, "failed to map IO base\n");
-		ret = -ENOMEM;
-		goto err_put;
-	}
-
-	info->alt_addr = devm_ioremap(dev,
-			mem_res->start + CF_ALT_IDE_OFFSET, CF_IDE_RES_SIZE);
-
-	if (!info->alt_addr) {
-		dev_err(dev, "failed to map CTL base\n");
-		ret = -ENOMEM;
-		goto err_put;
-	}
-
-	ap->ioaddr.cmd_addr = info->ide_addr;
-	ap->ioaddr.ctl_addr = info->alt_addr + 0x06;
-	ap->ioaddr.altstatus_addr = ap->ioaddr.ctl_addr;
-
-	ata_sff_std_ports(&ap->ioaddr);
-
-	ata_port_desc(ap, "mmio cmd 0x%llx ctl 0x%llx",
-			(unsigned long long)mem_res->start + CF_IDE_OFFSET,
-			(unsigned long long)mem_res->start + CF_ALT_IDE_OFFSET);
-
-	host->private_data = info;
-
-	return ata_host_activate(host, irq ? gpio_to_irq(irq) : 0,
-			irq ? ata_sff_interrupt : NULL,
-			irq_flags, &pata_at91_sht);
-
-err_put:
-	clk_put(info->mck);
-	return ret;
-}
-
-static int __devexit pata_at91_remove(struct platform_device *pdev)
-{
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	struct at91_ide_info *info;
-
-	if (!host)
-		return 0;
-	info = host->private_data;
-
-	ata_host_detach(host);
-
-	if (!info)
-		return 0;
-
-	clk_put(info->mck);
-
-	return 0;
-}
-
-static struct platform_driver pata_at91_driver = {
-	.probe		= pata_at91_probe,
-	.remove		= __devexit_p(pata_at91_remove),
-	.driver 	= {
-		.name		= DRV_NAME,
-		.owner		= THIS_MODULE,
-	},
-};
-
-static int __init pata_at91_init(void)
-{
-	return platform_driver_register(&pata_at91_driver);
-}
-
-static void __exit pata_at91_exit(void)
-{
-	platform_driver_unregister(&pata_at91_driver);
-}
-
-
-module_init(pata_at91_init);
-module_exit(pata_at91_exit);
-
-
-MODULE_LICENSE("GPL");
-MODULE_DESCRIPTION("Driver for CF in True IDE mode on AT91SAM9260 SoC");
-MODULE_AUTHOR("Matyukevich Sergey");
-MODULE_VERSION(DRV_VERSION);
-
diff -Nur linux-sh4/drivers/ata.org/pata_atiixp.c linux-sh4/drivers/ata/pata_atiixp.c
--- linux-sh4/drivers/ata.org/pata_atiixp.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_atiixp.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  * pata_atiixp.c 	- ATI PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
- *			  (C) 2009 Bartlomiej Zolnierkiewicz
+ *			  Alan Cox <alan@redhat.com>
  *
  * Based on
  *
@@ -33,6 +33,25 @@
 	ATIIXP_IDE_UDMA_MODE 	= 0x56
 };
 
+static int atiixp_pre_reset(struct ata_port *ap, unsigned long deadline)
+{
+	static const struct pci_bits atiixp_enable_bits[] = {
+		{ 0x48, 1, 0x01, 0x00 },
+		{ 0x48, 1, 0x08, 0x00 }
+	};
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+
+	if (!pci_test_config_bits(pdev, &atiixp_enable_bits[ap->port_no]))
+		return -ENOENT;
+
+	return ata_std_prereset(ap, deadline);
+}
+
+static void atiixp_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, atiixp_pre_reset, ata_std_softreset, NULL,   ata_std_postreset);
+}
+
 static int atiixp_cable_detect(struct ata_port *ap)
 {
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
@@ -62,19 +81,20 @@
 
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	int dn = 2 * ap->port_no + adev->devno;
+
+	/* Check this is correct - the order is odd in both drivers */
 	int timing_shift = (16 * ap->port_no) + 8 * (adev->devno ^ 1);
-	u32 pio_timing_data;
-	u16 pio_mode_data;
+	u16 pio_mode_data, pio_timing_data;
 
 	pci_read_config_word(pdev, ATIIXP_IDE_PIO_MODE, &pio_mode_data);
 	pio_mode_data &= ~(0x7 << (4 * dn));
 	pio_mode_data |= pio << (4 * dn);
 	pci_write_config_word(pdev, ATIIXP_IDE_PIO_MODE, pio_mode_data);
 
-	pci_read_config_dword(pdev, ATIIXP_IDE_PIO_TIMING, &pio_timing_data);
-	pio_timing_data &= ~(0xFF << timing_shift);
-	pio_timing_data |= (pio_timings[pio] << timing_shift);
-	pci_write_config_dword(pdev, ATIIXP_IDE_PIO_TIMING, pio_timing_data);
+	pci_read_config_word(pdev, ATIIXP_IDE_PIO_TIMING, &pio_timing_data);
+	pio_mode_data &= ~(0xFF << timing_shift);
+	pio_mode_data |= (pio_timings[pio] << timing_shift);
+	pci_write_config_word(pdev, ATIIXP_IDE_PIO_TIMING, pio_timing_data);
 }
 
 /**
@@ -119,17 +139,16 @@
 		udma_mode_data |= dma << (4 * dn);
 		pci_write_config_word(pdev, ATIIXP_IDE_UDMA_MODE, udma_mode_data);
 	} else {
+		u16 mwdma_timing_data;
+		/* Check this is correct - the order is odd in both drivers */
 		int timing_shift = (16 * ap->port_no) + 8 * (adev->devno ^ 1);
-		u32 mwdma_timing_data;
 
 		dma -= XFER_MW_DMA_0;
 
-		pci_read_config_dword(pdev, ATIIXP_IDE_MWDMA_TIMING,
-				      &mwdma_timing_data);
+		pci_read_config_word(pdev, ATIIXP_IDE_MWDMA_TIMING, &mwdma_timing_data);
 		mwdma_timing_data &= ~(0xFF << timing_shift);
 		mwdma_timing_data |= (mwdma_timings[dma] << timing_shift);
-		pci_write_config_dword(pdev, ATIIXP_IDE_MWDMA_TIMING,
-				       mwdma_timing_data);
+		pci_write_config_word(pdev, ATIIXP_IDE_MWDMA_TIMING, mwdma_timing_data);
 	}
 	/*
 	 *	We must now look at the PIO mode situation. We may need to
@@ -153,9 +172,6 @@
  *
  *	When DMA begins we need to ensure that the UDMA control
  *	register for the channel is correctly set.
- *
- *	Note: The host lock held by the libata layer protects
- *	us from two channels both trying to set DMA bits at once
  */
 
 static void atiixp_bmdma_start(struct ata_queued_cmd *qc)
@@ -168,7 +184,7 @@
 	u16 tmp16;
 
 	pci_read_config_word(pdev, ATIIXP_IDE_UDMA_CONTROL, &tmp16);
-	if (ata_using_udma(adev))
+	if (adev->dma_mode >= XFER_UDMA_0)
 		tmp16 |= (1 << dn);
 	else
 		tmp16 &= ~(1 << dn);
@@ -182,9 +198,6 @@
  *
  *	DMA has completed. Clear the UDMA flag as the next operations will
  *	be PIO ones not UDMA data transfer.
- *
- *	Note: The host lock held by the libata layer protects
- *	us from two channels both trying to set DMA bits at once
  */
 
 static void atiixp_bmdma_stop(struct ata_queued_cmd *qc)
@@ -201,43 +214,70 @@
 }
 
 static struct scsi_host_template atiixp_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-	.sg_tablesize		= LIBATA_DUMB_MAX_PRD,
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations atiixp_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= atiixp_set_piomode,
+	.set_dmamode	= atiixp_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= atiixp_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= atiixp_cable_detect,
 
-	.qc_prep 	= ata_sff_dumb_qc_prep,
+	.bmdma_setup 	= ata_bmdma_setup,
 	.bmdma_start 	= atiixp_bmdma_start,
 	.bmdma_stop	= atiixp_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
 
-	.cable_detect	= atiixp_cable_detect,
-	.set_piomode	= atiixp_set_piomode,
-	.set_dmamode	= atiixp_set_dmamode,
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
-static int atiixp_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
+static int atiixp_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &atiixp_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA12_ONLY,
-		.udma_mask = ATA_UDMA5,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x06,	/* No MWDMA0 support */
+		.udma_mask = 0x3F,
 		.port_ops = &atiixp_port_ops
 	};
-	static const struct pci_bits atiixp_enable_bits[] = {
-		{ 0x48, 1, 0x01, 0x00 },
-		{ 0x48, 1, 0x08, 0x00 }
-	};
-	const struct ata_port_info *ppi[] = { &info, &info };
-	int i;
-
-	for (i = 0; i < 2; i++)
-		if (!pci_test_config_bits(pdev, &atiixp_enable_bits[i]))
-			ppi[i] = &ata_dummy_port_info;
-
-	return ata_pci_sff_init_one(pdev, ppi, &atiixp_sht, NULL);
+	const struct ata_port_info *ppi[] = { &info, NULL };
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id atiixp[] = {
@@ -246,7 +286,6 @@
 	{ PCI_VDEVICE(ATI, PCI_DEVICE_ID_ATI_IXP400_IDE), },
 	{ PCI_VDEVICE(ATI, PCI_DEVICE_ID_ATI_IXP600_IDE), },
 	{ PCI_VDEVICE(ATI, PCI_DEVICE_ID_ATI_IXP700_IDE), },
-	{ PCI_VDEVICE(AMD, PCI_DEVICE_ID_AMD_HUDSON2_IDE), },
 
 	{ },
 };
diff -Nur linux-sh4/drivers/ata.org/pata_atp867x.c linux-sh4/drivers/ata/pata_atp867x.c
--- linux-sh4/drivers/ata.org/pata_atp867x.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_atp867x.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,587 +0,0 @@
-/*
- * pata_atp867x.c - ARTOP 867X 64bit 4-channel UDMA133 ATA controller driver
- *
- *	(C) 2009 Google Inc. John(Jung-Ik) Lee <jilee@google.com>
- *
- * Per Atp867 data sheet rev 1.2, Acard.
- * Based in part on early ide code from
- *	2003-2004 by Eric Uhrhane, Google, Inc.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
- *
- *
- * TODO:
- *   1. RAID features [comparison, XOR, striping, mirroring, etc.]
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <linux/delay.h>
-#include <linux/device.h>
-#include <scsi/scsi_host.h>
-#include <linux/libata.h>
-
-#define	DRV_NAME	"pata_atp867x"
-#define	DRV_VERSION	"0.7.5"
-
-/*
- * IO Registers
- * Note that all runtime hot priv ports are cached in ap private_data
- */
-
-enum {
-	ATP867X_IO_CHANNEL_OFFSET	= 0x10,
-
-	/*
-	 * IO Register Bitfields
-	 */
-
-	ATP867X_IO_PIOSPD_ACTIVE_SHIFT	= 4,
-	ATP867X_IO_PIOSPD_RECOVER_SHIFT	= 0,
-
-	ATP867X_IO_DMAMODE_MSTR_SHIFT	= 0,
-	ATP867X_IO_DMAMODE_MSTR_MASK	= 0x07,
-	ATP867X_IO_DMAMODE_SLAVE_SHIFT	= 4,
-	ATP867X_IO_DMAMODE_SLAVE_MASK	= 0x70,
-
-	ATP867X_IO_DMAMODE_UDMA_6	= 0x07,
-	ATP867X_IO_DMAMODE_UDMA_5	= 0x06,
-	ATP867X_IO_DMAMODE_UDMA_4	= 0x05,
-	ATP867X_IO_DMAMODE_UDMA_3	= 0x04,
-	ATP867X_IO_DMAMODE_UDMA_2	= 0x03,
-	ATP867X_IO_DMAMODE_UDMA_1	= 0x02,
-	ATP867X_IO_DMAMODE_UDMA_0	= 0x01,
-	ATP867X_IO_DMAMODE_DISABLE	= 0x00,
-
-	ATP867X_IO_SYS_INFO_66MHZ	= 0x04,
-	ATP867X_IO_SYS_INFO_SLOW_UDMA5	= 0x02,
-	ATP867X_IO_SYS_MASK_RESERVED	= (~0xf1),
-
-	ATP867X_IO_PORTSPD_VAL		= 0x1143,
-	ATP867X_PREREAD_VAL		= 0x0200,
-
-	ATP867X_NUM_PORTS		= 4,
-	ATP867X_BAR_IOBASE		= 0,
-	ATP867X_BAR_ROMBASE		= 6,
-};
-
-#define ATP867X_IOBASE(ap)		((ap)->host->iomap[0])
-#define ATP867X_SYS_INFO(ap)		(0x3F + ATP867X_IOBASE(ap))
-
-#define ATP867X_IO_PORTBASE(ap, port)	(0x00 + ATP867X_IOBASE(ap) + \
-					(port) * ATP867X_IO_CHANNEL_OFFSET)
-#define ATP867X_IO_DMABASE(ap, port)	(0x40 + \
-					ATP867X_IO_PORTBASE((ap), (port)))
-
-#define ATP867X_IO_STATUS(ap, port)	(0x07 + \
-					ATP867X_IO_PORTBASE((ap), (port)))
-#define ATP867X_IO_ALTSTATUS(ap, port)	(0x0E + \
-					ATP867X_IO_PORTBASE((ap), (port)))
-
-/*
- * hot priv ports
- */
-#define ATP867X_IO_MSTRPIOSPD(ap, port)	(0x08 + \
-					ATP867X_IO_DMABASE((ap), (port)))
-#define ATP867X_IO_SLAVPIOSPD(ap, port)	(0x09 + \
-					ATP867X_IO_DMABASE((ap), (port)))
-#define ATP867X_IO_8BPIOSPD(ap, port)	(0x0A + \
-					ATP867X_IO_DMABASE((ap), (port)))
-#define ATP867X_IO_DMAMODE(ap, port)	(0x0B + \
-					ATP867X_IO_DMABASE((ap), (port)))
-
-#define ATP867X_IO_PORTSPD(ap, port)	(0x4A + \
-					ATP867X_IO_PORTBASE((ap), (port)))
-#define ATP867X_IO_PREREAD(ap, port)	(0x4C + \
-					ATP867X_IO_PORTBASE((ap), (port)))
-
-struct atp867x_priv {
-	void __iomem *dma_mode;
-	void __iomem *mstr_piospd;
-	void __iomem *slave_piospd;
-	void __iomem *eightb_piospd;
-	int		pci66mhz;
-};
-
-static void atp867x_set_dmamode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct pci_dev *pdev	= to_pci_dev(ap->host->dev);
-	struct atp867x_priv *dp = ap->private_data;
-	u8 speed = adev->dma_mode;
-	u8 b;
-	u8 mode = speed - XFER_UDMA_0 + 1;
-
-	/*
-	 * Doc 6.6.9: decrease the udma mode value by 1 for safer UDMA speed
-	 * on 66MHz bus
-	 *   rev-A: UDMA_1~4 (5, 6 no change)
-	 *   rev-B: all UDMA modes
-	 *   UDMA_0 stays not to disable UDMA
-	 */
-	if (dp->pci66mhz && mode > ATP867X_IO_DMAMODE_UDMA_0  &&
-	   (pdev->device == PCI_DEVICE_ID_ARTOP_ATP867B ||
-	    mode < ATP867X_IO_DMAMODE_UDMA_5))
-		mode--;
-
-	b = ioread8(dp->dma_mode);
-	if (adev->devno & 1) {
-		b = (b & ~ATP867X_IO_DMAMODE_SLAVE_MASK) |
-			(mode << ATP867X_IO_DMAMODE_SLAVE_SHIFT);
-	} else {
-		b = (b & ~ATP867X_IO_DMAMODE_MSTR_MASK) |
-			(mode << ATP867X_IO_DMAMODE_MSTR_SHIFT);
-	}
-	iowrite8(b, dp->dma_mode);
-}
-
-static int atp867x_get_active_clocks_shifted(struct ata_port *ap,
-	unsigned int clk)
-{
-	struct atp867x_priv *dp = ap->private_data;
-	unsigned char clocks = clk;
-
-	/*
-	 * Doc 6.6.9: increase the clock value by 1 for safer PIO speed
-	 * on 66MHz bus
-	 */
-	if (dp->pci66mhz)
-		clocks++;
-
-	switch (clocks) {
-	case 0:
-		clocks = 1;
-		break;
-	case 1 ... 6:
-		break;
-	default:
-		printk(KERN_WARNING "ATP867X: active %dclk is invalid. "
-			"Using 12clk.\n", clk);
-	case 9 ... 12:
-		clocks = 7;	/* 12 clk */
-		break;
-	case 7:
-	case 8:	/* default 8 clk */
-		clocks = 0;
-		goto active_clock_shift_done;
-	}
-
-active_clock_shift_done:
-	return clocks << ATP867X_IO_PIOSPD_ACTIVE_SHIFT;
-}
-
-static int atp867x_get_recover_clocks_shifted(unsigned int clk)
-{
-	unsigned char clocks = clk;
-
-	switch (clocks) {
-	case 0:
-		clocks = 1;
-		break;
-	case 1 ... 11:
-		break;
-	case 13:
-	case 14:
-		--clocks;	/* by the spec */
-		break;
-	case 15:
-		break;
-	default:
-		printk(KERN_WARNING "ATP867X: recover %dclk is invalid. "
-			"Using default 12clk.\n", clk);
-	case 12:	/* default 12 clk */
-		clocks = 0;
-		break;
-	}
-
-	return clocks << ATP867X_IO_PIOSPD_RECOVER_SHIFT;
-}
-
-static void atp867x_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct ata_device *peer = ata_dev_pair(adev);
-	struct atp867x_priv *dp = ap->private_data;
-	u8 speed = adev->pio_mode;
-	struct ata_timing t, p;
-	int T, UT;
-	u8 b;
-
-	T = 1000000000 / 33333;
-	UT = T / 4;
-
-	ata_timing_compute(adev, speed, &t, T, UT);
-	if (peer && peer->pio_mode) {
-		ata_timing_compute(peer, peer->pio_mode, &p, T, UT);
-		ata_timing_merge(&p, &t, &t, ATA_TIMING_8BIT);
-	}
-
-	b = ioread8(dp->dma_mode);
-	if (adev->devno & 1)
-		b = (b & ~ATP867X_IO_DMAMODE_SLAVE_MASK);
-	else
-		b = (b & ~ATP867X_IO_DMAMODE_MSTR_MASK);
-	iowrite8(b, dp->dma_mode);
-
-	b = atp867x_get_active_clocks_shifted(ap, t.active) |
-	    atp867x_get_recover_clocks_shifted(t.recover);
-
-	if (adev->devno & 1)
-		iowrite8(b, dp->slave_piospd);
-	else
-		iowrite8(b, dp->mstr_piospd);
-
-	b = atp867x_get_active_clocks_shifted(ap, t.act8b) |
-	    atp867x_get_recover_clocks_shifted(t.rec8b);
-
-	iowrite8(b, dp->eightb_piospd);
-}
-
-static int atp867x_cable_override(struct pci_dev *pdev)
-{
-	if (pdev->subsystem_vendor == PCI_VENDOR_ID_ARTOP &&
-		(pdev->subsystem_device == PCI_DEVICE_ID_ARTOP_ATP867A ||
-		 pdev->subsystem_device == PCI_DEVICE_ID_ARTOP_ATP867B)) {
-		return 1;
-	}
-	return 0;
-}
-
-static int atp867x_cable_detect(struct ata_port *ap)
-{
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-
-	if (atp867x_cable_override(pdev))
-		return ATA_CBL_PATA40_SHORT;
-
-	return ATA_CBL_PATA_UNK;
-}
-
-static struct scsi_host_template atp867x_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations atp867x_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.cable_detect		= atp867x_cable_detect,
-	.set_piomode		= atp867x_set_piomode,
-	.set_dmamode		= atp867x_set_dmamode,
-};
-
-
-#ifdef	ATP867X_DEBUG
-static void atp867x_check_res(struct pci_dev *pdev)
-{
-	int i;
-	unsigned long start, len;
-
-	/* Check the PCI resources for this channel are enabled */
-	for (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {
-		start = pci_resource_start(pdev, i);
-		len   = pci_resource_len(pdev, i);
-		printk(KERN_DEBUG "ATP867X: resource start:len=%lx:%lx\n",
-			start, len);
-	}
-}
-
-static void atp867x_check_ports(struct ata_port *ap, int port)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	struct atp867x_priv *dp = ap->private_data;
-
-	printk(KERN_DEBUG "ATP867X: port[%d] addresses\n"
-		"  cmd_addr	=0x%llx, 0x%llx\n"
-		"  ctl_addr	=0x%llx, 0x%llx\n"
-		"  bmdma_addr	=0x%llx, 0x%llx\n"
-		"  data_addr	=0x%llx\n"
-		"  error_addr	=0x%llx\n"
-		"  feature_addr	=0x%llx\n"
-		"  nsect_addr	=0x%llx\n"
-		"  lbal_addr	=0x%llx\n"
-		"  lbam_addr	=0x%llx\n"
-		"  lbah_addr	=0x%llx\n"
-		"  device_addr	=0x%llx\n"
-		"  status_addr	=0x%llx\n"
-		"  command_addr	=0x%llx\n"
-		"  dp->dma_mode	=0x%llx\n"
-		"  dp->mstr_piospd	=0x%llx\n"
-		"  dp->slave_piospd	=0x%llx\n"
-		"  dp->eightb_piospd	=0x%llx\n"
-		"  dp->pci66mhz		=0x%lx\n",
-		port,
-		(unsigned long long)ioaddr->cmd_addr,
-		(unsigned long long)ATP867X_IO_PORTBASE(ap, port),
-		(unsigned long long)ioaddr->ctl_addr,
-		(unsigned long long)ATP867X_IO_ALTSTATUS(ap, port),
-		(unsigned long long)ioaddr->bmdma_addr,
-		(unsigned long long)ATP867X_IO_DMABASE(ap, port),
-		(unsigned long long)ioaddr->data_addr,
-		(unsigned long long)ioaddr->error_addr,
-		(unsigned long long)ioaddr->feature_addr,
-		(unsigned long long)ioaddr->nsect_addr,
-		(unsigned long long)ioaddr->lbal_addr,
-		(unsigned long long)ioaddr->lbam_addr,
-		(unsigned long long)ioaddr->lbah_addr,
-		(unsigned long long)ioaddr->device_addr,
-		(unsigned long long)ioaddr->status_addr,
-		(unsigned long long)ioaddr->command_addr,
-		(unsigned long long)dp->dma_mode,
-		(unsigned long long)dp->mstr_piospd,
-		(unsigned long long)dp->slave_piospd,
-		(unsigned long long)dp->eightb_piospd,
-		(unsigned long)dp->pci66mhz);
-}
-#endif
-
-static int atp867x_set_priv(struct ata_port *ap)
-{
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	struct atp867x_priv *dp;
-	int port = ap->port_no;
-
-	dp = ap->private_data =
-		devm_kzalloc(&pdev->dev, sizeof(*dp), GFP_KERNEL);
-	if (dp == NULL)
-		return -ENOMEM;
-
-	dp->dma_mode	 = ATP867X_IO_DMAMODE(ap, port);
-	dp->mstr_piospd	 = ATP867X_IO_MSTRPIOSPD(ap, port);
-	dp->slave_piospd = ATP867X_IO_SLAVPIOSPD(ap, port);
-	dp->eightb_piospd = ATP867X_IO_8BPIOSPD(ap, port);
-
-	dp->pci66mhz =
-		ioread8(ATP867X_SYS_INFO(ap)) & ATP867X_IO_SYS_INFO_66MHZ;
-
-	return 0;
-}
-
-static void atp867x_fixup(struct ata_host *host)
-{
-	struct pci_dev *pdev = to_pci_dev(host->dev);
-	struct ata_port *ap = host->ports[0];
-	int i;
-	u8 v;
-
-	/*
-	 * Broken BIOS might not set latency high enough
-	 */
-	pci_read_config_byte(pdev, PCI_LATENCY_TIMER, &v);
-	if (v < 0x80) {
-		v = 0x80;
-		pci_write_config_byte(pdev, PCI_LATENCY_TIMER, v);
-		printk(KERN_DEBUG "ATP867X: set latency timer of device %s"
-			" to %d\n", pci_name(pdev), v);
-	}
-
-	/*
-	 * init 8bit io ports speed(0aaarrrr) to 43h and
-	 * init udma modes of master/slave to 0/0(11h)
-	 */
-	for (i = 0; i < ATP867X_NUM_PORTS; i++)
-		iowrite16(ATP867X_IO_PORTSPD_VAL, ATP867X_IO_PORTSPD(ap, i));
-
-	/*
-	 * init PreREAD counts
-	 */
-	for (i = 0; i < ATP867X_NUM_PORTS; i++)
-		iowrite16(ATP867X_PREREAD_VAL, ATP867X_IO_PREREAD(ap, i));
-
-	v = ioread8(ATP867X_IOBASE(ap) + 0x28);
-	v &= 0xcf;	/* Enable INTA#: bit4=0 means enable */
-	v |= 0xc0;	/* Enable PCI burst, MRM & not immediate interrupts */
-	iowrite8(v, ATP867X_IOBASE(ap) + 0x28);
-
-	/*
-	 * Turn off the over clocked udma5 mode, only for Rev-B
-	 */
-	v = ioread8(ATP867X_SYS_INFO(ap));
-	v &= ATP867X_IO_SYS_MASK_RESERVED;
-	if (pdev->device == PCI_DEVICE_ID_ARTOP_ATP867B)
-		v |= ATP867X_IO_SYS_INFO_SLOW_UDMA5;
-	iowrite8(v, ATP867X_SYS_INFO(ap));
-}
-
-static int atp867x_ata_pci_sff_init_host(struct ata_host *host)
-{
-	struct device *gdev = host->dev;
-	struct pci_dev *pdev = to_pci_dev(gdev);
-	unsigned int mask = 0;
-	int i, rc;
-
-	/*
-	 * do not map rombase
-	 */
-	rc = pcim_iomap_regions(pdev, 1 << ATP867X_BAR_IOBASE, DRV_NAME);
-	if (rc == -EBUSY)
-		pcim_pin_device(pdev);
-	if (rc)
-		return rc;
-	host->iomap = pcim_iomap_table(pdev);
-
-#ifdef	ATP867X_DEBUG
-	atp867x_check_res(pdev);
-
-	for (i = 0; i < PCI_ROM_RESOURCE; i++)
-		printk(KERN_DEBUG "ATP867X: iomap[%d]=0x%llx\n", i,
-			(unsigned long long)(host->iomap[i]));
-#endif
-
-	/*
-	 * request, iomap BARs and init port addresses accordingly
-	 */
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		struct ata_ioports *ioaddr = &ap->ioaddr;
-
-		ioaddr->cmd_addr = ATP867X_IO_PORTBASE(ap, i);
-		ioaddr->ctl_addr = ioaddr->altstatus_addr
-				 = ATP867X_IO_ALTSTATUS(ap, i);
-		ioaddr->bmdma_addr = ATP867X_IO_DMABASE(ap, i);
-
-		ata_sff_std_ports(ioaddr);
-		rc = atp867x_set_priv(ap);
-		if (rc)
-			return rc;
-
-#ifdef	ATP867X_DEBUG
-		atp867x_check_ports(ap, i);
-#endif
-		ata_port_desc(ap, "cmd 0x%lx ctl 0x%lx",
-			(unsigned long)ioaddr->cmd_addr,
-			(unsigned long)ioaddr->ctl_addr);
-		ata_port_desc(ap, "bmdma 0x%lx",
-			(unsigned long)ioaddr->bmdma_addr);
-
-		mask |= 1 << i;
-	}
-
-	if (!mask) {
-		dev_printk(KERN_ERR, gdev, "no available native port\n");
-		return -ENODEV;
-	}
-
-	atp867x_fixup(host);
-
-	rc = pci_set_dma_mask(pdev, ATA_DMA_MASK);
-	if (rc)
-		return rc;
-
-	rc = pci_set_consistent_dma_mask(pdev, ATA_DMA_MASK);
-	return rc;
-}
-
-static int atp867x_init_one(struct pci_dev *pdev,
-	const struct pci_device_id *id)
-{
-	static int printed_version;
-	static const struct ata_port_info info_867x = {
-		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.udma_mask 	= ATA_UDMA6,
-		.port_ops	= &atp867x_ops,
-	};
-
-	struct ata_host *host;
-	const struct ata_port_info *ppi[] = { &info_867x, NULL };
-	int rc;
-
-	if (!printed_version++)
-		dev_printk(KERN_INFO, &pdev->dev, "version " DRV_VERSION "\n");
-
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
-	printk(KERN_INFO "ATP867X: ATP867 ATA UDMA133 controller (rev %02X)",
-		pdev->device);
-
-	host = ata_host_alloc_pinfo(&pdev->dev, ppi, ATP867X_NUM_PORTS);
-	if (!host) {
-		dev_printk(KERN_ERR, &pdev->dev,
-			"failed to allocate ATA host\n");
-		rc = -ENOMEM;
-		goto err_out;
-	}
-
-	rc = atp867x_ata_pci_sff_init_host(host);
-	if (rc) {
-		dev_printk(KERN_ERR, &pdev->dev, "failed to init host\n");
-		goto err_out;
-	}
-
-	pci_set_master(pdev);
-
-	rc = ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				IRQF_SHARED, &atp867x_sht);
-	if (rc)
-		dev_printk(KERN_ERR, &pdev->dev, "failed to activate host\n");
-
-err_out:
-	return rc;
-}
-
-#ifdef CONFIG_PM
-static int atp867x_reinit_one(struct pci_dev *pdev)
-{
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
-
-	atp867x_fixup(host);
-
-	ata_host_resume(host);
-	return 0;
-}
-#endif
-
-static struct pci_device_id atp867x_pci_tbl[] = {
-	{ PCI_VDEVICE(ARTOP, PCI_DEVICE_ID_ARTOP_ATP867A),	0 },
-	{ PCI_VDEVICE(ARTOP, PCI_DEVICE_ID_ARTOP_ATP867B),	0 },
-	{ },
-};
-
-static struct pci_driver atp867x_driver = {
-	.name 		= DRV_NAME,
-	.id_table 	= atp867x_pci_tbl,
-	.probe 		= atp867x_init_one,
-	.remove		= ata_pci_remove_one,
-#ifdef CONFIG_PM
-	.suspend	= ata_pci_device_suspend,
-	.resume		= atp867x_reinit_one,
-#endif
-};
-
-static int __init atp867x_init(void)
-{
-	return pci_register_driver(&atp867x_driver);
-}
-
-static void __exit atp867x_exit(void)
-{
-	pci_unregister_driver(&atp867x_driver);
-}
-
-MODULE_AUTHOR("John(Jung-Ik) Lee, Google Inc.");
-MODULE_DESCRIPTION("low level driver for Artop/Acard 867x ATA controller");
-MODULE_LICENSE("GPL");
-MODULE_DEVICE_TABLE(pci, atp867x_pci_tbl);
-MODULE_VERSION(DRV_VERSION);
-
-module_init(atp867x_init);
-module_exit(atp867x_exit);
diff -Nur linux-sh4/drivers/ata.org/pata_bf54x.c linux-sh4/drivers/ata/pata_bf54x.c
--- linux-sh4/drivers/ata.org/pata_bf54x.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_bf54x.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,1742 +0,0 @@
-/*
- * File:         drivers/ata/pata_bf54x.c
- * Author:       Sonic Zhang <sonic.zhang@analog.com>
- *
- * Created:
- * Description:  PATA Driver for blackfin 54x
- *
- * Modified:
- *               Copyright 2007 Analog Devices Inc.
- *
- * Bugs:         Enter bugs at http://blackfin.uclinux.org/
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, see the file COPYING, or write
- * to the Free Software Foundation, Inc.,
- * 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <linux/delay.h>
-#include <linux/device.h>
-#include <scsi/scsi_host.h>
-#include <linux/libata.h>
-#include <linux/platform_device.h>
-#include <asm/dma.h>
-#include <asm/gpio.h>
-#include <asm/portmux.h>
-
-#define DRV_NAME		"pata-bf54x"
-#define DRV_VERSION		"0.9"
-
-#define ATA_REG_CTRL		0x0E
-#define ATA_REG_ALTSTATUS	ATA_REG_CTRL
-
-/* These are the offset of the controller's registers */
-#define ATAPI_OFFSET_CONTROL		0x00
-#define ATAPI_OFFSET_STATUS		0x04
-#define ATAPI_OFFSET_DEV_ADDR		0x08
-#define ATAPI_OFFSET_DEV_TXBUF		0x0c
-#define ATAPI_OFFSET_DEV_RXBUF		0x10
-#define ATAPI_OFFSET_INT_MASK		0x14
-#define ATAPI_OFFSET_INT_STATUS		0x18
-#define ATAPI_OFFSET_XFER_LEN		0x1c
-#define ATAPI_OFFSET_LINE_STATUS	0x20
-#define ATAPI_OFFSET_SM_STATE		0x24
-#define ATAPI_OFFSET_TERMINATE		0x28
-#define ATAPI_OFFSET_PIO_TFRCNT		0x2c
-#define ATAPI_OFFSET_DMA_TFRCNT		0x30
-#define ATAPI_OFFSET_UMAIN_TFRCNT	0x34
-#define ATAPI_OFFSET_UDMAOUT_TFRCNT	0x38
-#define ATAPI_OFFSET_REG_TIM_0		0x40
-#define ATAPI_OFFSET_PIO_TIM_0		0x44
-#define ATAPI_OFFSET_PIO_TIM_1		0x48
-#define ATAPI_OFFSET_MULTI_TIM_0	0x50
-#define ATAPI_OFFSET_MULTI_TIM_1	0x54
-#define ATAPI_OFFSET_MULTI_TIM_2	0x58
-#define ATAPI_OFFSET_ULTRA_TIM_0	0x60
-#define ATAPI_OFFSET_ULTRA_TIM_1	0x64
-#define ATAPI_OFFSET_ULTRA_TIM_2	0x68
-#define ATAPI_OFFSET_ULTRA_TIM_3	0x6c
-
-
-#define ATAPI_GET_CONTROL(base)\
-	bfin_read16(base + ATAPI_OFFSET_CONTROL)
-#define ATAPI_SET_CONTROL(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_CONTROL, val)
-#define ATAPI_GET_STATUS(base)\
-	bfin_read16(base + ATAPI_OFFSET_STATUS)
-#define ATAPI_GET_DEV_ADDR(base)\
-	bfin_read16(base + ATAPI_OFFSET_DEV_ADDR)
-#define ATAPI_SET_DEV_ADDR(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_DEV_ADDR, val)
-#define ATAPI_GET_DEV_TXBUF(base)\
-	bfin_read16(base + ATAPI_OFFSET_DEV_TXBUF)
-#define ATAPI_SET_DEV_TXBUF(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_DEV_TXBUF, val)
-#define ATAPI_GET_DEV_RXBUF(base)\
-	bfin_read16(base + ATAPI_OFFSET_DEV_RXBUF)
-#define ATAPI_SET_DEV_RXBUF(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_DEV_RXBUF, val)
-#define ATAPI_GET_INT_MASK(base)\
-	bfin_read16(base + ATAPI_OFFSET_INT_MASK)
-#define ATAPI_SET_INT_MASK(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_INT_MASK, val)
-#define ATAPI_GET_INT_STATUS(base)\
-	bfin_read16(base + ATAPI_OFFSET_INT_STATUS)
-#define ATAPI_SET_INT_STATUS(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_INT_STATUS, val)
-#define ATAPI_GET_XFER_LEN(base)\
-	bfin_read16(base + ATAPI_OFFSET_XFER_LEN)
-#define ATAPI_SET_XFER_LEN(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_XFER_LEN, val)
-#define ATAPI_GET_LINE_STATUS(base)\
-	bfin_read16(base + ATAPI_OFFSET_LINE_STATUS)
-#define ATAPI_GET_SM_STATE(base)\
-	bfin_read16(base + ATAPI_OFFSET_SM_STATE)
-#define ATAPI_GET_TERMINATE(base)\
-	bfin_read16(base + ATAPI_OFFSET_TERMINATE)
-#define ATAPI_SET_TERMINATE(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_TERMINATE, val)
-#define ATAPI_GET_PIO_TFRCNT(base)\
-	bfin_read16(base + ATAPI_OFFSET_PIO_TFRCNT)
-#define ATAPI_GET_DMA_TFRCNT(base)\
-	bfin_read16(base + ATAPI_OFFSET_DMA_TFRCNT)
-#define ATAPI_GET_UMAIN_TFRCNT(base)\
-	bfin_read16(base + ATAPI_OFFSET_UMAIN_TFRCNT)
-#define ATAPI_GET_UDMAOUT_TFRCNT(base)\
-	bfin_read16(base + ATAPI_OFFSET_UDMAOUT_TFRCNT)
-#define ATAPI_GET_REG_TIM_0(base)\
-	bfin_read16(base + ATAPI_OFFSET_REG_TIM_0)
-#define ATAPI_SET_REG_TIM_0(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_REG_TIM_0, val)
-#define ATAPI_GET_PIO_TIM_0(base)\
-	bfin_read16(base + ATAPI_OFFSET_PIO_TIM_0)
-#define ATAPI_SET_PIO_TIM_0(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_PIO_TIM_0, val)
-#define ATAPI_GET_PIO_TIM_1(base)\
-	bfin_read16(base + ATAPI_OFFSET_PIO_TIM_1)
-#define ATAPI_SET_PIO_TIM_1(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_PIO_TIM_1, val)
-#define ATAPI_GET_MULTI_TIM_0(base)\
-	bfin_read16(base + ATAPI_OFFSET_MULTI_TIM_0)
-#define ATAPI_SET_MULTI_TIM_0(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_MULTI_TIM_0, val)
-#define ATAPI_GET_MULTI_TIM_1(base)\
-	bfin_read16(base + ATAPI_OFFSET_MULTI_TIM_1)
-#define ATAPI_SET_MULTI_TIM_1(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_MULTI_TIM_1, val)
-#define ATAPI_GET_MULTI_TIM_2(base)\
-	bfin_read16(base + ATAPI_OFFSET_MULTI_TIM_2)
-#define ATAPI_SET_MULTI_TIM_2(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_MULTI_TIM_2, val)
-#define ATAPI_GET_ULTRA_TIM_0(base)\
-	bfin_read16(base + ATAPI_OFFSET_ULTRA_TIM_0)
-#define ATAPI_SET_ULTRA_TIM_0(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_ULTRA_TIM_0, val)
-#define ATAPI_GET_ULTRA_TIM_1(base)\
-	bfin_read16(base + ATAPI_OFFSET_ULTRA_TIM_1)
-#define ATAPI_SET_ULTRA_TIM_1(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_ULTRA_TIM_1, val)
-#define ATAPI_GET_ULTRA_TIM_2(base)\
-	bfin_read16(base + ATAPI_OFFSET_ULTRA_TIM_2)
-#define ATAPI_SET_ULTRA_TIM_2(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_ULTRA_TIM_2, val)
-#define ATAPI_GET_ULTRA_TIM_3(base)\
-	bfin_read16(base + ATAPI_OFFSET_ULTRA_TIM_3)
-#define ATAPI_SET_ULTRA_TIM_3(base, val)\
-	bfin_write16(base + ATAPI_OFFSET_ULTRA_TIM_3, val)
-
-/**
- * PIO Mode - Frequency compatibility
- */
-/* mode: 0         1         2         3         4 */
-static const u32 pio_fsclk[] =
-{ 33333333, 33333333, 33333333, 33333333, 33333333 };
-
-/**
- * MDMA Mode - Frequency compatibility
- */
-/*               mode:      0         1         2        */
-static const u32 mdma_fsclk[] = { 33333333, 33333333, 33333333 };
-
-/**
- * UDMA Mode - Frequency compatibility
- *
- * UDMA5 - 100 MB/s   - SCLK  = 133 MHz
- * UDMA4 - 66 MB/s    - SCLK >=  80 MHz
- * UDMA3 - 44.4 MB/s  - SCLK >=  50 MHz
- * UDMA2 - 33 MB/s    - SCLK >=  40 MHz
- */
-/* mode: 0         1         2         3         4          5 */
-static const u32 udma_fsclk[] =
-{ 33333333, 33333333, 40000000, 50000000, 80000000, 133333333 };
-
-/**
- * Register transfer timing table
- */
-/*               mode:       0    1    2    3    4    */
-/* Cycle Time                     */
-static const u32 reg_t0min[]   = { 600, 383, 330, 180, 120 };
-/* DIOR/DIOW to end cycle         */
-static const u32 reg_t2min[]   = { 290, 290, 290, 70,  25  };
-/* DIOR/DIOW asserted pulse width */
-static const u32 reg_teocmin[] = { 290, 290, 290, 80,  70  };
-
-/**
- * PIO timing table
- */
-/*               mode:       0    1    2    3    4    */
-/* Cycle Time                     */
-static const u32 pio_t0min[]   = { 600, 383, 240, 180, 120 };
-/* Address valid to DIOR/DIORW    */
-static const u32 pio_t1min[]   = { 70,  50,  30,  30,  25  };
-/* DIOR/DIOW to end cycle         */
-static const u32 pio_t2min[]   = { 165, 125, 100, 80,  70  };
-/* DIOR/DIOW asserted pulse width */
-static const u32 pio_teocmin[] = { 165, 125, 100, 70,  25  };
-/* DIOW data hold                 */
-static const u32 pio_t4min[]   = { 30,  20,  15,  10,  10  };
-
-/* ******************************************************************
- * Multiword DMA timing table
- * ******************************************************************
- */
-/*               mode:       0   1    2        */
-/* Cycle Time                     */
-static const u32 mdma_t0min[]  = { 480, 150, 120 };
-/* DIOR/DIOW asserted pulse width */
-static const u32 mdma_tdmin[]  = { 215, 80,  70  };
-/* DMACK to read data released    */
-static const u32 mdma_thmin[]  = { 20,  15,  10  };
-/* DIOR/DIOW to DMACK hold        */
-static const u32 mdma_tjmin[]  = { 20,  5,   5   };
-/* DIOR negated pulse width       */
-static const u32 mdma_tkrmin[] = { 50,  50,  25  };
-/* DIOR negated pulse width       */
-static const u32 mdma_tkwmin[] = { 215, 50,  25  };
-/* CS[1:0] valid to DIOR/DIOW     */
-static const u32 mdma_tmmin[]  = { 50,  30,  25  };
-/* DMACK to read data released    */
-static const u32 mdma_tzmax[]  = { 20,  25,  25  };
-
-/**
- * Ultra DMA timing table
- */
-/*               mode:         0    1    2    3    4    5       */
-static const u32 udma_tcycmin[]  = { 112, 73,  54,  39,  25,  17 };
-static const u32 udma_tdvsmin[]  = { 70,  48,  31,  20,  7,   5  };
-static const u32 udma_tenvmax[]  = { 70,  70,  70,  55,  55,  50 };
-static const u32 udma_trpmin[]   = { 160, 125, 100, 100, 100, 85 };
-static const u32 udma_tmin[]     = { 5,   5,   5,   5,   3,   3  };
-
-
-static const u32 udma_tmlimin = 20;
-static const u32 udma_tzahmin = 20;
-static const u32 udma_tenvmin = 20;
-static const u32 udma_tackmin = 20;
-static const u32 udma_tssmin = 50;
-
-/**
- *
- *	Function:       num_clocks_min
- *
- *	Description:
- *	calculate number of SCLK cycles to meet minimum timing
- */
-static unsigned short num_clocks_min(unsigned long tmin,
-				unsigned long fsclk)
-{
-	unsigned long tmp ;
-	unsigned short result;
-
-	tmp = tmin * (fsclk/1000/1000) / 1000;
-	result = (unsigned short)tmp;
-	if ((tmp*1000*1000) < (tmin*(fsclk/1000))) {
-		result++;
-	}
-
-	return result;
-}
-
-/**
- *	bfin_set_piomode - Initialize host controller PATA PIO timings
- *	@ap: Port whose timings we are configuring
- *	@adev: um
- *
- *	Set PIO mode for device.
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static void bfin_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	int mode = adev->pio_mode - XFER_PIO_0;
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	unsigned int fsclk = get_sclk();
-	unsigned short teoc_reg, t2_reg, teoc_pio;
-	unsigned short t4_reg, t2_pio, t1_reg;
-	unsigned short n0, n6, t6min = 5;
-
-	/* the most restrictive timing value is t6 and tc, the DIOW - data hold
-	* If one SCLK pulse is longer than this minimum value then register
-	* transfers cannot be supported at this frequency.
-	*/
-	n6 = num_clocks_min(t6min, fsclk);
-	if (mode >= 0 && mode <= 4 && n6 >= 1) {
-		dev_dbg(adev->link->ap->dev, "set piomode: mode=%d, fsclk=%ud\n", mode, fsclk);
-		/* calculate the timing values for register transfers. */
-		while (mode > 0 && pio_fsclk[mode] > fsclk)
-			mode--;
-
-		/* DIOR/DIOW to end cycle time */
-		t2_reg = num_clocks_min(reg_t2min[mode], fsclk);
-		/* DIOR/DIOW asserted pulse width */
-		teoc_reg = num_clocks_min(reg_teocmin[mode], fsclk);
-		/* Cycle Time */
-		n0  = num_clocks_min(reg_t0min[mode], fsclk);
-
-		/* increase t2 until we meed the minimum cycle length */
-		if (t2_reg + teoc_reg < n0)
-			t2_reg = n0 - teoc_reg;
-
-		/* calculate the timing values for pio transfers. */
-
-		/* DIOR/DIOW to end cycle time */
-		t2_pio = num_clocks_min(pio_t2min[mode], fsclk);
-		/* DIOR/DIOW asserted pulse width */
-		teoc_pio = num_clocks_min(pio_teocmin[mode], fsclk);
-		/* Cycle Time */
-		n0  = num_clocks_min(pio_t0min[mode], fsclk);
-
-		/* increase t2 until we meed the minimum cycle length */
-		if (t2_pio + teoc_pio < n0)
-			t2_pio = n0 - teoc_pio;
-
-		/* Address valid to DIOR/DIORW */
-		t1_reg = num_clocks_min(pio_t1min[mode], fsclk);
-
-		/* DIOW data hold */
-		t4_reg = num_clocks_min(pio_t4min[mode], fsclk);
-
-		ATAPI_SET_REG_TIM_0(base, (teoc_reg<<8 | t2_reg));
-		ATAPI_SET_PIO_TIM_0(base, (t4_reg<<12 | t2_pio<<4 | t1_reg));
-		ATAPI_SET_PIO_TIM_1(base, teoc_pio);
-		if (mode > 2) {
-			ATAPI_SET_CONTROL(base,
-				ATAPI_GET_CONTROL(base) | IORDY_EN);
-		} else {
-			ATAPI_SET_CONTROL(base,
-				ATAPI_GET_CONTROL(base) & ~IORDY_EN);
-		}
-
-		/* Disable host ATAPI PIO interrupts */
-		ATAPI_SET_INT_MASK(base, ATAPI_GET_INT_MASK(base)
-			& ~(PIO_DONE_MASK | HOST_TERM_XFER_MASK));
-		SSYNC();
-	}
-}
-
-/**
- *	bfin_set_dmamode - Initialize host controller PATA DMA timings
- *	@ap: Port whose timings we are configuring
- *	@adev: um
- *
- *	Set UDMA mode for device.
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static void bfin_set_dmamode(struct ata_port *ap, struct ata_device *adev)
-{
-	int mode;
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	unsigned long fsclk = get_sclk();
-	unsigned short tenv, tack, tcyc_tdvs, tdvs, tmli, tss, trp, tzah;
-	unsigned short tm, td, tkr, tkw, teoc, th;
-	unsigned short n0, nf, tfmin = 5;
-	unsigned short nmin, tcyc;
-
-	mode = adev->dma_mode - XFER_UDMA_0;
-	if (mode >= 0 && mode <= 5) {
-		dev_dbg(adev->link->ap->dev, "set udmamode: mode=%d\n", mode);
-		/* the most restrictive timing value is t6 and tc,
-		 * the DIOW - data hold. If one SCLK pulse is longer
-		 * than this minimum value then register
-		 * transfers cannot be supported at this frequency.
-		 */
-		while (mode > 0 && udma_fsclk[mode] > fsclk)
-			mode--;
-
-		nmin = num_clocks_min(udma_tmin[mode], fsclk);
-		if (nmin >= 1) {
-			/* calculate the timing values for Ultra DMA. */
-			tdvs = num_clocks_min(udma_tdvsmin[mode], fsclk);
-			tcyc = num_clocks_min(udma_tcycmin[mode], fsclk);
-			tcyc_tdvs = 2;
-
-			/* increase tcyc - tdvs (tcyc_tdvs) until we meed
-			 * the minimum cycle length
-			 */
-			if (tdvs + tcyc_tdvs < tcyc)
-				tcyc_tdvs = tcyc - tdvs;
-
-			/* Mow assign the values required for the timing
-			 * registers
-			 */
-			if (tcyc_tdvs < 2)
-				tcyc_tdvs = 2;
-
-			if (tdvs < 2)
-				tdvs = 2;
-
-			tack = num_clocks_min(udma_tackmin, fsclk);
-			tss = num_clocks_min(udma_tssmin, fsclk);
-			tmli = num_clocks_min(udma_tmlimin, fsclk);
-			tzah = num_clocks_min(udma_tzahmin, fsclk);
-			trp = num_clocks_min(udma_trpmin[mode], fsclk);
-			tenv = num_clocks_min(udma_tenvmin, fsclk);
-			if (tenv <= udma_tenvmax[mode]) {
-				ATAPI_SET_ULTRA_TIM_0(base, (tenv<<8 | tack));
-				ATAPI_SET_ULTRA_TIM_1(base,
-					(tcyc_tdvs<<8 | tdvs));
-				ATAPI_SET_ULTRA_TIM_2(base, (tmli<<8 | tss));
-				ATAPI_SET_ULTRA_TIM_3(base, (trp<<8 | tzah));
-
-				/* Enable host ATAPI Untra DMA interrupts */
-				ATAPI_SET_INT_MASK(base,
-					ATAPI_GET_INT_MASK(base)
-					| UDMAIN_DONE_MASK
-					| UDMAOUT_DONE_MASK
-					| UDMAIN_TERM_MASK
-					| UDMAOUT_TERM_MASK);
-			}
-		}
-	}
-
-	mode = adev->dma_mode - XFER_MW_DMA_0;
-	if (mode >= 0 && mode <= 2) {
-		dev_dbg(adev->link->ap->dev, "set mdmamode: mode=%d\n", mode);
-		/* the most restrictive timing value is tf, the DMACK to
-		 * read data released. If one SCLK pulse is longer than
-		 * this maximum value then the MDMA mode
-		 * cannot be supported at this frequency.
-		 */
-		while (mode > 0 && mdma_fsclk[mode] > fsclk)
-			mode--;
-
-		nf = num_clocks_min(tfmin, fsclk);
-		if (nf >= 1) {
-			/* calculate the timing values for Multi-word DMA. */
-
-			/* DIOR/DIOW asserted pulse width */
-			td = num_clocks_min(mdma_tdmin[mode], fsclk);
-
-			/* DIOR negated pulse width */
-			tkw = num_clocks_min(mdma_tkwmin[mode], fsclk);
-
-			/* Cycle Time */
-			n0  = num_clocks_min(mdma_t0min[mode], fsclk);
-
-			/* increase tk until we meed the minimum cycle length */
-			if (tkw + td < n0)
-				tkw = n0 - td;
-
-			/* DIOR negated pulse width - read */
-			tkr = num_clocks_min(mdma_tkrmin[mode], fsclk);
-			/* CS{1:0] valid to DIOR/DIOW */
-			tm = num_clocks_min(mdma_tmmin[mode], fsclk);
-			/* DIOR/DIOW to DMACK hold */
-			teoc = num_clocks_min(mdma_tjmin[mode], fsclk);
-			/* DIOW Data hold */
-			th = num_clocks_min(mdma_thmin[mode], fsclk);
-
-			ATAPI_SET_MULTI_TIM_0(base, (tm<<8 | td));
-			ATAPI_SET_MULTI_TIM_1(base, (tkr<<8 | tkw));
-			ATAPI_SET_MULTI_TIM_2(base, (teoc<<8 | th));
-
-			/* Enable host ATAPI Multi DMA interrupts */
-			ATAPI_SET_INT_MASK(base, ATAPI_GET_INT_MASK(base)
-				| MULTI_DONE_MASK | MULTI_TERM_MASK);
-			SSYNC();
-		}
-	}
-	return;
-}
-
-/**
- *
- *    Function:       wait_complete
- *
- *    Description:    Waits the interrupt from device
- *
- */
-static inline void wait_complete(void __iomem *base, unsigned short mask)
-{
-	unsigned short status;
-	unsigned int i = 0;
-
-#define PATA_BF54X_WAIT_TIMEOUT		10000
-
-	for (i = 0; i < PATA_BF54X_WAIT_TIMEOUT; i++) {
-		status = ATAPI_GET_INT_STATUS(base) & mask;
-		if (status)
-			break;
-	}
-
-	ATAPI_SET_INT_STATUS(base, mask);
-}
-
-/**
- *
- *    Function:       write_atapi_register
- *
- *    Description:    Writes to ATA Device Resgister
- *
- */
-
-static void write_atapi_register(void __iomem *base,
-		unsigned long ata_reg, unsigned short value)
-{
-	/* Program the ATA_DEV_TXBUF register with write data (to be
-	 * written into the device).
-	 */
-	ATAPI_SET_DEV_TXBUF(base, value);
-
-	/* Program the ATA_DEV_ADDR register with address of the
-	 * device register (0x01 to 0x0F).
-	 */
-	ATAPI_SET_DEV_ADDR(base, ata_reg);
-
-	/* Program the ATA_CTRL register with dir set to write (1)
-	 */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | XFER_DIR));
-
-	/* ensure PIO DMA is not set */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~PIO_USE_DMA));
-
-	/* and start the transfer */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | PIO_START));
-
-	/* Wait for the interrupt to indicate the end of the transfer.
-	 * (We need to wait on and clear rhe ATA_DEV_INT interrupt status)
-	 */
-	wait_complete(base, PIO_DONE_INT);
-}
-
-/**
- *
- *	Function:       read_atapi_register
- *
- *Description:    Reads from ATA Device Resgister
- *
- */
-
-static unsigned short read_atapi_register(void __iomem *base,
-		unsigned long ata_reg)
-{
-	/* Program the ATA_DEV_ADDR register with address of the
-	 * device register (0x01 to 0x0F).
-	 */
-	ATAPI_SET_DEV_ADDR(base, ata_reg);
-
-	/* Program the ATA_CTRL register with dir set to read (0) and
-	 */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~XFER_DIR));
-
-	/* ensure PIO DMA is not set */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~PIO_USE_DMA));
-
-	/* and start the transfer */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | PIO_START));
-
-	/* Wait for the interrupt to indicate the end of the transfer.
-	 * (PIO_DONE interrupt is set and it doesn't seem to matter
-	 * that we don't clear it)
-	 */
-	wait_complete(base, PIO_DONE_INT);
-
-	/* Read the ATA_DEV_RXBUF register with write data (to be
-	 * written into the device).
-	 */
-	return ATAPI_GET_DEV_RXBUF(base);
-}
-
-/**
- *
- *    Function:       write_atapi_register_data
- *
- *    Description:    Writes to ATA Device Resgister
- *
- */
-
-static void write_atapi_data(void __iomem *base,
-		int len, unsigned short *buf)
-{
-	int i;
-
-	/* Set transfer length to 1 */
-	ATAPI_SET_XFER_LEN(base, 1);
-
-	/* Program the ATA_DEV_ADDR register with address of the
-	 * ATA_REG_DATA
-	 */
-	ATAPI_SET_DEV_ADDR(base, ATA_REG_DATA);
-
-	/* Program the ATA_CTRL register with dir set to write (1)
-	 */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | XFER_DIR));
-
-	/* ensure PIO DMA is not set */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~PIO_USE_DMA));
-
-	for (i = 0; i < len; i++) {
-		/* Program the ATA_DEV_TXBUF register with write data (to be
-		 * written into the device).
-		 */
-		ATAPI_SET_DEV_TXBUF(base, buf[i]);
-
-		/* and start the transfer */
-		ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | PIO_START));
-
-		/* Wait for the interrupt to indicate the end of the transfer.
-		 * (We need to wait on and clear rhe ATA_DEV_INT
-		 * interrupt status)
-		 */
-		wait_complete(base, PIO_DONE_INT);
-	}
-}
-
-/**
- *
- *	Function:       read_atapi_register_data
- *
- *	Description:    Reads from ATA Device Resgister
- *
- */
-
-static void read_atapi_data(void __iomem *base,
-		int len, unsigned short *buf)
-{
-	int i;
-
-	/* Set transfer length to 1 */
-	ATAPI_SET_XFER_LEN(base, 1);
-
-	/* Program the ATA_DEV_ADDR register with address of the
-	 * ATA_REG_DATA
-	 */
-	ATAPI_SET_DEV_ADDR(base, ATA_REG_DATA);
-
-	/* Program the ATA_CTRL register with dir set to read (0) and
-	 */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~XFER_DIR));
-
-	/* ensure PIO DMA is not set */
-	ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~PIO_USE_DMA));
-
-	for (i = 0; i < len; i++) {
-		/* and start the transfer */
-		ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | PIO_START));
-
-		/* Wait for the interrupt to indicate the end of the transfer.
-		 * (PIO_DONE interrupt is set and it doesn't seem to matter
-		 * that we don't clear it)
-		 */
-		wait_complete(base, PIO_DONE_INT);
-
-		/* Read the ATA_DEV_RXBUF register with write data (to be
-		 * written into the device).
-		 */
-		buf[i] = ATAPI_GET_DEV_RXBUF(base);
-	}
-}
-
-/**
- *	bfin_tf_load - send taskfile registers to host controller
- *	@ap: Port to which output is sent
- *	@tf: ATA taskfile register set
- *
- *	Note: Original code is ata_sff_tf_load().
- */
-
-static void bfin_tf_load(struct ata_port *ap, const struct ata_taskfile *tf)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	unsigned int is_addr = tf->flags & ATA_TFLAG_ISADDR;
-
-	if (tf->ctl != ap->last_ctl) {
-		write_atapi_register(base, ATA_REG_CTRL, tf->ctl);
-		ap->last_ctl = tf->ctl;
-		ata_wait_idle(ap);
-	}
-
-	if (is_addr) {
-		if (tf->flags & ATA_TFLAG_LBA48) {
-			write_atapi_register(base, ATA_REG_FEATURE,
-						tf->hob_feature);
-			write_atapi_register(base, ATA_REG_NSECT,
-						tf->hob_nsect);
-			write_atapi_register(base, ATA_REG_LBAL, tf->hob_lbal);
-			write_atapi_register(base, ATA_REG_LBAM, tf->hob_lbam);
-			write_atapi_register(base, ATA_REG_LBAH, tf->hob_lbah);
-			dev_dbg(ap->dev, "hob: feat 0x%X nsect 0x%X, lba 0x%X "
-				 "0x%X 0x%X\n",
-				tf->hob_feature,
-				tf->hob_nsect,
-				tf->hob_lbal,
-				tf->hob_lbam,
-				tf->hob_lbah);
-		}
-
-		write_atapi_register(base, ATA_REG_FEATURE, tf->feature);
-		write_atapi_register(base, ATA_REG_NSECT, tf->nsect);
-		write_atapi_register(base, ATA_REG_LBAL, tf->lbal);
-		write_atapi_register(base, ATA_REG_LBAM, tf->lbam);
-		write_atapi_register(base, ATA_REG_LBAH, tf->lbah);
-		dev_dbg(ap->dev, "feat 0x%X nsect 0x%X lba 0x%X 0x%X 0x%X\n",
-			tf->feature,
-			tf->nsect,
-			tf->lbal,
-			tf->lbam,
-			tf->lbah);
-	}
-
-	if (tf->flags & ATA_TFLAG_DEVICE) {
-		write_atapi_register(base, ATA_REG_DEVICE, tf->device);
-		dev_dbg(ap->dev, "device 0x%X\n", tf->device);
-	}
-
-	ata_wait_idle(ap);
-}
-
-/**
- *	bfin_check_status - Read device status reg & clear interrupt
- *	@ap: port where the device is
- *
- *	Note: Original code is ata_check_status().
- */
-
-static u8 bfin_check_status(struct ata_port *ap)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	return read_atapi_register(base, ATA_REG_STATUS);
-}
-
-/**
- *	bfin_tf_read - input device's ATA taskfile shadow registers
- *	@ap: Port from which input is read
- *	@tf: ATA taskfile register set for storing input
- *
- *	Note: Original code is ata_sff_tf_read().
- */
-
-static void bfin_tf_read(struct ata_port *ap, struct ata_taskfile *tf)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-
-	tf->command = bfin_check_status(ap);
-	tf->feature = read_atapi_register(base, ATA_REG_ERR);
-	tf->nsect = read_atapi_register(base, ATA_REG_NSECT);
-	tf->lbal = read_atapi_register(base, ATA_REG_LBAL);
-	tf->lbam = read_atapi_register(base, ATA_REG_LBAM);
-	tf->lbah = read_atapi_register(base, ATA_REG_LBAH);
-	tf->device = read_atapi_register(base, ATA_REG_DEVICE);
-
-	if (tf->flags & ATA_TFLAG_LBA48) {
-		write_atapi_register(base, ATA_REG_CTRL, tf->ctl | ATA_HOB);
-		tf->hob_feature = read_atapi_register(base, ATA_REG_ERR);
-		tf->hob_nsect = read_atapi_register(base, ATA_REG_NSECT);
-		tf->hob_lbal = read_atapi_register(base, ATA_REG_LBAL);
-		tf->hob_lbam = read_atapi_register(base, ATA_REG_LBAM);
-		tf->hob_lbah = read_atapi_register(base, ATA_REG_LBAH);
-	}
-}
-
-/**
- *	bfin_exec_command - issue ATA command to host controller
- *	@ap: port to which command is being issued
- *	@tf: ATA taskfile register set
- *
- *	Note: Original code is ata_sff_exec_command().
- */
-
-static void bfin_exec_command(struct ata_port *ap,
-			      const struct ata_taskfile *tf)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	dev_dbg(ap->dev, "ata%u: cmd 0x%X\n", ap->print_id, tf->command);
-
-	write_atapi_register(base, ATA_REG_CMD, tf->command);
-	ata_sff_pause(ap);
-}
-
-/**
- *	bfin_check_altstatus - Read device alternate status reg
- *	@ap: port where the device is
- */
-
-static u8 bfin_check_altstatus(struct ata_port *ap)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	return read_atapi_register(base, ATA_REG_ALTSTATUS);
-}
-
-/**
- *	bfin_dev_select - Select device 0/1 on ATA bus
- *	@ap: ATA channel to manipulate
- *	@device: ATA device (numbered from zero) to select
- *
- *	Note: Original code is ata_sff_dev_select().
- */
-
-static void bfin_dev_select(struct ata_port *ap, unsigned int device)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	u8 tmp;
-
-	if (device == 0)
-		tmp = ATA_DEVICE_OBS;
-	else
-		tmp = ATA_DEVICE_OBS | ATA_DEV1;
-
-	write_atapi_register(base, ATA_REG_DEVICE, tmp);
-	ata_sff_pause(ap);
-}
-
-/**
- *	bfin_bmdma_setup - Set up IDE DMA transaction
- *	@qc: Info associated with this ATA transaction.
- *
- *	Note: Original code is ata_bmdma_setup().
- */
-
-static void bfin_bmdma_setup(struct ata_queued_cmd *qc)
-{
-	unsigned short config = WDSIZE_16;
-	struct scatterlist *sg;
-	unsigned int si;
-
-	dev_dbg(qc->ap->dev, "in atapi dma setup\n");
-	/* Program the ATA_CTRL register with dir */
-	if (qc->tf.flags & ATA_TFLAG_WRITE) {
-		/* fill the ATAPI DMA controller */
-		set_dma_config(CH_ATAPI_TX, config);
-		set_dma_x_modify(CH_ATAPI_TX, 2);
-		for_each_sg(qc->sg, sg, qc->n_elem, si) {
-			set_dma_start_addr(CH_ATAPI_TX, sg_dma_address(sg));
-			set_dma_x_count(CH_ATAPI_TX, sg_dma_len(sg) >> 1);
-		}
-	} else {
-		config |= WNR;
-		/* fill the ATAPI DMA controller */
-		set_dma_config(CH_ATAPI_RX, config);
-		set_dma_x_modify(CH_ATAPI_RX, 2);
-		for_each_sg(qc->sg, sg, qc->n_elem, si) {
-			set_dma_start_addr(CH_ATAPI_RX, sg_dma_address(sg));
-			set_dma_x_count(CH_ATAPI_RX, sg_dma_len(sg) >> 1);
-		}
-	}
-}
-
-/**
- *	bfin_bmdma_start - Start an IDE DMA transaction
- *	@qc: Info associated with this ATA transaction.
- *
- *	Note: Original code is ata_bmdma_start().
- */
-
-static void bfin_bmdma_start(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	struct scatterlist *sg;
-	unsigned int si;
-
-	dev_dbg(qc->ap->dev, "in atapi dma start\n");
-	if (!(ap->udma_mask || ap->mwdma_mask))
-		return;
-
-	/* start ATAPI DMA controller*/
-	if (qc->tf.flags & ATA_TFLAG_WRITE) {
-		/*
-		 * On blackfin arch, uncacheable memory is not
-		 * allocated with flag GFP_DMA. DMA buffer from
-		 * common kenel code should be flushed if WB
-		 * data cache is enabled. Otherwise, this loop
-		 * is an empty loop and optimized out.
-		 */
-		for_each_sg(qc->sg, sg, qc->n_elem, si) {
-			flush_dcache_range(sg_dma_address(sg),
-				sg_dma_address(sg) + sg_dma_len(sg));
-		}
-		enable_dma(CH_ATAPI_TX);
-		dev_dbg(qc->ap->dev, "enable udma write\n");
-
-		/* Send ATA DMA write command */
-		bfin_exec_command(ap, &qc->tf);
-
-		/* set ATA DMA write direction */
-		ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base)
-			| XFER_DIR));
-	} else {
-		enable_dma(CH_ATAPI_RX);
-		dev_dbg(qc->ap->dev, "enable udma read\n");
-
-		/* Send ATA DMA read command */
-		bfin_exec_command(ap, &qc->tf);
-
-		/* set ATA DMA read direction */
-		ATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base)
-			& ~XFER_DIR));
-	}
-
-	/* Reset all transfer count */
-	ATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base) | TFRCNT_RST);
-
-	/* Set ATAPI state machine contorl in terminate sequence */
-	ATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base) | END_ON_TERM);
-
-	/* Set transfer length to buffer len */
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		ATAPI_SET_XFER_LEN(base, (sg_dma_len(sg) >> 1));
-	}
-
-	/* Enable ATA DMA operation*/
-	if (ap->udma_mask)
-		ATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base)
-			| ULTRA_START);
-	else
-		ATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base)
-			| MULTI_START);
-}
-
-/**
- *	bfin_bmdma_stop - Stop IDE DMA transfer
- *	@qc: Command we are ending DMA for
- */
-
-static void bfin_bmdma_stop(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct scatterlist *sg;
-	unsigned int si;
-
-	dev_dbg(qc->ap->dev, "in atapi dma stop\n");
-	if (!(ap->udma_mask || ap->mwdma_mask))
-		return;
-
-	/* stop ATAPI DMA controller*/
-	if (qc->tf.flags & ATA_TFLAG_WRITE)
-		disable_dma(CH_ATAPI_TX);
-	else {
-		disable_dma(CH_ATAPI_RX);
-		if (ap->hsm_task_state & HSM_ST_LAST) {
-			/*
-			 * On blackfin arch, uncacheable memory is not
-			 * allocated with flag GFP_DMA. DMA buffer from
-			 * common kenel code should be invalidated if
-			 * data cache is enabled. Otherwise, this loop
-			 * is an empty loop and optimized out.
-			 */
-			for_each_sg(qc->sg, sg, qc->n_elem, si) {
-				invalidate_dcache_range(
-					sg_dma_address(sg),
-					sg_dma_address(sg)
-					+ sg_dma_len(sg));
-			}
-		}
-	}
-}
-
-/**
- *	bfin_devchk - PATA device presence detection
- *	@ap: ATA channel to examine
- *	@device: Device to examine (starting at zero)
- *
- *	Note: Original code is ata_devchk().
- */
-
-static unsigned int bfin_devchk(struct ata_port *ap,
-				unsigned int device)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	u8 nsect, lbal;
-
-	bfin_dev_select(ap, device);
-
-	write_atapi_register(base, ATA_REG_NSECT, 0x55);
-	write_atapi_register(base, ATA_REG_LBAL, 0xaa);
-
-	write_atapi_register(base, ATA_REG_NSECT, 0xaa);
-	write_atapi_register(base, ATA_REG_LBAL, 0x55);
-
-	write_atapi_register(base, ATA_REG_NSECT, 0x55);
-	write_atapi_register(base, ATA_REG_LBAL, 0xaa);
-
-	nsect = read_atapi_register(base, ATA_REG_NSECT);
-	lbal = read_atapi_register(base, ATA_REG_LBAL);
-
-	if ((nsect == 0x55) && (lbal == 0xaa))
-		return 1;	/* we found a device */
-
-	return 0;		/* nothing found */
-}
-
-/**
- *	bfin_bus_post_reset - PATA device post reset
- *
- *	Note: Original code is ata_bus_post_reset().
- */
-
-static void bfin_bus_post_reset(struct ata_port *ap, unsigned int devmask)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	unsigned int dev0 = devmask & (1 << 0);
-	unsigned int dev1 = devmask & (1 << 1);
-	unsigned long deadline;
-
-	/* if device 0 was found in ata_devchk, wait for its
-	 * BSY bit to clear
-	 */
-	if (dev0)
-		ata_sff_busy_sleep(ap, ATA_TMOUT_BOOT_QUICK, ATA_TMOUT_BOOT);
-
-	/* if device 1 was found in ata_devchk, wait for
-	 * register access, then wait for BSY to clear
-	 */
-	deadline = ata_deadline(jiffies, ATA_TMOUT_BOOT);
-	while (dev1) {
-		u8 nsect, lbal;
-
-		bfin_dev_select(ap, 1);
-		nsect = read_atapi_register(base, ATA_REG_NSECT);
-		lbal = read_atapi_register(base, ATA_REG_LBAL);
-		if ((nsect == 1) && (lbal == 1))
-			break;
-		if (time_after(jiffies, deadline)) {
-			dev1 = 0;
-			break;
-		}
-		msleep(50);	/* give drive a breather */
-	}
-	if (dev1)
-		ata_sff_busy_sleep(ap, ATA_TMOUT_BOOT_QUICK, ATA_TMOUT_BOOT);
-
-	/* is all this really necessary? */
-	bfin_dev_select(ap, 0);
-	if (dev1)
-		bfin_dev_select(ap, 1);
-	if (dev0)
-		bfin_dev_select(ap, 0);
-}
-
-/**
- *	bfin_bus_softreset - PATA device software reset
- *
- *	Note: Original code is ata_bus_softreset().
- */
-
-static unsigned int bfin_bus_softreset(struct ata_port *ap,
-				       unsigned int devmask)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-
-	/* software reset.  causes dev0 to be selected */
-	write_atapi_register(base, ATA_REG_CTRL, ap->ctl);
-	udelay(20);
-	write_atapi_register(base, ATA_REG_CTRL, ap->ctl | ATA_SRST);
-	udelay(20);
-	write_atapi_register(base, ATA_REG_CTRL, ap->ctl);
-
-	/* spec mandates ">= 2ms" before checking status.
-	 * We wait 150ms, because that was the magic delay used for
-	 * ATAPI devices in Hale Landis's ATADRVR, for the period of time
-	 * between when the ATA command register is written, and then
-	 * status is checked.  Because waiting for "a while" before
-	 * checking status is fine, post SRST, we perform this magic
-	 * delay here as well.
-	 *
-	 * Old drivers/ide uses the 2mS rule and then waits for ready
-	 */
-	msleep(150);
-
-	/* Before we perform post reset processing we want to see if
-	 * the bus shows 0xFF because the odd clown forgets the D7
-	 * pulldown resistor.
-	 */
-	if (bfin_check_status(ap) == 0xFF)
-		return 0;
-
-	bfin_bus_post_reset(ap, devmask);
-
-	return 0;
-}
-
-/**
- *	bfin_softreset - reset host port via ATA SRST
- *	@ap: port to reset
- *	@classes: resulting classes of attached devices
- *
- *	Note: Original code is ata_sff_softreset().
- */
-
-static int bfin_softreset(struct ata_link *link, unsigned int *classes,
-			  unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	unsigned int slave_possible = ap->flags & ATA_FLAG_SLAVE_POSS;
-	unsigned int devmask = 0, err_mask;
-	u8 err;
-
-	/* determine if device 0/1 are present */
-	if (bfin_devchk(ap, 0))
-		devmask |= (1 << 0);
-	if (slave_possible && bfin_devchk(ap, 1))
-		devmask |= (1 << 1);
-
-	/* select device 0 again */
-	bfin_dev_select(ap, 0);
-
-	/* issue bus reset */
-	err_mask = bfin_bus_softreset(ap, devmask);
-	if (err_mask) {
-		ata_port_printk(ap, KERN_ERR, "SRST failed (err_mask=0x%x)\n",
-				err_mask);
-		return -EIO;
-	}
-
-	/* determine by signature whether we have ATA or ATAPI devices */
-	classes[0] = ata_sff_dev_classify(&ap->link.device[0],
-				devmask & (1 << 0), &err);
-	if (slave_possible && err != 0x81)
-		classes[1] = ata_sff_dev_classify(&ap->link.device[1],
-					devmask & (1 << 1), &err);
-
-	return 0;
-}
-
-/**
- *	bfin_bmdma_status - Read IDE DMA status
- *	@ap: Port associated with this ATA transaction.
- */
-
-static unsigned char bfin_bmdma_status(struct ata_port *ap)
-{
-	unsigned char host_stat = 0;
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	unsigned short int_status = ATAPI_GET_INT_STATUS(base);
-
-	if (ATAPI_GET_STATUS(base) & (MULTI_XFER_ON|ULTRA_XFER_ON))
-		host_stat |= ATA_DMA_ACTIVE;
-	if (int_status & (MULTI_DONE_INT|UDMAIN_DONE_INT|UDMAOUT_DONE_INT|
-		ATAPI_DEV_INT))
-		host_stat |= ATA_DMA_INTR;
-	if (int_status & (MULTI_TERM_INT|UDMAIN_TERM_INT|UDMAOUT_TERM_INT))
-		host_stat |= ATA_DMA_ERR|ATA_DMA_INTR;
-
-	dev_dbg(ap->dev, "ATAPI: host_stat=0x%x\n", host_stat);
-
-	return host_stat;
-}
-
-/**
- *	bfin_data_xfer - Transfer data by PIO
- *	@adev: device for this I/O
- *	@buf: data buffer
- *	@buflen: buffer length
- *	@write_data: read/write
- *
- *	Note: Original code is ata_sff_data_xfer().
- */
-
-static unsigned int bfin_data_xfer(struct ata_device *dev, unsigned char *buf,
-				   unsigned int buflen, int rw)
-{
-	struct ata_port *ap = dev->link->ap;
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	unsigned int words = buflen >> 1;
-	unsigned short *buf16 = (u16 *)buf;
-
-	/* Transfer multiple of 2 bytes */
-	if (rw == READ)
-		read_atapi_data(base, words, buf16);
-	else
-		write_atapi_data(base, words, buf16);
-
-	/* Transfer trailing 1 byte, if any. */
-	if (unlikely(buflen & 0x01)) {
-		unsigned short align_buf[1] = { 0 };
-		unsigned char *trailing_buf = buf + buflen - 1;
-
-		if (rw == READ) {
-			read_atapi_data(base, 1, align_buf);
-			memcpy(trailing_buf, align_buf, 1);
-		} else {
-			memcpy(align_buf, trailing_buf, 1);
-			write_atapi_data(base, 1, align_buf);
-		}
-		words++;
-	}
-
-	return words << 1;
-}
-
-/**
- *	bfin_irq_clear - Clear ATAPI interrupt.
- *	@ap: Port associated with this ATA transaction.
- *
- *	Note: Original code is ata_sff_irq_clear().
- */
-
-static void bfin_irq_clear(struct ata_port *ap)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-
-	dev_dbg(ap->dev, "in atapi irq clear\n");
-	ATAPI_SET_INT_STATUS(base, ATAPI_GET_INT_STATUS(base)|ATAPI_DEV_INT
-		| MULTI_DONE_INT | UDMAIN_DONE_INT | UDMAOUT_DONE_INT
-		| MULTI_TERM_INT | UDMAIN_TERM_INT | UDMAOUT_TERM_INT);
-}
-
-/**
- *	bfin_irq_on - Enable interrupts on a port.
- *	@ap: Port on which interrupts are enabled.
- *
- *	Note: Original code is ata_sff_irq_on().
- */
-
-static unsigned char bfin_irq_on(struct ata_port *ap)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-	u8 tmp;
-
-	dev_dbg(ap->dev, "in atapi irq on\n");
-	ap->ctl &= ~ATA_NIEN;
-	ap->last_ctl = ap->ctl;
-
-	write_atapi_register(base, ATA_REG_CTRL, ap->ctl);
-	tmp = ata_wait_idle(ap);
-
-	bfin_irq_clear(ap);
-
-	return tmp;
-}
-
-/**
- *	bfin_freeze - Freeze DMA controller port
- *	@ap: port to freeze
- *
- *	Note: Original code is ata_sff_freeze().
- */
-
-static void bfin_freeze(struct ata_port *ap)
-{
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-
-	dev_dbg(ap->dev, "in atapi dma freeze\n");
-	ap->ctl |= ATA_NIEN;
-	ap->last_ctl = ap->ctl;
-
-	write_atapi_register(base, ATA_REG_CTRL, ap->ctl);
-
-	/* Under certain circumstances, some controllers raise IRQ on
-	 * ATA_NIEN manipulation.  Also, many controllers fail to mask
-	 * previously pending IRQ on ATA_NIEN assertion.  Clear it.
-	 */
-	ap->ops->sff_check_status(ap);
-
-	bfin_irq_clear(ap);
-}
-
-/**
- *	bfin_thaw - Thaw DMA controller port
- *	@ap: port to thaw
- *
- *	Note: Original code is ata_sff_thaw().
- */
-
-void bfin_thaw(struct ata_port *ap)
-{
-	dev_dbg(ap->dev, "in atapi dma thaw\n");
-	bfin_check_status(ap);
-	bfin_irq_on(ap);
-}
-
-/**
- *	bfin_postreset - standard postreset callback
- *	@ap: the target ata_port
- *	@classes: classes of attached devices
- *
- *	Note: Original code is ata_sff_postreset().
- */
-
-static void bfin_postreset(struct ata_link *link, unsigned int *classes)
-{
-	struct ata_port *ap = link->ap;
-	void __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;
-
-	/* re-enable interrupts */
-	bfin_irq_on(ap);
-
-	/* is double-select really necessary? */
-	if (classes[0] != ATA_DEV_NONE)
-		bfin_dev_select(ap, 1);
-	if (classes[1] != ATA_DEV_NONE)
-		bfin_dev_select(ap, 0);
-
-	/* bail out if no device is present */
-	if (classes[0] == ATA_DEV_NONE && classes[1] == ATA_DEV_NONE) {
-		return;
-	}
-
-	/* set up device control */
-	write_atapi_register(base, ATA_REG_CTRL, ap->ctl);
-}
-
-static void bfin_port_stop(struct ata_port *ap)
-{
-	dev_dbg(ap->dev, "in atapi port stop\n");
-	if (ap->udma_mask != 0 || ap->mwdma_mask != 0) {
-		free_dma(CH_ATAPI_RX);
-		free_dma(CH_ATAPI_TX);
-	}
-}
-
-static int bfin_port_start(struct ata_port *ap)
-{
-	dev_dbg(ap->dev, "in atapi port start\n");
-	if (!(ap->udma_mask || ap->mwdma_mask))
-		return 0;
-
-	if (request_dma(CH_ATAPI_RX, "BFIN ATAPI RX DMA") >= 0) {
-		if (request_dma(CH_ATAPI_TX,
-			"BFIN ATAPI TX DMA") >= 0)
-			return 0;
-
-		free_dma(CH_ATAPI_RX);
-	}
-
-	ap->udma_mask = 0;
-	ap->mwdma_mask = 0;
-	dev_err(ap->dev, "Unable to request ATAPI DMA!"
-		" Continue in PIO mode.\n");
-
-	return 0;
-}
-
-static unsigned int bfin_ata_host_intr(struct ata_port *ap,
-				   struct ata_queued_cmd *qc)
-{
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	u8 status, host_stat = 0;
-
-	VPRINTK("ata%u: protocol %d task_state %d\n",
-		ap->print_id, qc->tf.protocol, ap->hsm_task_state);
-
-	/* Check whether we are expecting interrupt in this state */
-	switch (ap->hsm_task_state) {
-	case HSM_ST_FIRST:
-		/* Some pre-ATAPI-4 devices assert INTRQ
-		 * at this state when ready to receive CDB.
-		 */
-
-		/* Check the ATA_DFLAG_CDB_INTR flag is enough here.
-		 * The flag was turned on only for atapi devices.
-		 * No need to check is_atapi_taskfile(&qc->tf) again.
-		 */
-		if (!(qc->dev->flags & ATA_DFLAG_CDB_INTR))
-			goto idle_irq;
-		break;
-	case HSM_ST_LAST:
-		if (qc->tf.protocol == ATA_PROT_DMA ||
-		    qc->tf.protocol == ATAPI_PROT_DMA) {
-			/* check status of DMA engine */
-			host_stat = ap->ops->bmdma_status(ap);
-			VPRINTK("ata%u: host_stat 0x%X\n",
-				ap->print_id, host_stat);
-
-			/* if it's not our irq... */
-			if (!(host_stat & ATA_DMA_INTR))
-				goto idle_irq;
-
-			/* before we do anything else, clear DMA-Start bit */
-			ap->ops->bmdma_stop(qc);
-
-			if (unlikely(host_stat & ATA_DMA_ERR)) {
-				/* error when transfering data to/from memory */
-				qc->err_mask |= AC_ERR_HOST_BUS;
-				ap->hsm_task_state = HSM_ST_ERR;
-			}
-		}
-		break;
-	case HSM_ST:
-		break;
-	default:
-		goto idle_irq;
-	}
-
-	/* check altstatus */
-	status = ap->ops->sff_check_altstatus(ap);
-	if (status & ATA_BUSY)
-		goto busy_ata;
-
-	/* check main status, clearing INTRQ */
-	status = ap->ops->sff_check_status(ap);
-	if (unlikely(status & ATA_BUSY))
-		goto busy_ata;
-
-	/* ack bmdma irq events */
-	ap->ops->sff_irq_clear(ap);
-
-	ata_sff_hsm_move(ap, qc, status, 0);
-
-	if (unlikely(qc->err_mask) && (qc->tf.protocol == ATA_PROT_DMA ||
-				       qc->tf.protocol == ATAPI_PROT_DMA))
-		ata_ehi_push_desc(ehi, "BMDMA stat 0x%x", host_stat);
-
-busy_ata:
-	return 1;	/* irq handled */
-
-idle_irq:
-	ap->stats.idle_irq++;
-
-#ifdef ATA_IRQ_TRAP
-	if ((ap->stats.idle_irq % 1000) == 0) {
-		ap->ops->irq_ack(ap, 0); /* debug trap */
-		ata_port_printk(ap, KERN_WARNING, "irq trap\n");
-		return 1;
-	}
-#endif
-	return 0;	/* irq not handled */
-}
-
-static irqreturn_t bfin_ata_interrupt(int irq, void *dev_instance)
-{
-	struct ata_host *host = dev_instance;
-	unsigned int i;
-	unsigned int handled = 0;
-	unsigned long flags;
-
-	/* TODO: make _irqsave conditional on x86 PCI IDE legacy mode */
-	spin_lock_irqsave(&host->lock, flags);
-
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap;
-
-		ap = host->ports[i];
-		if (ap &&
-		    !(ap->flags & ATA_FLAG_DISABLED)) {
-			struct ata_queued_cmd *qc;
-
-			qc = ata_qc_from_tag(ap, ap->link.active_tag);
-			if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)) &&
-			    (qc->flags & ATA_QCFLAG_ACTIVE))
-				handled |= bfin_ata_host_intr(ap, qc);
-		}
-	}
-
-	spin_unlock_irqrestore(&host->lock, flags);
-
-	return IRQ_RETVAL(handled);
-}
-
-
-static struct scsi_host_template bfin_sht = {
-	ATA_BASE_SHT(DRV_NAME),
-	.sg_tablesize		= SG_NONE,
-	.dma_boundary		= ATA_DMA_BOUNDARY,
-};
-
-static struct ata_port_operations bfin_pata_ops = {
-	.inherits		= &ata_sff_port_ops,
-
-	.set_piomode		= bfin_set_piomode,
-	.set_dmamode		= bfin_set_dmamode,
-
-	.sff_tf_load		= bfin_tf_load,
-	.sff_tf_read		= bfin_tf_read,
-	.sff_exec_command	= bfin_exec_command,
-	.sff_check_status	= bfin_check_status,
-	.sff_check_altstatus	= bfin_check_altstatus,
-	.sff_dev_select		= bfin_dev_select,
-
-	.bmdma_setup		= bfin_bmdma_setup,
-	.bmdma_start		= bfin_bmdma_start,
-	.bmdma_stop		= bfin_bmdma_stop,
-	.bmdma_status		= bfin_bmdma_status,
-	.sff_data_xfer		= bfin_data_xfer,
-
-	.qc_prep		= ata_noop_qc_prep,
-
-	.freeze			= bfin_freeze,
-	.thaw			= bfin_thaw,
-	.softreset		= bfin_softreset,
-	.postreset		= bfin_postreset,
-
-	.sff_irq_clear		= bfin_irq_clear,
-	.sff_irq_on		= bfin_irq_on,
-
-	.port_start		= bfin_port_start,
-	.port_stop		= bfin_port_stop,
-};
-
-static struct ata_port_info bfin_port_info[] = {
-	{
-		.flags		= ATA_FLAG_SLAVE_POSS
-				| ATA_FLAG_MMIO
-				| ATA_FLAG_NO_LEGACY,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= 0,
-		.udma_mask	= 0,
-		.port_ops	= &bfin_pata_ops,
-	},
-};
-
-/**
- *	bfin_reset_controller - initialize BF54x ATAPI controller.
- */
-
-static int bfin_reset_controller(struct ata_host *host)
-{
-	void __iomem *base = (void __iomem *)host->ports[0]->ioaddr.ctl_addr;
-	int count;
-	unsigned short status;
-
-	/* Disable all ATAPI interrupts */
-	ATAPI_SET_INT_MASK(base, 0);
-	SSYNC();
-
-	/* Assert the RESET signal 25us*/
-	ATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base) | DEV_RST);
-	udelay(30);
-
-	/* Negate the RESET signal for 2ms*/
-	ATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base) & ~DEV_RST);
-	msleep(2);
-
-	/* Wait on Busy flag to clear */
-	count = 10000000;
-	do {
-		status = read_atapi_register(base, ATA_REG_STATUS);
-	} while (--count && (status & ATA_BUSY));
-
-	/* Enable only ATAPI Device interrupt */
-	ATAPI_SET_INT_MASK(base, 1);
-	SSYNC();
-
-	return (!count);
-}
-
-/**
- *	atapi_io_port - define atapi peripheral port pins.
- */
-static unsigned short atapi_io_port[] = {
-	P_ATAPI_RESET,
-	P_ATAPI_DIOR,
-	P_ATAPI_DIOW,
-	P_ATAPI_CS0,
-	P_ATAPI_CS1,
-	P_ATAPI_DMACK,
-	P_ATAPI_DMARQ,
-	P_ATAPI_INTRQ,
-	P_ATAPI_IORDY,
-	0
-};
-
-/**
- *	bfin_atapi_probe	-	attach a bfin atapi interface
- *	@pdev: platform device
- *
- *	Register a bfin atapi interface.
- *
- *
- *	Platform devices are expected to contain 2 resources per port:
- *
- *		- I/O Base (IORESOURCE_IO)
- *		- IRQ	   (IORESOURCE_IRQ)
- *
- */
-static int __devinit bfin_atapi_probe(struct platform_device *pdev)
-{
-	int board_idx = 0;
-	struct resource *res;
-	struct ata_host *host;
-	unsigned int fsclk = get_sclk();
-	int udma_mode = 5;
-	const struct ata_port_info *ppi[] =
-		{ &bfin_port_info[board_idx], NULL };
-
-	/*
-	 * Simple resource validation ..
-	 */
-	if (unlikely(pdev->num_resources != 2)) {
-		dev_err(&pdev->dev, "invalid number of resources\n");
-		return -EINVAL;
-	}
-
-	/*
-	 * Get the register base first
-	 */
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	if (res == NULL)
-		return -EINVAL;
-
-	while (bfin_port_info[board_idx].udma_mask > 0 &&
-			udma_fsclk[udma_mode] > fsclk) {
-		udma_mode--;
-		bfin_port_info[board_idx].udma_mask >>= 1;
-	}
-
-	/*
-	 * Now that that's out of the way, wire up the port..
-	 */
-	host = ata_host_alloc_pinfo(&pdev->dev, ppi, 1);
-	if (!host)
-		return -ENOMEM;
-
-	host->ports[0]->ioaddr.ctl_addr = (void *)res->start;
-
-	if (peripheral_request_list(atapi_io_port, "atapi-io-port")) {
-		dev_err(&pdev->dev, "Requesting Peripherals faild\n");
-		return -EFAULT;
-	}
-
-	if (bfin_reset_controller(host)) {
-		peripheral_free_list(atapi_io_port);
-		dev_err(&pdev->dev, "Fail to reset ATAPI device\n");
-		return -EFAULT;
-	}
-
-	if (ata_host_activate(host, platform_get_irq(pdev, 0),
-		bfin_ata_interrupt, IRQF_SHARED, &bfin_sht) != 0) {
-		peripheral_free_list(atapi_io_port);
-		dev_err(&pdev->dev, "Fail to attach ATAPI device\n");
-		return -ENODEV;
-	}
-
-	dev_set_drvdata(&pdev->dev, host);
-
-	return 0;
-}
-
-/**
- *	bfin_atapi_remove	-	unplug a bfin atapi interface
- *	@pdev: platform device
- *
- *	A bfin atapi device has been unplugged. Perform the needed
- *	cleanup. Also called on module unload for any active devices.
- */
-static int __devexit bfin_atapi_remove(struct platform_device *pdev)
-{
-	struct device *dev = &pdev->dev;
-	struct ata_host *host = dev_get_drvdata(dev);
-
-	ata_host_detach(host);
-	dev_set_drvdata(&pdev->dev, NULL);
-
-	peripheral_free_list(atapi_io_port);
-
-	return 0;
-}
-
-#ifdef CONFIG_PM
-static int bfin_atapi_suspend(struct platform_device *pdev, pm_message_t state)
-{
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	if (host)
-		return ata_host_suspend(host, state);
-	else
-		return 0;
-}
-
-static int bfin_atapi_resume(struct platform_device *pdev)
-{
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int ret;
-
-	if (host) {
-		ret = bfin_reset_controller(host);
-		if (ret) {
-			printk(KERN_ERR DRV_NAME ": Error during HW init\n");
-			return ret;
-		}
-		ata_host_resume(host);
-	}
-
-	return 0;
-}
-#else
-#define bfin_atapi_suspend NULL
-#define bfin_atapi_resume NULL
-#endif
-
-static struct platform_driver bfin_atapi_driver = {
-	.probe			= bfin_atapi_probe,
-	.remove			= __devexit_p(bfin_atapi_remove),
-	.suspend		= bfin_atapi_suspend,
-	.resume			= bfin_atapi_resume,
-	.driver = {
-		.name		= DRV_NAME,
-		.owner		= THIS_MODULE,
-	},
-};
-
-#define ATAPI_MODE_SIZE		10
-static char bfin_atapi_mode[ATAPI_MODE_SIZE];
-
-static int __init bfin_atapi_init(void)
-{
-	pr_info("register bfin atapi driver\n");
-
-	switch(bfin_atapi_mode[0]) {
-	case 'p':
-	case 'P':
-		break;
-	case 'm':
-	case 'M':
-		bfin_port_info[0].mwdma_mask = ATA_MWDMA2;
-		break;
-	default:
-		bfin_port_info[0].udma_mask = ATA_UDMA5;
-	};
-
-	return platform_driver_register(&bfin_atapi_driver);
-}
-
-static void __exit bfin_atapi_exit(void)
-{
-	platform_driver_unregister(&bfin_atapi_driver);
-}
-
-module_init(bfin_atapi_init);
-module_exit(bfin_atapi_exit);
-/*
- * ATAPI mode:
- * pio/PIO
- * udma/UDMA (default)
- * mwdma/MWDMA
- */
-module_param_string(bfin_atapi_mode, bfin_atapi_mode, ATAPI_MODE_SIZE, 0);
-
-MODULE_AUTHOR("Sonic Zhang <sonic.zhang@analog.com>");
-MODULE_DESCRIPTION("PATA driver for blackfin 54x ATAPI controller");
-MODULE_LICENSE("GPL");
-MODULE_VERSION(DRV_VERSION);
-MODULE_ALIAS("platform:" DRV_NAME);
diff -Nur linux-sh4/drivers/ata.org/pata_cmd640.c linux-sh4/drivers/ata/pata_cmd640.c
--- linux-sh4/drivers/ata.org/pata_cmd640.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_cmd640.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_cmd640.c 	- CMD640 PCI PATA for new ATA layer
  *			  (C) 2007 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  * Based upon
  *  linux/drivers/ide/pci/cmd640.c		Version 1.02  Sep 01, 1996
@@ -106,8 +107,8 @@
 		pci_write_config_byte(pdev, arttim + 1, (t.active << 4) | t.recover);
 	} else {
 		/* Save the shared timings for channel, they will be loaded
-		   by qc_issue. Reloading the setup time is expensive so we
-		   keep a merged one loaded */
+		   by qc_issue_prot. Reloading the setup time is expensive
+		   so we keep a merged one loaded */
 		pci_read_config_byte(pdev, ARTIM23, &reg);
 		reg &= 0x3F;
 		reg |= t.setup;
@@ -118,14 +119,14 @@
 
 
 /**
- *	cmd640_qc_issue	-	command preparation hook
+ *	cmd640_qc_issue_prot	-	command preparation hook
  *	@qc: Command to be issued
  *
  *	Channel 1 has shared timings. We must reprogram the
  *	clock each drive 2/3 switch we do.
  */
 
-static unsigned int cmd640_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int cmd640_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
@@ -136,7 +137,7 @@
 		pci_write_config_byte(pdev, DRWTIM23, timing->reg58[adev->devno]);
 		timing->last = adev->devno;
 	}
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 /**
@@ -152,7 +153,7 @@
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	struct cmd640_reg *timing;
 
-	int ret = ata_sff_port_start(ap);
+	int ret = ata_port_start(ap);
 	if (ret < 0)
 		return ret;
 
@@ -165,16 +166,55 @@
 }
 
 static struct scsi_host_template cmd640_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations cmd640_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	/* In theory xfer_noirq is not needed once we kill the prefetcher */
-	.sff_data_xfer	= ata_sff_data_xfer_noirq,
-	.qc_issue	= cmd640_qc_issue,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= cmd640_set_piomode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= cmd640_qc_issue_prot,
+
+	/* In theory this is not needed once we kill the prefetcher */
+	.data_xfer	= ata_data_xfer_noirq,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
 	.port_start	= cmd640_port_start,
 };
 
@@ -210,36 +250,26 @@
 static int cmd640_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &cmd640_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
+		.pio_mask = 0x1f,
 		.port_ops = &cmd640_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
-	int rc;
-
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
 
 	cmd640_hardware_init(pdev);
-
-	return ata_pci_sff_init_one(pdev, ppi, &cmd640_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
-#ifdef CONFIG_PM
 static int cmd640_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
 	cmd640_hardware_init(pdev);
-	ata_host_resume(host);
+#ifdef CONFIG_PM
+	return ata_pci_device_resume(pdev);
+#else
 	return 0;
-}
 #endif
+}
 
 static const struct pci_device_id cmd640[] = {
 	{ PCI_VDEVICE(CMD, 0x640), 0 },
@@ -253,8 +283,8 @@
 	.remove		= ata_pci_remove_one,
 #ifdef CONFIG_PM
 	.suspend	= ata_pci_device_suspend,
-	.resume		= cmd640_reinit_one,
 #endif
+	.resume		= cmd640_reinit_one,
 };
 
 static int __init cmd640_init(void)
diff -Nur linux-sh4/drivers/ata.org/pata_cmd64x.c linux-sh4/drivers/ata/pata_cmd64x.c
--- linux-sh4/drivers/ata.org/pata_cmd64x.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_cmd64x.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,8 +1,7 @@
 /*
  * pata_cmd64x.c 	- CMD64x PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
- *			  Alan Cox <alan@lxorguk.ukuu.org.uk>
- *			  (C) 2009-2010 Bartlomiej Zolnierkiewicz
+ *			  Alan Cox <alan@redhat.com>
  *
  * Based upon
  * linux/drivers/ide/pci/cmd64x.c		Version 1.30	Sept 10, 2002
@@ -32,7 +31,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "pata_cmd64x"
-#define DRV_VERSION "0.2.5"
+#define DRV_VERSION "0.2.4"
 
 /*
  * CMD64x specific registers definition.
@@ -40,10 +39,11 @@
 
 enum {
 	CFR 		= 0x50,
-		CFR_INTR_CH0  = 0x04,
-	CNTRL		= 0x51,
-		CNTRL_CH0     = 0x04,
-		CNTRL_CH1     = 0x08,
+		CFR_INTR_CH0  = 0x02,
+	CNTRL 		= 0x51,
+		CNTRL_DIS_RA0 = 0x40,
+		CNTRL_DIS_RA1 = 0x80,
+		CNTRL_ENA_2ND = 0x08,
 	CMDTIM 		= 0x52,
 	ARTTIM0 	= 0x53,
 	DRWTIM0 	= 0x54,
@@ -53,6 +53,9 @@
 		ARTTIM23_DIS_RA2  = 0x04,
 		ARTTIM23_DIS_RA3  = 0x08,
 		ARTTIM23_INTR_CH1 = 0x10,
+	ARTTIM2 	= 0x57,
+	ARTTIM3 	= 0x57,
+	DRWTIM23	= 0x58,
 	DRWTIM2 	= 0x58,
 	BRST 		= 0x59,
 	DRWTIM3 	= 0x5b,
@@ -60,11 +63,14 @@
 	MRDMODE		= 0x71,
 		MRDMODE_INTR_CH0 = 0x04,
 		MRDMODE_INTR_CH1 = 0x08,
+		MRDMODE_BLK_CH0  = 0x10,
+		MRDMODE_BLK_CH1	 = 0x20,
 	BMIDESR0	= 0x72,
 	UDIDETCR0	= 0x73,
 	DTPR0		= 0x74,
 	BMIDECR1	= 0x78,
 	BMIDECSR	= 0x79,
+	BMIDESR1	= 0x7A,
 	UDIDETCR1	= 0x7B,
 	DTPR1		= 0x7C
 };
@@ -82,15 +88,14 @@
 }
 
 /**
- *	cmd64x_set_piomode	-	set PIO and MWDMA timing
+ *	cmd64x_set_piomode	-	set initial PIO mode data
  *	@ap: ATA interface
  *	@adev: ATA device
- *	@mode: mode
  *
- *	Called to do the PIO and MWDMA mode setup.
+ *	Called to do the PIO mode setup.
  */
 
-static void cmd64x_set_timing(struct ata_port *ap, struct ata_device *adev, u8 mode)
+static void cmd64x_set_piomode(struct ata_port *ap, struct ata_device *adev)
 {
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	struct ata_timing t;
@@ -112,9 +117,8 @@
 	int arttim = arttim_port[ap->port_no][adev->devno];
 	int drwtim = drwtim_port[ap->port_no][adev->devno];
 
-	/* ata_timing_compute is smart and will produce timings for MWDMA
-	   that don't violate the drives PIO capabilities. */
-	if (ata_timing_compute(adev, mode, &t, T, 0) < 0) {
+
+	if (ata_timing_compute(adev, adev->pio_mode, &t, T, 0) < 0) {
 		printk(KERN_ERR DRV_NAME ": mode computation failed.\n");
 		return;
 	}
@@ -141,9 +145,7 @@
 	/* Now convert the clocks into values we can actually stuff into
 	   the chip */
 
-	if (t.recover == 16)
-		t.recover = 0;
-	else if (t.recover > 1)
+	if (t.recover > 1)
 		t.recover--;
 	else
 		t.recover = 15;
@@ -166,20 +168,6 @@
 }
 
 /**
- *	cmd64x_set_piomode	-	set initial PIO mode data
- *	@ap: ATA interface
- *	@adev: ATA device
- *
- *	Used when configuring the devices ot set the PIO timings. All the
- *	actual work is done by the PIO/MWDMA setting helper
- */
-
-static void cmd64x_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	cmd64x_set_timing(ap, adev, adev->pio_mode);
-}
-
-/**
  *	cmd64x_set_dmamode	-	set initial DMA mode data
  *	@ap: ATA interface
  *	@adev: ATA device
@@ -192,6 +180,9 @@
 	static const u8 udma_data[] = {
 		0x30, 0x20, 0x10, 0x20, 0x10, 0x00
 	};
+	static const u8 mwdma_data[] = {
+		0x30, 0x20, 0x10
+	};
 
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	u8 regU, regD;
@@ -211,16 +202,14 @@
 	regU &= ~(0x05 << adev->devno);
 
 	if (adev->dma_mode >= XFER_UDMA_0) {
-		/* Merge the timing value */
+		/* Merge thge timing value */
 		regU |= udma_data[adev->dma_mode - XFER_UDMA_0] << shift;
 		/* Merge the control bits */
 		regU |= 1 << adev->devno; /* UDMA on */
-		if (adev->dma_mode > XFER_UDMA_2) /* 15nS timing */
+		if (adev->dma_mode > 2)	/* 15nS timing */
 			regU |= 4 << adev->devno;
-	} else {
-		regU &= ~ (1 << adev->devno);	/* UDMA off */
-		cmd64x_set_timing(ap, adev, adev->dma_mode);
-	}
+	} else
+		regD |= mwdma_data[adev->dma_mode - XFER_MW_DMA_0] << shift;
 
 	regD |= 0x20 << adev->devno;
 
@@ -241,7 +230,7 @@
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	u8 dma_intr;
 	int dma_mask = ap->port_no ? ARTTIM23_INTR_CH1 : CFR_INTR_CH0;
-	int dma_reg = ap->port_no ? ARTTIM23 : CFR;
+	int dma_reg = ap->port_no ? ARTTIM2 : CFR;
 
 	ata_bmdma_stop(qc);
 
@@ -262,110 +251,195 @@
 }
 
 static struct scsi_host_template cmd64x_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static const struct ata_port_operations cmd64x_base_ops = {
-	.inherits	= &ata_bmdma_port_ops,
+static struct ata_port_operations cmd64x_port_ops = {
+	.port_disable	= ata_port_disable,
 	.set_piomode	= cmd64x_set_piomode,
 	.set_dmamode	= cmd64x_set_dmamode,
-};
-
-static struct ata_port_operations cmd64x_port_ops = {
-	.inherits	= &cmd64x_base_ops,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
 	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations cmd646r1_port_ops = {
-	.inherits	= &cmd64x_base_ops,
-	.bmdma_stop	= cmd646r1_bmdma_stop,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= cmd64x_set_piomode,
+	.set_dmamode	= cmd64x_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
 	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= cmd646r1_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations cmd648_port_ops = {
-	.inherits	= &cmd64x_base_ops,
-	.bmdma_stop	= cmd648_bmdma_stop,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= cmd64x_set_piomode,
+	.set_dmamode	= cmd64x_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
 	.cable_detect	= cmd648_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= cmd648_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int cmd64x_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
 {
+	u32 class_rev;
+
 	static const struct ata_port_info cmd_info[6] = {
 		{	/* CMD 643 - no UDMA */
+			.sht = &cmd64x_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.port_ops = &cmd64x_port_ops
 		},
 		{	/* CMD 646 with broken UDMA */
+			.sht = &cmd64x_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.port_ops = &cmd64x_port_ops
 		},
 		{	/* CMD 646 with working UDMA */
+			.sht = &cmd64x_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.udma_mask = ATA_UDMA2,
 			.port_ops = &cmd64x_port_ops
 		},
 		{	/* CMD 646 rev 1  */
+			.sht = &cmd64x_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.port_ops = &cmd646r1_port_ops
 		},
 		{	/* CMD 648 */
+			.sht = &cmd64x_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.udma_mask = ATA_UDMA4,
 			.port_ops = &cmd648_port_ops
 		},
 		{	/* CMD 649 */
+			.sht = &cmd64x_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.udma_mask = ATA_UDMA5,
 			.port_ops = &cmd648_port_ops
 		}
 	};
-	const struct ata_port_info *ppi[] = {
-		&cmd_info[id->driver_data],
-		&cmd_info[id->driver_data],
-		NULL
-	};
-	u8 mrdmode, reg;
-	int rc;
-	struct pci_dev *bridge = pdev->bus->self;
-	/* mobility split bridges don't report enabled ports correctly */
-	int port_ok = !(bridge && bridge->vendor ==
-			PCI_VENDOR_ID_MOBILITY_ELECTRONICS);
-	/* all (with exceptions below) apart from 643 have CNTRL_CH0 bit */
-	int cntrl_ch0_ok = (id->driver_data != 0);
-
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
+	const struct ata_port_info *ppi[] = { &cmd_info[id->driver_data], NULL };
+	u8 mrdmode;
+
+	pci_read_config_dword(pdev, PCI_CLASS_REVISION, &class_rev);
+	class_rev &= 0xFF;
 
 	if (id->driver_data == 0)	/* 643 */
-		ata_pci_bmdma_clear_simplex(pdev);
+		ata_pci_clear_simplex(pdev);
 
 	if (pdev->device == PCI_DEVICE_ID_CMD_646) {
 		/* Does UDMA work ? */
-		if (pdev->revision > 4) {
+		if (class_rev > 4)
 			ppi[0] = &cmd_info[2];
-			ppi[1] = &cmd_info[2];
-		}
 		/* Early rev with other problems ? */
-		else if (pdev->revision == 1) {
+		else if (class_rev == 1)
 			ppi[0] = &cmd_info[3];
-			ppi[1] = &cmd_info[3];
-		}
-		/* revs 1,2 have no CNTRL_CH0 */
-		if (pdev->revision < 3)
-			cntrl_ch0_ok = 0;
 	}
 
 	pci_write_config_byte(pdev, PCI_LATENCY_TIMER, 64);
@@ -374,20 +448,6 @@
 	mrdmode |= 0x02;	/* Memory read line enable */
 	pci_write_config_byte(pdev, MRDMODE, mrdmode);
 
-	/* check for enabled ports */
-	pci_read_config_byte(pdev, CNTRL, &reg);
-	if (!port_ok)
-		dev_printk(KERN_NOTICE, &pdev->dev, "Mobility Bridge detected, ignoring CNTRL port enable/disable\n");
-	if (port_ok && cntrl_ch0_ok && !(reg & CNTRL_CH0)) {
-		dev_printk(KERN_NOTICE, &pdev->dev, "Primary port is disabled\n");
-		ppi[0] = &ata_dummy_port_info;
-
-	}
-	if (port_ok && !(reg & CNTRL_CH1)) {
-		dev_printk(KERN_NOTICE, &pdev->dev, "Secondary port is disabled\n");
-		ppi[1] = &ata_dummy_port_info;
-	}
-
 	/* Force PIO 0 here.. */
 
 	/* PPC specific fixup copied from old driver */
@@ -395,20 +455,13 @@
 	pci_write_config_byte(pdev, UDIDETCR0, 0xF0);
 #endif
 
-	return ata_pci_sff_init_one(pdev, ppi, &cmd64x_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 #ifdef CONFIG_PM
 static int cmd64x_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
 	u8 mrdmode;
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
-
 	pci_write_config_byte(pdev, PCI_LATENCY_TIMER, 64);
 	pci_read_config_byte(pdev, MRDMODE, &mrdmode);
 	mrdmode &= ~ 0x30;	/* IRQ set up */
@@ -417,8 +470,7 @@
 #ifdef CONFIG_PPC
 	pci_write_config_byte(pdev, UDIDETCR0, 0xF0);
 #endif
-	ata_host_resume(host);
-	return 0;
+	return ata_pci_device_resume(pdev);
 }
 #endif
 
diff -Nur linux-sh4/drivers/ata.org/pata_cs5520.c linux-sh4/drivers/ata/pata_cs5520.c
--- linux-sh4/drivers/ata.org/pata_cs5520.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_cs5520.c	2012-01-15 06:30:15.000000000 -0800
@@ -140,38 +140,69 @@
 }
 
 static struct scsi_host_template cs5520_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= LIBATA_DUMB_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations cs5520_port_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.qc_prep		= ata_sff_dumb_qc_prep,
-	.cable_detect		= ata_cable_40wire,
+	.port_disable		= ata_port_disable,
 	.set_piomode		= cs5520_set_piomode,
 	.set_dmamode		= cs5520_set_dmamode,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ata_cable_40wire,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_dumb_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 static int __devinit cs5520_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
 {
-	static const unsigned int cmd_port[] = { 0x1F0, 0x170 };
-	static const unsigned int ctl_port[] = { 0x3F6, 0x376 };
 	struct ata_port_info pi = {
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
+		.pio_mask	= 0x1f,
 		.port_ops	= &cs5520_port_ops,
 	};
 	const struct ata_port_info *ppi[2];
 	u8 pcicfg;
-	void __iomem *iomap[5];
+	void *iomap[5];
 	struct ata_host *host;
 	struct ata_ioports *ioaddr;
 	int i, rc;
 
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
 	/* IDE port enable bits */
 	pci_read_config_byte(pdev, 0x60, &pcicfg);
 
@@ -198,25 +229,25 @@
 		return -ENOMEM;
 
 	/* Perform set up for DMA */
-	if (pci_enable_device_io(pdev)) {
+	if (pci_enable_device_bars(pdev, 1<<2)) {
 		printk(KERN_ERR DRV_NAME ": unable to configure BAR2.\n");
 		return -ENODEV;
 	}
 
-	if (pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) {
+	if (pci_set_dma_mask(pdev, DMA_32BIT_MASK)) {
 		printk(KERN_ERR DRV_NAME ": unable to configure DMA mask.\n");
 		return -ENODEV;
 	}
-	if (pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32))) {
+	if (pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK)) {
 		printk(KERN_ERR DRV_NAME ": unable to configure consistent DMA mask.\n");
 		return -ENODEV;
 	}
 
 	/* Map IO ports and initialize host accordingly */
-	iomap[0] = devm_ioport_map(&pdev->dev, cmd_port[0], 8);
-	iomap[1] = devm_ioport_map(&pdev->dev, ctl_port[0], 1);
-	iomap[2] = devm_ioport_map(&pdev->dev, cmd_port[1], 8);
-	iomap[3] = devm_ioport_map(&pdev->dev, ctl_port[1], 1);
+	iomap[0] = devm_ioport_map(&pdev->dev, 0x1F0, 8);
+	iomap[1] = devm_ioport_map(&pdev->dev, 0x3F6, 1);
+	iomap[2] = devm_ioport_map(&pdev->dev, 0x170, 8);
+	iomap[3] = devm_ioport_map(&pdev->dev, 0x376, 1);
 	iomap[4] = pcim_iomap(pdev, 2, 0);
 
 	if (!iomap[0] || !iomap[1] || !iomap[2] || !iomap[3] || !iomap[4])
@@ -227,22 +258,14 @@
 	ioaddr->ctl_addr = iomap[1];
 	ioaddr->altstatus_addr = iomap[1];
 	ioaddr->bmdma_addr = iomap[4];
-	ata_sff_std_ports(ioaddr);
-
-	ata_port_desc(host->ports[0],
-		      "cmd 0x%x ctl 0x%x", cmd_port[0], ctl_port[0]);
-	ata_port_pbar_desc(host->ports[0], 4, 0, "bmdma");
+	ata_std_ports(ioaddr);
 
 	ioaddr = &host->ports[1]->ioaddr;
 	ioaddr->cmd_addr = iomap[2];
 	ioaddr->ctl_addr = iomap[3];
 	ioaddr->altstatus_addr = iomap[3];
 	ioaddr->bmdma_addr = iomap[4] + 8;
-	ata_sff_std_ports(ioaddr);
-
-	ata_port_desc(host->ports[1],
-		      "cmd 0x%x ctl 0x%x", cmd_port[1], ctl_port[1]);
-	ata_port_pbar_desc(host->ports[1], 4, 8, "bmdma");
+	ata_std_ports(ioaddr);
 
 	/* activate the host */
 	pci_set_master(pdev);
@@ -258,16 +281,37 @@
 			continue;
 
 		rc = devm_request_irq(&pdev->dev, irq[ap->port_no],
-				      ata_sff_interrupt, 0, DRV_NAME, host);
+				      ata_interrupt, 0, DRV_NAME, host);
 		if (rc)
 			return rc;
 
-		ata_port_desc(ap, "irq %d", irq[i]);
+		if (i == 0)
+			host->irq = irq[0];
+		else
+			host->irq2 = irq[1];
 	}
 
 	return ata_host_register(host, &cs5520_sht);
 }
 
+/**
+ *	cs5520_remove_one	-	device unload
+ *	@pdev: PCI device being removed
+ *
+ *	Handle an unplug/unload event for a PCI device. Unload the
+ *	PCI driver but do not use the default handler as we manage
+ *	resources ourself and *MUST NOT* disable the device as it has
+ *	other functions.
+ */
+
+static void __devexit cs5520_remove_one(struct pci_dev *pdev)
+{
+	struct device *dev = pci_dev_to_dev(pdev);
+	struct ata_host *host = dev_get_drvdata(dev);
+
+	ata_host_detach(host);
+}
+
 #ifdef CONFIG_PM
 /**
  *	cs5520_reinit_one	-	device resume
@@ -279,20 +323,11 @@
 
 static int cs5520_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
 	u8 pcicfg;
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
-
 	pci_read_config_byte(pdev, 0x60, &pcicfg);
 	if ((pcicfg & 0x40) == 0)
 		pci_write_config_byte(pdev, 0x60, pcicfg | 0x40);
-
-	ata_host_resume(host);
-	return 0;
+	return ata_pci_device_resume(pdev);
 }
 
 /**
@@ -333,7 +368,7 @@
 	.name 		= DRV_NAME,
 	.id_table	= pata_cs5520,
 	.probe 		= cs5520_init_one,
-	.remove		= ata_pci_remove_one,
+	.remove		= cs5520_remove_one,
 #ifdef CONFIG_PM
 	.suspend	= cs5520_pci_device_suspend,
 	.resume		= cs5520_reinit_one,
diff -Nur linux-sh4/drivers/ata.org/pata_cs5530.c linux-sh4/drivers/ata/pata_cs5530.c
--- linux-sh4/drivers/ata.org/pata_cs5530.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_cs5530.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata-cs5530.c 	- CS5530 PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  * based upon cs5530.c by Mark Lord.
  *
@@ -132,50 +133,88 @@
 }
 
 /**
- *	cs5530_qc_issue		-	command issue
+ *	cs5530_qc_issue_prot	-	command issue
  *	@qc: command pending
  *
  *	Called when the libata layer is about to issue a command. We wrap
  *	this interface so that we can load the correct ATA timings if
- *	necessary.  Specifically we have a problem that there is only
+ *	neccessary.  Specifically we have a problem that there is only
  *	one MWDMA/UDMA bit.
  */
 
-static unsigned int cs5530_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int cs5530_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
 	struct ata_device *prev = ap->private_data;
 
 	/* See if the DMA settings could be wrong */
-	if (ata_dma_enabled(adev) && adev != prev && prev != NULL) {
+	if (adev->dma_mode != 0 && adev != prev && prev != NULL) {
 		/* Maybe, but do the channels match MWDMA/UDMA ? */
-		if ((ata_using_udma(adev) && !ata_using_udma(prev)) ||
-		    (ata_using_udma(prev) && !ata_using_udma(adev)))
+		if ((adev->dma_mode >= XFER_UDMA_0 && prev->dma_mode < XFER_UDMA_0) ||
+		    (adev->dma_mode < XFER_UDMA_0 && prev->dma_mode >= XFER_UDMA_0))
 		    	/* Switch the mode bits */
 		    	cs5530_set_dmamode(ap, adev);
 	}
 
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 static struct scsi_host_template cs5530_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-	.sg_tablesize	= LIBATA_DUMB_MAX_PRD,
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_DUMB_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations cs5530_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-
-	.qc_prep 	= ata_sff_dumb_qc_prep,
-	.qc_issue	= cs5530_qc_issue,
-
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= cs5530_set_piomode,
 	.set_dmamode	= cs5530_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_dumb_qc_prep,
+	.qc_issue	= cs5530_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
-static const struct dmi_system_id palmax_dmi_table[] = {
+static struct dmi_system_id palmax_dmi_table[] = {
 	{
 		.ident = "Palmax PD1100",
 		.matches = {
@@ -297,24 +336,21 @@
 static int cs5530_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &cs5530_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
+		.udma_mask = 0x07,
 		.port_ops = &cs5530_port_ops
 	};
 	/* The docking connector doesn't do UDMA, and it seems not MWDMA */
 	static const struct ata_port_info info_palmax_secondary = {
+		.sht = &cs5530_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
+		.pio_mask = 0x1f,
 		.port_ops = &cs5530_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
-	int rc;
-
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
 
 	/* Chip initialisation */
 	if (cs5530_init_chip())
@@ -324,25 +360,16 @@
 		ppi[1] = &info_palmax_secondary;
 
 	/* Now kick off ATA set up */
-	return ata_pci_sff_init_one(pdev, ppi, &cs5530_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 #ifdef CONFIG_PM
 static int cs5530_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
-
 	/* If we fail on resume we are doomed */
 	if (cs5530_init_chip())
-		return -EIO;
-
-	ata_host_resume(host);
-	return 0;
+		BUG();
+	return ata_pci_device_resume(pdev);
 }
 #endif /* CONFIG_PM */
 
diff -Nur linux-sh4/drivers/ata.org/pata_cs5535.c linux-sh4/drivers/ata/pata_cs5535.c
--- linux-sh4/drivers/ata.org/pata_cs5535.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_cs5535.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  * pata-cs5535.c 	- CS5535 PATA for new ATA layer
  *			  (C) 2005-2006 Red Hat Inc
- *			  Alan Cox <alan@lxorguk.ukuu.org.uk>
+ *			  Alan Cox <alan@redhat.com>
  *
  * based upon cs5535.c from AMD <Jens.Altmann@amd.com> as cleaned up and
  * made readable and Linux style by Wolfgang Zuleger <wolfgang.zuleger@gmx.de
@@ -25,7 +25,7 @@
  * Documentation:
  *	Available from AMD web site.
  * TODO
- *	Review errata to see if serializing is necessary
+ *	Review errata to see if serializing is neccessary
  */
 
 #include <linux/kernel.h>
@@ -72,6 +72,7 @@
 /**
  *	cs5535_cable_detect	-	detect cable type
  *	@ap: Port to detect on
+ *	@deadline: deadline jiffies for the operation
  *
  *	Perform cable detection for ATA66 capable cable. Return a libata
  *	cable type.
@@ -157,14 +158,57 @@
 }
 
 static struct scsi_host_template cs5535_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations cs5535_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= cs5535_cable_detect,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= cs5535_set_piomode,
 	.set_dmamode	= cs5535_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= cs5535_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -180,9 +224,10 @@
 static int cs5535_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &cs5535_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA4,
 		.port_ops = &cs5535_port_ops
 	};
@@ -198,12 +243,11 @@
 	rdmsr(ATAC_CH0D1_PIO, timings, dummy);
 	if (CS5535_BAD_PIO(timings))
 		wrmsr(ATAC_CH0D1_PIO, 0xF7F4F7F4UL, 0);
-	return ata_pci_sff_init_one(dev, ppi, &cs5535_sht, NULL);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id cs5535[] = {
-	{ PCI_VDEVICE(NS, PCI_DEVICE_ID_NS_CS5535_IDE), },
-	{ PCI_VDEVICE(AMD, PCI_DEVICE_ID_AMD_CS5535_IDE), },
+	{ PCI_VDEVICE(NS, 0x002D), },
 
 	{ },
 };
diff -Nur linux-sh4/drivers/ata.org/pata_cs5536.c linux-sh4/drivers/ata/pata_cs5536.c
--- linux-sh4/drivers/ata.org/pata_cs5536.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_cs5536.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,301 +0,0 @@
-/*
- * pata_cs5536.c	- CS5536 PATA for new ATA layer
- *			  (C) 2007 Martin K. Petersen <mkp@mkp.net>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	 See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307	 USA
- *
- * Documentation:
- *	Available from AMD web site.
- *
- * The IDE timing registers for the CS5536 live in the Geode Machine
- * Specific Register file and not PCI config space.  Most BIOSes
- * virtualize the PCI registers so the chip looks like a standard IDE
- * controller.	Unfortunately not all implementations get this right.
- * In particular some have problems with unaligned accesses to the
- * virtualized PCI registers.  This driver always does full dword
- * writes to work around the issue.  Also, in case of a bad BIOS this
- * driver can be loaded with the "msr=1" parameter which forces using
- * the Machine Specific Registers to configure the device.
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <linux/delay.h>
-#include <linux/libata.h>
-#include <scsi/scsi_host.h>
-#include <asm/msr.h>
-
-#define DRV_NAME	"pata_cs5536"
-#define DRV_VERSION	"0.0.7"
-
-enum {
-	CFG			= 0,
-	DTC			= 1,
-	CAST			= 2,
-	ETC			= 3,
-
-	MSR_IDE_BASE		= 0x51300000,
-	MSR_IDE_CFG		= (MSR_IDE_BASE + 0x10),
-	MSR_IDE_DTC		= (MSR_IDE_BASE + 0x12),
-	MSR_IDE_CAST		= (MSR_IDE_BASE + 0x13),
-	MSR_IDE_ETC		= (MSR_IDE_BASE + 0x14),
-
-	PCI_IDE_CFG		= 0x40,
-	PCI_IDE_DTC		= 0x48,
-	PCI_IDE_CAST		= 0x4c,
-	PCI_IDE_ETC		= 0x50,
-
-	IDE_CFG_CHANEN		= 0x2,
-	IDE_CFG_CABLE		= 0x10000,
-
-	IDE_D0_SHIFT		= 24,
-	IDE_D1_SHIFT		= 16,
-	IDE_DRV_MASK		= 0xff,
-
-	IDE_CAST_D0_SHIFT	= 6,
-	IDE_CAST_D1_SHIFT	= 4,
-	IDE_CAST_DRV_MASK	= 0x3,
-	IDE_CAST_CMD_MASK	= 0xff,
-	IDE_CAST_CMD_SHIFT	= 24,
-
-	IDE_ETC_NODMA		= 0x03,
-};
-
-static int use_msr;
-
-static const u32 msr_reg[4] = {
-	MSR_IDE_CFG, MSR_IDE_DTC, MSR_IDE_CAST, MSR_IDE_ETC,
-};
-
-static const u8 pci_reg[4] = {
-	PCI_IDE_CFG, PCI_IDE_DTC, PCI_IDE_CAST, PCI_IDE_ETC,
-};
-
-static inline int cs5536_read(struct pci_dev *pdev, int reg, u32 *val)
-{
-	if (unlikely(use_msr)) {
-		u32 dummy;
-
-		rdmsr(msr_reg[reg], *val, dummy);
-		return 0;
-	}
-
-	return pci_read_config_dword(pdev, pci_reg[reg], val);
-}
-
-static inline int cs5536_write(struct pci_dev *pdev, int reg, int val)
-{
-	if (unlikely(use_msr)) {
-		wrmsr(msr_reg[reg], val, 0);
-		return 0;
-	}
-
-	return pci_write_config_dword(pdev, pci_reg[reg], val);
-}
-
-/**
- *	cs5536_cable_detect	-	detect cable type
- *	@ap: Port to detect on
- *
- *	Perform cable detection for ATA66 capable cable. Return a libata
- *	cable type.
- */
-
-static int cs5536_cable_detect(struct ata_port *ap)
-{
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	u32 cfg;
-
-	cs5536_read(pdev, CFG, &cfg);
-
-	if (cfg & (IDE_CFG_CABLE << ap->port_no))
-		return ATA_CBL_PATA80;
-	else
-		return ATA_CBL_PATA40;
-}
-
-/**
- *	cs5536_set_piomode		-	PIO setup
- *	@ap: ATA interface
- *	@adev: device on the interface
- */
-
-static void cs5536_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	static const u8 drv_timings[5] = {
-		0x98, 0x55, 0x32, 0x21, 0x20,
-	};
-
-	static const u8 addr_timings[5] = {
-		0x2, 0x1, 0x0, 0x0, 0x0,
-	};
-
-	static const u8 cmd_timings[5] = {
-		0x99, 0x92, 0x90, 0x22, 0x20,
-	};
-
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	struct ata_device *pair = ata_dev_pair(adev);
-	int mode = adev->pio_mode - XFER_PIO_0;
-	int cmdmode = mode;
-	int dshift = adev->devno ? IDE_D1_SHIFT : IDE_D0_SHIFT;
-	int cshift = adev->devno ? IDE_CAST_D1_SHIFT : IDE_CAST_D0_SHIFT;
-	u32 dtc, cast, etc;
-
-	if (pair)
-		cmdmode = min(mode, pair->pio_mode - XFER_PIO_0);
-
-	cs5536_read(pdev, DTC, &dtc);
-	cs5536_read(pdev, CAST, &cast);
-	cs5536_read(pdev, ETC, &etc);
-
-	dtc &= ~(IDE_DRV_MASK << dshift);
-	dtc |= drv_timings[mode] << dshift;
-
-	cast &= ~(IDE_CAST_DRV_MASK << cshift);
-	cast |= addr_timings[mode] << cshift;
-
-	cast &= ~(IDE_CAST_CMD_MASK << IDE_CAST_CMD_SHIFT);
-	cast |= cmd_timings[cmdmode] << IDE_CAST_CMD_SHIFT;
-
-	etc &= ~(IDE_DRV_MASK << dshift);
-	etc |= IDE_ETC_NODMA << dshift;
-
-	cs5536_write(pdev, DTC, dtc);
-	cs5536_write(pdev, CAST, cast);
-	cs5536_write(pdev, ETC, etc);
-}
-
-/**
- *	cs5536_set_dmamode		-	DMA timing setup
- *	@ap: ATA interface
- *	@adev: Device being configured
- *
- */
-
-static void cs5536_set_dmamode(struct ata_port *ap, struct ata_device *adev)
-{
-	static const u8 udma_timings[6] = {
-		0xc2, 0xc1, 0xc0, 0xc4, 0xc5, 0xc6,
-	};
-
-	static const u8 mwdma_timings[3] = {
-		0x67, 0x21, 0x20,
-	};
-
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	u32 dtc, etc;
-	int mode = adev->dma_mode;
-	int dshift = adev->devno ? IDE_D1_SHIFT : IDE_D0_SHIFT;
-
-	if (mode >= XFER_UDMA_0) {
-		cs5536_read(pdev, ETC, &etc);
-
-		etc &= ~(IDE_DRV_MASK << dshift);
-		etc |= udma_timings[mode - XFER_UDMA_0] << dshift;
-
-		cs5536_write(pdev, ETC, etc);
-	} else { /* MWDMA */
-		cs5536_read(pdev, DTC, &dtc);
-
-		dtc &= ~(IDE_DRV_MASK << dshift);
-		dtc |= mwdma_timings[mode - XFER_MW_DMA_0] << dshift;
-
-		cs5536_write(pdev, DTC, dtc);
-	}
-}
-
-static struct scsi_host_template cs5536_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations cs5536_port_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.cable_detect		= cs5536_cable_detect,
-	.set_piomode		= cs5536_set_piomode,
-	.set_dmamode		= cs5536_set_dmamode,
-};
-
-/**
- *	cs5536_init_one
- *	@dev: PCI device
- *	@id: Entry in match table
- *
- */
-
-static int cs5536_init_one(struct pci_dev *dev, const struct pci_device_id *id)
-{
-	static const struct ata_port_info info = {
-		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA5,
-		.port_ops = &cs5536_port_ops,
-	};
-
-	const struct ata_port_info *ppi[] = { &info, &ata_dummy_port_info };
-	u32 cfg;
-
-	if (use_msr)
-		printk(KERN_ERR DRV_NAME ": Using MSR regs instead of PCI\n");
-
-	cs5536_read(dev, CFG, &cfg);
-
-	if ((cfg & IDE_CFG_CHANEN) == 0) {
-		printk(KERN_ERR DRV_NAME ": disabled by BIOS\n");
-		return -ENODEV;
-	}
-
-	return ata_pci_sff_init_one(dev, ppi, &cs5536_sht, NULL);
-}
-
-static const struct pci_device_id cs5536[] = {
-	{ PCI_VDEVICE(AMD,	PCI_DEVICE_ID_AMD_CS5536_IDE), },
-	{ },
-};
-
-static struct pci_driver cs5536_pci_driver = {
-	.name		= DRV_NAME,
-	.id_table	= cs5536,
-	.probe		= cs5536_init_one,
-	.remove		= ata_pci_remove_one,
-#ifdef CONFIG_PM
-	.suspend	= ata_pci_device_suspend,
-	.resume		= ata_pci_device_resume,
-#endif
-};
-
-static int __init cs5536_init(void)
-{
-	return pci_register_driver(&cs5536_pci_driver);
-}
-
-static void __exit cs5536_exit(void)
-{
-	pci_unregister_driver(&cs5536_pci_driver);
-}
-
-MODULE_AUTHOR("Martin K. Petersen");
-MODULE_DESCRIPTION("low-level driver for the CS5536 IDE controller");
-MODULE_LICENSE("GPL");
-MODULE_DEVICE_TABLE(pci, cs5536);
-MODULE_VERSION(DRV_VERSION);
-module_param_named(msr, use_msr, int, 0644);
-MODULE_PARM_DESC(msr, "Force using MSR to configure IDE function (Default: 0)");
-
-module_init(cs5536_init);
-module_exit(cs5536_exit);
diff -Nur linux-sh4/drivers/ata.org/pata_cypress.c linux-sh4/drivers/ata/pata_cypress.c
--- linux-sh4/drivers/ata.org/pata_cypress.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_cypress.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  * pata_cypress.c 	- Cypress PATA for new ATA layer
  *			  (C) 2006 Red Hat Inc
- *			  Alan Cox
+ *			  Alan Cox <alan@redhat.com>
  *
  * Based heavily on
  * linux/drivers/ide/pci/cy82c693.c		Version 0.40	Sep. 10, 2002
@@ -62,14 +62,14 @@
 		return;
 	}
 
-	time_16 = clamp_val(t.recover, 0, 15) | (clamp_val(t.active, 0, 15) << 4);
-	time_8 = clamp_val(t.act8b, 0, 15) | (clamp_val(t.rec8b, 0, 15) << 4);
+	time_16 = FIT(t.recover, 0, 15) | (FIT(t.active, 0, 15) << 4);
+	time_8 = FIT(t.act8b, 0, 15) | (FIT(t.rec8b, 0, 15) << 4);
 
 	if (adev->devno == 0) {
 		pci_read_config_dword(pdev, CY82_IDE_ADDRSETUP, &addr);
 
 		addr &= ~0x0F;	/* Mask bits */
-		addr |= clamp_val(t.setup, 0, 15);
+		addr |= FIT(t.setup, 0, 15);
 
 		pci_write_config_dword(pdev, CY82_IDE_ADDRSETUP, addr);
 		pci_write_config_byte(pdev, CY82_IDE_MASTER_IOR, time_16);
@@ -79,7 +79,7 @@
 		pci_read_config_dword(pdev, CY82_IDE_ADDRSETUP, &addr);
 
 		addr &= ~0xF0;	/* Mask bits */
-		addr |= (clamp_val(t.setup, 0, 15) << 4);
+		addr |= (FIT(t.setup, 0, 15) << 4);
 
 		pci_write_config_dword(pdev, CY82_IDE_ADDRSETUP, addr);
 		pci_write_config_byte(pdev, CY82_IDE_SLAVE_IOR, time_16);
@@ -110,22 +110,66 @@
 }
 
 static struct scsi_host_template cy82c693_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations cy82c693_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= cy82c693_set_piomode,
 	.set_dmamode	= cy82c693_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int cy82c693_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &cy82c693_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.port_ops = &cy82c693_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, &ata_dummy_port_info };
@@ -136,7 +180,7 @@
 	if (PCI_FUNC(pdev->devfn) != 1)
 		return -ENODEV;
 
-	return ata_pci_sff_init_one(pdev, ppi, &cy82c693_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id cy82c693[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_efar.c linux-sh4/drivers/ata/pata_efar.c
--- linux-sh4/drivers/ata.org/pata_efar.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_efar.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  *    pata_efar.c - EFAR PIIX clone controller driver
  *
- *	(C) 2005 Red Hat
+ *	(C) 2005 Red Hat <alan@redhat.com>
  *
  *    Some parts based on ata_piix.c by Jeff Garzik and others.
  *
@@ -22,30 +22,42 @@
 #include <linux/ata.h>
 
 #define DRV_NAME	"pata_efar"
-#define DRV_VERSION	"0.4.5"
+#define DRV_VERSION	"0.4.4"
 
 /**
  *	efar_pre_reset	-	Enable bits
- *	@link: ATA link
+ *	@ap: Port
  *	@deadline: deadline jiffies for the operation
  *
  *	Perform cable detection for the EFAR ATA interface. This is
  *	different to the PIIX arrangement
  */
 
-static int efar_pre_reset(struct ata_link *link, unsigned long deadline)
+static int efar_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits efar_enable_bits[] = {
 		{ 0x41U, 1U, 0x80UL, 0x80UL },	/* port 0 */
 		{ 0x43U, 1U, 0x80UL, 0x80UL },	/* port 1 */
 	};
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	if (!pci_test_config_bits(pdev, &efar_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	efar_probe_reset - Probe specified port on PATA host controller
+ *	@ap: Port to probe
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void efar_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, efar_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -98,17 +110,18 @@
 			    { 2, 1 },
 			    { 2, 3 }, };
 
-	if (pio > 1)
-		control |= 1;	/* TIME */
+	if (pio > 2)
+		control |= 1;	/* TIME1 enable */
 	if (ata_pio_need_iordy(adev))	/* PIO 3/4 require IORDY */
-		control |= 2;	/* IE */
-	/* Intel specifies that the prefetch/posting is for disk only */
+		control |= 2;	/* IE enable */
+	/* Intel specifies that the PPE functionality is for disk only */
 	if (adev->class == ATA_DEV_ATA)
-		control |= 4;	/* PPE */
+		control |= 4;	/* PPE enable */
 
 	pci_read_config_word(dev, idetm_port, &idetm_data);
 
-	/* Set PPE, IE, and TIME as appropriate */
+	/* Enable PPE, IE and TIME as appropriate */
+
 	if (adev->devno == 0) {
 		idetm_data &= 0xCCF0;
 		idetm_data |= control;
@@ -121,14 +134,14 @@
 		idetm_data &= 0xCC0F;
 		idetm_data |= (control << 4);
 
-		/* Slave timing in separate register */
+		/* Slave timing in seperate register */
 		pci_read_config_byte(dev, 0x44, &slave_data);
 		slave_data &= 0x0F << shift;
 		slave_data |= ((timings[pio][0] << 2) | timings[pio][1]) << shift;
 		pci_write_config_byte(dev, 0x44, slave_data);
 	}
 
-	idetm_data |= 0x4000;	/* Ensure SITRE is set */
+	idetm_data |= 0x4000;	/* Ensure SITRE is enabled */
 	pci_write_config_word(dev, idetm_port, idetm_data);
 }
 
@@ -219,15 +232,55 @@
 }
 
 static struct scsi_host_template efar_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations efar_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.cable_detect		= efar_cable_detect,
+static const struct ata_port_operations efar_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= efar_set_piomode,
 	.set_dmamode		= efar_set_dmamode,
-	.prereset		= efar_pre_reset,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= efar_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= efar_cable_detect,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 
@@ -249,10 +302,11 @@
 {
 	static int printed_version;
 	static const struct ata_port_info info = {
+		.sht		= &efar_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask 	= ATA_UDMA4,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma1-2 */
+		.udma_mask 	= 0x0f, /* UDMA 66 */
 		.port_ops	= &efar_ops,
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
@@ -261,7 +315,7 @@
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "version " DRV_VERSION "\n");
 
-	return ata_pci_sff_init_one(pdev, ppi, &efar_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id efar_pci_tbl[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_hpt366.c linux-sh4/drivers/ata/pata_hpt366.c
--- linux-sh4/drivers/ata.org/pata_hpt366.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_hpt366.c	2012-01-15 06:30:15.000000000 -0800
@@ -27,10 +27,10 @@
 #include <linux/libata.h>
 
 #define DRV_NAME	"pata_hpt366"
-#define DRV_VERSION	"0.6.2"
+#define DRV_VERSION	"0.6.1"
 
 struct hpt_clock {
-	u8	xfer_mode;
+	u8	xfer_speed;
 	u32	timing;
 };
 
@@ -180,40 +180,65 @@
 		if (hpt_dma_blacklisted(adev, "UDMA",  bad_ata33))
 			mask &= ~ATA_MASK_UDMA;
 		if (hpt_dma_blacklisted(adev, "UDMA3", bad_ata66_3))
-			mask &= ~(0xF8 << ATA_SHIFT_UDMA);
+			mask &= ~(0x07 << ATA_SHIFT_UDMA);
 		if (hpt_dma_blacklisted(adev, "UDMA4", bad_ata66_4))
-			mask &= ~(0xF0 << ATA_SHIFT_UDMA);
-	} else if (adev->class == ATA_DEV_ATAPI)
-		mask &= ~(ATA_MASK_MWDMA | ATA_MASK_UDMA);
+			mask &= ~(0x0F << ATA_SHIFT_UDMA);
+	}
+	return ata_pci_default_filter(adev, mask);
+}
+
+/**
+ *	hpt36x_find_mode	-	reset the hpt36x bus
+ *	@ap: ATA port
+ *	@speed: transfer mode
+ *
+ *	Return the 32bit register programming information for this channel
+ *	that matches the speed provided.
+ */
+
+static u32 hpt36x_find_mode(struct ata_port *ap, int speed)
+{
+	struct hpt_clock *clocks = ap->host->private_data;
 
-	return ata_bmdma_mode_filter(adev, mask);
+	while(clocks->xfer_speed) {
+		if (clocks->xfer_speed == speed)
+			return clocks->timing;
+		clocks++;
+	}
+	BUG();
+	return 0xffffffffU;	/* silence compiler warning */
 }
 
 static int hpt36x_cable_detect(struct ata_port *ap)
 {
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	u8 ata66;
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
-	/*
-	 * Each channel of pata_hpt366 occupies separate PCI function
-	 * as the primary channel and bit1 indicates the cable type.
-	 */
 	pci_read_config_byte(pdev, 0x5A, &ata66);
-	if (ata66 & 2)
+	if (ata66 & (1 << ap->port_no))
 		return ATA_CBL_PATA40;
 	return ATA_CBL_PATA80;
 }
 
-static void hpt366_set_mode(struct ata_port *ap, struct ata_device *adev,
-			    u8 mode)
+/**
+ *	hpt366_set_piomode		-	PIO setup
+ *	@ap: ATA interface
+ *	@adev: device on the interface
+ *
+ *	Perform PIO mode setup.
+ */
+
+static void hpt366_set_piomode(struct ata_port *ap, struct ata_device *adev)
 {
-	struct hpt_clock *clocks = ap->host->private_data;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	u32 addr1 = 0x40 + 4 * (adev->devno + 2 * ap->port_no);
-	u32 addr2 = 0x51 + 4 * ap->port_no;
-	u32 mask, reg;
+	u32 addr1, addr2;
+	u32 reg;
+	u32 mode;
 	u8 fast;
 
+	addr1 = 0x40 + 4 * (adev->devno + 2 * ap->port_no);
+	addr2 = 0x51 + 4 * ap->port_no;
+
 	/* Fast interrupt prediction disable, hold off interrupt disable */
 	pci_read_config_byte(pdev, addr2, &fast);
 	if (fast & 0x80) {
@@ -221,43 +246,12 @@
 		pci_write_config_byte(pdev, addr2, fast);
 	}
 
-	/* determine timing mask and find matching clock entry */
-	if (mode < XFER_MW_DMA_0)
-		mask = 0xc1f8ffff;
-	else if (mode < XFER_UDMA_0)
-		mask = 0x303800ff;
-	else
-		mask = 0x30070000;
-
-	while (clocks->xfer_mode) {
-		if (clocks->xfer_mode == mode)
-			break;
-		clocks++;
-	}
-	if (!clocks->xfer_mode)
-		BUG();
-
-	/*
-	 * Combine new mode bits with old config bits and disable
-	 * on-chip PIO FIFO/buffer (and PIO MST mode as well) to avoid
-	 * problems handling I/O errors later.
-	 */
 	pci_read_config_dword(pdev, addr1, &reg);
-	reg = ((reg & ~mask) | (clocks->timing & mask)) & ~0xc0000000;
-	pci_write_config_dword(pdev, addr1, reg);
-}
-
-/**
- *	hpt366_set_piomode		-	PIO setup
- *	@ap: ATA interface
- *	@adev: device on the interface
- *
- *	Perform PIO mode setup.
- */
-
-static void hpt366_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	hpt366_set_mode(ap, adev, adev->pio_mode);
+	mode = hpt36x_find_mode(ap, adev->pio_mode);
+	mode &= ~0x8000000;	/* No FIFO in PIO */
+	mode &= ~0x30070000;	/* Leave config bits alone */
+	reg &= 0x30070000;	/* Strip timing bits */
+	pci_write_config_dword(pdev, addr1, reg | mode);
 }
 
 /**
@@ -271,11 +265,46 @@
 
 static void hpt366_set_dmamode(struct ata_port *ap, struct ata_device *adev)
 {
-	hpt366_set_mode(ap, adev, adev->dma_mode);
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	u32 addr1, addr2;
+	u32 reg;
+	u32 mode;
+	u8 fast;
+
+	addr1 = 0x40 + 4 * (adev->devno + 2 * ap->port_no);
+	addr2 = 0x51 + 4 * ap->port_no;
+
+	/* Fast interrupt prediction disable, hold off interrupt disable */
+	pci_read_config_byte(pdev, addr2, &fast);
+	if (fast & 0x80) {
+		fast &= ~0x80;
+		pci_write_config_byte(pdev, addr2, fast);
+	}
+
+	pci_read_config_dword(pdev, addr1, &reg);
+	mode = hpt36x_find_mode(ap, adev->dma_mode);
+	mode |= 0x8000000;	/* FIFO in MWDMA or UDMA */
+	mode &= ~0xC0000000;	/* Leave config bits alone */
+	reg &= 0xC0000000;	/* Strip timing bits */
+	pci_write_config_dword(pdev, addr1, reg | mode);
 }
 
 static struct scsi_host_template hpt36x_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 /*
@@ -283,11 +312,39 @@
  */
 
 static struct ata_port_operations hpt366_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= hpt36x_cable_detect,
-	.mode_filter	= hpt366_filter,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= hpt366_set_piomode,
 	.set_dmamode	= hpt366_set_dmamode,
+	.mode_filter	= hpt366_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= hpt36x_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -335,26 +392,26 @@
 static int hpt36x_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info_hpt366 = {
+		.sht = &hpt36x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA4,
 		.port_ops = &hpt366_port_ops
 	};
-	const struct ata_port_info *ppi[] = { &info_hpt366, NULL };
+	struct ata_port_info info = info_hpt366;
+	const struct ata_port_info *ppi[] = { &info, NULL };
 
-	void *hpriv = NULL;
+	u32 class_rev;
 	u32 reg1;
-	int rc;
 
-	rc = pcim_enable_device(dev);
-	if (rc)
-		return rc;
+	pci_read_config_dword(dev, PCI_CLASS_REVISION, &class_rev);
+	class_rev &= 0xFF;
 
 	/* May be a later chip in disguise. Check */
 	/* Newer chips are not in the HPT36x driver. Ignore them */
-	if (dev->revision > 2)
-		return -ENODEV;
+	if (class_rev > 2)
+			return -ENODEV;
 
 	hpt36x_init_chipset(dev);
 
@@ -363,32 +420,25 @@
 	/* PCI clocking determines the ATA timing values to use */
 	/* info_hpt366 is safe against re-entry so we can scribble on it */
 	switch((reg1 & 0x700) >> 8) {
-		case 9:
-			hpriv = &hpt366_40;
-			break;
 		case 5:
-			hpriv = &hpt366_25;
+			info.private_data = &hpt366_40;
+			break;
+		case 9:
+			info.private_data = &hpt366_25;
 			break;
 		default:
-			hpriv = &hpt366_33;
+			info.private_data = &hpt366_33;
 			break;
 	}
 	/* Now kick off ATA set up */
-	return ata_pci_sff_init_one(dev, ppi, &hpt36x_sht, hpriv);
+	return ata_pci_init_one(dev, ppi);
 }
 
 #ifdef CONFIG_PM
 static int hpt36x_reinit_one(struct pci_dev *dev)
 {
-	struct ata_host *host = dev_get_drvdata(&dev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(dev);
-	if (rc)
-		return rc;
 	hpt36x_init_chipset(dev);
-	ata_host_resume(host);
-	return 0;
+	return ata_pci_device_resume(dev);
 }
 #endif
 
diff -Nur linux-sh4/drivers/ata.org/pata_hpt37x.c linux-sh4/drivers/ata/pata_hpt37x.c
--- linux-sh4/drivers/ata.org/pata_hpt37x.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_hpt37x.c	2012-01-15 06:30:15.000000000 -0800
@@ -8,7 +8,7 @@
  * Copyright (C) 1999-2003		Andre Hedrick <andre@linux-ide.org>
  * Portions Copyright (C) 2001	        Sun Microsystems, Inc.
  * Portions Copyright (C) 2003		Red Hat Inc
- * Portions Copyright (C) 2005-2009	MontaVista Software, Inc.
+ * Portions Copyright (C) 2005-2007	MontaVista Software, Inc.
  *
  * TODO
  *	Look into engine reset on timeout errors. Should not be	required.
@@ -24,7 +24,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME	"pata_hpt37x"
-#define DRV_VERSION	"0.6.14"
+#define DRV_VERSION	"0.6.9"
 
 struct hpt_clock {
 	u8	xfer_speed;
@@ -281,9 +281,9 @@
 		if (hpt_dma_blacklisted(adev, "UDMA", bad_ata33))
 			mask &= ~ATA_MASK_UDMA;
 		if (hpt_dma_blacklisted(adev, "UDMA100", bad_ata100_5))
-			mask &= ~(0xE0 << ATA_SHIFT_UDMA);
+			mask &= ~(0x1F << ATA_SHIFT_UDMA);
 	}
-	return ata_bmdma_mode_filter(adev, mask);
+	return ata_pci_default_filter(adev, mask);
 }
 
 /**
@@ -295,25 +295,24 @@
 
 static unsigned long hpt370a_filter(struct ata_device *adev, unsigned long mask)
 {
-	if (adev->class == ATA_DEV_ATA) {
+	if (adev->class != ATA_DEV_ATA) {
 		if (hpt_dma_blacklisted(adev, "UDMA100", bad_ata100_5))
-			mask &= ~(0xE0 << ATA_SHIFT_UDMA);
+			mask &= ~ (0x1F << ATA_SHIFT_UDMA);
 	}
-	return ata_bmdma_mode_filter(adev, mask);
+	return ata_pci_default_filter(adev, mask);
 }
 
 /**
  *	hpt37x_pre_reset	-	reset the hpt37x bus
- *	@link: ATA link to reset
+ *	@ap: ATA port to reset
  *	@deadline: deadline jiffies for the operation
  *
  *	Perform the initial reset handling for the 370/372 and 374 func 0
  */
 
-static int hpt37x_pre_reset(struct ata_link *link, unsigned long deadline)
+static int hpt37x_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	u8 scr2, ata66;
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	static const struct pci_bits hpt37x_enable_bits[] = {
 		{ 0x50, 1, 0x04, 0x04 },
@@ -329,7 +328,7 @@
 	/* Restore state */
 	pci_write_config_byte(pdev, 0x5B, scr2);
 
-	if (ata66 & (2 >> ap->port_no))
+	if (ata66 & (1 << ap->port_no))
 		ap->cbl = ATA_CBL_PATA40;
 	else
 		ap->cbl = ATA_CBL_PATA80;
@@ -338,34 +337,48 @@
 	pci_write_config_byte(pdev, 0x50 + 4 * ap->port_no, 0x37);
 	udelay(100);
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
 }
 
-static int hpt374_fn1_pre_reset(struct ata_link *link, unsigned long deadline)
+/**
+ *	hpt37x_error_handler	-	reset the hpt374
+ *	@ap: ATA port to reset
+ *
+ *	Perform probe for HPT37x, except for HPT374 channel 2
+ */
+
+static void hpt37x_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, hpt37x_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
+}
+
+static int hpt374_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits hpt37x_enable_bits[] = {
 		{ 0x50, 1, 0x04, 0x04 },
 		{ 0x54, 1, 0x04, 0x04 }
 	};
-	u16 mcr3;
+	u16 mcr3, mcr6;
 	u8 ata66;
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	unsigned int mcrbase = 0x50 + 4 * ap->port_no;
 
 	if (!pci_test_config_bits(pdev, &hpt37x_enable_bits[ap->port_no]))
 		return -ENOENT;
 
 	/* Do the extra channel work */
-	pci_read_config_word(pdev, mcrbase + 2, &mcr3);
+	pci_read_config_word(pdev, 0x52, &mcr3);
+	pci_read_config_word(pdev, 0x56, &mcr6);
 	/* Set bit 15 of 0x52 to enable TCBLID as input
+	   Set bit 15 of 0x56 to enable FCBLID as input
 	 */
-	pci_write_config_word(pdev, mcrbase + 2, mcr3 | 0x8000);
+	pci_write_config_word(pdev, 0x52, mcr3 | 0x8000);
+	pci_write_config_word(pdev, 0x56, mcr6 | 0x8000);
 	pci_read_config_byte(pdev, 0x5A, &ata66);
 	/* Reset TCBLID/FCBLID to output */
-	pci_write_config_word(pdev, mcrbase + 2, mcr3);
+	pci_write_config_word(pdev, 0x52, mcr3);
+	pci_write_config_word(pdev, 0x56, mcr6);
 
-	if (ata66 & (2 >> ap->port_no))
+	if (ata66 & (1 << ap->port_no))
 		ap->cbl = ATA_CBL_PATA40;
 	else
 		ap->cbl = ATA_CBL_PATA80;
@@ -374,7 +387,26 @@
 	pci_write_config_byte(pdev, 0x50 + 4 * ap->port_no, 0x37);
 	udelay(100);
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	hpt374_error_handler	-	reset the hpt374
+ *	@classes:
+ *
+ *	The 374 cable detect is a little different due to the extra
+ *	channels. The function 0 channels work like usual but function 1
+ *	is special
+ */
+
+static void hpt374_error_handler(struct ata_port *ap)
+{
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+
+	if (!(PCI_FUNC(pdev->devfn) & 1))
+		hpt37x_error_handler(ap);
+	else
+		ata_bmdma_drive_eh(ap, hpt374_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -404,8 +436,9 @@
 
 	pci_read_config_dword(pdev, addr1, &reg);
 	mode = hpt37x_find_mode(ap, adev->pio_mode);
-	mode &= 0xCFC3FFFF;	/* Leave DMA bits alone */
-	reg &= ~0xCFC3FFFF;	/* Strip timing bits */
+	mode &= ~0x8000000;	/* No FIFO in PIO */
+	mode &= ~0x30070000;	/* Leave config bits alone */
+	reg &= 0x30070000;	/* Strip timing bits */
 	pci_write_config_dword(pdev, addr1, reg | mode);
 }
 
@@ -422,7 +455,8 @@
 {
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	u32 addr1, addr2;
-	u32 reg, mode, mask;
+	u32 reg;
+	u32 mode;
 	u8 fast;
 
 	addr1 = 0x40 + 4 * (adev->devno + 2 * ap->port_no);
@@ -434,16 +468,32 @@
 	fast |= 0x01;
 	pci_write_config_byte(pdev, addr2, fast);
 
-	mask = adev->dma_mode < XFER_UDMA_0 ? 0x31C001FF : 0x303C0000;
-
 	pci_read_config_dword(pdev, addr1, &reg);
 	mode = hpt37x_find_mode(ap, adev->dma_mode);
-	mode &= mask;
-	reg &= ~mask;
+	mode |= 0x8000000;	/* FIFO in MWDMA or UDMA */
+	mode &= ~0xC0000000;	/* Leave config bits alone */
+	reg &= 0xC0000000;	/* Strip timing bits */
 	pci_write_config_dword(pdev, addr1, reg | mode);
 }
 
 /**
+ *	hpt370_bmdma_start		-	DMA engine begin
+ *	@qc: ATA command
+ *
+ *	The 370 and 370A want us to reset the DMA engine each time we
+ *	use it. The 372 and later are fine.
+ */
+
+static void hpt370_bmdma_start(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	pci_write_config_byte(pdev, 0x50 + 4 * ap->port_no, 0x37);
+	udelay(10);
+	ata_bmdma_start(qc);
+}
+
+/**
  *	hpt370_bmdma_end		-	DMA engine stop
  *	@qc: ATA command
  *
@@ -507,8 +557,9 @@
 	mode = hpt37x_find_mode(ap, adev->pio_mode);
 
 	printk("Find mode for %d reports %X\n", adev->pio_mode, mode);
-	mode &= 0xCFC3FFFF;	/* Leave DMA bits alone */
-	reg &= ~0xCFC3FFFF;	/* Strip timing bits */
+	mode &= ~0x80000000;	/* No FIFO in PIO */
+	mode &= ~0x30070000;	/* Leave config bits alone */
+	reg &= 0x30070000;	/* Strip timing bits */
 	pci_write_config_dword(pdev, addr1, reg | mode);
 }
 
@@ -525,7 +576,8 @@
 {
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	u32 addr1, addr2;
-	u32 reg, mode, mask;
+	u32 reg;
+	u32 mode;
 	u8 fast;
 
 	addr1 = 0x40 + 4 * (adev->devno + 2 * ap->port_no);
@@ -536,13 +588,12 @@
 	fast &= ~0x07;
 	pci_write_config_byte(pdev, addr2, fast);
 
-	mask = adev->dma_mode < XFER_UDMA_0 ? 0x31C001FF : 0x303C0000;
-
 	pci_read_config_dword(pdev, addr1, &reg);
 	mode = hpt37x_find_mode(ap, adev->dma_mode);
 	printk("Find mode for DMA %d reports %X\n", adev->dma_mode, mode);
-	mode &= mask;
-	reg &= ~mask;
+	mode &= ~0xC0000000;	/* Leave config bits alone */
+	mode |= 0x80000000;	/* FIFO in MWDMA or UDMA */
+	reg &= 0xC0000000;	/* Strip timing bits */
 	pci_write_config_dword(pdev, addr1, reg | mode);
 }
 
@@ -569,7 +620,21 @@
 
 
 static struct scsi_host_template hpt37x_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 /*
@@ -577,14 +642,38 @@
  */
 
 static struct ata_port_operations hpt370_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= hpt370_set_piomode,
+	.set_dmamode	= hpt370_set_dmamode,
+	.mode_filter	= hpt370_filter,
 
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= hpt37x_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= hpt370_bmdma_start,
 	.bmdma_stop	= hpt370_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
 
-	.mode_filter	= hpt370_filter,
-	.set_piomode	= hpt370_set_piomode,
-	.set_dmamode	= hpt370_set_dmamode,
-	.prereset	= hpt37x_pre_reset,
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
@@ -592,8 +681,38 @@
  */
 
 static struct ata_port_operations hpt370a_port_ops = {
-	.inherits	= &hpt370_port_ops,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= hpt370_set_piomode,
+	.set_dmamode	= hpt370_set_dmamode,
 	.mode_filter	= hpt370a_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= hpt37x_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= hpt370_bmdma_start,
+	.bmdma_stop	= hpt370_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
@@ -602,27 +721,82 @@
  */
 
 static struct ata_port_operations hpt372_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= hpt372_set_piomode,
+	.set_dmamode	= hpt372_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= hpt37x_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
 
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
 	.bmdma_stop	= hpt37x_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
 
-	.set_piomode	= hpt372_set_piomode,
-	.set_dmamode	= hpt372_set_dmamode,
-	.prereset	= hpt37x_pre_reset,
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
  *	Configuration for HPT374. Mode setting works like 372 and friends
- *	but we have a different cable detection procedure for function 1.
+ *	but we have a different cable detection procedure.
  */
 
-static struct ata_port_operations hpt374_fn1_port_ops = {
-	.inherits	= &hpt372_port_ops,
-	.prereset	= hpt374_fn1_pre_reset,
+static struct ata_port_operations hpt374_port_ops = {
+	.port_disable	= ata_port_disable,
+	.set_piomode	= hpt372_set_piomode,
+	.set_dmamode	= hpt372_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= hpt374_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= hpt37x_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
- *	hpt37x_clock_slot	-	Turn timing to PC clock entry
+ *	htp37x_clock_slot	-	Turn timing to PC clock entry
  *	@freq: Reported frequency timing
  *	@base: Base timing
  *
@@ -676,26 +850,6 @@
 	/* Never went stable */
 	return 0;
 }
-
-static u32 hpt374_read_freq(struct pci_dev *pdev)
-{
-	u32 freq;
-	unsigned long io_base = pci_resource_start(pdev, 4);
-	if (PCI_FUNC(pdev->devfn) & 1) {
-		struct pci_dev *pdev_0;
-
-		pdev_0 = pci_get_slot(pdev->bus, pdev->devfn - 1);
-		/* Someone hot plugged the controller on us ? */
-		if (pdev_0 == NULL)
-			return 0;
-		io_base = pci_resource_start(pdev_0, 4);
-		freq = inl(io_base + 0x90);
-		pci_dev_put(pdev_0);
-	} else
-		freq = inl(io_base + 0x90);
-	return freq;
-}
-
 /**
  *	hpt37x_init_one		-	Initialise an HPT37X/302
  *	@dev: PCI device
@@ -732,65 +886,67 @@
 {
 	/* HPT370 - UDMA100 */
 	static const struct ata_port_info info_hpt370 = {
+		.sht = &hpt37x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA5,
 		.port_ops = &hpt370_port_ops
 	};
 	/* HPT370A - UDMA100 */
 	static const struct ata_port_info info_hpt370a = {
+		.sht = &hpt37x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA5,
 		.port_ops = &hpt370a_port_ops
 	};
 	/* HPT370 - UDMA100 */
 	static const struct ata_port_info info_hpt370_33 = {
+		.sht = &hpt37x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA5,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
+		.udma_mask = 0x0f,
 		.port_ops = &hpt370_port_ops
 	};
 	/* HPT370A - UDMA100 */
 	static const struct ata_port_info info_hpt370a_33 = {
+		.sht = &hpt37x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA5,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
+		.udma_mask = 0x0f,
 		.port_ops = &hpt370a_port_ops
 	};
 	/* HPT371, 372 and friends - UDMA133 */
 	static const struct ata_port_info info_hpt372 = {
+		.sht = &hpt37x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA6,
 		.port_ops = &hpt372_port_ops
 	};
-	/* HPT374 - UDMA100, function 1 uses different prereset method */
-	static const struct ata_port_info info_hpt374_fn0 = {
-		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA5,
-		.port_ops = &hpt372_port_ops
-	};
-	static const struct ata_port_info info_hpt374_fn1 = {
+	/* HPT374 - UDMA100 */
+	static const struct ata_port_info info_hpt374 = {
+		.sht = &hpt37x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA5,
-		.port_ops = &hpt374_fn1_port_ops
+		.port_ops = &hpt374_port_ops
 	};
 
 	static const int MHz[4] = { 33, 40, 50, 66 };
+	const struct ata_port_info *port;
 	void *private_data = NULL;
-	const struct ata_port_info *ppi[] = { NULL, NULL };
-	u8 rev = dev->revision;
+	struct ata_port_info port_info;
+	const struct ata_port_info *ppi[] = { &port_info, NULL };
+
 	u8 irqmask;
+	u32 class_rev;
 	u8 mcr1;
 	u32 freq;
 	int prefer_dpll = 1;
@@ -799,62 +955,59 @@
 
 	const struct hpt_chip *chip_table;
 	int clock_slot;
-	int rc;
 
-	rc = pcim_enable_device(dev);
-	if (rc)
-		return rc;
+	pci_read_config_dword(dev, PCI_CLASS_REVISION, &class_rev);
+	class_rev &= 0xFF;
 
 	if (dev->device == PCI_DEVICE_ID_TTI_HPT366) {
 		/* May be a later chip in disguise. Check */
 		/* Older chips are in the HPT366 driver. Ignore them */
-		if (rev < 3)
+		if (class_rev < 3)
 			return -ENODEV;
 		/* N series chips have their own driver. Ignore */
-		if (rev == 6)
+		if (class_rev == 6)
 			return -ENODEV;
 
-		switch(rev) {
+		switch(class_rev) {
 			case 3:
-				ppi[0] = &info_hpt370;
+				port = &info_hpt370;
 				chip_table = &hpt370;
 				prefer_dpll = 0;
 				break;
 			case 4:
-				ppi[0] = &info_hpt370a;
+				port = &info_hpt370a;
 				chip_table = &hpt370a;
 				prefer_dpll = 0;
 				break;
 			case 5:
-				ppi[0] = &info_hpt372;
+				port = &info_hpt372;
 				chip_table = &hpt372;
 				break;
 			default:
-				printk(KERN_ERR "pata_hpt37x: Unknown HPT366 "
-				       "subtype, please report (%d).\n", rev);
+				printk(KERN_ERR "pata_hpt37x: Unknown HPT366 subtype please report (%d).\n", class_rev);
 				return -ENODEV;
 		}
 	} else {
 		switch(dev->device) {
 			case PCI_DEVICE_ID_TTI_HPT372:
 				/* 372N if rev >= 2*/
-				if (rev >= 2)
+				if (class_rev >= 2)
 					return -ENODEV;
-				ppi[0] = &info_hpt372;
+				port = &info_hpt372;
 				chip_table = &hpt372a;
 				break;
 			case PCI_DEVICE_ID_TTI_HPT302:
 				/* 302N if rev > 1 */
-				if (rev > 1)
+				if (class_rev > 1)
 					return -ENODEV;
-				ppi[0] = &info_hpt372;
+				port = &info_hpt372;
 				/* Check this */
 				chip_table = &hpt302;
 				break;
 			case PCI_DEVICE_ID_TTI_HPT371:
-				if (rev > 1)
+				if (class_rev > 1)
 					return -ENODEV;
-				ppi[0] = &info_hpt372;
+				port = &info_hpt372;
 				chip_table = &hpt371;
 				/* Single channel device, master is not present
 				   but the BIOS (or us for non x86) must mark it
@@ -865,10 +1018,7 @@
 				break;
 			case PCI_DEVICE_ID_TTI_HPT374:
 				chip_table = &hpt374;
-				if (!(PCI_FUNC(dev->devfn) & 1))
-					*ppi = &info_hpt374_fn0;
-				else
-					*ppi = &info_hpt374_fn1;
+				port = &info_hpt374;
 				break;
 			default:
 				printk(KERN_ERR "pata_hpt37x: PCI table is bogus please report (%d).\n", dev->device);
@@ -903,16 +1053,9 @@
 		outb(0x0e, iobase + 0x9c);
 
 	/* Some devices do not let this value be accessed via PCI space
-	   according to the old driver. In addition we must use the value
-	   from FN 0 on the HPT374 */
-
-	if (chip_table == &hpt374) {
-		freq = hpt374_read_freq(dev);
-		if (freq == 0)
-			return -ENODEV;
-	} else
-		freq = inl(iobase + 0x90);
+	   according to the old driver */
 
+	freq = inl(iobase + 0x90);
 	if ((freq >> 12) != 0xABCDE) {
 		int i;
 		u8 sr;
@@ -947,7 +1090,7 @@
 		int dpll, adjust;
 
 		/* Compute DPLL */
-		dpll = (ppi[0]->udma_mask & 0xC0) ? 3 : 2;
+		dpll = (port->udma_mask & 0xC0) ? 3 : 2;
 
 		f_low = (MHz[clock_slot] * 48) / MHz[dpll];
 		f_high = f_low + 2;
@@ -987,16 +1130,19 @@
 		 *	about lack of UDMA133 support on lower clocks
  		 */
 
-		if (clock_slot < 2 && ppi[0] == &info_hpt370)
-			ppi[0] = &info_hpt370_33;
-		if (clock_slot < 2 && ppi[0] == &info_hpt370a)
-			ppi[0] = &info_hpt370a_33;
+		if (clock_slot < 2 && port == &info_hpt370)
+			port = &info_hpt370_33;
+		if (clock_slot < 2 && port == &info_hpt370a)
+			port = &info_hpt370a_33;
 		printk(KERN_INFO "pata_hpt37x: %s using %dMHz bus clock.\n",
 		       chip_table->name, MHz[clock_slot]);
 	}
 
 	/* Now kick off ATA set up */
-	return ata_pci_sff_init_one(dev, ppi, &hpt37x_sht, private_data);
+	port_info = *port;
+	port_info.private_data = private_data;
+
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id hpt37x[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_hpt3x2n.c linux-sh4/drivers/ata/pata_hpt3x2n.c
--- linux-sh4/drivers/ata.org/pata_hpt3x2n.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_hpt3x2n.c	2012-01-15 06:30:15.000000000 -0800
@@ -8,7 +8,7 @@
  * Copyright (C) 1999-2003		Andre Hedrick <andre@linux-ide.org>
  * Portions Copyright (C) 2001	        Sun Microsystems, Inc.
  * Portions Copyright (C) 2003		Red Hat Inc
- * Portions Copyright (C) 2005-2009	MontaVista Software, Inc.
+ * Portions Copyright (C) 2005-2007	MontaVista Software, Inc.
  *
  *
  * TODO
@@ -25,7 +25,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME	"pata_hpt3x2n"
-#define DRV_VERSION	"0.3.9"
+#define DRV_VERSION	"0.3.4"
 
 enum {
 	HPT_PCI_FAST	=	(1 << 31),
@@ -141,22 +141,33 @@
 
 /**
  *	hpt3x2n_pre_reset	-	reset the hpt3x2n bus
- *	@link: ATA link to reset
+ *	@ap: ATA port to reset
  *	@deadline: deadline jiffies for the operation
  *
  *	Perform the initial reset handling for the 3x2n series controllers.
  *	Reset the hardware and state machine,
  */
 
-static int hpt3x2n_pre_reset(struct ata_link *link, unsigned long deadline)
+static int hpt3xn_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	/* Reset the state machine */
 	pci_write_config_byte(pdev, 0x50 + 4 * ap->port_no, 0x37);
 	udelay(100);
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	hpt3x2n_error_handler	-	probe the hpt3x2n bus
+ *	@ap: ATA port to reset
+ *
+ *	Perform the probe reset handling for the 3x2N
+ */
+
+static void hpt3x2n_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, hpt3xn_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -185,8 +196,9 @@
 
 	pci_read_config_dword(pdev, addr1, &reg);
 	mode = hpt3x2n_find_mode(ap, adev->pio_mode);
-	mode &= 0xCFC3FFFF;	/* Leave DMA bits alone */
-	reg &= ~0xCFC3FFFF;	/* Strip timing bits */
+	mode &= ~0x8000000;	/* No FIFO in PIO */
+	mode &= ~0x30070000;	/* Leave config bits alone */
+	reg &= 0x30070000;	/* Strip timing bits */
 	pci_write_config_dword(pdev, addr1, reg | mode);
 }
 
@@ -203,7 +215,8 @@
 {
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	u32 addr1, addr2;
-	u32 reg, mode, mask;
+	u32 reg;
+	u32 mode;
 	u8 fast;
 
 	addr1 = 0x40 + 4 * (adev->devno + 2 * ap->port_no);
@@ -214,12 +227,11 @@
 	fast &= ~0x07;
 	pci_write_config_byte(pdev, addr2, fast);
 
-	mask = adev->dma_mode < XFER_UDMA_0 ? 0x31C001FF : 0x303C0000;
-
 	pci_read_config_dword(pdev, addr1, &reg);
 	mode = hpt3x2n_find_mode(ap, adev->dma_mode);
-	mode &= mask;
-	reg &= ~mask;
+	mode |= 0x8000000;	/* FIFO in MWDMA or UDMA */
+	mode &= ~0xC0000000;	/* Leave config bits alone */
+	reg &= 0xC0000000;	/* Strip timing bits */
 	pci_write_config_dword(pdev, addr1, reg | mode);
 }
 
@@ -262,7 +274,7 @@
 
 static void hpt3x2n_set_clock(struct ata_port *ap, int source)
 {
-	void __iomem *bmdma = ap->ioaddr.bmdma_addr - ap->port_no * 8;
+	void __iomem *bmdma = ap->ioaddr.bmdma_addr;
 
 	/* Tristate the bus */
 	iowrite8(0x80, bmdma+0x73);
@@ -272,9 +284,9 @@
 	iowrite8(source, bmdma+0x7B);
 	iowrite8(0xC0, bmdma+0x79);
 
-	/* Reset state machines, avoid enabling the disabled channels */
-	iowrite8(ioread8(bmdma+0x70) | 0x32, bmdma+0x70);
-	iowrite8(ioread8(bmdma+0x74) | 0x32, bmdma+0x74);
+	/* Reset state machines */
+	iowrite8(0x37, bmdma+0x70);
+	iowrite8(0x37, bmdma+0x74);
 
 	/* Complete reset */
 	iowrite8(0x00, bmdma+0x79);
@@ -284,10 +296,21 @@
 	iowrite8(0x00, bmdma+0x77);
 }
 
+/* Check if our partner interface is busy */
+
+static int hpt3x2n_pair_idle(struct ata_port *ap)
+{
+	struct ata_host *host = ap->host;
+	struct ata_port *pair = host->ports[ap->port_no ^ 1];
+
+	if (pair->hsm_task_state == HSM_ST_IDLE)
+		return 1;
+	return 0;
+}
+
 static int hpt3x2n_use_dpll(struct ata_port *ap, int writing)
 {
 	long flags = (long)ap->host->private_data;
-
 	/* See if we should use the DPLL */
 	if (writing)
 		return USE_DPLL;	/* Needed for write */
@@ -296,41 +319,40 @@
 	return 0;
 }
 
-static int hpt3x2n_qc_defer(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct ata_port *alt = ap->host->ports[ap->port_no ^ 1];
-	int rc, flags = (long)ap->host->private_data;
-	int dpll = hpt3x2n_use_dpll(ap, qc->tf.flags & ATA_TFLAG_WRITE);
-
-	/* First apply the usual rules */
-	rc = ata_std_qc_defer(qc);
-	if (rc != 0)
-		return rc;
-
-	if ((flags & USE_DPLL) != dpll && alt->qc_active)
-		return ATA_DEFER_PORT;
-	return 0;
-}
-
-static unsigned int hpt3x2n_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int hpt3x2n_qc_issue_prot(struct ata_queued_cmd *qc)
 {
+	struct ata_taskfile *tf = &qc->tf;
 	struct ata_port *ap = qc->ap;
 	int flags = (long)ap->host->private_data;
-	int dpll = hpt3x2n_use_dpll(ap, qc->tf.flags & ATA_TFLAG_WRITE);
 
-	if ((flags & USE_DPLL) != dpll) {
-		flags &= ~USE_DPLL;
-		flags |= dpll;
-		ap->host->private_data = (void *)(long)flags;
-
-		hpt3x2n_set_clock(ap, dpll ? 0x21 : 0x23);
+	if (hpt3x2n_pair_idle(ap)) {
+		int dpll = hpt3x2n_use_dpll(ap, (tf->flags & ATA_TFLAG_WRITE));
+		if ((flags & USE_DPLL) != dpll) {
+			if (dpll == 1)
+				hpt3x2n_set_clock(ap, 0x21);
+			else
+				hpt3x2n_set_clock(ap, 0x23);
+		}
 	}
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 static struct scsi_host_template hpt3x2n_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 /*
@@ -338,17 +360,39 @@
  */
 
 static struct ata_port_operations hpt3x2n_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= hpt3x2n_set_piomode,
+	.set_dmamode	= hpt3x2n_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
 
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= hpt3x2n_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= hpt3x2n_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
 	.bmdma_stop	= hpt3x2n_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
 
-	.qc_defer	= hpt3x2n_qc_defer,
-	.qc_issue	= hpt3x2n_qc_issue,
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= hpt3x2n_qc_issue_prot,
 
-	.cable_detect	= hpt3x2n_cable_detect,
-	.set_piomode	= hpt3x2n_set_piomode,
-	.set_dmamode	= hpt3x2n_set_dmamode,
-	.prereset	= hpt3x2n_pre_reset,
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -445,43 +489,44 @@
 {
 	/* HPT372N and friends - UDMA133 */
 	static const struct ata_port_info info = {
+		.sht = &hpt3x2n_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA6,
 		.port_ops = &hpt3x2n_port_ops
 	};
-	const struct ata_port_info *ppi[] = { &info, NULL };
-	u8 rev = dev->revision;
+	struct ata_port_info port = info;
+	const struct ata_port_info *ppi[] = { &port, NULL };
+
 	u8 irqmask;
+	u32 class_rev;
+
 	unsigned int pci_mhz;
 	unsigned int f_low, f_high;
 	int adjust;
 	unsigned long iobase = pci_resource_start(dev, 4);
-	void *hpriv = (void *)USE_DPLL;
-	int rc;
 
-	rc = pcim_enable_device(dev);
-	if (rc)
-		return rc;
+	pci_read_config_dword(dev, PCI_CLASS_REVISION, &class_rev);
+	class_rev &= 0xFF;
 
 	switch(dev->device) {
 		case PCI_DEVICE_ID_TTI_HPT366:
-			if (rev < 6)
+			if (class_rev < 6)
 				return -ENODEV;
 			break;
 		case PCI_DEVICE_ID_TTI_HPT371:
-			if (rev < 2)
+			if (class_rev < 2)
 				return -ENODEV;
 			/* 371N if rev > 1 */
 			break;
 		case PCI_DEVICE_ID_TTI_HPT372:
 			/* 372N if rev >= 2*/
-			if (rev < 2)
+			if (class_rev < 2)
 				return -ENODEV;
 			break;
 		case PCI_DEVICE_ID_TTI_HPT302:
-			if (rev < 2)
+			if (class_rev < 2)
 				return -ENODEV;
 			break;
 		case PCI_DEVICE_ID_TTI_HPT372N:
@@ -542,19 +587,20 @@
 	       pci_mhz);
 	/* Set our private data up. We only need a few flags so we use
 	   it directly */
-	if (pci_mhz > 60)
-		hpriv = (void *)(PCI66 | USE_DPLL);
-
-	/*
-	 * On  HPT371N, if ATA clock is 66 MHz we must set bit 2 in
-	 * the MISC. register to stretch the UltraDMA Tss timing.
-	 * NOTE: This register is only writeable via I/O space.
-	 */
-	if (dev->device == PCI_DEVICE_ID_TTI_HPT371)
-		outb(inb(iobase + 0x9c) | 0x04, iobase + 0x9c);
+	port.private_data = NULL;
+	if (pci_mhz > 60) {
+		port.private_data = (void *)PCI66;
+		/*
+		 * On  HPT371N, if ATA clock is 66 MHz we must set bit 2 in
+		 * the MISC. register to stretch the UltraDMA Tss timing.
+		 * NOTE: This register is only writeable via I/O space.
+		 */
+		if (dev->device == PCI_DEVICE_ID_TTI_HPT371)
+			outb(inb(iobase + 0x9c) | 0x04, iobase + 0x9c);
+	}
 
 	/* Now kick off ATA set up */
-	return ata_pci_sff_init_one(dev, ppi, &hpt3x2n_sht, hpriv);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id hpt3x2n[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_hpt3x3.c linux-sh4/drivers/ata/pata_hpt3x3.c
--- linux-sh4/drivers/ata.org/pata_hpt3x3.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_hpt3x3.c	2012-01-15 06:30:15.000000000 -0800
@@ -23,7 +23,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME	"pata_hpt3x3"
-#define DRV_VERSION	"0.6.1"
+#define DRV_VERSION	"0.5.3"
 
 /**
  *	hpt3x3_set_piomode		-	PIO setup
@@ -80,48 +80,14 @@
 	r2 &= ~(0x11 << dn);	/* Clear MWDMA and UDMA bits */
 
 	if (adev->dma_mode >= XFER_UDMA_0)
-		r2 |= (0x01 << dn);	/* Ultra mode */
+		r2 |= (0x10 << dn);	/* Ultra mode */
 	else
-		r2 |= (0x10 << dn);	/* MWDMA */
+		r2 |= (0x01 << dn);	/* MWDMA */
 
 	pci_write_config_dword(pdev, 0x44, r1);
 	pci_write_config_dword(pdev, 0x48, r2);
 }
-
-/**
- *	hpt3x3_freeze		-	DMA workaround
- *	@ap: port to freeze
- *
- *	When freezing an HPT3x3 we must stop any pending DMA before
- *	writing to the control register or the chip will hang
- */
-
-static void hpt3x3_freeze(struct ata_port *ap)
-{
-	void __iomem *mmio = ap->ioaddr.bmdma_addr;
-
-	iowrite8(ioread8(mmio + ATA_DMA_CMD) & ~ ATA_DMA_START,
-			mmio + ATA_DMA_CMD);
-	ata_sff_dma_pause(ap);
-	ata_sff_freeze(ap);
-}
-
-/**
- *	hpt3x3_bmdma_setup	-	DMA workaround
- *	@qc: Queued command
- *
- *	When issuing BMDMA we must clean up the error/active bits in
- *	software on this device
- */
-
-static void hpt3x3_bmdma_setup(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	u8 r = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
-	r |= ATA_DMA_INTR | ATA_DMA_ERR;
-	iowrite8(r, ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
-	return ata_bmdma_setup(qc);
-}
+#endif /* CONFIG_PATA_HPT3X3_DMA */
 
 /**
  *	hpt3x3_atapi_dma	-	ATAPI DMA check
@@ -135,23 +101,61 @@
 	return 1;
 }
 
-#endif /* CONFIG_PATA_HPT3X3_DMA */
-
 static struct scsi_host_template hpt3x3_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations hpt3x3_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= hpt3x3_set_piomode,
 #if defined(CONFIG_PATA_HPT3X3_DMA)
 	.set_dmamode	= hpt3x3_set_dmamode,
-	.bmdma_setup	= hpt3x3_bmdma_setup,
-	.check_atapi_dma= hpt3x3_atapi_dma,
-	.freeze		= hpt3x3_freeze,
 #endif
-	
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+	.check_atapi_dma= hpt3x3_atapi_dma,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -187,12 +191,13 @@
 {
 	static int printed_version;
 	static const struct ata_port_info info = {
+		.sht = &hpt3x3_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
+		.pio_mask = 0x1f,
 #if defined(CONFIG_PATA_HPT3X3_DMA)
 		/* Further debug needed */
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA2,
+		.mwdma_mask = 0x07,
+		.udma_mask = 0x07,
 #endif
 		.port_ops = &hpt3x3_port_ops
 	};
@@ -234,22 +239,18 @@
 	base = host->iomap[4];	/* Bus mastering base */
 
 	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		struct ata_ioports *ioaddr = &ap->ioaddr;
+		struct ata_ioports *ioaddr = &host->ports[i]->ioaddr;
 
 		ioaddr->cmd_addr = base + offset_cmd[i];
 		ioaddr->altstatus_addr =
 		ioaddr->ctl_addr = base + offset_ctl[i];
 		ioaddr->scr_addr = NULL;
-		ata_sff_std_ports(ioaddr);
+		ata_std_ports(ioaddr);
 		ioaddr->bmdma_addr = base + 8 * i;
-
-		ata_port_pbar_desc(ap, 4, -1, "ioport");
-		ata_port_pbar_desc(ap, 4, offset_cmd[i], "cmd");
 	}
 	pci_set_master(pdev);
-	return ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &hpt3x3_sht);
+	return ata_host_activate(host, pdev->irq, ata_interrupt, IRQF_SHARED,
+				 &hpt3x3_sht);
 }
 
 #ifdef CONFIG_PM
diff -Nur linux-sh4/drivers/ata.org/pata_icside.c linux-sh4/drivers/ata/pata_icside.c
--- linux-sh4/drivers/ata.org/pata_icside.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_icside.c	2012-01-15 06:30:15.000000000 -0800
@@ -45,6 +45,8 @@
 	.stepping	= 6,
 };
 
+#define PATA_ICSIDE_MAX_SG	128
+
 struct pata_icside_state {
 	void __iomem *irq_port;
 	void __iomem *ioc_base;
@@ -55,6 +57,7 @@
 		u8 disabled;
 		unsigned int speed[ATA_MAX_DEVICES];
 	} port[2];
+	struct scatterlist sg[PATA_ICSIDE_MAX_SG];
 };
 
 struct pata_icside_info {
@@ -67,8 +70,6 @@
 	unsigned int		mwdma_mask;
 	unsigned int		nr_ports;
 	const struct portinfo	*port[2];
-	unsigned long		raw_base;
-	unsigned long		raw_ioc_base;
 };
 
 #define ICS_TYPE_A3IN	0
@@ -219,6 +220,7 @@
 {
 	struct ata_port *ap = qc->ap;
 	struct pata_icside_state *state = ap->host->private_data;
+	struct scatterlist *sg, *rsg = state->sg;
 	unsigned int write = qc->tf.flags & ATA_TFLAG_WRITE;
 
 	/*
@@ -228,16 +230,24 @@
 	BUG_ON(dma_channel_active(state->dma));
 
 	/*
+	 * Copy ATAs scattered sg list into a contiguous array of sg
+	 */
+	ata_for_each_sg(sg, qc) {
+		memcpy(rsg, sg, sizeof(*sg));
+		rsg++;
+	}
+
+	/*
 	 * Route the DMA signals to the correct interface
 	 */
 	writeb(state->port[ap->port_no].port_sel, state->ioc_base);
 
 	set_dma_speed(state->dma, state->port[ap->port_no].speed[qc->dev->devno]);
-	set_dma_sg(state->dma, qc->sg, qc->n_elem);
+	set_dma_sg(state->dma, state->sg, rsg - state->sg);
 	set_dma_mode(state->dma, write ? DMA_MODE_WRITE : DMA_MODE_READ);
 
 	/* issue r/w command */
-	ap->ops->sff_exec_command(ap, &qc->tf);
+	ap->ops->exec_command(ap, &qc->tf);
 }
 
 static void pata_icside_bmdma_start(struct ata_queued_cmd *qc)
@@ -257,7 +267,7 @@
 	disable_dma(state->dma);
 
 	/* see ata_bmdma_stop */
-	ata_sff_dma_pause(ap);
+	ata_altstatus(ap);
 }
 
 static u8 pata_icside_bmdma_status(struct ata_port *ap)
@@ -284,26 +294,48 @@
 
 	if (ec->dma != NO_DMA && !request_dma(ec->dma, DRV_NAME)) {
 		state->dma = ec->dma;
-		info->mwdma_mask = ATA_MWDMA2;
+		info->mwdma_mask = 0x07;	/* MW0..2 */
 	}
 
 	return 0;
 }
 
 
+static int pata_icside_port_start(struct ata_port *ap)
+{
+	/* No PRD to alloc */
+	return ata_pad_alloc(ap, ap->dev);
+}
+
 static struct scsi_host_template pata_icside_sht = {
-	ATA_BASE_SHT(DRV_NAME),
-	.sg_tablesize		= SCSI_MAX_SG_CHAIN_SEGMENTS,
-	.dma_boundary		= IOMD_DMA_BOUNDARY,
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= PATA_ICSIDE_MAX_SG,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ~0, /* no dma boundaries */
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static void pata_icside_postreset(struct ata_link *link, unsigned int *classes)
+/* wish this was exported from libata-core */
+static void ata_dummy_noret(struct ata_port *port)
+{
+}
+
+static void pata_icside_postreset(struct ata_port *ap, unsigned int *classes)
 {
-	struct ata_port *ap = link->ap;
 	struct pata_icside_state *state = ap->host->private_data;
 
 	if (classes[0] != ATA_DEV_NONE || classes[1] != ATA_DEV_NONE)
-		return ata_sff_postreset(link, classes);
+		return ata_std_postreset(ap, classes);
 
 	state->port[ap->port_no].disabled = 1;
 
@@ -319,51 +351,86 @@
 	}
 }
 
+static void pata_icside_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, ata_std_prereset, ata_std_softreset, NULL,
+			   pata_icside_postreset);
+}
+
+static u8 pata_icside_irq_ack(struct ata_port *ap, unsigned int chk_drq)
+{
+	unsigned int bits = chk_drq ? ATA_BUSY | ATA_DRQ : ATA_BUSY;
+	u8 status;
+
+	status = ata_busy_wait(ap, bits, 1000);
+	if (status & bits)
+		if (ata_msg_err(ap))
+			printk(KERN_ERR "abnormal status 0x%X\n", status);
+
+	if (ata_msg_intr(ap))
+		printk(KERN_INFO "%s: irq ack: drv_stat 0x%X\n",
+			__FUNCTION__, status);
+
+	return status;
+}
+
 static struct ata_port_operations pata_icside_port_ops = {
-	.inherits		= &ata_sff_port_ops,
-	/* no need to build any PRD tables for DMA */
-	.qc_prep		= ata_noop_qc_prep,
-	.sff_data_xfer		= ata_sff_data_xfer_noirq,
+	.port_disable		= ata_port_disable,
+
+	.set_dmamode		= pata_icside_set_dmamode,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.exec_command		= ata_exec_command,
+	.check_status		= ata_check_status,
+	.dev_select		= ata_std_dev_select,
+
+	.cable_detect		= ata_cable_40wire,
+
 	.bmdma_setup		= pata_icside_bmdma_setup,
 	.bmdma_start		= pata_icside_bmdma_start,
-	.bmdma_stop		= pata_icside_bmdma_stop,
-	.bmdma_status		= pata_icside_bmdma_status,
 
-	.cable_detect		= ata_cable_40wire,
-	.set_dmamode		= pata_icside_set_dmamode,
-	.postreset		= pata_icside_postreset,
+	.data_xfer		= ata_data_xfer_noirq,
+
+	/* no need to build any PRD tables for DMA */
+	.qc_prep		= ata_noop_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= pata_icside_error_handler,
 	.post_internal_cmd	= pata_icside_bmdma_stop,
+
+	.irq_clear		= ata_dummy_noret,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= pata_icside_irq_ack,
+
+	.port_start		= pata_icside_port_start,
+
+	.bmdma_stop		= pata_icside_bmdma_stop,
+	.bmdma_status		= pata_icside_bmdma_status,
 };
 
 static void __devinit
-pata_icside_setup_ioaddr(struct ata_port *ap, void __iomem *base,
-			 struct pata_icside_info *info,
-			 const struct portinfo *port)
+pata_icside_setup_ioaddr(struct ata_ioports *ioaddr, void __iomem *base,
+			 const struct portinfo *info)
 {
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	void __iomem *cmd = base + port->dataoffset;
+	void __iomem *cmd = base + info->dataoffset;
 
 	ioaddr->cmd_addr	= cmd;
-	ioaddr->data_addr	= cmd + (ATA_REG_DATA    << port->stepping);
-	ioaddr->error_addr	= cmd + (ATA_REG_ERR     << port->stepping);
-	ioaddr->feature_addr	= cmd + (ATA_REG_FEATURE << port->stepping);
-	ioaddr->nsect_addr	= cmd + (ATA_REG_NSECT   << port->stepping);
-	ioaddr->lbal_addr	= cmd + (ATA_REG_LBAL    << port->stepping);
-	ioaddr->lbam_addr	= cmd + (ATA_REG_LBAM    << port->stepping);
-	ioaddr->lbah_addr	= cmd + (ATA_REG_LBAH    << port->stepping);
-	ioaddr->device_addr	= cmd + (ATA_REG_DEVICE  << port->stepping);
-	ioaddr->status_addr	= cmd + (ATA_REG_STATUS  << port->stepping);
-	ioaddr->command_addr	= cmd + (ATA_REG_CMD     << port->stepping);
+	ioaddr->data_addr	= cmd + (ATA_REG_DATA    << info->stepping);
+	ioaddr->error_addr	= cmd + (ATA_REG_ERR     << info->stepping);
+	ioaddr->feature_addr	= cmd + (ATA_REG_FEATURE << info->stepping);
+	ioaddr->nsect_addr	= cmd + (ATA_REG_NSECT   << info->stepping);
+	ioaddr->lbal_addr	= cmd + (ATA_REG_LBAL    << info->stepping);
+	ioaddr->lbam_addr	= cmd + (ATA_REG_LBAM    << info->stepping);
+	ioaddr->lbah_addr	= cmd + (ATA_REG_LBAH    << info->stepping);
+	ioaddr->device_addr	= cmd + (ATA_REG_DEVICE  << info->stepping);
+	ioaddr->status_addr	= cmd + (ATA_REG_STATUS  << info->stepping);
+	ioaddr->command_addr	= cmd + (ATA_REG_CMD     << info->stepping);
 
-	ioaddr->ctl_addr	= base + port->ctrloffset;
+	ioaddr->ctl_addr	= base + info->ctrloffset;
 	ioaddr->altstatus_addr	= ioaddr->ctl_addr;
-
-	ata_port_desc(ap, "cmd 0x%lx ctl 0x%lx",
-		      info->raw_base + port->dataoffset,
-		      info->raw_base + port->ctrloffset);
-
-	if (info->raw_ioc_base)
-		ata_port_desc(ap, "iocbase 0x%lx", info->raw_ioc_base);
 }
 
 static int __devinit pata_icside_register_v5(struct pata_icside_info *info)
@@ -384,8 +451,6 @@
 	info->nr_ports = 1;
 	info->port[0] = &pata_icside_portinfo_v5;
 
-	info->raw_base = ecard_resource_start(info->ec, ECARD_RES_MEMC);
-
 	return 0;
 }
 
@@ -426,9 +491,6 @@
 	info->port[0] = &pata_icside_portinfo_v6_1;
 	info->port[1] = &pata_icside_portinfo_v6_2;
 
-	info->raw_base = ecard_resource_start(ec, ECARD_RES_EASI);
-	info->raw_ioc_base = ecard_resource_start(ec, ECARD_RES_IOCFAST);
-
 	return icside_dma_init(info);
 }
 
@@ -460,15 +522,15 @@
 	for (i = 0; i < info->nr_ports; i++) {
 		struct ata_port *ap = host->ports[i];
 
-		ap->pio_mask = ATA_PIO4;
+		ap->pio_mask = 0x1f;
 		ap->mwdma_mask = info->mwdma_mask;
 		ap->flags |= ATA_FLAG_SLAVE_POSS;
 		ap->ops = &pata_icside_port_ops;
 
-		pata_icside_setup_ioaddr(ap, info->base, info, info->port[i]);
+		pata_icside_setup_ioaddr(&ap->ioaddr, info->base, info->port[i]);
 	}
 
-	return ata_host_activate(host, ec->irq, ata_sff_interrupt, 0,
+	return ata_host_activate(host, ec->irq, ata_interrupt, 0,
 				 &pata_icside_sht);
 }
 
diff -Nur linux-sh4/drivers/ata.org/pata_isapnp.c linux-sh4/drivers/ata/pata_isapnp.c
--- linux-sh4/drivers/ata.org/pata_isapnp.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_isapnp.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 
 /*
  *   pata-isapnp.c - ISA PnP PATA controller driver.
- *   Copyright 2005/2006 Red Hat Inc, all rights reserved.
+ *   Copyright 2005/2006 Red Hat Inc <alan@redhat.com>, all rights reserved.
  *
  *   Based in part on ide-pnp.c by Andrey Panin <pazke@donpac.ru>
  */
@@ -17,22 +17,50 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "pata_isapnp"
-#define DRV_VERSION "0.2.5"
+#define DRV_VERSION "0.2.2"
 
 static struct scsi_host_template isapnp_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations isapnp_port_ops = {
-	.inherits	= &ata_sff_port_ops,
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
 	.cable_detect	= ata_cable_40wire,
-};
 
-static struct ata_port_operations isapnp_noalt_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.cable_detect	= ata_cable_40wire,
-	/* No altstatus so we don't want to use the lost interrupt poll */
-	.lost_interrupt = ATA_OP_NULL,
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -49,16 +77,13 @@
 	struct ata_host *host;
 	struct ata_port *ap;
 	void __iomem *cmd_addr, *ctl_addr;
-	int irq = 0;
-	irq_handler_t handler = NULL;
 
 	if (pnp_port_valid(idev, 0) == 0)
 		return -ENODEV;
 
-	if (pnp_irq_valid(idev, 0)) {
-		irq = pnp_irq(idev, 0);
-		handler = ata_sff_interrupt;
-	}
+	/* FIXME: Should selected polled PIO here not fail */
+	if (pnp_irq_valid(idev, 0) == 0)
+		return -ENODEV;
 
 	/* allocate host */
 	host = ata_host_alloc(&idev->dev, 1);
@@ -72,8 +97,8 @@
 
 	ap = host->ports[0];
 
-	ap->ops = &isapnp_noalt_port_ops;
-	ap->pio_mask = ATA_PIO0;
+	ap->ops = &isapnp_port_ops;
+	ap->pio_mask = 1;
 	ap->flags |= ATA_FLAG_SLAVE_POSS;
 
 	ap->ioaddr.cmd_addr = cmd_addr;
@@ -83,17 +108,12 @@
 					   pnp_port_start(idev, 1), 1);
 		ap->ioaddr.altstatus_addr = ctl_addr;
 		ap->ioaddr.ctl_addr = ctl_addr;
-		ap->ops = &isapnp_port_ops;
 	}
 
-	ata_sff_std_ports(&ap->ioaddr);
-
-	ata_port_desc(ap, "cmd 0x%llx ctl 0x%llx",
-		      (unsigned long long)pnp_port_start(idev, 0),
-		      (unsigned long long)pnp_port_start(idev, 1));
+	ata_std_ports(&ap->ioaddr);
 
 	/* activate */
-	return ata_host_activate(host, irq, handler, 0,
+	return ata_host_activate(host, pnp_irq(idev, 0), ata_interrupt, 0,
 				 &isapnp_sht);
 }
 
diff -Nur linux-sh4/drivers/ata.org/pata_it8213.c linux-sh4/drivers/ata/pata_it8213.c
--- linux-sh4/drivers/ata.org/pata_it8213.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_it8213.c	2012-01-15 06:30:15.000000000 -0800
@@ -23,24 +23,36 @@
 
 /**
  *	it8213_pre_reset	-	check for 40/80 pin
- *	@link: link
+ *	@ap: Port
  *	@deadline: deadline jiffies for the operation
  *
  *	Filter out ports by the enable bits before doing the normal reset
  *	and probe.
  */
 
-static int it8213_pre_reset(struct ata_link *link, unsigned long deadline)
+static int it8213_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits it8213_enable_bits[] = {
 		{ 0x41U, 1U, 0x80UL, 0x80UL },	/* port 0 */
 	};
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	if (!pci_test_config_bits(pdev, &it8213_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	it8213_error_handler - Probe specified port on PATA host controller
+ *	@ap: Port to probe
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void it8213_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, it8213_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -115,7 +127,7 @@
 		idetm_data &= 0xCC0F;
 		idetm_data |= (control << 4);
 
-		/* Slave timing in separate register */
+		/* Slave timing in seperate register */
 		pci_read_config_byte(dev, 0x44, &slave_data);
 		slave_data &= 0xF0;
 		slave_data |= ((timings[pio][0] << 2) | timings[pio][1]) << 4;
@@ -230,16 +242,55 @@
 }
 
 static struct scsi_host_template it8213_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.max_sectors		= ATA_MAX_SECTORS,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.bios_param		= ata_std_bios_param,
 };
 
-
-static struct ata_port_operations it8213_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.cable_detect		= it8213_cable_detect,
+static const struct ata_port_operations it8213_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= it8213_set_piomode,
 	.set_dmamode		= it8213_set_dmamode,
-	.prereset		= it8213_pre_reset,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= it8213_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= it8213_cable_detect,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 
@@ -261,9 +312,10 @@
 {
 	static int printed_version;
 	static const struct ata_port_info info = {
+		.sht		= &it8213_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask 	= ATA_UDMA4, /* FIXME: want UDMA 100? */
 		.port_ops	= &it8213_ops,
 	};
@@ -274,7 +326,7 @@
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "version " DRV_VERSION "\n");
 
-	return ata_pci_sff_init_one(pdev, ppi, &it8213_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id it8213_pci_tbl[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_it821x.c linux-sh4/drivers/ata/pata_it821x.c
--- linux-sh4/drivers/ata.org/pata_it821x.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_it821x.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  * pata_it821x.c 	- IT821x PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
- *			  Alan Cox <alan@lxorguk.ukuu.org.uk>
+ *			  Alan Cox <alan@redhat.com>
  *			  (C) 2007 Bartlomiej Zolnierkiewicz
  *
  * based upon
@@ -10,7 +10,7 @@
  *
  * linux/drivers/ide/pci/it821x.c		Version 0.09	December 2004
  *
- * Copyright (C) 2004		Red Hat
+ * Copyright (C) 2004		Red Hat <alan@redhat.com>
  *
  *  May be copied or modified under the terms of the GNU General Public License
  *  Based in part on the ITE vendor provided SCSI driver.
@@ -80,7 +80,7 @@
 
 
 #define DRV_NAME "pata_it821x"
-#define DRV_VERSION "0.4.2"
+#define DRV_VERSION "0.3.8"
 
 struct it821x_dev
 {
@@ -105,7 +105,7 @@
 
 /*
  *	We allow users to force the card into non raid mode without
- *	flashing the alternative BIOS. This is also necessary right now
+ *	flashing the alternative BIOS. This is also neccessary right now
  *	for embedded platforms that cannot run a PC BIOS but are using this
  *	device.
  */
@@ -383,7 +383,7 @@
  *	@ap: ATA port
  *	@device: Device number (not pointer)
  *
- *	Device selection hook. If necessary perform clock switching
+ *	Device selection hook. If neccessary perform clock switching
  */
 
 static void it821x_passthru_dev_select(struct ata_port *ap,
@@ -391,15 +391,15 @@
 {
 	struct it821x_dev *itdev = ap->private_data;
 	if (itdev && device != itdev->last_device) {
-		struct ata_device *adev = &ap->link.device[device];
+		struct ata_device *adev = &ap->device[device];
 		it821x_program(ap, adev, itdev->pio[adev->devno]);
 		itdev->last_device = device;
 	}
-	ata_sff_dev_select(ap, device);
+	ata_std_dev_select(ap, device);
 }
 
 /**
- *	it821x_smart_qc_issue		-	wrap qc issue prot
+ *	it821x_smart_qc_issue_prot	-	wrap qc issue prot
  *	@qc: command
  *
  *	Wrap the command issue sequence for the IT821x. We need to
@@ -407,7 +407,7 @@
  *	usual happenings kick off
  */
 
-static unsigned int it821x_smart_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int it821x_smart_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	switch(qc->tf.command)
 	{
@@ -425,18 +425,16 @@
 		case ATA_CMD_WRITE_MULTI:
 		case ATA_CMD_WRITE_MULTI_EXT:
 		case ATA_CMD_ID_ATA:
-		case ATA_CMD_INIT_DEV_PARAMS:
-		case 0xFC:	/* Internal 'report rebuild state' */
 		/* Arguably should just no-op this one */
 		case ATA_CMD_SET_FEATURES:
-			return ata_sff_qc_issue(qc);
+			return ata_qc_issue_prot(qc);
 	}
 	printk(KERN_DEBUG "it821x: can't process command 0x%02X\n", qc->tf.command);
-	return AC_ERR_DEV;
+	return AC_ERR_INVALID;
 }
 
 /**
- *	it821x_passthru_qc_issue	-	wrap qc issue prot
+ *	it821x_passthru_qc_issue_prot	-	wrap qc issue prot
  *	@qc: command
  *
  *	Wrap the command issue sequence for the IT821x. We need to
@@ -444,15 +442,15 @@
  *	usual happenings kick off
  */
 
-static unsigned int it821x_passthru_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int it821x_passthru_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	it821x_passthru_dev_select(qc->ap, qc->dev->devno);
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 /**
  *	it821x_smart_set_mode	-	mode setting
- *	@link: interface to set up
+ *	@ap: interface to set up
  *	@unused: device that failed (error only)
  *
  *	Use a non standard set_mode function. We don't want to be tuned.
@@ -461,26 +459,29 @@
  *	and respect them.
  */
 
-static int it821x_smart_set_mode(struct ata_link *link, struct ata_device **unused)
+static int it821x_smart_set_mode(struct ata_port *ap, struct ata_device **unused)
 {
-	struct ata_device *dev;
+	int i;
 
-	ata_for_each_dev(dev, link, ENABLED) {
-		/* We don't really care */
-		dev->pio_mode = XFER_PIO_0;
-		dev->dma_mode = XFER_MW_DMA_0;
-		/* We do need the right mode information for DMA or PIO
-		   and this comes from the current configuration flags */
-		if (ata_id_has_dma(dev->id)) {
-			ata_dev_printk(dev, KERN_INFO, "configured for DMA\n");
-			dev->xfer_mode = XFER_MW_DMA_0;
-			dev->xfer_shift = ATA_SHIFT_MWDMA;
-			dev->flags &= ~ATA_DFLAG_PIO;
-		} else {
-			ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
-			dev->xfer_mode = XFER_PIO_0;
-			dev->xfer_shift = ATA_SHIFT_PIO;
-			dev->flags |= ATA_DFLAG_PIO;
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+		if (ata_dev_enabled(dev)) {
+			/* We don't really care */
+			dev->pio_mode = XFER_PIO_0;
+			dev->dma_mode = XFER_MW_DMA_0;
+			/* We do need the right mode information for DMA or PIO
+			   and this comes from the current configuration flags */
+			if (ata_id_has_dma(dev->id)) {
+				ata_dev_printk(dev, KERN_INFO, "configured for DMA\n");
+				dev->xfer_mode = XFER_MW_DMA_0;
+				dev->xfer_shift = ATA_SHIFT_MWDMA;
+				dev->flags &= ~ATA_DFLAG_PIO;
+			} else {
+				ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
+				dev->xfer_mode = XFER_PIO_0;
+				dev->xfer_shift = ATA_SHIFT_PIO;
+				dev->flags |= ATA_DFLAG_PIO;
+			}
 		}
 	}
 	return 0;
@@ -494,6 +495,8 @@
  *	special. In our case we need to lock the sector count to avoid
  *	blowing the brains out of the firmware with large LBA48 requests
  *
+ *	FIXME: When FUA appears we need to block FUA too. And SMART and
+ *	basically we need to filter commands for this chip.
  */
 
 static void it821x_dev_config(struct ata_device *adev)
@@ -507,62 +510,15 @@
 
 	if (strstr(model_num, "Integrated Technology Express")) {
 		/* RAID mode */
-		ata_dev_printk(adev, KERN_INFO, "%sRAID%d volume",
+		printk(KERN_INFO "IT821x %sRAID%d volume",
 			adev->id[147]?"Bootable ":"",
 			adev->id[129]);
 		if (adev->id[129] != 1)
 			printk("(%dK stripe)", adev->id[146]);
 		printk(".\n");
 	}
-	/* This is a controller firmware triggered funny, don't
-	   report the drive faulty! */
-	adev->horkage &= ~ATA_HORKAGE_DIAGNOSTIC;
-	/* No HPA in 'smart' mode */
-	adev->horkage |= ATA_HORKAGE_BROKEN_HPA;
 }
 
-/**
- *	it821x_read_id	-	Hack identify data up
- *	@adev: device to read
- *	@tf: proposed taskfile
- *	@id: buffer for returned ident data
- *
- *	Query the devices on this firmware driven port and slightly
- *	mash the identify data to stop us and common tools trying to
- *	use features not firmware supported. The firmware itself does
- *	some masking (eg SMART) but not enough.
- */
-
-static unsigned int it821x_read_id(struct ata_device *adev,
-					struct ata_taskfile *tf, u16 *id)
-{
-	unsigned int err_mask;
-	unsigned char model_num[ATA_ID_PROD_LEN + 1];
-
-	err_mask = ata_do_dev_read_id(adev, tf, id);
-	if (err_mask)
-		return err_mask;
-	ata_id_c_string(id, model_num, ATA_ID_PROD, sizeof(model_num));
-
-	id[83] &= ~(1 << 12);	/* Cache flush is firmware handled */
-	id[83] &= ~(1 << 13);	/* Ditto for LBA48 flushes */
-	id[84] &= ~(1 << 6);	/* No FUA */
-	id[85] &= ~(1 << 10);	/* No HPA */
-	id[76] = 0;		/* No NCQ/AN etc */
-
-	if (strstr(model_num, "Integrated Technology Express")) {
-		/* Set feature bits the firmware neglects */
-		id[49] |= 0x0300;	/* LBA, DMA */
-		id[83] &= 0x7FFF;
-		id[83] |= 0x4400;	/* Word 83 is valid and LBA48 */
-		id[86] |= 0x0400;	/* LBA48 on */
-		id[ATA_ID_MAJOR_VER] |= 0x1F;
-		/* Clear the serial number because it's different each boot
-		   which breaks validation on resume */
-		memset(&id[ATA_ID_SERNO], 0x20, ATA_ID_SERNO_LEN);
-	}
-	return err_mask;
-}
 
 /**
  *	it821x_check_atapi_dma	-	ATAPI DMA handler
@@ -578,7 +534,7 @@
 	struct it821x_dev *itdev = ap->private_data;
 
 	/* Only use dma for transfers to/from the media. */
-	if (ata_qc_raw_nbytes(qc) < 2048)
+	if (qc->nbytes < 2048)
 		return -EOPNOTSUPP;
 
 	/* No ATAPI DMA in smart mode */
@@ -591,136 +547,6 @@
 	return 0;
 }
 
-/**
- *	it821x_display_disk	-	display disk setup
- *	@n: Device number
- *	@buf: Buffer block from firmware
- *
- *	Produce a nice informative display of the device setup as provided
- *	by the firmware.
- */
-
-static void it821x_display_disk(int n, u8 *buf)
-{
-	unsigned char id[41];
-	int mode = 0;
-	char *mtype = "";
-	char mbuf[8];
-	char *cbl = "(40 wire cable)";
-
-	static const char *types[5] = {
-		"RAID0", "RAID1" "RAID 0+1", "JBOD", "DISK"
-	};
-
-	if (buf[52] > 4)	/* No Disk */
-		return;
-
-	ata_id_c_string((u16 *)buf, id, 0, 41); 
-
-	if (buf[51]) {
-		mode = ffs(buf[51]);
-		mtype = "UDMA";
-	} else if (buf[49]) {
-		mode = ffs(buf[49]);
-		mtype = "MWDMA";
-	}
-
-	if (buf[76])
-		cbl = "";
-
-	if (mode)
-		snprintf(mbuf, 8, "%5s%d", mtype, mode - 1);
-	else
-		strcpy(mbuf, "PIO");
-	if (buf[52] == 4)
-		printk(KERN_INFO "%d: %-6s %-8s          %s %s\n",
-				n, mbuf, types[buf[52]], id, cbl);
-	else
-		printk(KERN_INFO "%d: %-6s %-8s Volume: %1d %s %s\n",
-				n, mbuf, types[buf[52]], buf[53], id, cbl);
-	if (buf[125] < 100)
-		printk(KERN_INFO "%d: Rebuilding: %d%%\n", n, buf[125]);
-}
-
-/**
- *	it821x_firmware_command		-	issue firmware command
- *	@ap: IT821x port to interrogate
- *	@cmd: command
- *	@len: length
- *
- *	Issue firmware commands expecting data back from the controller. We
- *	use this to issue commands that do not go via the normal paths. Other
- *	commands such as 0xFC can be issued normally.
- */
-
-static u8 *it821x_firmware_command(struct ata_port *ap, u8 cmd, int len)
-{
-	u8 status;
-	int n = 0;
-	u16 *buf = kmalloc(len, GFP_KERNEL);
-	if (buf == NULL) {
-		printk(KERN_ERR "it821x_firmware_command: Out of memory\n");
-		return NULL;
-	}
-	/* This isn't quite a normal ATA command as we are talking to the
-	   firmware not the drives */
-	ap->ctl |= ATA_NIEN;
-	iowrite8(ap->ctl, ap->ioaddr.ctl_addr);
-	ata_wait_idle(ap);
-	iowrite8(ATA_DEVICE_OBS, ap->ioaddr.device_addr);
-	iowrite8(cmd, ap->ioaddr.command_addr);
-	udelay(1);
-	/* This should be almost immediate but a little paranoia goes a long
-	   way. */
-	while(n++ < 10) {
-		status = ioread8(ap->ioaddr.status_addr);
-		if (status & ATA_ERR) {
-			kfree(buf);
-			printk(KERN_ERR "it821x_firmware_command: rejected\n");
-			return NULL;
-		}
-		if (status & ATA_DRQ) {
-			ioread16_rep(ap->ioaddr.data_addr, buf, len/2);
-			return (u8 *)buf;
-		}
-		mdelay(1);
-	}
-	kfree(buf);
-	printk(KERN_ERR "it821x_firmware_command: timeout\n");
-	return NULL;
-}
-
-/**
- *	it821x_probe_firmware	-	firmware reporting/setup
- *	@ap: IT821x port being probed
- *
- *	Probe the firmware of the controller by issuing firmware command
- *	0xFA and analysing the returned data.
- */
-
-static void it821x_probe_firmware(struct ata_port *ap)
-{
-	u8 *buf;
-	int i;
-
-	/* This is a bit ugly as we can't just issue a task file to a device
-	   as this is controller magic */
-
-	buf = it821x_firmware_command(ap, 0xFA, 512);
-
-	if (buf != NULL) {
-		printk(KERN_INFO "pata_it821x: Firmware %02X/%02X/%02X%02X\n",
-				buf[505],
-				buf[506],
-				buf[507],
-				buf[508]);
-		for (i = 0; i < 4; i++)
- 			it821x_display_disk(i, buf + 128 * i);
-		kfree(buf);
-	}
-}
-
-
 
 /**
  *	it821x_port_start	-	port setup
@@ -738,7 +564,7 @@
 	struct it821x_dev *itdev;
 	u8 conf;
 
-	int ret = ata_sff_port_start(ap);
+	int ret = ata_port_start(ap);
 	if (ret < 0)
 		return ret;
 
@@ -754,8 +580,6 @@
 		/* Long I/O's although allowed in LBA48 space cause the
 		   onboard firmware to enter the twighlight zone */
 		/* No ATAPI DMA in this mode either */
-		if (ap->port_no == 0)
-			it821x_probe_firmware(ap);
 	}
 	/* Pull the current clocks from 0x50 */
 	if (conf & (1 << (1 + ap->port_no)))
@@ -777,82 +601,100 @@
 	return 0;
 }
 
-/**
- *	it821x_rdc_cable	-	Cable detect for RDC1010
- *	@ap: port we are checking
- *
- *	Return the RDC1010 cable type. Unlike the IT821x we know how to do
- *	this and can do host side cable detect
- */
-
-static int it821x_rdc_cable(struct ata_port *ap)
-{
-	u16 r40;
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-
-	pci_read_config_word(pdev, 0x40, &r40);
-	if (r40 & (1 << (2 + ap->port_no)))
-		return ATA_CBL_PATA40;
-	return ATA_CBL_PATA80;
-}
-
 static struct scsi_host_template it821x_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations it821x_smart_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
+	.set_mode	= it821x_smart_set_mode,
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.mode_filter	= ata_pci_default_filter,
 
+	.check_status 	= ata_check_status,
 	.check_atapi_dma= it821x_check_atapi_dma,
-	.qc_issue	= it821x_smart_qc_issue,
-
-	.cable_detect	= ata_cable_80wire,
-	.set_mode	= it821x_smart_set_mode,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
 	.dev_config	= it821x_dev_config,
-	.read_id	= it821x_read_id,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_unknown,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= it821x_smart_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
 
 	.port_start	= it821x_port_start,
 };
 
 static struct ata_port_operations it821x_passthru_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-
-	.check_atapi_dma= it821x_check_atapi_dma,
-	.sff_dev_select	= it821x_passthru_dev_select,
-	.bmdma_start 	= it821x_passthru_bmdma_start,
-	.bmdma_stop	= it821x_passthru_bmdma_stop,
-	.qc_issue	= it821x_passthru_qc_issue,
-
-	.cable_detect	= ata_cable_unknown,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= it821x_passthru_set_piomode,
 	.set_dmamode	= it821x_passthru_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
 
-	.port_start	= it821x_port_start,
-};
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.check_atapi_dma= it821x_check_atapi_dma,
+	.dev_select 	= it821x_passthru_dev_select,
 
-static struct ata_port_operations it821x_rdc_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_unknown,
 
-	.check_atapi_dma= it821x_check_atapi_dma,
-	.sff_dev_select	= it821x_passthru_dev_select,
+	.bmdma_setup 	= ata_bmdma_setup,
 	.bmdma_start 	= it821x_passthru_bmdma_start,
 	.bmdma_stop	= it821x_passthru_bmdma_stop,
-	.qc_issue	= it821x_passthru_qc_issue,
+	.bmdma_status 	= ata_bmdma_status,
 
-	.cable_detect	= it821x_rdc_cable,
-	.set_piomode	= it821x_passthru_set_piomode,
-	.set_dmamode	= it821x_passthru_set_dmamode,
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= it821x_passthru_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_handler	= ata_interrupt,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
 
 	.port_start	= it821x_port_start,
 };
 
 static void it821x_disable_raid(struct pci_dev *pdev)
 {
-	/* Neither the RDC nor the IT8211 */
-	if (pdev->vendor != PCI_VENDOR_ID_ITE ||
-			pdev->device != PCI_DEVICE_ID_ITE_8212)
-			return;
-
 	/* Reset local CPU, and set BIOS not ready */
 	pci_write_config_byte(pdev, 0x5E, 0x01);
 
@@ -874,88 +716,54 @@
 	u8 conf;
 
 	static const struct ata_port_info info_smart = {
+		.sht = &it821x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA6,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.port_ops = &it821x_smart_port_ops
 	};
 	static const struct ata_port_info info_passthru = {
+		.sht = &it821x_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA6,
 		.port_ops = &it821x_passthru_port_ops
 	};
-	static const struct ata_port_info info_rdc = {
-		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA6,
-		.port_ops = &it821x_rdc_port_ops
-	};
-	static const struct ata_port_info info_rdc_11 = {
-		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		/* No UDMA */
-		.port_ops = &it821x_rdc_port_ops
-	};
 
 	const struct ata_port_info *ppi[] = { NULL, NULL };
 	static char *mode[2] = { "pass through", "smart" };
-	int rc;
 
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-		
-	if (pdev->vendor == PCI_VENDOR_ID_RDC) {
-		/* Deal with Vortex86SX */
-		if (pdev->revision == 0x11)
-			ppi[0] = &info_rdc_11;
-		else
-			ppi[0] = &info_rdc;
-	} else {
-		/* Force the card into bypass mode if so requested */
-		if (it8212_noraid) {
-			printk(KERN_INFO DRV_NAME ": forcing bypass mode.\n");
-			it821x_disable_raid(pdev);
-		}
-		pci_read_config_byte(pdev, 0x50, &conf);
-		conf &= 1;
-
-		printk(KERN_INFO DRV_NAME": controller in %s mode.\n",
-								mode[conf]);
-		if (conf == 0)
-			ppi[0] = &info_passthru;
-		else
-			ppi[0] = &info_smart;
+	/* Force the card into bypass mode if so requested */
+	if (it8212_noraid) {
+		printk(KERN_INFO DRV_NAME ": forcing bypass mode.\n");
+		it821x_disable_raid(pdev);
 	}
-	return ata_pci_sff_init_one(pdev, ppi, &it821x_sht, NULL);
+	pci_read_config_byte(pdev, 0x50, &conf);
+	conf &= 1;
+
+	printk(KERN_INFO DRV_NAME ": controller in %s mode.\n", mode[conf]);
+	if (conf == 0)
+		ppi[0] = &info_passthru;
+	else
+		ppi[0] = &info_smart;
+
+	return ata_pci_init_one(pdev, ppi);
 }
 
 #ifdef CONFIG_PM
 static int it821x_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
 	/* Resume - turn raid back off if need be */
 	if (it8212_noraid)
 		it821x_disable_raid(pdev);
-	ata_host_resume(host);
-	return rc;
+	return ata_pci_device_resume(pdev);
 }
 #endif
 
 static const struct pci_device_id it821x[] = {
 	{ PCI_VDEVICE(ITE, PCI_DEVICE_ID_ITE_8211), },
 	{ PCI_VDEVICE(ITE, PCI_DEVICE_ID_ITE_8212), },
-	{ PCI_VDEVICE(RDC, 0x1010), },
 
 	{ },
 };
diff -Nur linux-sh4/drivers/ata.org/pata_ixp4xx_cf.c linux-sh4/drivers/ata/pata_ixp4xx_cf.c
--- linux-sh4/drivers/ata.org/pata_ixp4xx_cf.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_ixp4xx_cf.c	2012-01-15 06:30:15.000000000 -0800
@@ -26,27 +26,30 @@
 #define DRV_NAME	"pata_ixp4xx_cf"
 #define DRV_VERSION	"0.2"
 
-static int ixp4xx_set_mode(struct ata_link *link, struct ata_device **error)
+static int ixp4xx_set_mode(struct ata_port *ap, struct ata_device **error)
 {
-	struct ata_device *dev;
+	int i;
 
-	ata_for_each_dev(dev, link, ENABLED) {
-		ata_dev_printk(dev, KERN_INFO, "configured for PIO0\n");
-		dev->pio_mode = XFER_PIO_0;
-		dev->xfer_mode = XFER_PIO_0;
-		dev->xfer_shift = ATA_SHIFT_PIO;
-		dev->flags |= ATA_DFLAG_PIO;
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+		if (ata_dev_enabled(dev)) {
+			ata_dev_printk(dev, KERN_INFO, "configured for PIO0\n");
+			dev->pio_mode = XFER_PIO_0;
+			dev->xfer_mode = XFER_PIO_0;
+			dev->xfer_shift = ATA_SHIFT_PIO;
+			dev->flags |= ATA_DFLAG_PIO;
+		}
 	}
 	return 0;
 }
 
-static unsigned int ixp4xx_mmio_data_xfer(struct ata_device *dev,
-				unsigned char *buf, unsigned int buflen, int rw)
+static void ixp4xx_mmio_data_xfer(struct ata_device *adev, unsigned char *buf,
+				unsigned int buflen, int write_data)
 {
 	unsigned int i;
 	unsigned int words = buflen >> 1;
 	u16 *buf16 = (u16 *) buf;
-	struct ata_port *ap = dev->link->ap;
+	struct ata_port *ap = adev->ap;
 	void __iomem *mmio = ap->ioaddr.data_addr;
 	struct ixp4xx_pata_data *data = ap->host->dev->platform_data;
 
@@ -57,58 +60,87 @@
 	udelay(100);
 
 	/* Transfer multiple of 2 bytes */
-	if (rw == READ)
-		for (i = 0; i < words; i++)
-			buf16[i] = readw(mmio);
-	else
+	if (write_data) {
 		for (i = 0; i < words; i++)
 			writew(buf16[i], mmio);
+	} else {
+		for (i = 0; i < words; i++)
+			buf16[i] = readw(mmio);
+	}
 
 	/* Transfer trailing 1 byte, if any. */
 	if (unlikely(buflen & 0x01)) {
 		u16 align_buf[1] = { 0 };
 		unsigned char *trailing_buf = buf + buflen - 1;
 
-		if (rw == READ) {
-			align_buf[0] = readw(mmio);
-			memcpy(trailing_buf, align_buf, 1);
-		} else {
+		if (write_data) {
 			memcpy(align_buf, trailing_buf, 1);
 			writew(align_buf[0], mmio);
+		} else {
+			align_buf[0] = readw(mmio);
+			memcpy(trailing_buf, align_buf, 1);
 		}
-		words++;
 	}
 
 	udelay(100);
 	*data->cs0_cfg |= 0x01;
-
-	return words << 1;
 }
 
 static struct scsi_host_template ixp4xx_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations ixp4xx_port_ops = {
-	.inherits		= &ata_sff_port_ops,
-	.sff_data_xfer		= ixp4xx_mmio_data_xfer,
-	.cable_detect		= ata_cable_40wire,
 	.set_mode		= ixp4xx_set_mode,
-};
+	.mode_filter		= ata_pci_default_filter,
+
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.exec_command		= ata_exec_command,
+	.check_status 		= ata_check_status,
+	.dev_select 		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+
+	.qc_prep 		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ixp4xx_mmio_data_xfer,
+	.cable_detect		= ata_cable_40wire,
 
-static void ixp4xx_setup_port(struct ata_port *ap,
-			      struct ixp4xx_pata_data *data,
-			      unsigned long raw_cs0, unsigned long raw_cs1)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	unsigned long raw_cmd = raw_cs0;
-	unsigned long raw_ctl = raw_cs1 + 0x06;
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_dummy_irq_ack,
 
+	.port_start		= ata_port_start,
+};
+
+static void ixp4xx_setup_port(struct ata_ioports *ioaddr,
+				struct ixp4xx_pata_data *data)
+{
 	ioaddr->cmd_addr	= data->cs0;
 	ioaddr->altstatus_addr	= data->cs1 + 0x06;
 	ioaddr->ctl_addr	= data->cs1 + 0x06;
 
-	ata_sff_std_ports(ioaddr);
+	ata_std_ports(ioaddr);
 
 #ifndef __ARMEB__
 
@@ -129,12 +161,7 @@
 	*(unsigned long *)&ioaddr->device_addr		^= 0x03;
 	*(unsigned long *)&ioaddr->status_addr		^= 0x03;
 	*(unsigned long *)&ioaddr->command_addr		^= 0x03;
-
-	raw_cmd ^= 0x03;
-	raw_ctl ^= 0x03;
 #endif
-
-	ata_port_desc(ap, "cmd 0x%lx ctl 0x%lx", raw_cmd, raw_ctl);
 }
 
 static __devinit int ixp4xx_pata_probe(struct platform_device *pdev)
@@ -157,7 +184,7 @@
 		return -ENOMEM;
 
 	/* acquire resources and fill host */
-	pdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+	pdev->dev.coherent_dma_mask = DMA_32BIT_MASK;
 
 	data->cs0 = devm_ioremap(&pdev->dev, cs0->start, 0x1000);
 	data->cs1 = devm_ioremap(&pdev->dev, cs1->start, 0x1000);
@@ -167,7 +194,7 @@
 
 	irq = platform_get_irq(pdev, 0);
 	if (irq)
-		set_irq_type(irq, IRQ_TYPE_EDGE_RISING);
+		set_irq_type(irq, IRQT_RISING);
 
 	/* Setup expansion bus chip selects */
 	*data->cs0_cfg = data->cs0_bits;
@@ -176,15 +203,15 @@
 	ap = host->ports[0];
 
 	ap->ops	= &ixp4xx_port_ops;
-	ap->pio_mask = ATA_PIO4;
+	ap->pio_mask = 0x1f; /* PIO4 */
 	ap->flags |= ATA_FLAG_MMIO | ATA_FLAG_NO_LEGACY | ATA_FLAG_NO_ATAPI;
 
-	ixp4xx_setup_port(ap, data, cs0->start, cs1->start);
+	ixp4xx_setup_port(&ap->ioaddr, data);
 
 	dev_printk(KERN_INFO, &pdev->dev, "version " DRV_VERSION "\n");
 
 	/* activate host */
-	return ata_host_activate(host, irq, ata_sff_interrupt, 0, &ixp4xx_sht);
+	return ata_host_activate(host, irq, ata_interrupt, 0, &ixp4xx_sht);
 }
 
 static __devexit int ixp4xx_pata_remove(struct platform_device *dev)
@@ -219,7 +246,6 @@
 MODULE_DESCRIPTION("low-level driver for ixp4xx Compact Flash PATA");
 MODULE_LICENSE("GPL");
 MODULE_VERSION(DRV_VERSION);
-MODULE_ALIAS("platform:" DRV_NAME);
 
 module_init(ixp4xx_pata_init);
 module_exit(ixp4xx_pata_exit);
diff -Nur linux-sh4/drivers/ata.org/pata_jmicron.c linux-sh4/drivers/ata/pata_jmicron.c
--- linux-sh4/drivers/ata.org/pata_jmicron.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_jmicron.c	2012-01-15 06:30:15.000000000 -0800
@@ -4,7 +4,7 @@
  *			driven by AHCI in the usual configuration although
  *			this driver can handle other setups if we need it.
  *
- *	(c) 2006 Red Hat
+ *	(c) 2006 Red Hat  <alan@redhat.com>
  */
 
 #include <linux/kernel.h>
@@ -29,7 +29,7 @@
 
 /**
  *	jmicron_pre_reset	-	check for 40/80 pin
- *	@link: ATA link
+ *	@ap: Port
  *	@deadline: deadline jiffies for the operation
  *
  *	Perform the PATA port setup we need.
@@ -39,9 +39,9 @@
  *	and setup here. We assume that has been done by init_one and the
  *	BIOS.
  */
-static int jmicron_pre_reset(struct ata_link *link, unsigned long deadline)
+
+static int jmicron_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	u32 control;
 	u32 control5;
@@ -80,10 +80,11 @@
 	 *	actually do our cable checking etc. Thankfully we don't need
 	 *	to do the plumbing for other cases.
 	 */
-	switch (port_map[port]) {
+	switch (port_map[port])
+	{
 	case PORT_PATA0:
-		if ((control & (1 << 5)) == 0)
-			return -ENOENT;
+		if (control & (1 << 5))
+			return 0;
 		if (control & (1 << 3))	/* 40/80 pin primary */
 			ap->cbl = ATA_CBL_PATA40;
 		else
@@ -92,7 +93,7 @@
 	case PORT_PATA1:
 		/* Bit 21 is set if the port is enabled */
 		if ((control5 & (1 << 21)) == 0)
-			return -ENOENT;
+			return 0;
 		if (control5 & (1 << 19))	/* 40/80 pin secondary */
 			ap->cbl = ATA_CBL_PATA40;
 		else
@@ -102,18 +103,75 @@
 		ap->cbl = ATA_CBL_SATA;
 		break;
 	}
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	jmicron_error_handler - Setup and error handler
+ *	@ap: Port to handle
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void jmicron_error_handler(struct ata_port *ap)
+{
+	return ata_bmdma_drive_eh(ap, jmicron_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /* No PIO or DMA methods needed for this device */
 
 static struct scsi_host_template jmicron_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	/* Use standard CHS mapping rules */
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations jmicron_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.prereset		= jmicron_pre_reset,
+static const struct ata_port_operations jmicron_ops = {
+	.port_disable		= ata_port_disable,
+
+	/* Task file is PCI ATA format, use helpers */
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= jmicron_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+
+	/* BMDMA handling is PCI ATA format, use helpers */
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	/* IRQ-related hooks */
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	/* Generic PATA PCI ATA helpers */
+	.port_start		= ata_port_start,
 };
 
 
@@ -134,22 +192,32 @@
 static int jmicron_init_one (struct pci_dev *pdev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht		= &jmicron_sht,
 		.flags	= ATA_FLAG_SLAVE_POSS,
 
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,
+		.mwdma_mask	= 0x07,
 		.udma_mask 	= ATA_UDMA5,
 
 		.port_ops	= &jmicron_ops,
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
 
-	return ata_pci_sff_init_one(pdev, ppi, &jmicron_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id jmicron_pci_tbl[] = {
-	{ PCI_VENDOR_ID_JMICRON, PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID,
-	  PCI_CLASS_STORAGE_IDE << 8, 0xffff00, 0 },
+	{ PCI_VENDOR_ID_JMICRON, PCI_DEVICE_ID_JMICRON_JMB361,
+	  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_STORAGE_IDE << 8, 0xffff00, 361 },
+	{ PCI_VENDOR_ID_JMICRON, PCI_DEVICE_ID_JMICRON_JMB363,
+	  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_STORAGE_IDE << 8, 0xffff00, 363 },
+	{ PCI_VENDOR_ID_JMICRON, PCI_DEVICE_ID_JMICRON_JMB365,
+	  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_STORAGE_IDE << 8, 0xffff00, 365 },
+	{ PCI_VENDOR_ID_JMICRON, PCI_DEVICE_ID_JMICRON_JMB366,
+	  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_STORAGE_IDE << 8, 0xffff00, 366 },
+	{ PCI_VENDOR_ID_JMICRON, PCI_DEVICE_ID_JMICRON_JMB368,
+	  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_STORAGE_IDE << 8, 0xffff00, 368 },
+
 	{ }	/* terminate list */
 };
 
diff -Nur linux-sh4/drivers/ata.org/pata_legacy.c linux-sh4/drivers/ata/pata_legacy.c
--- linux-sh4/drivers/ata.org/pata_legacy.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_legacy.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,6 @@
 /*
  *   pata-legacy.c - Legacy port PATA/SATA controller driver.
- *   Copyright 2005/2006 Red Hat, all rights reserved.
+ *   Copyright 2005/2006 Red Hat <alan@redhat.com>, all rights reserved.
  *
  *  This program is free software; you can redistribute it and/or modify
  *  it under the terms of the GNU General Public License as published by
@@ -28,6 +28,7 @@
  *
  *  Unsupported but docs exist:
  *	Appian/Adaptec AIC25VL01/Cirrus Logic PD7220
+ *	Winbond W83759A
  *
  *  This driver handles legacy (that is "ISA/VLB side") IDE ports found
  *  on PC class systems. There are three hybrid devices that are exceptions
@@ -35,7 +36,7 @@
  *  the MPIIX where the tuning is PCI side but the IDE is "ISA side".
  *
  *  Specific support is included for the ht6560a/ht6560b/opti82c611a/
- *  opti82c465mv/promise 20230c/20630/winbond83759A
+ *  opti82c465mv/promise 20230c/20630
  *
  *  Use the autospeed and pio_mask options with:
  *	Appian ADI/2 aka CLPD7220 or AIC25VL01.
@@ -46,9 +47,11 @@
  *  For now use autospeed and pio_mask as above with the W83759A. This may
  *  change.
  *
+ *  TODO
+ *	Merge existing pata_qdi driver
+ *
  */
 
-#include <linux/async.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/pci.h>
@@ -61,13 +64,12 @@
 #include <linux/platform_device.h>
 
 #define DRV_NAME "pata_legacy"
-#define DRV_VERSION "0.6.5"
+#define DRV_VERSION "0.5.5"
 
 #define NR_HOST 6
 
-static int all;
-module_param(all, int, 0444);
-MODULE_PARM_DESC(all, "Grab all legacy port devices, even if PCI(0=off, 1=on)");
+static int legacy_port[NR_HOST] = { 0x1f0, 0x170, 0x1e8, 0x168, 0x1e0, 0x160 };
+static int legacy_irq[NR_HOST] = { 14, 15, 11, 10, 8, 12 };
 
 struct legacy_data {
 	unsigned long timing;
@@ -78,110 +80,23 @@
 
 };
 
-enum controller {
-	BIOS = 0,
-	SNOOP = 1,
-	PDC20230 = 2,
-	HT6560A = 3,
-	HT6560B = 4,
-	OPTI611A = 5,
-	OPTI46X = 6,
-	QDI6500 = 7,
-	QDI6580 = 8,
-	QDI6580DP = 9,		/* Dual channel mode is different */
-	W83759A = 10,
-
-	UNKNOWN = -1
-};
-
-
-struct legacy_probe {
-	unsigned char *name;
-	unsigned long port;
-	unsigned int irq;
-	unsigned int slot;
-	enum controller type;
-	unsigned long private;
-};
-
-struct legacy_controller {
-	const char *name;
-	struct ata_port_operations *ops;
-	unsigned int pio_mask;
-	unsigned int flags;
-	unsigned int pflags;
-	int (*setup)(struct platform_device *, struct legacy_probe *probe,
-		struct legacy_data *data);
-};
-
-static int legacy_port[NR_HOST] = { 0x1f0, 0x170, 0x1e8, 0x168, 0x1e0, 0x160 };
-
-static struct legacy_probe probe_list[NR_HOST];
 static struct legacy_data legacy_data[NR_HOST];
 static struct ata_host *legacy_host[NR_HOST];
 static int nr_legacy_host;
 
 
-static int probe_all;		/* Set to check all ISA port ranges */
-static int ht6560a;		/* HT 6560A on primary 1, second 2, both 3 */
-static int ht6560b;		/* HT 6560A on primary 1, second 2, both 3 */
-static int opti82c611a;		/* Opti82c611A on primary 1, sec 2, both 3 */
-static int opti82c46x;		/* Opti 82c465MV present(pri/sec autodetect) */
-static int qdi;			/* Set to probe QDI controllers */
-static int winbond;		/* Set to probe Winbond controllers,
-					give I/O port if non standard */
-static int autospeed;		/* Chip present which snoops speed changes */
-static int pio_mask = ATA_PIO4;	/* PIO range for autospeed devices */
+static int probe_all;			/* Set to check all ISA port ranges */
+static int ht6560a;			/* HT 6560A on primary 1, secondary 2, both 3 */
+static int ht6560b;			/* HT 6560A on primary 1, secondary 2, both 3 */
+static int opti82c611a;			/* Opti82c611A on primary 1, secondary 2, both 3 */
+static int opti82c46x;			/* Opti 82c465MV present (pri/sec autodetect) */
+static int autospeed;			/* Chip present which snoops speed changes */
+static int pio_mask = 0x1F;		/* PIO range for autospeed devices */
 static int iordy_mask = 0xFFFFFFFF;	/* Use iordy if available */
 
 /**
- *	legacy_probe_add	-	Add interface to probe list
- *	@port: Controller port
- *	@irq: IRQ number
- *	@type: Controller type
- *	@private: Controller specific info
- *
- *	Add an entry into the probe list for ATA controllers. This is used
- *	to add the default ISA slots and then to build up the table
- *	further according to other ISA/VLB/Weird device scans
- *
- *	An I/O port list is used to keep ordering stable and sane, as we
- *	don't have any good way to talk about ordering otherwise
- */
-
-static int legacy_probe_add(unsigned long port, unsigned int irq,
-				enum controller type, unsigned long private)
-{
-	struct legacy_probe *lp = &probe_list[0];
-	int i;
-	struct legacy_probe *free = NULL;
-
-	for (i = 0; i < NR_HOST; i++) {
-		if (lp->port == 0 && free == NULL)
-			free = lp;
-		/* Matching port, or the correct slot for ordering */
-		if (lp->port == port || legacy_port[i] == port) {
-			free = lp;
-			break;
-		}
-		lp++;
-	}
-	if (free == NULL) {
-		printk(KERN_ERR "pata_legacy: Too many interfaces.\n");
-		return -1;
-	}
-	/* Fill in the entry for later probing */
-	free->port = port;
-	free->irq = irq;
-	free->type = type;
-	free->private = private;
-	return 0;
-}
-
-
-/**
  *	legacy_set_mode		-	mode setting
- *	@link: IDE link
+ *	@ap: IDE interface
  *	@unused: Device that failed when error is returned
  *
  *	Use a non standard set_mode function. We don't want to be tuned.
@@ -192,27 +107,39 @@
  *	expand on this as per hdparm in the base kernel.
  */
 
-static int legacy_set_mode(struct ata_link *link, struct ata_device **unused)
+static int legacy_set_mode(struct ata_port *ap, struct ata_device **unused)
 {
-	struct ata_device *dev;
+	int i;
 
-	ata_for_each_dev(dev, link, ENABLED) {
-		ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
-		dev->pio_mode = XFER_PIO_0;
-		dev->xfer_mode = XFER_PIO_0;
-		dev->xfer_shift = ATA_SHIFT_PIO;
-		dev->flags |= ATA_DFLAG_PIO;
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+		if (ata_dev_enabled(dev)) {
+			ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
+			dev->pio_mode = XFER_PIO_0;
+			dev->xfer_mode = XFER_PIO_0;
+			dev->xfer_shift = ATA_SHIFT_PIO;
+			dev->flags |= ATA_DFLAG_PIO;
+		}
 	}
 	return 0;
 }
 
 static struct scsi_host_template legacy_sht = {
-	ATA_PIO_SHT(DRV_NAME),
-};
-
-static const struct ata_port_operations legacy_base_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.cable_detect	= ata_cable_40wire,
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 /*
@@ -224,23 +151,67 @@
  */
 
 static struct ata_port_operations simple_port_ops = {
-	.inherits	= &legacy_base_port_ops,
-	.sff_data_xfer	= ata_sff_data_xfer_noirq,
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer_noirq,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations legacy_port_ops = {
-	.inherits	= &legacy_base_port_ops,
-	.sff_data_xfer	= ata_sff_data_xfer_noirq,
 	.set_mode	= legacy_set_mode,
+
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+	.cable_detect	= ata_cable_40wire,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer_noirq,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
  *	Promise 20230C and 20620 support
  *
- *	This controller supports PIO0 to PIO2. We set PIO timings
- *	conservatively to allow for 50MHz Vesa Local Bus. The 20620 DMA
- *	support is weird being DMA to controller and PIO'd to the host
- *	and not supported.
+ *	This controller supports PIO0 to PIO2. We set PIO timings conservatively to
+ *	allow for 50MHz Vesa Local Bus. The 20620 DMA support is weird being DMA to
+ *	controller and PIO'd to the host and not supported.
  */
 
 static void pdc20230_set_piomode(struct ata_port *ap, struct ata_device *adev)
@@ -255,7 +226,8 @@
 	local_irq_save(flags);
 
 	/* Unlock the control interface */
-	do {
+	do
+	{
 		inb(0x1F5);
 		outb(inb(0x1F2) | 0x80, 0x1F2);
 		inb(0x1F2);
@@ -264,7 +236,7 @@
 		inb(0x1F2);
 		inb(0x1F2);
 	}
-	while ((inb(0x1F2) & 0x80) && --tries);
+	while((inb(0x1F2) & 0x80) && --tries);
 
 	local_irq_restore(flags);
 
@@ -282,17 +254,13 @@
 
 }
 
-static unsigned int pdc_data_xfer_vlb(struct ata_device *dev,
-			unsigned char *buf, unsigned int buflen, int rw)
+static void pdc_data_xfer_vlb(struct ata_device *adev, unsigned char *buf, unsigned int buflen, int write_data)
 {
+	struct ata_port *ap = adev->ap;
 	int slop = buflen & 3;
-	struct ata_port *ap = dev->link->ap;
-
-	/* 32bit I/O capable *and* we need to write a whole number of dwords */
-	if (ata_id_has_dword_io(dev->id) && (slop == 0 || slop == 3)
-					&& (ap->pflags & ATA_PFLAG_PIO32)) {
-		unsigned long flags;
+	unsigned long flags;
 
+	if (ata_id_has_dword_io(adev->id)) {
 		local_irq_save(flags);
 
 		/* Perform the 32bit I/O synchronization sequence */
@@ -301,40 +269,64 @@
 		ioread8(ap->ioaddr.nsect_addr);
 
 		/* Now the data */
-		if (rw == READ)
-			ioread32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
-		else
+
+		if (write_data)
 			iowrite32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
+		else
+			ioread32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
 
 		if (unlikely(slop)) {
-			__le32 pad;
-			if (rw == READ) {
-				pad = cpu_to_le32(ioread32(ap->ioaddr.data_addr));
-				memcpy(buf + buflen - slop, &pad, slop);
-			} else {
+			u32 pad;
+			if (write_data) {
 				memcpy(&pad, buf + buflen - slop, slop);
-				iowrite32(le32_to_cpu(pad), ap->ioaddr.data_addr);
+				pad = le32_to_cpu(pad);
+				iowrite32(pad, ap->ioaddr.data_addr);
+			} else {
+				pad = ioread32(ap->ioaddr.data_addr);
+				pad = cpu_to_le16(pad);
+				memcpy(buf + buflen - slop, &pad, slop);
 			}
-			buflen += 4 - slop;
 		}
 		local_irq_restore(flags);
-	} else
-		buflen = ata_sff_data_xfer_noirq(dev, buf, buflen, rw);
-
-	return buflen;
+	}
+	else
+		ata_data_xfer_noirq(adev, buf, buflen, write_data);
 }
 
 static struct ata_port_operations pdc20230_port_ops = {
-	.inherits	= &legacy_base_port_ops,
 	.set_piomode	= pdc20230_set_piomode,
-	.sff_data_xfer	= pdc_data_xfer_vlb,
+
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= pdc_data_xfer_vlb,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
  *	Holtek 6560A support
  *
- *	This controller supports PIO0 to PIO2 (no IORDY even though higher
- *	timings can be loaded).
+ *	This controller supports PIO0 to PIO2 (no IORDY even though higher timings
+ *	can be loaded).
  */
 
 static void ht6560a_set_piomode(struct ata_port *ap, struct ata_device *adev)
@@ -345,8 +337,8 @@
 	/* Get the timing data in cycles. For now play safe at 50Mhz */
 	ata_timing_compute(adev, adev->pio_mode, &t, 20000, 1000);
 
-	active = clamp_val(t.active, 2, 15);
-	recover = clamp_val(t.recover, 4, 15);
+	active = FIT(t.active, 2, 15);
+	recover = FIT(t.recover, 4, 15);
 
 	inb(0x3E6);
 	inb(0x3E6);
@@ -358,15 +350,39 @@
 }
 
 static struct ata_port_operations ht6560a_port_ops = {
-	.inherits	= &legacy_base_port_ops,
 	.set_piomode	= ht6560a_set_piomode,
+
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,	/* Check vlb/noirq */
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
  *	Holtek 6560B support
  *
- *	This controller supports PIO0 to PIO4. We honour the BIOS/jumper FIFO
- *	setting unless we see an ATAPI device in which case we force it off.
+ *	This controller supports PIO0 to PIO4. We honour the BIOS/jumper FIFO setting
+ *	unless we see an ATAPI device in which case we force it off.
  *
  *	FIXME: need to implement 2nd channel support.
  */
@@ -379,8 +395,8 @@
 	/* Get the timing data in cycles. For now play safe at 50Mhz */
 	ata_timing_compute(adev, adev->pio_mode, &t, 20000, 1000);
 
-	active = clamp_val(t.active, 2, 15);
-	recover = clamp_val(t.recover, 2, 16);
+	active = FIT(t.active, 2, 15);
+	recover = FIT(t.recover, 2, 16);
 	recover &= 0x15;
 
 	inb(0x3E6);
@@ -393,7 +409,7 @@
 	if (adev->class != ATA_DEV_ATA) {
 		u8 rconf = inb(0x3E6);
 		if (rconf & 0x24) {
-			rconf &= ~0x24;
+			rconf &= ~ 0x24;
 			outb(rconf, 0x3E6);
 		}
 	}
@@ -401,8 +417,32 @@
 }
 
 static struct ata_port_operations ht6560b_port_ops = {
-	.inherits	= &legacy_base_port_ops,
 	.set_piomode	= ht6560b_set_piomode,
+
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,	/* FIXME: Check 32bit and noirq */
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
@@ -435,8 +475,7 @@
  *	This controller supports PIO0 to PIO3.
  */
 
-static void opti82c611a_set_piomode(struct ata_port *ap,
-						struct ata_device *adev)
+static void opti82c611a_set_piomode(struct ata_port *ap, struct ata_device *adev)
 {
 	u8 active, recover, setup;
 	struct ata_timing t;
@@ -464,9 +503,9 @@
 		ata_timing_merge(&t, &tp, &t, ATA_TIMING_SETUP);
 	}
 
-	active = clamp_val(t.active, 2, 17) - 2;
-	recover = clamp_val(t.recover, 1, 16) - 1;
-	setup = clamp_val(t.setup, 1, 4) - 1;
+	active = FIT(t.active, 2, 17) - 2;
+	recover = FIT(t.recover, 1, 16) - 1;
+	setup = FIT(t.setup, 1, 4) - 1;
 
 	/* Select the right timing bank for write timing */
 	rc = ioread8(ap->ioaddr.lbal_addr);
@@ -500,8 +539,32 @@
 
 
 static struct ata_port_operations opti82c611a_port_ops = {
-	.inherits	= &legacy_base_port_ops,
 	.set_piomode	= opti82c611a_set_piomode,
+
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /*
@@ -543,9 +606,9 @@
 		ata_timing_merge(&t, &tp, &t, ATA_TIMING_SETUP);
 	}
 
-	active = clamp_val(t.active, 2, 17) - 2;
-	recover = clamp_val(t.recover, 1, 16) - 1;
-	setup = clamp_val(t.setup, 1, 4) - 1;
+	active = FIT(t.active, 2, 17) - 2;
+	recover = FIT(t.recover, 1, 16) - 1;
+	setup = FIT(t.setup, 1, 4) - 1;
 
 	/* Select the right timing bank for write timing */
 	rc = ioread8(ap->ioaddr.lbal_addr);
@@ -581,7 +644,7 @@
 }
 
 /**
- *	opt82c465mv_qc_issue		-	command issue
+ *	opt82c465mv_qc_issue_prot	-	command issue
  *	@qc: command pending
  *
  *	Called when the libata layer is about to issue a command. We wrap
@@ -595,7 +658,7 @@
  *	FIXME: dual channel needs ->serialize support
  */
 
-static unsigned int opti82c46x_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int opti82c46x_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
@@ -606,323 +669,106 @@
 	    && ap->host->private_data != NULL)
 		opti82c46x_set_piomode(ap, adev);
 
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 static struct ata_port_operations opti82c46x_port_ops = {
-	.inherits	= &legacy_base_port_ops,
 	.set_piomode	= opti82c46x_set_piomode,
-	.qc_issue	= opti82c46x_qc_issue,
-};
 
-static void qdi6500_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct ata_timing t;
-	struct legacy_data *ld_qdi = ap->host->private_data;
-	int active, recovery;
-	u8 timing;
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
 
-	/* Get the timing data in cycles */
-	ata_timing_compute(adev, adev->pio_mode, &t, 30303, 1000);
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= opti82c46x_qc_issue_prot,
 
-	if (ld_qdi->fast) {
-		active = 8 - clamp_val(t.active, 1, 8);
-		recovery = 18 - clamp_val(t.recover, 3, 18);
-	} else {
-		active = 9 - clamp_val(t.active, 2, 9);
-		recovery = 15 - clamp_val(t.recover, 0, 15);
-	}
-	timing = (recovery << 4) | active | 0x08;
+	.data_xfer	= ata_data_xfer,
 
-	ld_qdi->clock[adev->devno] = timing;
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
+};
 
-	outb(timing, ld_qdi->timing);
-}
 
 /**
- *	qdi6580dp_set_piomode		-	PIO setup for dual channel
- *	@ap: Port
- *	@adev: Device
+ *	legacy_init_one		-	attach a legacy interface
+ *	@port: port number
+ *	@io: I/O port start
+ *	@ctrl: control port
+ *	@irq: interrupt line
  *
- *	In dual channel mode the 6580 has one clock per channel and we have
- *	to software clockswitch in qc_issue.
+ *	Register an ISA bus IDE interface. Such interfaces are PIO and we
+ *	assume do not support IRQ sharing.
  */
 
-static void qdi6580dp_set_piomode(struct ata_port *ap, struct ata_device *adev)
+static __init int legacy_init_one(int port, unsigned long io, unsigned long ctrl, int irq)
 {
-	struct ata_timing t;
-	struct legacy_data *ld_qdi = ap->host->private_data;
-	int active, recovery;
-	u8 timing;
-
-	/* Get the timing data in cycles */
-	ata_timing_compute(adev, adev->pio_mode, &t, 30303, 1000);
-
-	if (ld_qdi->fast) {
-		active = 8 - clamp_val(t.active, 1, 8);
-		recovery = 18 - clamp_val(t.recover, 3, 18);
-	} else {
-		active = 9 - clamp_val(t.active, 2, 9);
-		recovery = 15 - clamp_val(t.recover, 0, 15);
-	}
-	timing = (recovery << 4) | active | 0x08;
-
-	ld_qdi->clock[adev->devno] = timing;
-
-	outb(timing, ld_qdi->timing + 2 * ap->port_no);
-	/* Clear the FIFO */
-	if (adev->class != ATA_DEV_ATA)
-		outb(0x5F, ld_qdi->timing + 3);
-}
+	struct legacy_data *ld = &legacy_data[nr_legacy_host];
+	struct ata_host *host;
+	struct ata_port *ap;
+	struct platform_device *pdev;
+	struct ata_port_operations *ops = &legacy_port_ops;
+	void __iomem *io_addr, *ctrl_addr;
+	int pio_modes = pio_mask;
+	u32 mask = (1 << port);
+	u32 iordy = (iordy_mask & mask) ? 0: ATA_FLAG_NO_IORDY;
+	int ret;
 
-/**
- *	qdi6580_set_piomode		-	PIO setup for single channel
- *	@ap: Port
- *	@adev: Device
- *
- *	In single channel mode the 6580 has one clock per device and we can
- *	avoid the requirement to clock switch. We also have to load the timing
- *	into the right clock according to whether we are master or slave.
- */
+	pdev = platform_device_register_simple(DRV_NAME, nr_legacy_host, NULL, 0);
+	if (IS_ERR(pdev))
+		return PTR_ERR(pdev);
 
-static void qdi6580_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct ata_timing t;
-	struct legacy_data *ld_qdi = ap->host->private_data;
-	int active, recovery;
-	u8 timing;
+	ret = -EBUSY;
+	if (devm_request_region(&pdev->dev, io, 8, "pata_legacy") == NULL ||
+	    devm_request_region(&pdev->dev, ctrl, 1, "pata_legacy") == NULL)
+		goto fail;
 
-	/* Get the timing data in cycles */
-	ata_timing_compute(adev, adev->pio_mode, &t, 30303, 1000);
+	ret = -ENOMEM;
+	io_addr = devm_ioport_map(&pdev->dev, io, 8);
+	ctrl_addr = devm_ioport_map(&pdev->dev, ctrl, 1);
+	if (!io_addr || !ctrl_addr)
+		goto fail;
 
-	if (ld_qdi->fast) {
-		active = 8 - clamp_val(t.active, 1, 8);
-		recovery = 18 - clamp_val(t.recover, 3, 18);
-	} else {
-		active = 9 - clamp_val(t.active, 2, 9);
-		recovery = 15 - clamp_val(t.recover, 0, 15);
+	if (ht6560a & mask) {
+		ops = &ht6560a_port_ops;
+		pio_modes = 0x07;
+		iordy = ATA_FLAG_NO_IORDY;
 	}
-	timing = (recovery << 4) | active | 0x08;
-	ld_qdi->clock[adev->devno] = timing;
-	outb(timing, ld_qdi->timing + 2 * adev->devno);
-	/* Clear the FIFO */
-	if (adev->class != ATA_DEV_ATA)
-		outb(0x5F, ld_qdi->timing + 3);
-}
-
-/**
- *	qdi_qc_issue		-	command issue
- *	@qc: command pending
- *
- *	Called when the libata layer is about to issue a command. We wrap
- *	this interface so that we can load the correct ATA timings.
- */
-
-static unsigned int qdi_qc_issue(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct ata_device *adev = qc->dev;
-	struct legacy_data *ld_qdi = ap->host->private_data;
-
-	if (ld_qdi->clock[adev->devno] != ld_qdi->last) {
-		if (adev->pio_mode) {
-			ld_qdi->last = ld_qdi->clock[adev->devno];
-			outb(ld_qdi->clock[adev->devno], ld_qdi->timing +
-							2 * ap->port_no);
-		}
+	if (ht6560b & mask) {
+		ops = &ht6560b_port_ops;
+		pio_modes = 0x1F;
+	}
+	if (opti82c611a & mask) {
+		ops = &opti82c611a_port_ops;
+		pio_modes = 0x0F;
+	}
+	if (opti82c46x & mask) {
+		ops = &opti82c46x_port_ops;
+		pio_modes = 0x0F;
 	}
-	return ata_sff_qc_issue(qc);
-}
-
-static unsigned int vlb32_data_xfer(struct ata_device *adev, unsigned char *buf,
-					unsigned int buflen, int rw)
-{
-	struct ata_port *ap = adev->link->ap;
-	int slop = buflen & 3;
-
-	if (ata_id_has_dword_io(adev->id) && (slop == 0 || slop == 3)
-					&& (ap->pflags & ATA_PFLAG_PIO32)) {
-		if (rw == WRITE)
-			iowrite32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
-		else
-			ioread32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
-
-		if (unlikely(slop)) {
-			__le32 pad;
-			if (rw == WRITE) {
-				memcpy(&pad, buf + buflen - slop, slop);
-				iowrite32(le32_to_cpu(pad), ap->ioaddr.data_addr);
-			} else {
-				pad = cpu_to_le32(ioread32(ap->ioaddr.data_addr));
-				memcpy(buf + buflen - slop, &pad, slop);
-			}
-		}
-		return (buflen + 3) & ~3;
-	} else
-		return ata_sff_data_xfer(adev, buf, buflen, rw);
-}
-
-static int qdi_port(struct platform_device *dev,
-			struct legacy_probe *lp, struct legacy_data *ld)
-{
-	if (devm_request_region(&dev->dev, lp->private, 4, "qdi") == NULL)
-		return -EBUSY;
-	ld->timing = lp->private;
-	return 0;
-}
-
-static struct ata_port_operations qdi6500_port_ops = {
-	.inherits	= &legacy_base_port_ops,
-	.set_piomode	= qdi6500_set_piomode,
-	.qc_issue	= qdi_qc_issue,
-	.sff_data_xfer	= vlb32_data_xfer,
-};
-
-static struct ata_port_operations qdi6580_port_ops = {
-	.inherits	= &legacy_base_port_ops,
-	.set_piomode	= qdi6580_set_piomode,
-	.sff_data_xfer	= vlb32_data_xfer,
-};
-
-static struct ata_port_operations qdi6580dp_port_ops = {
-	.inherits	= &legacy_base_port_ops,
-	.set_piomode	= qdi6580dp_set_piomode,
-	.sff_data_xfer	= vlb32_data_xfer,
-};
-
-static DEFINE_SPINLOCK(winbond_lock);
-
-static void winbond_writecfg(unsigned long port, u8 reg, u8 val)
-{
-	unsigned long flags;
-	spin_lock_irqsave(&winbond_lock, flags);
-	outb(reg, port + 0x01);
-	outb(val, port + 0x02);
-	spin_unlock_irqrestore(&winbond_lock, flags);
-}
-
-static u8 winbond_readcfg(unsigned long port, u8 reg)
-{
-	u8 val;
-
-	unsigned long flags;
-	spin_lock_irqsave(&winbond_lock, flags);
-	outb(reg, port + 0x01);
-	val = inb(port + 0x02);
-	spin_unlock_irqrestore(&winbond_lock, flags);
-
-	return val;
-}
-
-static void winbond_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct ata_timing t;
-	struct legacy_data *ld_winbond = ap->host->private_data;
-	int active, recovery;
-	u8 reg;
-	int timing = 0x88 + (ap->port_no * 4) + (adev->devno * 2);
-
-	reg = winbond_readcfg(ld_winbond->timing, 0x81);
-
-	/* Get the timing data in cycles */
-	if (reg & 0x40)		/* Fast VLB bus, assume 50MHz */
-		ata_timing_compute(adev, adev->pio_mode, &t, 20000, 1000);
-	else
-		ata_timing_compute(adev, adev->pio_mode, &t, 30303, 1000);
-
-	active = (clamp_val(t.active, 3, 17) - 1) & 0x0F;
-	recovery = (clamp_val(t.recover, 1, 15) + 1) & 0x0F;
-	timing = (active << 4) | recovery;
-	winbond_writecfg(ld_winbond->timing, timing, reg);
-
-	/* Load the setup timing */
-
-	reg = 0x35;
-	if (adev->class != ATA_DEV_ATA)
-		reg |= 0x08;	/* FIFO off */
-	if (!ata_pio_need_iordy(adev))
-		reg |= 0x02;	/* IORDY off */
-	reg |= (clamp_val(t.setup, 0, 3) << 6);
-	winbond_writecfg(ld_winbond->timing, timing + 1, reg);
-}
-
-static int winbond_port(struct platform_device *dev,
-			struct legacy_probe *lp, struct legacy_data *ld)
-{
-	if (devm_request_region(&dev->dev, lp->private, 4, "winbond") == NULL)
-		return -EBUSY;
-	ld->timing = lp->private;
-	return 0;
-}
-
-static struct ata_port_operations winbond_port_ops = {
-	.inherits	= &legacy_base_port_ops,
-	.set_piomode	= winbond_set_piomode,
-	.sff_data_xfer	= vlb32_data_xfer,
-};
-
-static struct legacy_controller controllers[] = {
-	{"BIOS",	&legacy_port_ops, 	0x1F,
-			ATA_FLAG_NO_IORDY,	0,			NULL },
-	{"Snooping", 	&simple_port_ops, 	0x1F,
-			0,			0,			NULL },
-	{"PDC20230",	&pdc20230_port_ops,	0x7,
-			ATA_FLAG_NO_IORDY,
-			ATA_PFLAG_PIO32 | ATA_PFLAG_PIO32CHANGE,	NULL },
-	{"HT6560A",	&ht6560a_port_ops,	0x07,
-			ATA_FLAG_NO_IORDY,	0,			NULL },
-	{"HT6560B",	&ht6560b_port_ops,	0x1F,
-			ATA_FLAG_NO_IORDY,	0,			NULL },
-	{"OPTI82C611A",	&opti82c611a_port_ops,	0x0F,
-			0,			0,			NULL },
-	{"OPTI82C46X",	&opti82c46x_port_ops,	0x0F,
-			0,			0,			NULL },
-	{"QDI6500",	&qdi6500_port_ops,	0x07,
-			ATA_FLAG_NO_IORDY,
-			ATA_PFLAG_PIO32 | ATA_PFLAG_PIO32CHANGE,    qdi_port },
-	{"QDI6580",	&qdi6580_port_ops,	0x1F,
-			0, ATA_PFLAG_PIO32 | ATA_PFLAG_PIO32CHANGE, qdi_port },
-	{"QDI6580DP",	&qdi6580dp_port_ops,	0x1F,
-			0, ATA_PFLAG_PIO32 | ATA_PFLAG_PIO32CHANGE, qdi_port },
-	{"W83759A",	&winbond_port_ops,	0x1F,
-			0, ATA_PFLAG_PIO32 | ATA_PFLAG_PIO32CHANGE,
-								winbond_port }
-};
-
-/**
- *	probe_chip_type		-	Discover controller
- *	@probe: Probe entry to check
- *
- *	Probe an ATA port and identify the type of controller. We don't
- *	check if the controller appears to be driveless at this point.
- */
-
-static __init int probe_chip_type(struct legacy_probe *probe)
-{
-	int mask = 1 << probe->slot;
-
-	if (winbond && (probe->port == 0x1F0 || probe->port == 0x170)) {
-		u8 reg = winbond_readcfg(winbond, 0x81);
-		reg |= 0x80;	/* jumpered mode off */
-		winbond_writecfg(winbond, 0x81, reg);
-		reg = winbond_readcfg(winbond, 0x83);
-		reg |= 0xF0;	/* local control */
-		winbond_writecfg(winbond, 0x83, reg);
-		reg = winbond_readcfg(winbond, 0x85);
-		reg |= 0xF0;	/* programmable timing */
-		winbond_writecfg(winbond, 0x85, reg);
 
-		reg = winbond_readcfg(winbond, 0x81);
+	/* Probe for automatically detectable controllers */
 
-		if (reg & mask)
-			return W83759A;
-	}
-	if (probe->port == 0x1F0) {
+	if (io == 0x1F0 && ops == &legacy_port_ops) {
 		unsigned long flags;
+
 		local_irq_save(flags);
+
 		/* Probes */
-		outb(inb(0x1F2) | 0x80, 0x1F2);
 		inb(0x1F5);
+		outb(inb(0x1F2) | 0x80, 0x1F2);
 		inb(0x1F2);
 		inb(0x3F6);
 		inb(0x3F6);
@@ -931,83 +777,29 @@
 
 		if ((inb(0x1F2) & 0x80) == 0) {
 			/* PDC20230c or 20630 ? */
-			printk(KERN_INFO  "PDC20230-C/20630 VLB ATA controller"
-							" detected.\n");
+			printk(KERN_INFO "PDC20230-C/20630 VLB ATA controller detected.\n");
+				pio_modes = 0x07;
+			ops = &pdc20230_port_ops;
+			iordy = ATA_FLAG_NO_IORDY;
 			udelay(100);
 			inb(0x1F5);
-			local_irq_restore(flags);
-			return PDC20230;
 		} else {
 			outb(0x55, 0x1F2);
 			inb(0x1F2);
 			inb(0x1F2);
-			if (inb(0x1F2) == 0x00)
-				printk(KERN_INFO "PDC20230-B VLB ATA "
-						     "controller detected.\n");
-			local_irq_restore(flags);
-			return BIOS;
+			if (inb(0x1F2) == 0x00) {
+				printk(KERN_INFO "PDC20230-B VLB ATA controller detected.\n");
+			}
 		}
 		local_irq_restore(flags);
 	}
 
-	if (ht6560a & mask)
-		return HT6560A;
-	if (ht6560b & mask)
-		return HT6560B;
-	if (opti82c611a & mask)
-		return OPTI611A;
-	if (opti82c46x & mask)
-		return OPTI46X;
-	if (autospeed & mask)
-		return SNOOP;
-	return BIOS;
-}
 
-
-/**
- *	legacy_init_one		-	attach a legacy interface
- *	@pl: probe record
- *
- *	Register an ISA bus IDE interface. Such interfaces are PIO and we
- *	assume do not support IRQ sharing.
- */
-
-static __init int legacy_init_one(struct legacy_probe *probe)
-{
-	struct legacy_controller *controller = &controllers[probe->type];
-	int pio_modes = controller->pio_mask;
-	unsigned long io = probe->port;
-	u32 mask = (1 << probe->slot);
-	struct ata_port_operations *ops = controller->ops;
-	struct legacy_data *ld = &legacy_data[probe->slot];
-	struct ata_host *host = NULL;
-	struct ata_port *ap;
-	struct platform_device *pdev;
-	struct ata_device *dev;
-	void __iomem *io_addr, *ctrl_addr;
-	u32 iordy = (iordy_mask & mask) ? 0: ATA_FLAG_NO_IORDY;
-	int ret;
-
-	iordy |= controller->flags;
-
-	pdev = platform_device_register_simple(DRV_NAME, probe->slot, NULL, 0);
-	if (IS_ERR(pdev))
-		return PTR_ERR(pdev);
-
-	ret = -EBUSY;
-	if (devm_request_region(&pdev->dev, io, 8, "pata_legacy") == NULL ||
-	    devm_request_region(&pdev->dev, io + 0x0206, 1,
-							"pata_legacy") == NULL)
-		goto fail;
+	/* Chip does mode setting by command snooping */
+	if (ops == &legacy_port_ops && (autospeed & mask))
+		ops = &simple_port_ops;
 
 	ret = -ENOMEM;
-	io_addr = devm_ioport_map(&pdev->dev, io, 8);
-	ctrl_addr = devm_ioport_map(&pdev->dev, io + 0x0206, 1);
-	if (!io_addr || !ctrl_addr)
-		goto fail;
-	if (controller->setup)
-		if (controller->setup(pdev, probe, ld) < 0)
-			goto fail;
 	host = ata_host_alloc(&pdev->dev, 1);
 	if (!host)
 		goto fail;
@@ -1016,33 +808,20 @@
 	ap->ops = ops;
 	ap->pio_mask = pio_modes;
 	ap->flags |= ATA_FLAG_SLAVE_POSS | iordy;
-	ap->pflags |= controller->pflags;
 	ap->ioaddr.cmd_addr = io_addr;
 	ap->ioaddr.altstatus_addr = ctrl_addr;
 	ap->ioaddr.ctl_addr = ctrl_addr;
-	ata_sff_std_ports(&ap->ioaddr);
-	ap->host->private_data = ld;
+	ata_std_ports(&ap->ioaddr);
+	ap->private_data = ld;
 
-	ata_port_desc(ap, "cmd 0x%lx ctl 0x%lx", io, io + 0x0206);
-
-	ret = ata_host_activate(host, probe->irq, ata_sff_interrupt, 0,
-				&legacy_sht);
+	ret = ata_host_activate(host, irq, ata_interrupt, 0, &legacy_sht);
 	if (ret)
 		goto fail;
-	async_synchronize_full();
-	ld->platform_dev = pdev;
 
-	/* Nothing found means we drop the port as its probably not there */
+	legacy_host[nr_legacy_host++] = dev_get_drvdata(&pdev->dev);
+	ld->platform_dev = pdev;
+	return 0;
 
-	ret = -ENODEV;
-	ata_for_each_dev(dev, &ap->link, ALL) {
-		if (!ata_dev_absent(dev)) {
-			legacy_host[probe->slot] = host;
-			ld->platform_dev = pdev;
-			return 0;
-		}
-	}
-	ata_host_detach(host);
 fail:
 	platform_device_unregister(pdev);
 	return ret;
@@ -1054,15 +833,13 @@
  *	@master: set this if we find an ATA master
  *	@master: set this if we find an ATA secondary
  *
- *	A small number of vendors implemented early PCI ATA interfaces
- *	on bridge logic without the ATA interface being PCI visible.
- *	Where we have a matching PCI driver we must skip the relevant
- *	device here. If we don't know about it then the legacy driver
- *	is the right driver anyway.
+ *	A small number of vendors implemented early PCI ATA interfaces on bridge logic
+ *	without the ATA interface being PCI visible. Where we have a matching PCI driver
+ *	we must skip the relevant device here. If we don't know about it then the legacy
+ *	driver is the right driver anyway.
  */
 
-static void __init legacy_check_special_cases(struct pci_dev *p, int *primary,
-								int *secondary)
+static void legacy_check_special_cases(struct pci_dev *p, int *primary, int *secondary)
 {
 	/* Cyrix CS5510 pre SFF MWDMA ATA on the bridge */
 	if (p->vendor == 0x1078 && p->device == 0x0000) {
@@ -1078,8 +855,7 @@
 	if (p->vendor == 0x8086 && p->device == 0x1234) {
 		u16 r;
 		pci_read_config_word(p, 0x6C, &r);
-		if (r & 0x8000) {
-			/* ATA port enabled */
+		if (r & 0x8000) {	/* ATA port enabled */
 			if (r & 0x4000)
 				*secondary = 1;
 			else
@@ -1089,114 +865,6 @@
 	}
 }
 
-static __init void probe_opti_vlb(void)
-{
-	/* If an OPTI 82C46X is present find out where the channels are */
-	static const char *optis[4] = {
-		"3/463MV", "5MV",
-		"5MVA", "5MVB"
-	};
-	u8 chans = 1;
-	u8 ctrl = (opti_syscfg(0x30) & 0xC0) >> 6;
-
-	opti82c46x = 3;	/* Assume master and slave first */
-	printk(KERN_INFO DRV_NAME ": Opti 82C46%s chipset support.\n",
-								optis[ctrl]);
-	if (ctrl == 3)
-		chans = (opti_syscfg(0x3F) & 0x20) ? 2 : 1;
-	ctrl = opti_syscfg(0xAC);
-	/* Check enabled and this port is the 465MV port. On the
-	   MVB we may have two channels */
-	if (ctrl & 8) {
-		if (chans == 2) {
-			legacy_probe_add(0x1F0, 14, OPTI46X, 0);
-			legacy_probe_add(0x170, 15, OPTI46X, 0);
-		}
-		if (ctrl & 4)
-			legacy_probe_add(0x170, 15, OPTI46X, 0);
-		else
-			legacy_probe_add(0x1F0, 14, OPTI46X, 0);
-	} else
-		legacy_probe_add(0x1F0, 14, OPTI46X, 0);
-}
-
-static __init void qdi65_identify_port(u8 r, u8 res, unsigned long port)
-{
-	static const unsigned long ide_port[2] = { 0x170, 0x1F0 };
-	/* Check card type */
-	if ((r & 0xF0) == 0xC0) {
-		/* QD6500: single channel */
-		if (r & 8)
-			/* Disabled ? */
-			return;
-		legacy_probe_add(ide_port[r & 0x01], 14 + (r & 0x01),
-								QDI6500, port);
-	}
-	if (((r & 0xF0) == 0xA0) || (r & 0xF0) == 0x50) {
-		/* QD6580: dual channel */
-		if (!request_region(port + 2 , 2, "pata_qdi")) {
-			release_region(port, 2);
-			return;
-		}
-		res = inb(port + 3);
-		/* Single channel mode ? */
-		if (res & 1)
-			legacy_probe_add(ide_port[r & 0x01], 14 + (r & 0x01),
-								QDI6580, port);
-		else { /* Dual channel mode */
-			legacy_probe_add(0x1F0, 14, QDI6580DP, port);
-			/* port + 0x02, r & 0x04 */
-			legacy_probe_add(0x170, 15, QDI6580DP, port + 2);
-		}
-		release_region(port + 2, 2);
-	}
-}
-
-static __init void probe_qdi_vlb(void)
-{
-	unsigned long flags;
-	static const unsigned long qd_port[2] = { 0x30, 0xB0 };
-	int i;
-
-	/*
-	 *	Check each possible QD65xx base address
-	 */
-
-	for (i = 0; i < 2; i++) {
-		unsigned long port = qd_port[i];
-		u8 r, res;
-
-
-		if (request_region(port, 2, "pata_qdi")) {
-			/* Check for a card */
-			local_irq_save(flags);
-			/* I have no h/w that needs this delay but it
-			   is present in the historic code */
-			r = inb(port);
-			udelay(1);
-			outb(0x19, port);
-			udelay(1);
-			res = inb(port);
-			udelay(1);
-			outb(r, port);
-			udelay(1);
-			local_irq_restore(flags);
-
-			/* Fail */
-			if (res == 0x19) {
-				release_region(port, 2);
-				continue;
-			}
-			/* Passes the presence test */
-			r = inb(port + 1);
-			udelay(1);
-			/* Check port agrees with port set */
-			if ((r & 2) >> 1 == i)
-				qdi65_identify_port(r, res, port);
-			release_region(port, 2);
-		}
-	}
-}
 
 /**
  *	legacy_init		-	attach legacy interfaces
@@ -1214,17 +882,15 @@
 	int ct = 0;
 	int primary = 0;
 	int secondary = 0;
-	int pci_present = 0;
-	struct legacy_probe *pl = &probe_list[0];
-	int slot = 0;
+	int last_port = NR_HOST;
 
 	struct pci_dev *p = NULL;
 
 	for_each_pci_dev(p) {
 		int r;
-		/* Check for any overlap of the system ATA mappings. Native
-		   mode controllers stuck on these addresses or some devices
-		   in 'raid' mode won't be found by the storage class test */
+		/* Check for any overlap of the system ATA mappings. Native mode controllers
+		   stuck on these addresses or some devices in 'raid' mode won't be found by
+		   the storage class test */
 		for (r = 0; r < 6; r++) {
 			if (pci_resource_start(p, r) == 0x1f0)
 				primary = 1;
@@ -1234,39 +900,49 @@
 		/* Check for special cases */
 		legacy_check_special_cases(p, &primary, &secondary);
 
-		/* If PCI bus is present then don't probe for tertiary
-		   legacy ports */
-		pci_present = 1;
+		/* If PCI bus is present then don't probe for tertiary legacy ports */
+		if (probe_all == 0)
+			last_port = 2;
 	}
 
-	if (winbond == 1)
-		winbond = 0x130;	/* Default port, alt is 1B0 */
-
-	if (primary == 0 || all)
-		legacy_probe_add(0x1F0, 14, UNKNOWN, 0);
-	if (secondary == 0 || all)
-		legacy_probe_add(0x170, 15, UNKNOWN, 0);
-
-	if (probe_all || !pci_present) {
-		/* ISA/VLB extra ports */
-		legacy_probe_add(0x1E8, 11, UNKNOWN, 0);
-		legacy_probe_add(0x168, 10, UNKNOWN, 0);
-		legacy_probe_add(0x1E0, 8, UNKNOWN, 0);
-		legacy_probe_add(0x160, 12, UNKNOWN, 0);
+	/* If an OPTI 82C46X is present find out where the channels are */
+	if (opti82c46x) {
+		static const char *optis[4] = {
+			"3/463MV", "5MV",
+			"5MVA", "5MVB"
+		};
+		u8 chans = 1;
+		u8 ctrl = (opti_syscfg(0x30) & 0xC0) >> 6;
+
+		opti82c46x = 3;	/* Assume master and slave first */
+		printk(KERN_INFO DRV_NAME ": Opti 82C46%s chipset support.\n", optis[ctrl]);
+		if (ctrl == 3)
+			chans = (opti_syscfg(0x3F) & 0x20) ? 2 : 1;
+		ctrl = opti_syscfg(0xAC);
+		/* Check enabled and this port is the 465MV port. On the
+		   MVB we may have two channels */
+		if (ctrl & 8) {
+			if (ctrl & 4)
+				opti82c46x = 2;	/* Slave */
+			else
+				opti82c46x = 1;	/* Master */
+			if (chans == 2)
+				opti82c46x = 3; /* Master and Slave */
+		}	/* Slave only */
+		else if (chans == 1)
+			opti82c46x = 1;
 	}
 
-	if (opti82c46x)
-		probe_opti_vlb();
-	if (qdi)
-		probe_qdi_vlb();
-
-	for (i = 0; i < NR_HOST; i++, pl++) {
-		if (pl->port == 0)
+	for (i = 0; i < last_port; i++) {
+		/* Skip primary if we have seen a PCI one */
+		if (i == 0 && primary == 1)
+			continue;
+		/* Skip secondary if we have seen a PCI one */
+		if (i == 1 && secondary == 1)
 			continue;
-		if (pl->type == UNKNOWN)
-			pl->type = probe_chip_type(pl);
-		pl->slot = slot++;
-		if (legacy_init_one(pl) == 0)
+		if (legacy_init_one(i, legacy_port[i],
+				   legacy_port[i] + 0x0206,
+				   legacy_irq[i]) == 0)
 			ct++;
 	}
 	if (ct != 0)
@@ -1280,8 +956,11 @@
 
 	for (i = 0; i < nr_legacy_host; i++) {
 		struct legacy_data *ld = &legacy_data[i];
+
 		ata_host_detach(legacy_host[i]);
 		platform_device_unregister(ld->platform_dev);
+		if (ld->timing)
+			release_region(ld->timing, 2);
 	}
 }
 
@@ -1296,9 +975,9 @@
 module_param(ht6560b, int, 0);
 module_param(opti82c611a, int, 0);
 module_param(opti82c46x, int, 0);
-module_param(qdi, int, 0);
 module_param(pio_mask, int, 0);
 module_param(iordy_mask, int, 0);
 
 module_init(legacy_init);
 module_exit(legacy_exit);
+
diff -Nur linux-sh4/drivers/ata.org/pata_marvell.c linux-sh4/drivers/ata/pata_marvell.c
--- linux-sh4/drivers/ata.org/pata_marvell.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_marvell.c	2012-01-15 06:30:15.000000000 -0800
@@ -5,7 +5,7 @@
  *	isn't making full use of the device functionality but it is
  *	easy to get working.
  *
- *	(c) 2006 Red Hat
+ *	(c) 2006 Red Hat  <alan@redhat.com>
  */
 
 #include <linux/kernel.h>
@@ -20,30 +20,28 @@
 #include <linux/ata.h>
 
 #define DRV_NAME	"pata_marvell"
-#define DRV_VERSION	"0.1.6"
+#define DRV_VERSION	"0.1.4"
 
 /**
- *	marvell_pata_active	-	check if PATA is active
- *	@pdev: PCI device
+ *	marvell_pre_reset	-	check for 40/80 pin
+ *	@ap: Port
+ *	@deadline: deadline jiffies for the operation
  *
- *	Returns 1 if the PATA port may be active. We know how to check this
- *	for the 6145 but not the other devices
+ *	Perform the PATA port setup we need.
  */
 
-static int marvell_pata_active(struct pci_dev *pdev)
+static int marvell_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	int i;
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	u32 devices;
 	void __iomem *barp;
+	int i;
 
-	/* We don't yet know how to do this for other devices */
-	if (pdev->device != 0x6145)
-		return 1;	
+	/* Check if our port is enabled */
 
 	barp = pci_iomap(pdev, 5, 0x10);
 	if (barp == NULL)
 		return -ENOMEM;
-
 	printk("BAR5:");
 	for(i = 0; i <= 0x0F; i++)
 		printk("%02X:%02X ", i, ioread8(barp + i));
@@ -52,29 +50,11 @@
 	devices = ioread32(barp + 0x0C);
 	pci_iounmap(pdev, barp);
 
-	if (devices & 0x10)
-		return 1;
-	return 0;
-}
-
-/**
- *	marvell_pre_reset	-	check for 40/80 pin
- *	@link: link
- *	@deadline: deadline jiffies for the operation
- *
- *	Perform the PATA port setup we need.
- */
+	if ((pdev->device == 0x6145) && (ap->port_no == 0) &&
+	    (!(devices & 0x10)))	/* PATA enable ? */
+		return -ENOENT;
 
-static int marvell_pre_reset(struct ata_link *link, unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-
-	if (pdev->device == 0x6145 && ap->port_no == 0 &&
-		!marvell_pata_active(pdev))	/* PATA enable ? */
-			return -ENOENT;
-
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
 }
 
 static int marvell_cable_detect(struct ata_port *ap)
@@ -94,16 +74,74 @@
 	return 0;	/* Our BUG macro needs the right markup */
 }
 
+/**
+ *	marvell_error_handler - Setup and error handler
+ *	@ap: Port to handle
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void marvell_error_handler(struct ata_port *ap)
+{
+	return ata_bmdma_drive_eh(ap, marvell_pre_reset, ata_std_softreset,
+				  NULL, ata_std_postreset);
+}
+
 /* No PIO or DMA methods needed for this device */
 
 static struct scsi_host_template marvell_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	/* Use standard CHS mapping rules */
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations marvell_ops = {
-	.inherits		= &ata_bmdma_port_ops,
+static const struct ata_port_operations marvell_ops = {
+	.port_disable		= ata_port_disable,
+
+	/* Task file is PCI ATA format, use helpers */
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= marvell_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
 	.cable_detect		= marvell_cable_detect,
-	.prereset		= marvell_pre_reset,
+
+	/* BMDMA handling is PCI ATA format, use helpers */
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	/* Timeout handling */
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	/* Generic PATA PCI ATA helpers */
+	.port_start		= ata_port_start,
 };
 
 
@@ -124,20 +162,22 @@
 static int marvell_init_one (struct pci_dev *pdev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht		= &marvell_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
 
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,
+		.mwdma_mask	= 0x07,
 		.udma_mask 	= ATA_UDMA5,
 
 		.port_ops	= &marvell_ops,
 	};
 	static const struct ata_port_info info_sata = {
+		.sht		= &marvell_sht,
 		/* Slave possible as its magically mapped not real */
 		.flags		= ATA_FLAG_SLAVE_POSS,
 
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,
+		.mwdma_mask	= 0x07,
 		.udma_mask 	= ATA_UDMA6,
 
 		.port_ops	= &marvell_ops,
@@ -147,13 +187,7 @@
 	if (pdev->device == 0x6101)
 		ppi[1] = &ata_dummy_port_info;
 
-#if defined(CONFIG_AHCI) || defined(CONFIG_AHCI_MODULE)
-	if (!marvell_pata_active(pdev)) {
-		printk(KERN_INFO DRV_NAME ": PATA port not active, deferring to AHCI driver.\n");
-		return -ENODEV;
-	}
-#endif
-	return ata_pci_sff_init_one(pdev, ppi, &marvell_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id marvell_pci_tbl[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_mpc52xx.c linux-sh4/drivers/ata/pata_mpc52xx.c
--- linux-sh4/drivers/ata.org/pata_mpc52xx.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_mpc52xx.c	2012-01-15 06:30:15.000000000 -0800
@@ -6,9 +6,6 @@
  * Copyright (C) 2006 Sylvain Munaut <tnt@246tNt.com>
  * Copyright (C) 2003 Mipsys - Benjamin Herrenschmidt
  *
- * UDMA support based on patches by Freescale (Bernard Kuhn, John Rigby),
- * Domen Puncer and Tim Yamin.
- *
  * This file is licensed under the terms of the GNU General Public License
  * version 2. This program is licensed "as is" without any warranty of any
  * kind, whether express or implied.
@@ -19,47 +16,29 @@
 #include <linux/slab.h>
 #include <linux/delay.h>
 #include <linux/libata.h>
-#include <linux/of_platform.h>
-#include <linux/types.h>
 
-#include <asm/cacheflush.h>
+#include <asm/types.h>
 #include <asm/prom.h>
+#include <asm/of_platform.h>
 #include <asm/mpc52xx.h>
 
-#include <sysdev/bestcomm/bestcomm.h>
-#include <sysdev/bestcomm/bestcomm_priv.h>
-#include <sysdev/bestcomm/ata.h>
 
 #define DRV_NAME	"mpc52xx_ata"
+#define DRV_VERSION	"0.1.2"
+
 
 /* Private structures used by the driver */
 struct mpc52xx_ata_timings {
 	u32	pio1;
 	u32	pio2;
-	u32	mdma1;
-	u32	mdma2;
-	u32	udma1;
-	u32	udma2;
-	u32	udma3;
-	u32	udma4;
-	u32	udma5;
-	int	using_udma;
 };
 
 struct mpc52xx_ata_priv {
 	unsigned int			ipb_period;
-	struct mpc52xx_ata __iomem	*ata_regs;
-	phys_addr_t			ata_regs_pa;
+	struct mpc52xx_ata __iomem *	ata_regs;
 	int				ata_irq;
 	struct mpc52xx_ata_timings	timings[2];
 	int				csel;
-
-	/* DMA */
-	struct bcom_task		*dmatsk;
-	const struct udmaspec		*udmaspec;
-	const struct mdmaspec		*mdmaspec;
-	int 				mpc52xx_ata_dma_last_write;
-	int				waiting_for_dma;
 };
 
 
@@ -74,107 +53,6 @@
 
 #define CALC_CLKCYC(c,v) ((((v)+(c)-1)/(c)))
 
-/* ======================================================================== */
-
-/* ATAPI-4 MDMA specs (in clocks) */
-struct mdmaspec {
-	u32 t0M;
-	u32 td;
-	u32 th;
-	u32 tj;
-	u32 tkw;
-	u32 tm;
-	u32 tn;
-};
-
-static const struct mdmaspec mdmaspec66[3] = {
-	{ .t0M = 32, .td = 15, .th = 2, .tj = 2, .tkw = 15, .tm = 4, .tn = 1 },
-	{ .t0M = 10, .td = 6,  .th = 1, .tj = 1, .tkw = 4,  .tm = 2, .tn = 1 },
-	{ .t0M = 8,  .td = 5,  .th = 1, .tj = 1, .tkw = 2,  .tm = 2, .tn = 1 },
-};
-
-static const struct mdmaspec mdmaspec132[3] = {
-	{ .t0M = 64, .td = 29, .th = 3, .tj = 3, .tkw = 29, .tm = 7, .tn = 2 },
-	{ .t0M = 20, .td = 11, .th = 2, .tj = 1, .tkw = 7,  .tm = 4, .tn = 1 },
-	{ .t0M = 16, .td = 10, .th = 2, .tj = 1, .tkw = 4,  .tm = 4, .tn = 1 },
-};
-
-/* ATAPI-4 UDMA specs (in clocks) */
-struct udmaspec {
-	u32 tcyc;
-	u32 t2cyc;
-	u32 tds;
-	u32 tdh;
-	u32 tdvs;
-	u32 tdvh;
-	u32 tfs;
-	u32 tli;
-	u32 tmli;
-	u32 taz;
-	u32 tzah;
-	u32 tenv;
-	u32 tsr;
-	u32 trfs;
-	u32 trp;
-	u32 tack;
-	u32 tss;
-};
-
-static const struct udmaspec udmaspec66[6] = {
-	{ .tcyc = 8,  .t2cyc = 16, .tds  = 1,  .tdh  = 1, .tdvs = 5,  .tdvh = 1,
-	  .tfs  = 16, .tli   = 10, .tmli = 2,  .taz  = 1, .tzah = 2,  .tenv = 2,
-	  .tsr  = 3,  .trfs  = 5,  .trp  = 11, .tack = 2, .tss  = 4,
-	},
-	{ .tcyc = 5,  .t2cyc = 11, .tds  = 1,  .tdh  = 1, .tdvs = 4,  .tdvh = 1,
-	  .tfs  = 14, .tli   = 10, .tmli = 2,  .taz  = 1, .tzah = 2,  .tenv = 2,
-	  .tsr  = 2,  .trfs  = 5,  .trp  = 9,  .tack = 2, .tss  = 4,
-	},
-	{ .tcyc = 4,  .t2cyc = 8,  .tds  = 1,  .tdh  = 1, .tdvs = 3,  .tdvh = 1,
-	  .tfs  = 12, .tli   = 10, .tmli = 2,  .taz  = 1, .tzah = 2,  .tenv = 2,
-	  .tsr  = 2,  .trfs  = 4,  .trp  = 7,  .tack = 2, .tss  = 4,
-	},
-	{ .tcyc = 3,  .t2cyc = 6,  .tds  = 1,  .tdh  = 1, .tdvs = 2,  .tdvh = 1,
-	  .tfs  = 9,  .tli   = 7,  .tmli = 2,  .taz  = 1, .tzah = 2,  .tenv = 2,
-	  .tsr  = 2,  .trfs  = 4,  .trp  = 7,  .tack = 2, .tss  = 4,
-	},
-	{ .tcyc = 2,  .t2cyc = 4,  .tds  = 1,  .tdh  = 1, .tdvs = 1,  .tdvh = 1,
-	  .tfs  = 8,  .tli   = 8,  .tmli = 2,  .taz  = 1, .tzah = 2,  .tenv = 2,
-	  .tsr  = 2,  .trfs  = 4,  .trp  = 7,  .tack = 2, .tss  = 4,
-	},
-	{ .tcyc = 2,  .t2cyc = 2,  .tds  = 1,  .tdh  = 1, .tdvs = 1,  .tdvh = 1,
-	  .tfs  = 6,  .tli   = 5,  .tmli = 2,  .taz  = 1, .tzah = 2,  .tenv = 2,
-	  .tsr  = 2,  .trfs  = 4,  .trp  = 6,  .tack = 2, .tss  = 4,
-	},
-};
-
-static const struct udmaspec udmaspec132[6] = {
-	{ .tcyc = 15, .t2cyc = 31, .tds  = 2,  .tdh  = 1, .tdvs = 10, .tdvh = 1,
-	  .tfs  = 30, .tli   = 20, .tmli = 3,  .taz  = 2, .tzah = 3,  .tenv = 3,
-	  .tsr  = 7,  .trfs  = 10, .trp  = 22, .tack = 3, .tss  = 7,
-	},
-	{ .tcyc = 10, .t2cyc = 21, .tds  = 2,  .tdh  = 1, .tdvs = 7,  .tdvh = 1,
-	  .tfs  = 27, .tli   = 20, .tmli = 3,  .taz  = 2, .tzah = 3,  .tenv = 3,
-	  .tsr  = 4,  .trfs  = 10, .trp  = 17, .tack = 3, .tss  = 7,
-	},
-	{ .tcyc = 6,  .t2cyc = 12, .tds  = 1,  .tdh  = 1, .tdvs = 5,  .tdvh = 1,
-	  .tfs  = 23, .tli   = 20, .tmli = 3,  .taz  = 2, .tzah = 3,  .tenv = 3,
-	  .tsr  = 3,  .trfs  = 8,  .trp  = 14, .tack = 3, .tss  = 7,
-	},
-	{ .tcyc = 7,  .t2cyc = 12, .tds  = 1,  .tdh  = 1, .tdvs = 3,  .tdvh = 1,
-	  .tfs  = 15, .tli   = 13, .tmli = 3,  .taz  = 2, .tzah = 3,  .tenv = 3,
-	  .tsr  = 3,  .trfs  = 8,  .trp  = 14, .tack = 3, .tss  = 7,
-	},
-	{ .tcyc = 2,  .t2cyc = 5,  .tds  = 0,  .tdh  = 0, .tdvs = 1,  .tdvh = 1,
-	  .tfs  = 16, .tli   = 14, .tmli = 2,  .taz  = 1, .tzah = 2,  .tenv = 2,
-	  .tsr  = 2,  .trfs  = 7,  .trp  = 13, .tack = 2, .tss  = 6,
-	},
-	{ .tcyc = 3,  .t2cyc = 6,  .tds  = 1,  .tdh  = 1, .tdvs = 1,  .tdvh = 1,
-	  .tfs  = 12, .tli   = 10, .tmli = 3,  .taz  = 2, .tzah = 3,  .tenv = 3,
-	  .tsr  = 3,  .trfs  = 7,  .trp  = 12, .tack = 3, .tss  = 7,
-	},
-};
-
-/* ======================================================================== */
 
 /* Bit definitions inside the registers */
 #define MPC52xx_ATA_HOSTCONF_SMR	0x80000000UL /* State machine reset */
@@ -188,7 +66,6 @@
 #define MPC52xx_ATA_HOSTSTAT_WERR	0x01000000UL /* Write Error */
 
 #define MPC52xx_ATA_FIFOSTAT_EMPTY	0x01 /* FIFO Empty */
-#define MPC52xx_ATA_FIFOSTAT_ERROR	0x40 /* FIFO Error */
 
 #define MPC52xx_ATA_DMAMODE_WRITE	0x01 /* Write DMA */
 #define MPC52xx_ATA_DMAMODE_READ	0x02 /* Read DMA */
@@ -198,8 +75,6 @@
 #define MPC52xx_ATA_DMAMODE_FR		0x20 /* FIFO Reset */
 #define MPC52xx_ATA_DMAMODE_HUT		0x40 /* Host UDMA burst terminate */
 
-#define MAX_DMA_BUFFERS 128
-#define MAX_DMA_BUFFER_SIZE 0x20000u
 
 /* Structure of the hardware registers */
 struct mpc52xx_ata {
@@ -265,6 +140,7 @@
 
 
 /* MPC52xx low level hw control */
+
 static int
 mpc52xx_ata_compute_pio_timings(struct mpc52xx_ata_priv *priv, int dev, int pio)
 {
@@ -272,7 +148,7 @@
 	unsigned int ipb_period = priv->ipb_period;
 	unsigned int t0, t1, t2_8, t2_16, t2i, t4, ta;
 
-	if ((pio < 0) || (pio > 4))
+	if ((pio<0) || (pio>4))
 		return -EINVAL;
 
 	t0	= CALC_CLKCYC(ipb_period, 1000 * ataspec_t0[pio]);
@@ -289,43 +165,6 @@
 	return 0;
 }
 
-static int
-mpc52xx_ata_compute_mdma_timings(struct mpc52xx_ata_priv *priv, int dev,
-				 int speed)
-{
-	struct mpc52xx_ata_timings *t = &priv->timings[dev];
-	const struct mdmaspec *s = &priv->mdmaspec[speed];
-
-	if (speed < 0 || speed > 2)
-		return -EINVAL;
-
-	t->mdma1 = (s->t0M << 24) | (s->td << 16) | (s->tkw << 8) | (s->tm);
-	t->mdma2 = (s->th << 24) | (s->tj << 16) | (s->tn << 8);
-	t->using_udma = 0;
-
-	return 0;
-}
-
-static int
-mpc52xx_ata_compute_udma_timings(struct mpc52xx_ata_priv *priv, int dev,
-				 int speed)
-{
-	struct mpc52xx_ata_timings *t = &priv->timings[dev];
-	const struct udmaspec *s = &priv->udmaspec[speed];
-
-	if (speed < 0 || speed > 2)
-		return -EINVAL;
-
-	t->udma1 = (s->t2cyc << 24) | (s->tcyc << 16) | (s->tds << 8) | s->tdh;
-	t->udma2 = (s->tdvs << 24) | (s->tdvh << 16) | (s->tfs << 8) | s->tli;
-	t->udma3 = (s->tmli << 24) | (s->taz << 16) | (s->tenv << 8) | s->tsr;
-	t->udma4 = (s->tss << 24) | (s->trfs << 16) | (s->trp << 8) | s->tack;
-	t->udma5 = (s->tzah << 24);
-	t->using_udma = 1;
-
-	return 0;
-}
-
 static void
 mpc52xx_ata_apply_timings(struct mpc52xx_ata_priv *priv, int device)
 {
@@ -334,13 +173,14 @@
 
 	out_be32(&regs->pio1,  timing->pio1);
 	out_be32(&regs->pio2,  timing->pio2);
-	out_be32(&regs->mdma1, timing->mdma1);
-	out_be32(&regs->mdma2, timing->mdma2);
-	out_be32(&regs->udma1, timing->udma1);
-	out_be32(&regs->udma2, timing->udma2);
-	out_be32(&regs->udma3, timing->udma3);
-	out_be32(&regs->udma4, timing->udma4);
-	out_be32(&regs->udma5, timing->udma5);
+	out_be32(&regs->mdma1, 0);
+	out_be32(&regs->mdma2, 0);
+	out_be32(&regs->udma1, 0);
+	out_be32(&regs->udma2, 0);
+	out_be32(&regs->udma3, 0);
+	out_be32(&regs->udma4, 0);
+	out_be32(&regs->udma5, 0);
+
 	priv->csel = device;
 }
 
@@ -368,7 +208,7 @@
 
 	/* Set the time slot to 1us */
 	tslot = CALC_CLKCYC(priv->ipb_period, 1000000);
-	out_be32(&regs->share_cnt, tslot << 16);
+	out_be32(&regs->share_cnt, tslot << 16 );
 
 	/* Init timings to PIO0 */
 	memset(priv->timings, 0x00, 2*sizeof(struct mpc52xx_ata_timings));
@@ -397,37 +237,13 @@
 	rv = mpc52xx_ata_compute_pio_timings(priv, adev->devno, pio);
 
 	if (rv) {
-		dev_err(ap->dev, "error: invalid PIO mode: %d\n", pio);
+		printk(KERN_ERR DRV_NAME
+			": Trying to select invalid PIO mode %d\n", pio);
 		return;
 	}
 
 	mpc52xx_ata_apply_timings(priv, adev->devno);
 }
-
-static void
-mpc52xx_ata_set_dmamode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct mpc52xx_ata_priv *priv = ap->host->private_data;
-	int rv;
-
-	if (adev->dma_mode >= XFER_UDMA_0) {
-		int dma = adev->dma_mode - XFER_UDMA_0;
-		rv = mpc52xx_ata_compute_udma_timings(priv, adev->devno, dma);
-	} else {
-		int dma = adev->dma_mode - XFER_MW_DMA_0;
-		rv = mpc52xx_ata_compute_mdma_timings(priv, adev->devno, dma);
-	}
-
-	if (rv) {
-		dev_alert(ap->dev,
-			"Trying to select invalid DMA mode %d\n",
-			adev->dma_mode);
-		return;
-	}
-
-	mpc52xx_ata_apply_timings(priv, adev->devno);
-}
-
 static void
 mpc52xx_ata_dev_select(struct ata_port *ap, unsigned int device)
 {
@@ -436,198 +252,64 @@
 	if (device != priv->csel)
 		mpc52xx_ata_apply_timings(priv, device);
 
-	ata_sff_dev_select(ap, device);
-}
-
-static int
-mpc52xx_ata_build_dmatable(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct mpc52xx_ata_priv *priv = ap->host->private_data;
-	struct bcom_ata_bd *bd;
-	unsigned int read = !(qc->tf.flags & ATA_TFLAG_WRITE), si;
-	struct scatterlist *sg;
-	int count = 0;
-
-	if (read)
-		bcom_ata_rx_prepare(priv->dmatsk);
-	else
-		bcom_ata_tx_prepare(priv->dmatsk);
-
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		dma_addr_t cur_addr = sg_dma_address(sg);
-		u32 cur_len = sg_dma_len(sg);
-
-		while (cur_len) {
-			unsigned int tc = min(cur_len, MAX_DMA_BUFFER_SIZE);
-			bd = (struct bcom_ata_bd *)
-				bcom_prepare_next_buffer(priv->dmatsk);
-
-			if (read) {
-				bd->status = tc;
-				bd->src_pa = (__force u32) priv->ata_regs_pa +
-					offsetof(struct mpc52xx_ata, fifo_data);
-				bd->dst_pa = (__force u32) cur_addr;
-			} else {
-				bd->status = tc;
-				bd->src_pa = (__force u32) cur_addr;
-				bd->dst_pa = (__force u32) priv->ata_regs_pa +
-					offsetof(struct mpc52xx_ata, fifo_data);
-			}
-
-			bcom_submit_next_buffer(priv->dmatsk, NULL);
-
-			cur_addr += tc;
-			cur_len -= tc;
-			count++;
-
-			if (count > MAX_DMA_BUFFERS) {
-				dev_alert(ap->dev, "dma table"
-					"too small\n");
-				goto use_pio_instead;
-			}
-		}
-	}
-	return 1;
-
- use_pio_instead:
-	bcom_ata_reset_bd(priv->dmatsk);
-	return 0;
+	ata_std_dev_select(ap,device);
 }
 
 static void
-mpc52xx_bmdma_setup(struct ata_queued_cmd *qc)
+mpc52xx_ata_error_handler(struct ata_port *ap)
 {
-	struct ata_port *ap = qc->ap;
-	struct mpc52xx_ata_priv *priv = ap->host->private_data;
-	struct mpc52xx_ata __iomem *regs = priv->ata_regs;
-
-	unsigned int read = !(qc->tf.flags & ATA_TFLAG_WRITE);
-	u8 dma_mode;
-
-	if (!mpc52xx_ata_build_dmatable(qc))
-		dev_alert(ap->dev, "%s: %i, return 1?\n",
-			__func__, __LINE__);
-
-	/* Check FIFO is OK... */
-	if (in_8(&priv->ata_regs->fifo_status) & MPC52xx_ATA_FIFOSTAT_ERROR)
-		dev_alert(ap->dev, "%s: FIFO error detected: 0x%02x!\n",
-			__func__, in_8(&priv->ata_regs->fifo_status));
-
-	if (read) {
-		dma_mode = MPC52xx_ATA_DMAMODE_IE | MPC52xx_ATA_DMAMODE_READ |
-				MPC52xx_ATA_DMAMODE_FE;
-
-		/* Setup FIFO if direction changed */
-		if (priv->mpc52xx_ata_dma_last_write != 0) {
-			priv->mpc52xx_ata_dma_last_write = 0;
-
-			/* Configure FIFO with granularity to 7 */
-			out_8(&regs->fifo_control, 7);
-			out_be16(&regs->fifo_alarm, 128);
-
-			/* Set FIFO Reset bit (FR) */
-			out_8(&regs->dma_mode, MPC52xx_ATA_DMAMODE_FR);
-		}
-	} else {
-		dma_mode = MPC52xx_ATA_DMAMODE_IE | MPC52xx_ATA_DMAMODE_WRITE;
-
-		/* Setup FIFO if direction changed */
-		if (priv->mpc52xx_ata_dma_last_write != 1) {
-			priv->mpc52xx_ata_dma_last_write = 1;
-
-			/* Configure FIFO with granularity to 4 */
-			out_8(&regs->fifo_control, 4);
-			out_be16(&regs->fifo_alarm, 128);
-		}
-	}
-
-	if (priv->timings[qc->dev->devno].using_udma)
-		dma_mode |= MPC52xx_ATA_DMAMODE_UDMA;
-
-	out_8(&regs->dma_mode, dma_mode);
-	priv->waiting_for_dma = ATA_DMA_ACTIVE;
-
-	ata_wait_idle(ap);
-	ap->ops->sff_exec_command(ap, &qc->tf);
-}
-
-static void
-mpc52xx_bmdma_start(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct mpc52xx_ata_priv *priv = ap->host->private_data;
-
-	bcom_set_task_auto_start(priv->dmatsk->tasknum, priv->dmatsk->tasknum);
-	bcom_enable(priv->dmatsk);
-}
-
-static void
-mpc52xx_bmdma_stop(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct mpc52xx_ata_priv *priv = ap->host->private_data;
-
-	bcom_disable(priv->dmatsk);
-	bcom_ata_reset_bd(priv->dmatsk);
-	priv->waiting_for_dma = 0;
-
-	/* Check FIFO is OK... */
-	if (in_8(&priv->ata_regs->fifo_status) & MPC52xx_ATA_FIFOSTAT_ERROR)
-		dev_alert(ap->dev, "%s: FIFO error detected: 0x%02x!\n",
-			__func__, in_8(&priv->ata_regs->fifo_status));
-}
-
-static u8
-mpc52xx_bmdma_status(struct ata_port *ap)
-{
-	struct mpc52xx_ata_priv *priv = ap->host->private_data;
-
-	/* Check FIFO is OK... */
-	if (in_8(&priv->ata_regs->fifo_status) & MPC52xx_ATA_FIFOSTAT_ERROR) {
-		dev_alert(ap->dev, "%s: FIFO error detected: 0x%02x!\n",
-			__func__, in_8(&priv->ata_regs->fifo_status));
-		return priv->waiting_for_dma | ATA_DMA_ERR;
-	}
-
-	return priv->waiting_for_dma;
+	ata_bmdma_drive_eh(ap, ata_std_prereset, ata_std_softreset, NULL,
+			ata_std_postreset);
 }
 
-static irqreturn_t
-mpc52xx_ata_task_irq(int irq, void *vpriv)
-{
-	struct mpc52xx_ata_priv *priv = vpriv;
-	while (bcom_buffer_done(priv->dmatsk))
-		bcom_retrieve_buffer(priv->dmatsk, NULL, NULL);
 
-	priv->waiting_for_dma |= ATA_DMA_INTR;
-
-	return IRQ_HANDLED;
-}
 
 static struct scsi_host_template mpc52xx_ata_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.max_sectors		= ATA_MAX_SECTORS,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations mpc52xx_ata_port_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.sff_dev_select		= mpc52xx_ata_dev_select,
+	.port_disable		= ata_port_disable,
 	.set_piomode		= mpc52xx_ata_set_piomode,
-	.set_dmamode		= mpc52xx_ata_set_dmamode,
-	.bmdma_setup		= mpc52xx_bmdma_setup,
-	.bmdma_start		= mpc52xx_bmdma_start,
-	.bmdma_stop		= mpc52xx_bmdma_stop,
-	.bmdma_status		= mpc52xx_bmdma_status,
-	.qc_prep		= ata_noop_qc_prep,
+	.dev_select		= mpc52xx_ata_dev_select,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= mpc52xx_ata_error_handler,
+	.cable_detect		= ata_cable_40wire,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+	.port_start		= ata_port_start,
 };
 
 static int __devinit
-mpc52xx_ata_init_one(struct device *dev, struct mpc52xx_ata_priv *priv,
-		     unsigned long raw_ata_regs, int mwdma_mask, int udma_mask)
+mpc52xx_ata_init_one(struct device *dev, struct mpc52xx_ata_priv *priv)
 {
 	struct ata_host *host;
 	struct ata_port *ap;
 	struct ata_ioports *aio;
+	int rc;
 
 	host = ata_host_alloc(dev, 1);
 	if (!host)
@@ -635,9 +317,9 @@
 
 	ap = host->ports[0];
 	ap->flags		|= ATA_FLAG_SLAVE_POSS;
-	ap->pio_mask		= ATA_PIO4;
-	ap->mwdma_mask		= mwdma_mask;
-	ap->udma_mask		= udma_mask;
+	ap->pio_mask		= 0x1f;	/* Up to PIO4 */
+	ap->mwdma_mask		= 0x00;	/* No MWDMA   */
+	ap->udma_mask		= 0x00;	/* No UDMA    */
 	ap->ops			= &mpc52xx_ata_port_ops;
 	host->private_data	= priv;
 
@@ -656,10 +338,8 @@
 	aio->status_addr	= &priv->ata_regs->tf_command;
 	aio->command_addr	= &priv->ata_regs->tf_command;
 
-	ata_port_desc(ap, "ata_regs 0x%lx", raw_ata_regs);
-
 	/* activate host */
-	return ata_host_activate(host, priv->ata_irq, ata_sff_interrupt, 0,
+	return ata_host_activate(host, priv->ata_irq, ata_interrupt, 0,
 				 &mpc52xx_ata_sht);
 }
 
@@ -684,139 +364,89 @@
 {
 	unsigned int ipb_freq;
 	struct resource res_mem;
-	int ata_irq = 0;
+	int ata_irq = NO_IRQ;
 	struct mpc52xx_ata __iomem *ata_regs;
-	struct mpc52xx_ata_priv *priv = NULL;
-	int rv, ret, task_irq = 0;
-	int mwdma_mask = 0, udma_mask = 0;
-	const __be32 *prop;
-	int proplen;
-	struct bcom_task *dmatsk = NULL;
+	struct mpc52xx_ata_priv *priv;
+	int rv;
 
 	/* Get ipb frequency */
-	ipb_freq = mpc5xxx_get_bus_frequency(op->node);
+	ipb_freq = mpc52xx_find_ipb_freq(op->node);
 	if (!ipb_freq) {
-		dev_err(&op->dev, "could not determine IPB bus frequency\n");
+		printk(KERN_ERR DRV_NAME ": "
+			"Unable to find IPB Bus frequency\n" );
 		return -ENODEV;
 	}
 
-	/* Get device base address from device tree, request the region
-	 * and ioremap it. */
+	/* Get IRQ and register */
 	rv = of_address_to_resource(op->node, 0, &res_mem);
 	if (rv) {
-		dev_err(&op->dev, "could not determine device base address\n");
+		printk(KERN_ERR DRV_NAME ": "
+			"Error while parsing device node resource\n" );
 		return rv;
 	}
 
+	ata_irq = irq_of_parse_and_map(op->node, 0);
+	if (ata_irq == NO_IRQ) {
+		printk(KERN_ERR DRV_NAME ": "
+			"Error while mapping the irq\n");
+		return -EINVAL;
+	}
+
+	/* Request mem region */
 	if (!devm_request_mem_region(&op->dev, res_mem.start,
-				     sizeof(*ata_regs), DRV_NAME)) {
-		dev_err(&op->dev, "error requesting register region\n");
-		return -EBUSY;
+				     sizeof(struct mpc52xx_ata), DRV_NAME)) {
+		printk(KERN_ERR DRV_NAME ": "
+			"Error while requesting mem region\n");
+		rv = -EBUSY;
+		goto err;
 	}
 
-	ata_regs = devm_ioremap(&op->dev, res_mem.start, sizeof(*ata_regs));
+	/* Remap registers */
+	ata_regs = devm_ioremap(&op->dev, res_mem.start,
+				sizeof(struct mpc52xx_ata));
 	if (!ata_regs) {
-		dev_err(&op->dev, "error mapping device registers\n");
+		printk(KERN_ERR DRV_NAME ": "
+			"Error while mapping register set\n");
 		rv = -ENOMEM;
 		goto err;
 	}
 
-	/*
-	 * By default, all DMA modes are disabled for the MPC5200.  Some
-	 * boards don't have the required signals routed to make DMA work.
-	 * Also, the MPC5200B has a silicon bug that causes data corruption
-	 * with UDMA if it is used at the same time as the LocalPlus bus.
-	 *
-	 * Instead of trying to guess what modes are usable, check the
-	 * ATA device tree node to find out what DMA modes work on the board.
-	 * UDMA/MWDMA modes can also be forced by adding "libata.force=<mode>"
-	 * to the kernel boot parameters.
-	 *
-	 * The MPC5200 ATA controller supports MWDMA modes 0, 1 and 2 and
-	 * UDMA modes 0, 1 and 2.
-	 */
-	prop = of_get_property(op->node, "mwdma-mode", &proplen);
-	if ((prop) && (proplen >= 4))
-		mwdma_mask = ATA_MWDMA2 & ((1 << (*prop + 1)) - 1);
-	prop = of_get_property(op->node, "udma-mode", &proplen);
-	if ((prop) && (proplen >= 4))
-		udma_mask = ATA_UDMA2 & ((1 << (*prop + 1)) - 1);
-
-	ata_irq = irq_of_parse_and_map(op->node, 0);
-	if (ata_irq == NO_IRQ) {
-		dev_err(&op->dev, "error mapping irq\n");
-		return -EINVAL;
-	}
-
 	/* Prepare our private structure */
-	priv = devm_kzalloc(&op->dev, sizeof(*priv), GFP_ATOMIC);
+	priv = devm_kzalloc(&op->dev, sizeof(struct mpc52xx_ata_priv),
+			    GFP_ATOMIC);
 	if (!priv) {
-		dev_err(&op->dev, "error allocating private structure\n");
+		printk(KERN_ERR DRV_NAME ": "
+			"Error while allocating private structure\n");
 		rv = -ENOMEM;
 		goto err;
 	}
 
 	priv->ipb_period = 1000000000 / (ipb_freq / 1000);
 	priv->ata_regs = ata_regs;
-	priv->ata_regs_pa = res_mem.start;
 	priv->ata_irq = ata_irq;
 	priv->csel = -1;
-	priv->mpc52xx_ata_dma_last_write = -1;
-
-	if (ipb_freq/1000000 == 66) {
-		priv->mdmaspec = mdmaspec66;
-		priv->udmaspec = udmaspec66;
-	} else {
-		priv->mdmaspec = mdmaspec132;
-		priv->udmaspec = udmaspec132;
-	}
-
-	/* Allocate a BestComm task for DMA */
-	dmatsk = bcom_ata_init(MAX_DMA_BUFFERS, MAX_DMA_BUFFER_SIZE);
-	if (!dmatsk) {
-		dev_err(&op->dev, "bestcomm initialization failed\n");
-		rv = -ENOMEM;
-		goto err;
-	}
-
-	task_irq = bcom_get_task_irq(dmatsk);
-	ret = request_irq(task_irq, &mpc52xx_ata_task_irq, IRQF_DISABLED,
-				"ATA task", priv);
-	if (ret) {
-		dev_err(&op->dev, "error requesting DMA IRQ\n");
-		goto err;
-	}
-	priv->dmatsk = dmatsk;
 
 	/* Init the hw */
 	rv = mpc52xx_ata_hw_init(priv);
 	if (rv) {
-		dev_err(&op->dev, "error initializing hardware\n");
+		printk(KERN_ERR DRV_NAME ": Error during HW init\n");
 		goto err;
 	}
 
 	/* Register ourselves to libata */
-	rv = mpc52xx_ata_init_one(&op->dev, priv, res_mem.start,
-				  mwdma_mask, udma_mask);
+	rv = mpc52xx_ata_init_one(&op->dev, priv);
 	if (rv) {
-		dev_err(&op->dev, "error registering with ATA layer\n");
-		goto err;
+		printk(KERN_ERR DRV_NAME ": "
+			"Error while registering to ATA layer\n");
+		return rv;
 	}
 
+	/* Done */
 	return 0;
 
- err:
-	devm_release_mem_region(&op->dev, res_mem.start, sizeof(*ata_regs));
-	if (ata_irq)
-		irq_dispose_mapping(ata_irq);
-	if (task_irq)
-		irq_dispose_mapping(task_irq);
-	if (dmatsk)
-		bcom_ata_release(dmatsk);
-	if (ata_regs)
-		devm_iounmap(&op->dev, ata_regs);
-	if (priv)
-		devm_kfree(&op->dev, priv);
+	/* Error path */
+err:
+	irq_dispose_mapping(ata_irq);
 	return rv;
 }
 
@@ -824,23 +454,10 @@
 mpc52xx_ata_remove(struct of_device *op)
 {
 	struct mpc52xx_ata_priv *priv;
-	int task_irq;
 
-	/* Deregister the ATA interface */
 	priv = mpc52xx_ata_remove_one(&op->dev);
-
-	/* Clean up DMA */
-	task_irq = bcom_get_task_irq(priv->dmatsk);
-	irq_dispose_mapping(task_irq);
-	bcom_ata_release(priv->dmatsk);
 	irq_dispose_mapping(priv->ata_irq);
 
-	/* Clear up IO allocations */
-	devm_iounmap(&op->dev, priv->ata_regs);
-	devm_release_mem_region(&op->dev, priv->ata_regs_pa,
-				sizeof(*priv->ata_regs));
-	devm_kfree(&op->dev, priv);
-
 	return 0;
 }
 
@@ -864,7 +481,7 @@
 
 	rv = mpc52xx_ata_hw_init(priv);
 	if (rv) {
-		dev_err(host->dev, "error initializing hardware\n");
+		printk(KERN_ERR DRV_NAME ": Error during HW init\n");
 		return rv;
 	}
 
@@ -877,8 +494,10 @@
 
 
 static struct of_device_id mpc52xx_ata_of_match[] = {
-	{ .compatible = "fsl,mpc5200-ata", },
-	{ .compatible = "mpc5200-ata", },
+	{
+		.type		= "ata",
+		.compatible	= "mpc5200-ata",
+	},
 	{},
 };
 
@@ -924,4 +543,5 @@
 MODULE_DESCRIPTION("Freescale MPC52xx IDE/ATA libata driver");
 MODULE_LICENSE("GPL");
 MODULE_DEVICE_TABLE(of, mpc52xx_ata_of_match);
+MODULE_VERSION(DRV_VERSION);
 
diff -Nur linux-sh4/drivers/ata.org/pata_mpiix.c linux-sh4/drivers/ata/pata_mpiix.c
--- linux-sh4/drivers/ata.org/pata_mpiix.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_mpiix.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  * pata_mpiix.c 	- Intel MPIIX PATA for new ATA layer
  *			  (C) 2005-2006 Red Hat Inc
- *			  Alan Cox <alan@lxorguk.ukuu.org.uk>
+ *			  Alan Cox <alan@redhat.com>
  *
  * The MPIIX is different enough to the PIIX4 and friends that we give it
  * a separate driver. The old ide/pci code handles this by just not tuning
@@ -35,7 +35,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "pata_mpiix"
-#define DRV_VERSION "0.7.7"
+#define DRV_VERSION "0.7.6"
 
 enum {
 	IDETIM = 0x6C,		/* IDE control register */
@@ -46,16 +46,29 @@
 	SECONDARY = (1 << 14)
 };
 
-static int mpiix_pre_reset(struct ata_link *link, unsigned long deadline)
+static int mpiix_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	static const struct pci_bits mpiix_enable_bits = { 0x6D, 1, 0x80, 0x80 };
 
 	if (!pci_test_config_bits(pdev, &mpiix_enable_bits))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	mpiix_error_handler		-	probe reset
+ *	@ap: ATA port
+ *
+ *	Perform the ATA probe and bus reset sequence plus specific handling
+ *	for this hardware. The MPIIX has the enable bits in a different place
+ *	to PIIX4 and friends. As a pure PIO device it has no cable detect
+ */
+
+static void mpiix_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, mpiix_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -69,8 +82,8 @@
  *
  *	This would get very ugly because we can only program timing for one
  *	device at a time, the other gets PIO0. Fortunately libata calls
- *	our qc_issue command before a command is issued so we can flip the
- *	timings back and forth to reduce the pain.
+ *	our qc_issue_prot command before a command is issued so we can
+ *	flip the timings back and forth to reduce the pain.
  */
 
 static void mpiix_set_piomode(struct ata_port *ap, struct ata_device *adev)
@@ -110,17 +123,17 @@
 }
 
 /**
- *	mpiix_qc_issue		-	command issue
+ *	mpiix_qc_issue_prot	-	command issue
  *	@qc: command pending
  *
  *	Called when the libata layer is about to issue a command. We wrap
  *	this interface so that we can load the correct ATA timings if
- *	necessary. Our logic also clears TIME0/TIME1 for the other device so
+ *	neccessary. Our logic also clears TIME0/TIME1 for the other device so
  *	that, even if we get this wrong, cycles to the other device will
  *	be made PIO0.
  */
 
-static unsigned int mpiix_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int mpiix_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
@@ -133,20 +146,52 @@
 	if (adev->pio_mode && adev != ap->private_data)
 		mpiix_set_piomode(ap, adev);
 
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 static struct scsi_host_template mpiix_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations mpiix_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.qc_issue	= mpiix_qc_issue,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= mpiix_set_piomode,
-	.prereset	= mpiix_pre_reset,
-	.sff_data_xfer	= ata_sff_data_xfer32,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= mpiix_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= mpiix_qc_issue_prot,
+	.data_xfer	= ata_data_xfer,
+
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int mpiix_init_one(struct pci_dev *dev, const struct pci_device_id *id)
@@ -157,7 +202,7 @@
 	struct ata_port *ap;
 	void __iomem *cmd_addr, *ctl_addr;
 	u16 idetim;
-	int cmd, ctl, irq;
+	int irq;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &dev->dev, "version " DRV_VERSION "\n");
@@ -165,7 +210,6 @@
 	host = ata_host_alloc(&dev->dev, 1);
 	if (!host)
 		return -ENOMEM;
-	ap = host->ports[0];
 
 	/* MPIIX has many functions which can be turned on or off according
 	   to other devices present. Make sure IDE is enabled before we try
@@ -177,30 +221,27 @@
 
 	/* See if it's primary or secondary channel... */
 	if (!(idetim & SECONDARY)) {
-		cmd = 0x1F0;
-		ctl = 0x3F6;
 		irq = 14;
+		cmd_addr = devm_ioport_map(&dev->dev, 0x1F0, 8);
+		ctl_addr = devm_ioport_map(&dev->dev, 0x3F6, 1);
 	} else {
-		cmd = 0x170;
-		ctl = 0x376;
 		irq = 15;
+		cmd_addr = devm_ioport_map(&dev->dev, 0x170, 8);
+		ctl_addr = devm_ioport_map(&dev->dev, 0x376, 1);
 	}
 
-	cmd_addr = devm_ioport_map(&dev->dev, cmd, 8);
-	ctl_addr = devm_ioport_map(&dev->dev, ctl, 1);
 	if (!cmd_addr || !ctl_addr)
 		return -ENOMEM;
 
-	ata_port_desc(ap, "cmd 0x%x ctl 0x%x", cmd, ctl);
-
 	/* We do our own plumbing to avoid leaking special cases for whacko
 	   ancient hardware into the core code. There are two issues to
 	   worry about.  #1 The chip is a bridge so if in legacy mode and
 	   without BARs set fools the setup.  #2 If you pci_disable_device
 	   the MPIIX your box goes castors up */
 
+	ap = host->ports[0];
 	ap->ops = &mpiix_port_ops;
-	ap->pio_mask = ATA_PIO4;
+	ap->pio_mask = 0x1F;
 	ap->flags |= ATA_FLAG_SLAVE_POSS;
 
 	ap->ioaddr.cmd_addr = cmd_addr;
@@ -208,10 +249,10 @@
 	ap->ioaddr.altstatus_addr = ctl_addr;
 
 	/* Let libata fill in the port details */
-	ata_sff_std_ports(&ap->ioaddr);
+	ata_std_ports(&ap->ioaddr);
 
 	/* activate host */
-	return ata_host_activate(host, irq, ata_sff_interrupt, IRQF_SHARED,
+	return ata_host_activate(host, irq, ata_interrupt, IRQF_SHARED,
 				 &mpiix_sht);
 }
 
diff -Nur linux-sh4/drivers/ata.org/pata_netcell.c linux-sh4/drivers/ata/pata_netcell.c
--- linux-sh4/drivers/ata.org/pata_netcell.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_netcell.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  *    pata_netcell.c - Netcell PATA driver
  *
- *	(c) 2006 Red Hat
+ *	(c) 2006 Red Hat  <alan@redhat.com>
  */
 
 #include <linux/kernel.h>
@@ -20,24 +20,58 @@
 
 /* No PIO or DMA methods needed for this device */
 
-static unsigned int netcell_read_id(struct ata_device *adev,
-					struct ata_taskfile *tf, u16 *id)
-{
-	unsigned int err_mask = ata_do_dev_read_id(adev, tf, id);
-	/* Firmware forgets to mark words 85-87 valid */
-	if (err_mask == 0)
-		id[ATA_ID_CSF_DEFAULT] |= 0x4000;
-	return err_mask;
-}
-
 static struct scsi_host_template netcell_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	/* Use standard CHS mapping rules */
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations netcell_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= ata_cable_80wire,
-	.read_id	= netcell_read_id,
+static const struct ata_port_operations netcell_ops = {
+	.port_disable		= ata_port_disable,
+
+	/* Task file is PCI ATA format, use helpers */
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ata_cable_80wire,
+
+	/* BMDMA handling is PCI ATA format, use helpers */
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	/* IRQ-related hooks */
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	/* Generic PATA PCI ATA helpers */
+	.port_start		= ata_port_start,
 };
 
 
@@ -59,30 +93,26 @@
 {
 	static int printed_version;
 	static const struct ata_port_info info = {
+		.sht		= &netcell_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
 		/* Actually we don't really care about these as the
 		   firmware deals with it */
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask 	= ATA_UDMA5, /* UDMA 133 */
 		.port_ops	= &netcell_ops,
 	};
 	const struct ata_port_info *port_info[] = { &info, NULL };
-	int rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "version " DRV_VERSION "\n");
 
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
 	/* Any chip specific setup/optimisation/messages here */
-	ata_pci_bmdma_clear_simplex(pdev);
+	ata_pci_clear_simplex(pdev);
 
 	/* And let the library code do the work */
-	return ata_pci_sff_init_one(pdev, port_info, &netcell_sht, NULL);
+	return ata_pci_init_one(pdev, port_info);
 }
 
 static const struct pci_device_id netcell_pci_tbl[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_ninja32.c linux-sh4/drivers/ata/pata_ninja32.c
--- linux-sh4/drivers/ata.org/pata_ninja32.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_ninja32.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,210 +0,0 @@
-/*
- * pata_ninja32.c 	- Ninja32 PATA for new ATA layer
- *			  (C) 2007 Red Hat Inc
- *
- * Note: The controller like many controllers has shared timings for
- * PIO and DMA. We thus flip to the DMA timings in dma_start and flip back
- * in the dma_stop function. Thus we actually don't need a set_dmamode
- * method as the PIO method is always called and will set the right PIO
- * timing parameters.
- *
- * The Ninja32 Cardbus is not a generic SFF controller. Instead it is
- * laid out as follows off BAR 0. This is based upon Mark Lord's delkin
- * driver and the extensive analysis done by the BSD developers, notably
- * ITOH Yasufumi.
- *
- *	Base + 0x00 IRQ Status
- *	Base + 0x01 IRQ control
- *	Base + 0x02 Chipset control
- *	Base + 0x03 Unknown
- *	Base + 0x04 VDMA and reset control + wait bits
- *	Base + 0x08 BMIMBA
- *	Base + 0x0C DMA Length
- *	Base + 0x10 Taskfile
- *	Base + 0x18 BMDMA Status ?
- *	Base + 0x1C
- *	Base + 0x1D Bus master control
- *		bit 0 = enable
- *		bit 1 = 0 write/1 read
- *		bit 2 = 1 sgtable
- *		bit 3 = go
- *		bit 4-6 wait bits
- *		bit 7 = done
- *	Base + 0x1E AltStatus
- *	Base + 0x1F timing register
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <linux/delay.h>
-#include <scsi/scsi_host.h>
-#include <linux/libata.h>
-
-#define DRV_NAME "pata_ninja32"
-#define DRV_VERSION "0.1.5"
-
-
-/**
- *	ninja32_set_piomode	-	set initial PIO mode data
- *	@ap: ATA interface
- *	@adev: ATA device
- *
- *	Called to do the PIO mode setup. Our timing registers are shared
- *	but we want to set the PIO timing by default.
- */
-
-static void ninja32_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	static u16 pio_timing[5] = {
-		0xd6, 0x85, 0x44, 0x33, 0x13
-	};
-	iowrite8(pio_timing[adev->pio_mode - XFER_PIO_0],
-		 ap->ioaddr.bmdma_addr + 0x1f);
-	ap->private_data = adev;
-}
-
-
-static void ninja32_dev_select(struct ata_port *ap, unsigned int device)
-{
-	struct ata_device *adev = &ap->link.device[device];
-	if (ap->private_data != adev) {
-		iowrite8(0xd6, ap->ioaddr.bmdma_addr + 0x1f);
-		ata_sff_dev_select(ap, device);
-		ninja32_set_piomode(ap, adev);
-	}
-}
-
-static struct scsi_host_template ninja32_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations ninja32_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.sff_dev_select = ninja32_dev_select,
-	.cable_detect	= ata_cable_40wire,
-	.set_piomode	= ninja32_set_piomode,
-	.sff_data_xfer	= ata_sff_data_xfer32
-};
-
-static void ninja32_program(void __iomem *base)
-{
-	iowrite8(0x05, base + 0x01);	/* Enable interrupt lines */
-	iowrite8(0xBE, base + 0x02);	/* Burst, ?? setup */
-	iowrite8(0x01, base + 0x03);	/* Unknown */
-	iowrite8(0x20, base + 0x04);	/* WAIT0 */
-	iowrite8(0x8f, base + 0x05);	/* Unknown */
-	iowrite8(0xa4, base + 0x1c);	/* Unknown */
-	iowrite8(0x83, base + 0x1d);	/* BMDMA control: WAIT0 */
-}
-
-static int ninja32_init_one(struct pci_dev *dev, const struct pci_device_id *id)
-{
-	struct ata_host *host;
-	struct ata_port *ap;
-	void __iomem *base;
-	int rc;
-
-	host = ata_host_alloc(&dev->dev, 1);
-	if (!host)
-		return -ENOMEM;
-	ap = host->ports[0];
-
-	/* Set up the PCI device */
-	rc = pcim_enable_device(dev);
-	if (rc)
-		return rc;
-	rc = pcim_iomap_regions(dev, 1 << 0, DRV_NAME);
-	if (rc == -EBUSY)
-		pcim_pin_device(dev);
-	if (rc)
-		return rc;
-
-	host->iomap = pcim_iomap_table(dev);
-	rc = pci_set_dma_mask(dev, ATA_DMA_MASK);
-	if (rc)
-		return rc;
-	rc = pci_set_consistent_dma_mask(dev, ATA_DMA_MASK);
-	if (rc)
-		return rc;
-	pci_set_master(dev);
-
-	/* Set up the register mappings. We use the I/O mapping as only the
-	   older chips also have MMIO on BAR 1 */
-	base = host->iomap[0];
-	if (!base)
-		return -ENOMEM;
-	ap->ops = &ninja32_port_ops;
-	ap->pio_mask = ATA_PIO4;
-	ap->flags |= ATA_FLAG_SLAVE_POSS;
-
-	ap->ioaddr.cmd_addr = base + 0x10;
-	ap->ioaddr.ctl_addr = base + 0x1E;
-	ap->ioaddr.altstatus_addr = base + 0x1E;
-	ap->ioaddr.bmdma_addr = base;
-	ata_sff_std_ports(&ap->ioaddr);
-	ap->pflags = ATA_PFLAG_PIO32 | ATA_PFLAG_PIO32CHANGE;
-
-	ninja32_program(base);
-	/* FIXME: Should we disable them at remove ? */
-	return ata_host_activate(host, dev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &ninja32_sht);
-}
-
-#ifdef CONFIG_PM
-
-static int ninja32_reinit_one(struct pci_dev *pdev)
-{
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
-	ninja32_program(host->iomap[0]);
-	ata_host_resume(host);
-	return 0;			
-}
-#endif
-
-static const struct pci_device_id ninja32[] = {
-	{ 0x10FC, 0x0003, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0 },
-	{ 0x1145, 0x8008, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0 },
-	{ 0x1145, 0xf008, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0 },
-	{ 0x1145, 0xf021, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0 },
-	{ 0x1145, 0xf024, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0 },
-	{ 0x1145, 0xf02C, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0 },
-	{ },
-};
-
-static struct pci_driver ninja32_pci_driver = {
-	.name 		= DRV_NAME,
-	.id_table	= ninja32,
-	.probe 		= ninja32_init_one,
-	.remove		= ata_pci_remove_one,
-#ifdef CONFIG_PM
-	.suspend	= ata_pci_device_suspend,
-	.resume		= ninja32_reinit_one,
-#endif
-};
-
-static int __init ninja32_init(void)
-{
-	return pci_register_driver(&ninja32_pci_driver);
-}
-
-static void __exit ninja32_exit(void)
-{
-	pci_unregister_driver(&ninja32_pci_driver);
-}
-
-MODULE_AUTHOR("Alan Cox");
-MODULE_DESCRIPTION("low-level driver for Ninja32 ATA");
-MODULE_LICENSE("GPL");
-MODULE_DEVICE_TABLE(pci, ninja32);
-MODULE_VERSION(DRV_VERSION);
-
-module_init(ninja32_init);
-module_exit(ninja32_exit);
diff -Nur linux-sh4/drivers/ata.org/pata_ns87410.c linux-sh4/drivers/ata/pata_ns87410.c
--- linux-sh4/drivers/ata.org/pata_ns87410.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_ns87410.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_ns87410.c 	- National Semiconductor 87410 PATA for new ATA layer
  *			  (C) 2006 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  *  This program is free software; you can redistribute it and/or modify
  *  it under the terms of the GNU General Public License as published by
@@ -31,15 +32,14 @@
 
 /**
  *	ns87410_pre_reset		-	probe begin
- *	@link: ATA link
+ *	@ap: ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	Check enabled ports
  */
 
-static int ns87410_pre_reset(struct ata_link *link, unsigned long deadline)
+static int ns87410_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	static const struct pci_bits ns87410_enable_bits[] = {
 		{ 0x43, 1, 0x08, 0x08 },
@@ -49,7 +49,21 @@
 	if (!pci_test_config_bits(pdev, &ns87410_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	ns87410_error_handler		-	probe reset
+ *	@ap: ATA port
+ *
+ *	Perform the ATA probe and bus reset sequence plus specific handling
+ *	for this hardware. The MPIIX has the enable bits in a different place
+ *	to PIIX4 and friends. As a pure PIO device it has no cable detect
+ */
+
+static void ns87410_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, ns87410_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -90,9 +104,9 @@
 		return;
 	}
 
-	at.active = clamp_val(at.active, 2, 16) - 2;
-	at.setup = clamp_val(at.setup, 1, 4) - 1;
-	at.recover = clamp_val(at.recover, 1, 12) - 1;
+	at.active = FIT(at.active, 2, 16) - 2;
+	at.setup = FIT(at.setup, 1, 4) - 1;
+	at.recover = FIT(at.recover, 1, 12) - 1;
 
 	idetcr = (at.setup << 6) | (recoverbits[at.recover] << 3) | activebits[at.active];
 
@@ -104,15 +118,15 @@
 }
 
 /**
- *	ns87410_qc_issue	-	command issue
+ *	ns87410_qc_issue_prot	-	command issue
  *	@qc: command pending
  *
  *	Called when the libata layer is about to issue a command. We wrap
  *	this interface so that we can load the correct ATA timings if
- *	necessary.
+ *	neccessary.
  */
 
-static unsigned int ns87410_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int ns87410_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
@@ -125,30 +139,66 @@
 	if (adev->pio_mode && adev != ap->private_data)
 		ns87410_set_piomode(ap, adev);
 
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 static struct scsi_host_template ns87410_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations ns87410_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.qc_issue	= ns87410_qc_issue,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= ns87410_set_piomode,
-	.prereset	= ns87410_pre_reset,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ns87410_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ns87410_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int ns87410_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &ns87410_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO3,
+		.pio_mask = 0x0F,
 		.port_ops = &ns87410_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
-	return ata_pci_sff_init_one(dev, ppi, &ns87410_sht, NULL);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id ns87410[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_ns87415.c linux-sh4/drivers/ata/pata_ns87415.c
--- linux-sh4/drivers/ata.org/pata_ns87415.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_ns87415.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,415 +0,0 @@
-/*
- *    pata_ns87415.c - NS87415 (non PARISC) PATA
- *
- *	(C) 2005 Red Hat <alan@lxorguk.ukuu.org.uk>
- *
- *    This is a fairly generic MWDMA controller. It has some limitations
- *    as it requires timing reloads on PIO/DMA transitions but it is otherwise
- *    fairly well designed.
- *
- *    This driver assumes the firmware has left the chip in a valid ST506
- *    compliant state, either legacy IRQ 14/15 or native INTA shared. You
- *    may need to add platform code if your system fails to do this.
- *
- *    The same cell appears in the 87560 controller used by some PARISC
- *    systems. This has its own special mountain of errata.
- *
- *    TODO:
- *	Test PARISC SuperIO
- *	Get someone to test on SPARC
- *	Implement lazy pio/dma switching for better performance
- *	8bit shared timing.
- *	See if we need to kill the FIFO for ATAPI
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <linux/delay.h>
-#include <linux/device.h>
-#include <scsi/scsi_host.h>
-#include <linux/libata.h>
-#include <linux/ata.h>
-
-#define DRV_NAME	"pata_ns87415"
-#define DRV_VERSION	"0.0.1"
-
-/**
- *	ns87415_set_mode - Initialize host controller mode timings
- *	@ap: Port whose timings we are configuring
- *	@adev: Device whose timings we are configuring
- *	@mode: Mode to set
- *
- *	Program the mode registers for this controller, channel and
- *	device. Because the chip is quite an old design we have to do this
- *	for PIO/DMA switches.
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static void ns87415_set_mode(struct ata_port *ap, struct ata_device *adev, u8 mode)
-{
-	struct pci_dev *dev	= to_pci_dev(ap->host->dev);
-	int unit		= 2 * ap->port_no + adev->devno;
-	int timing		= 0x44 + 2 * unit;
-	unsigned long T		= 1000000000 / 33333;	/* PCI clocks */
-	struct ata_timing t;
-	u16 clocking;
-	u8 iordy;
-	u8 status;
-
-	/* Timing register format is 17 - low nybble read timing with
-	   the high nybble being 16 - x for recovery time in PCI clocks */
-
-	ata_timing_compute(adev, adev->pio_mode, &t, T, 0);
-
-	clocking = 17 - clamp_val(t.active, 2, 17);
-	clocking |= (16 - clamp_val(t.recover, 1, 16)) << 4;
- 	/* Use the same timing for read and write bytes */
-	clocking |= (clocking << 8);
-	pci_write_config_word(dev, timing, clocking);
-
-	/* Set the IORDY enable versus DMA enable on or off properly */
-	pci_read_config_byte(dev, 0x42, &iordy);
-	iordy &= ~(1 << (4 + unit));
-	if (mode >= XFER_MW_DMA_0 || !ata_pio_need_iordy(adev))
-		iordy |= (1 << (4 + unit));
-
-	/* Paranoia: We shouldn't ever get here with busy write buffers
-	   but if so wait */
-
-	pci_read_config_byte(dev, 0x43, &status);
-	while (status & 0x03) {
-		udelay(1);
-		pci_read_config_byte(dev, 0x43, &status);
-	}
-	/* Flip the IORDY/DMA bits now we are sure the write buffers are
-	   clear */
-	pci_write_config_byte(dev, 0x42, iordy);
-
-	/* TODO: Set byte 54 command timing to the best 8bit
-	   mode shared by all four devices */
-}
-
-/**
- *	ns87415_set_piomode - Initialize host controller PATA PIO timings
- *	@ap: Port whose timings we are configuring
- *	@adev: Device to program
- *
- *	Set PIO mode for device, in host controller PCI config space.
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static void ns87415_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	ns87415_set_mode(ap, adev, adev->pio_mode);
-}
-
-/**
- *	ns87415_bmdma_setup		-	Set up DMA
- *	@qc: Command block
- *
- *	Set up for bus masterng DMA. We have to do this ourselves
- *	rather than use the helper due to a chip erratum
- */
-
-static void ns87415_bmdma_setup(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	unsigned int rw = (qc->tf.flags & ATA_TFLAG_WRITE);
-	u8 dmactl;
-
-	/* load PRD table addr. */
-	mb();	/* make sure PRD table writes are visible to controller */
-	iowrite32(ap->prd_dma, ap->ioaddr.bmdma_addr + ATA_DMA_TABLE_OFS);
-
-	/* specify data direction, triple-check start bit is clear */
-	dmactl = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
-	dmactl &= ~(ATA_DMA_WR | ATA_DMA_START);
-	/* Due to an erratum we need to write these bits to the wrong
-	   place - which does save us an I/O bizarrely */
-	dmactl |= ATA_DMA_INTR | ATA_DMA_ERR;
-	if (!rw)
-		dmactl |= ATA_DMA_WR;
-	iowrite8(dmactl, ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
-	/* issue r/w command */
-	ap->ops->sff_exec_command(ap, &qc->tf);
-}
-
-/**
- *	ns87415_bmdma_start		-	Begin DMA transfer
- *	@qc: Command block
- *
- *	Switch the timings for the chip and set up for a DMA transfer
- *	before the DMA burst begins.
- *
- *	FIXME: We should do lazy switching on bmdma_start versus
- *	ata_pio_data_xfer for better performance.
- */
-
-static void ns87415_bmdma_start(struct ata_queued_cmd *qc)
-{
-	ns87415_set_mode(qc->ap, qc->dev, qc->dev->dma_mode);
-	ata_bmdma_start(qc);
-}
-
-/**
- *	ns87415_bmdma_stop		-	End DMA transfer
- *	@qc: Command block
- *
- *	End DMA mode and switch the controller back into PIO mode
- */
-
-static void ns87415_bmdma_stop(struct ata_queued_cmd *qc)
-{
-	ata_bmdma_stop(qc);
-	ns87415_set_mode(qc->ap, qc->dev, qc->dev->pio_mode);
-}
-
-/**
- *	ns87415_irq_clear		-	Clear interrupt
- *	@ap: Channel to clear
- *
- *	Erratum: Due to a chip bug regisers 02 and 0A bit 1 and 2 (the
- *	error bits) are reset by writing to register 00 or 08.
- */
-
-static void ns87415_irq_clear(struct ata_port *ap)
-{
-	void __iomem *mmio = ap->ioaddr.bmdma_addr;
-
-	if (!mmio)
-		return;
-	iowrite8((ioread8(mmio + ATA_DMA_CMD) | ATA_DMA_INTR | ATA_DMA_ERR),
-			mmio + ATA_DMA_CMD);
-}
-
-/**
- *	ns87415_check_atapi_dma		-	ATAPI DMA filter
- *	@qc: Command block
- *
- *	Disable ATAPI DMA (for now). We may be able to do DMA if we
- *	kill the prefetching. This isn't clear.
- */
-
-static int ns87415_check_atapi_dma(struct ata_queued_cmd *qc)
-{
-	return -EOPNOTSUPP;
-}
-
-#if defined(CONFIG_SUPERIO)
-
-/* SUPERIO 87560 is a PoS chip that NatSem denies exists.
- * Unfortunately, it's built-in on all Astro-based PA-RISC workstations
- * which use the integrated NS87514 cell for CD-ROM support.
- * i.e we have to support for CD-ROM installs.
- * See drivers/parisc/superio.c for more gory details.
- *
- * Workarounds taken from drivers/ide/pci/ns87415.c
- */
-
-#include <asm/superio.h>
-
-#define SUPERIO_IDE_MAX_RETRIES 25
-
-/**
- *	ns87560_read_buggy	-	workaround buggy Super I/O chip
- *	@port: Port to read
- *
- *	Work around chipset problems in the 87560 SuperIO chip
- */
-
-static u8 ns87560_read_buggy(void __iomem *port)
-{
-	u8 tmp;
-	int retries = SUPERIO_IDE_MAX_RETRIES;
-	do {
-		tmp = ioread8(port);
-		if (tmp != 0)
-			return tmp;
-		udelay(50);
-	} while(retries-- > 0);
-	return tmp;
-}
-
-/**
- *	ns87560_check_status
- *	@ap: channel to check
- *
- *	Return the status of the channel working around the
- *	87560 flaws.
- */
-
-static u8 ns87560_check_status(struct ata_port *ap)
-{
-	return ns87560_read_buggy(ap->ioaddr.status_addr);
-}
-
-/**
- *	ns87560_tf_read - input device's ATA taskfile shadow registers
- *	@ap: Port from which input is read
- *	@tf: ATA taskfile register set for storing input
- *
- *	Reads ATA taskfile registers for currently-selected device
- *	into @tf. Work around the 87560 bugs.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-void ns87560_tf_read(struct ata_port *ap, struct ata_taskfile *tf)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-
-	tf->command = ns87560_check_status(ap);
-	tf->feature = ioread8(ioaddr->error_addr);
-	tf->nsect = ioread8(ioaddr->nsect_addr);
-	tf->lbal = ioread8(ioaddr->lbal_addr);
-	tf->lbam = ioread8(ioaddr->lbam_addr);
-	tf->lbah = ioread8(ioaddr->lbah_addr);
-	tf->device = ns87560_read_buggy(ioaddr->device_addr);
-
-	if (tf->flags & ATA_TFLAG_LBA48) {
-		iowrite8(tf->ctl | ATA_HOB, ioaddr->ctl_addr);
-		tf->hob_feature = ioread8(ioaddr->error_addr);
-		tf->hob_nsect = ioread8(ioaddr->nsect_addr);
-		tf->hob_lbal = ioread8(ioaddr->lbal_addr);
-		tf->hob_lbam = ioread8(ioaddr->lbam_addr);
-		tf->hob_lbah = ioread8(ioaddr->lbah_addr);
-		iowrite8(tf->ctl, ioaddr->ctl_addr);
-		ap->last_ctl = tf->ctl;
-	}
-}
-
-/**
- *	ns87560_bmdma_status
- *	@ap: channel to check
- *
- *	Return the DMA status of the channel working around the
- *	87560 flaws.
- */
-
-static u8 ns87560_bmdma_status(struct ata_port *ap)
-{
-	return ns87560_read_buggy(ap->ioaddr.bmdma_addr + ATA_DMA_STATUS);
-}
-#endif		/* 87560 SuperIO Support */
-
-static struct ata_port_operations ns87415_pata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-
-	.check_atapi_dma	= ns87415_check_atapi_dma,
-	.bmdma_setup		= ns87415_bmdma_setup,
-	.bmdma_start		= ns87415_bmdma_start,
-	.bmdma_stop		= ns87415_bmdma_stop,
-	.sff_irq_clear		= ns87415_irq_clear,
-
-	.cable_detect		= ata_cable_40wire,
-	.set_piomode		= ns87415_set_piomode,
-};
-
-#if defined(CONFIG_SUPERIO)
-static struct ata_port_operations ns87560_pata_ops = {
-	.inherits		= &ns87415_pata_ops,
-	.sff_tf_read		= ns87560_tf_read,
-	.sff_check_status	= ns87560_check_status,
-	.bmdma_status		= ns87560_bmdma_status,
-};
-#endif
-
-static struct scsi_host_template ns87415_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-
-/**
- *	ns87415_init_one - Register 87415 ATA PCI device with kernel services
- *	@pdev: PCI device to register
- *	@ent: Entry in ns87415_pci_tbl matching with @pdev
- *
- *	Called from kernel PCI layer.  We probe for combined mode (sigh),
- *	and then hand over control to libata, for it to do the rest.
- *
- *	LOCKING:
- *	Inherited from PCI layer (may sleep).
- *
- *	RETURNS:
- *	Zero on success, or -ERRNO value.
- */
-
-static int ns87415_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
-{
-	static int printed_version;
-	static const struct ata_port_info info = {
-		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.port_ops	= &ns87415_pata_ops,
-	};
-	const struct ata_port_info *ppi[] = { &info, NULL };
-	int rc;
-#if defined(CONFIG_SUPERIO)
-	static const struct ata_port_info info87560 = {
-		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.port_ops	= &ns87560_pata_ops,
-	};
-
-	if (PCI_SLOT(pdev->devfn) == 0x0E)
-		ppi[0] = &info87560;
-#endif
-	if (!printed_version++)
-		dev_printk(KERN_DEBUG, &pdev->dev,
-			   "version " DRV_VERSION "\n");
-
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
-	/* Select 512 byte sectors */
-	pci_write_config_byte(pdev, 0x55, 0xEE);
-	/* Select PIO0 8bit clocking */
-	pci_write_config_byte(pdev, 0x54, 0xB7);
-	return ata_pci_sff_init_one(pdev, ppi, &ns87415_sht, NULL);
-}
-
-static const struct pci_device_id ns87415_pci_tbl[] = {
-	{ PCI_VDEVICE(NS, PCI_DEVICE_ID_NS_87415), },
-
-	{ }	/* terminate list */
-};
-
-static struct pci_driver ns87415_pci_driver = {
-	.name			= DRV_NAME,
-	.id_table		= ns87415_pci_tbl,
-	.probe			= ns87415_init_one,
-	.remove			= ata_pci_remove_one,
-#ifdef CONFIG_PM
-	.suspend		= ata_pci_device_suspend,
-	.resume			= ata_pci_device_resume,
-#endif
-};
-
-static int __init ns87415_init(void)
-{
-	return pci_register_driver(&ns87415_pci_driver);
-}
-
-static void __exit ns87415_exit(void)
-{
-	pci_unregister_driver(&ns87415_pci_driver);
-}
-
-module_init(ns87415_init);
-module_exit(ns87415_exit);
-
-MODULE_AUTHOR("Alan Cox");
-MODULE_DESCRIPTION("ATA low-level driver for NS87415 controllers");
-MODULE_LICENSE("GPL");
-MODULE_DEVICE_TABLE(pci, ns87415_pci_tbl);
-MODULE_VERSION(DRV_VERSION);
diff -Nur linux-sh4/drivers/ata.org/pata_octeon_cf.c linux-sh4/drivers/ata/pata_octeon_cf.c
--- linux-sh4/drivers/ata.org/pata_octeon_cf.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_octeon_cf.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,966 +0,0 @@
-/*
- * Driver for the Octeon bootbus compact flash.
- *
- * This file is subject to the terms and conditions of the GNU General Public
- * License.  See the file "COPYING" in the main directory of this archive
- * for more details.
- *
- * Copyright (C) 2005 - 2009 Cavium Networks
- * Copyright (C) 2008 Wind River Systems
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/libata.h>
-#include <linux/irq.h>
-#include <linux/platform_device.h>
-#include <linux/workqueue.h>
-#include <scsi/scsi_host.h>
-
-#include <asm/octeon/octeon.h>
-
-/*
- * The Octeon bootbus compact flash interface is connected in at least
- * 3 different configurations on various evaluation boards:
- *
- * -- 8  bits no irq, no DMA
- * -- 16 bits no irq, no DMA
- * -- 16 bits True IDE mode with DMA, but no irq.
- *
- * In the last case the DMA engine can generate an interrupt when the
- * transfer is complete.  For the first two cases only PIO is supported.
- *
- */
-
-#define DRV_NAME	"pata_octeon_cf"
-#define DRV_VERSION	"2.1"
-
-
-struct octeon_cf_port {
-	struct workqueue_struct *wq;
-	struct delayed_work delayed_finish;
-	struct ata_port *ap;
-	int dma_finished;
-};
-
-static struct scsi_host_template octeon_cf_sht = {
-	ATA_PIO_SHT(DRV_NAME),
-};
-
-/**
- * Convert nanosecond based time to setting used in the
- * boot bus timing register, based on timing multiple
- */
-static unsigned int ns_to_tim_reg(unsigned int tim_mult, unsigned int nsecs)
-{
-	unsigned int val;
-
-	/*
-	 * Compute # of eclock periods to get desired duration in
-	 * nanoseconds.
-	 */
-	val = DIV_ROUND_UP(nsecs * (octeon_get_clock_rate() / 1000000),
-			  1000 * tim_mult);
-
-	return val;
-}
-
-static void octeon_cf_set_boot_reg_cfg(int cs)
-{
-	union cvmx_mio_boot_reg_cfgx reg_cfg;
-	reg_cfg.u64 = cvmx_read_csr(CVMX_MIO_BOOT_REG_CFGX(cs));
-	reg_cfg.s.dmack = 0;	/* Don't assert DMACK on access */
-	reg_cfg.s.tim_mult = 2;	/* Timing mutiplier 2x */
-	reg_cfg.s.rd_dly = 0;	/* Sample on falling edge of BOOT_OE */
-	reg_cfg.s.sam = 0;	/* Don't combine write and output enable */
-	reg_cfg.s.we_ext = 0;	/* No write enable extension */
-	reg_cfg.s.oe_ext = 0;	/* No read enable extension */
-	reg_cfg.s.en = 1;	/* Enable this region */
-	reg_cfg.s.orbit = 0;	/* Don't combine with previous region */
-	reg_cfg.s.ale = 0;	/* Don't do address multiplexing */
-	cvmx_write_csr(CVMX_MIO_BOOT_REG_CFGX(cs), reg_cfg.u64);
-}
-
-/**
- * Called after libata determines the needed PIO mode. This
- * function programs the Octeon bootbus regions to support the
- * timing requirements of the PIO mode.
- *
- * @ap:     ATA port information
- * @dev:    ATA device
- */
-static void octeon_cf_set_piomode(struct ata_port *ap, struct ata_device *dev)
-{
-	struct octeon_cf_data *ocd = ap->dev->platform_data;
-	union cvmx_mio_boot_reg_timx reg_tim;
-	int cs = ocd->base_region;
-	int T;
-	struct ata_timing timing;
-
-	int use_iordy;
-	int trh;
-	int pause;
-	/* These names are timing parameters from the ATA spec */
-	int t1;
-	int t2;
-	int t2i;
-
-	T = (int)(2000000000000LL / octeon_get_clock_rate());
-
-	if (ata_timing_compute(dev, dev->pio_mode, &timing, T, T))
-		BUG();
-
-	t1 = timing.setup;
-	if (t1)
-		t1--;
-	t2 = timing.active;
-	if (t2)
-		t2--;
-	t2i = timing.act8b;
-	if (t2i)
-		t2i--;
-
-	trh = ns_to_tim_reg(2, 20);
-	if (trh)
-		trh--;
-
-	pause = timing.cycle - timing.active - timing.setup - trh;
-	if (pause)
-		pause--;
-
-	octeon_cf_set_boot_reg_cfg(cs);
-	if (ocd->dma_engine >= 0)
-		/* True IDE mode, program both chip selects.  */
-		octeon_cf_set_boot_reg_cfg(cs + 1);
-
-
-	use_iordy = ata_pio_need_iordy(dev);
-
-	reg_tim.u64 = cvmx_read_csr(CVMX_MIO_BOOT_REG_TIMX(cs));
-	/* Disable page mode */
-	reg_tim.s.pagem = 0;
-	/* Enable dynamic timing */
-	reg_tim.s.waitm = use_iordy;
-	/* Pages are disabled */
-	reg_tim.s.pages = 0;
-	/* We don't use multiplexed address mode */
-	reg_tim.s.ale = 0;
-	/* Not used */
-	reg_tim.s.page = 0;
-	/* Time after IORDY to coninue to assert the data */
-	reg_tim.s.wait = 0;
-	/* Time to wait to complete the cycle. */
-	reg_tim.s.pause = pause;
-	/* How long to hold after a write to de-assert CE. */
-	reg_tim.s.wr_hld = trh;
-	/* How long to wait after a read to de-assert CE. */
-	reg_tim.s.rd_hld = trh;
-	/* How long write enable is asserted */
-	reg_tim.s.we = t2;
-	/* How long read enable is asserted */
-	reg_tim.s.oe = t2;
-	/* Time after CE that read/write starts */
-	reg_tim.s.ce = ns_to_tim_reg(2, 5);
-	/* Time before CE that address is valid */
-	reg_tim.s.adr = 0;
-
-	/* Program the bootbus region timing for the data port chip select. */
-	cvmx_write_csr(CVMX_MIO_BOOT_REG_TIMX(cs), reg_tim.u64);
-	if (ocd->dma_engine >= 0)
-		/* True IDE mode, program both chip selects.  */
-		cvmx_write_csr(CVMX_MIO_BOOT_REG_TIMX(cs + 1), reg_tim.u64);
-}
-
-static void octeon_cf_set_dmamode(struct ata_port *ap, struct ata_device *dev)
-{
-	struct octeon_cf_data *ocd = dev->link->ap->dev->platform_data;
-	union cvmx_mio_boot_dma_timx dma_tim;
-	unsigned int oe_a;
-	unsigned int oe_n;
-	unsigned int dma_ackh;
-	unsigned int dma_arq;
-	unsigned int pause;
-	unsigned int T0, Tkr, Td;
-	unsigned int tim_mult;
-
-	const struct ata_timing *timing;
-
-	timing = ata_timing_find_mode(dev->dma_mode);
-	T0	= timing->cycle;
-	Td	= timing->active;
-	Tkr	= timing->recover;
-	dma_ackh = timing->dmack_hold;
-
-	dma_tim.u64 = 0;
-	/* dma_tim.s.tim_mult = 0 --> 4x */
-	tim_mult = 4;
-
-	/* not spec'ed, value in eclocks, not affected by tim_mult */
-	dma_arq = 8;
-	pause = 25 - dma_arq * 1000 /
-		(octeon_get_clock_rate() / 1000000); /* Tz */
-
-	oe_a = Td;
-	/* Tkr from cf spec, lengthened to meet T0 */
-	oe_n = max(T0 - oe_a, Tkr);
-
-	dma_tim.s.dmack_pi = 1;
-
-	dma_tim.s.oe_n = ns_to_tim_reg(tim_mult, oe_n);
-	dma_tim.s.oe_a = ns_to_tim_reg(tim_mult, oe_a);
-
-	/*
-	 * This is tI, C.F. spec. says 0, but Sony CF card requires
-	 * more, we use 20 nS.
-	 */
-	dma_tim.s.dmack_s = ns_to_tim_reg(tim_mult, 20);
-	dma_tim.s.dmack_h = ns_to_tim_reg(tim_mult, dma_ackh);
-
-	dma_tim.s.dmarq = dma_arq;
-	dma_tim.s.pause = ns_to_tim_reg(tim_mult, pause);
-
-	dma_tim.s.rd_dly = 0;	/* Sample right on edge */
-
-	/*  writes only */
-	dma_tim.s.we_n = ns_to_tim_reg(tim_mult, oe_n);
-	dma_tim.s.we_a = ns_to_tim_reg(tim_mult, oe_a);
-
-	pr_debug("ns to ticks (mult %d) of %d is: %d\n", tim_mult, 60,
-		 ns_to_tim_reg(tim_mult, 60));
-	pr_debug("oe_n: %d, oe_a: %d, dmack_s: %d, dmack_h: "
-		 "%d, dmarq: %d, pause: %d\n",
-		 dma_tim.s.oe_n, dma_tim.s.oe_a, dma_tim.s.dmack_s,
-		 dma_tim.s.dmack_h, dma_tim.s.dmarq, dma_tim.s.pause);
-
-	cvmx_write_csr(CVMX_MIO_BOOT_DMA_TIMX(ocd->dma_engine),
-		       dma_tim.u64);
-
-}
-
-/**
- * Handle an 8 bit I/O request.
- *
- * @dev:        Device to access
- * @buffer:     Data buffer
- * @buflen:     Length of the buffer.
- * @rw:         True to write.
- */
-static unsigned int octeon_cf_data_xfer8(struct ata_device *dev,
-					 unsigned char *buffer,
-					 unsigned int buflen,
-					 int rw)
-{
-	struct ata_port *ap		= dev->link->ap;
-	void __iomem *data_addr		= ap->ioaddr.data_addr;
-	unsigned long words;
-	int count;
-
-	words = buflen;
-	if (rw) {
-		count = 16;
-		while (words--) {
-			iowrite8(*buffer, data_addr);
-			buffer++;
-			/*
-			 * Every 16 writes do a read so the bootbus
-			 * FIFO doesn't fill up.
-			 */
-			if (--count == 0) {
-				ioread8(ap->ioaddr.altstatus_addr);
-				count = 16;
-			}
-		}
-	} else {
-		ioread8_rep(data_addr, buffer, words);
-	}
-	return buflen;
-}
-
-/**
- * Handle a 16 bit I/O request.
- *
- * @dev:        Device to access
- * @buffer:     Data buffer
- * @buflen:     Length of the buffer.
- * @rw:         True to write.
- */
-static unsigned int octeon_cf_data_xfer16(struct ata_device *dev,
-					  unsigned char *buffer,
-					  unsigned int buflen,
-					  int rw)
-{
-	struct ata_port *ap		= dev->link->ap;
-	void __iomem *data_addr		= ap->ioaddr.data_addr;
-	unsigned long words;
-	int count;
-
-	words = buflen / 2;
-	if (rw) {
-		count = 16;
-		while (words--) {
-			iowrite16(*(uint16_t *)buffer, data_addr);
-			buffer += sizeof(uint16_t);
-			/*
-			 * Every 16 writes do a read so the bootbus
-			 * FIFO doesn't fill up.
-			 */
-			if (--count == 0) {
-				ioread8(ap->ioaddr.altstatus_addr);
-				count = 16;
-			}
-		}
-	} else {
-		while (words--) {
-			*(uint16_t *)buffer = ioread16(data_addr);
-			buffer += sizeof(uint16_t);
-		}
-	}
-	/* Transfer trailing 1 byte, if any. */
-	if (unlikely(buflen & 0x01)) {
-		__le16 align_buf[1] = { 0 };
-
-		if (rw == READ) {
-			align_buf[0] = cpu_to_le16(ioread16(data_addr));
-			memcpy(buffer, align_buf, 1);
-		} else {
-			memcpy(align_buf, buffer, 1);
-			iowrite16(le16_to_cpu(align_buf[0]), data_addr);
-		}
-		words++;
-	}
-	return buflen;
-}
-
-/**
- * Read the taskfile for 16bit non-True IDE only.
- */
-static void octeon_cf_tf_read16(struct ata_port *ap, struct ata_taskfile *tf)
-{
-	u16 blob;
-	/* The base of the registers is at ioaddr.data_addr. */
-	void __iomem *base = ap->ioaddr.data_addr;
-
-	blob = __raw_readw(base + 0xc);
-	tf->feature = blob >> 8;
-
-	blob = __raw_readw(base + 2);
-	tf->nsect = blob & 0xff;
-	tf->lbal = blob >> 8;
-
-	blob = __raw_readw(base + 4);
-	tf->lbam = blob & 0xff;
-	tf->lbah = blob >> 8;
-
-	blob = __raw_readw(base + 6);
-	tf->device = blob & 0xff;
-	tf->command = blob >> 8;
-
-	if (tf->flags & ATA_TFLAG_LBA48) {
-		if (likely(ap->ioaddr.ctl_addr)) {
-			iowrite8(tf->ctl | ATA_HOB, ap->ioaddr.ctl_addr);
-
-			blob = __raw_readw(base + 0xc);
-			tf->hob_feature = blob >> 8;
-
-			blob = __raw_readw(base + 2);
-			tf->hob_nsect = blob & 0xff;
-			tf->hob_lbal = blob >> 8;
-
-			blob = __raw_readw(base + 4);
-			tf->hob_lbam = blob & 0xff;
-			tf->hob_lbah = blob >> 8;
-
-			iowrite8(tf->ctl, ap->ioaddr.ctl_addr);
-			ap->last_ctl = tf->ctl;
-		} else {
-			WARN_ON(1);
-		}
-	}
-}
-
-static u8 octeon_cf_check_status16(struct ata_port *ap)
-{
-	u16 blob;
-	void __iomem *base = ap->ioaddr.data_addr;
-
-	blob = __raw_readw(base + 6);
-	return blob >> 8;
-}
-
-static int octeon_cf_softreset16(struct ata_link *link, unsigned int *classes,
-				 unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	void __iomem *base = ap->ioaddr.data_addr;
-	int rc;
-	u8 err;
-
-	DPRINTK("about to softreset\n");
-	__raw_writew(ap->ctl, base + 0xe);
-	udelay(20);
-	__raw_writew(ap->ctl | ATA_SRST, base + 0xe);
-	udelay(20);
-	__raw_writew(ap->ctl, base + 0xe);
-
-	rc = ata_sff_wait_after_reset(link, 1, deadline);
-	if (rc) {
-		ata_link_printk(link, KERN_ERR, "SRST failed (errno=%d)\n", rc);
-		return rc;
-	}
-
-	/* determine by signature whether we have ATA or ATAPI devices */
-	classes[0] = ata_sff_dev_classify(&link->device[0], 1, &err);
-	DPRINTK("EXIT, classes[0]=%u [1]=%u\n", classes[0], classes[1]);
-	return 0;
-}
-
-/**
- * Load the taskfile for 16bit non-True IDE only.  The device_addr is
- * not loaded, we do this as part of octeon_cf_exec_command16.
- */
-static void octeon_cf_tf_load16(struct ata_port *ap,
-				const struct ata_taskfile *tf)
-{
-	unsigned int is_addr = tf->flags & ATA_TFLAG_ISADDR;
-	/* The base of the registers is at ioaddr.data_addr. */
-	void __iomem *base = ap->ioaddr.data_addr;
-
-	if (tf->ctl != ap->last_ctl) {
-		iowrite8(tf->ctl, ap->ioaddr.ctl_addr);
-		ap->last_ctl = tf->ctl;
-		ata_wait_idle(ap);
-	}
-	if (is_addr && (tf->flags & ATA_TFLAG_LBA48)) {
-		__raw_writew(tf->hob_feature << 8, base + 0xc);
-		__raw_writew(tf->hob_nsect | tf->hob_lbal << 8, base + 2);
-		__raw_writew(tf->hob_lbam | tf->hob_lbah << 8, base + 4);
-		VPRINTK("hob: feat 0x%X nsect 0x%X, lba 0x%X 0x%X 0x%X\n",
-			tf->hob_feature,
-			tf->hob_nsect,
-			tf->hob_lbal,
-			tf->hob_lbam,
-			tf->hob_lbah);
-	}
-	if (is_addr) {
-		__raw_writew(tf->feature << 8, base + 0xc);
-		__raw_writew(tf->nsect | tf->lbal << 8, base + 2);
-		__raw_writew(tf->lbam | tf->lbah << 8, base + 4);
-		VPRINTK("feat 0x%X nsect 0x%X, lba 0x%X 0x%X 0x%X\n",
-			tf->feature,
-			tf->nsect,
-			tf->lbal,
-			tf->lbam,
-			tf->lbah);
-	}
-	ata_wait_idle(ap);
-}
-
-
-static void octeon_cf_dev_select(struct ata_port *ap, unsigned int device)
-{
-/*  There is only one device, do nothing. */
-	return;
-}
-
-/*
- * Issue ATA command to host controller.  The device_addr is also sent
- * as it must be written in a combined write with the command.
- */
-static void octeon_cf_exec_command16(struct ata_port *ap,
-				const struct ata_taskfile *tf)
-{
-	/* The base of the registers is at ioaddr.data_addr. */
-	void __iomem *base = ap->ioaddr.data_addr;
-	u16 blob;
-
-	if (tf->flags & ATA_TFLAG_DEVICE) {
-		VPRINTK("device 0x%X\n", tf->device);
-		blob = tf->device;
-	} else {
-		blob = 0;
-	}
-
-	DPRINTK("ata%u: cmd 0x%X\n", ap->print_id, tf->command);
-	blob |= (tf->command << 8);
-	__raw_writew(blob, base + 6);
-
-
-	ata_wait_idle(ap);
-}
-
-static u8 octeon_cf_irq_on(struct ata_port *ap)
-{
-	return 0;
-}
-
-static void octeon_cf_irq_clear(struct ata_port *ap)
-{
-	return;
-}
-
-static void octeon_cf_dma_setup(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct octeon_cf_port *cf_port;
-
-	cf_port = ap->private_data;
-	DPRINTK("ENTER\n");
-	/* issue r/w command */
-	qc->cursg = qc->sg;
-	cf_port->dma_finished = 0;
-	ap->ops->sff_exec_command(ap, &qc->tf);
-	DPRINTK("EXIT\n");
-}
-
-/**
- * Start a DMA transfer that was already setup
- *
- * @qc:     Information about the DMA
- */
-static void octeon_cf_dma_start(struct ata_queued_cmd *qc)
-{
-	struct octeon_cf_data *ocd = qc->ap->dev->platform_data;
-	union cvmx_mio_boot_dma_cfgx mio_boot_dma_cfg;
-	union cvmx_mio_boot_dma_intx mio_boot_dma_int;
-	struct scatterlist *sg;
-
-	VPRINTK("%d scatterlists\n", qc->n_elem);
-
-	/* Get the scatter list entry we need to DMA into */
-	sg = qc->cursg;
-	BUG_ON(!sg);
-
-	/*
-	 * Clear the DMA complete status.
-	 */
-	mio_boot_dma_int.u64 = 0;
-	mio_boot_dma_int.s.done = 1;
-	cvmx_write_csr(CVMX_MIO_BOOT_DMA_INTX(ocd->dma_engine),
-		       mio_boot_dma_int.u64);
-
-	/* Enable the interrupt.  */
-	cvmx_write_csr(CVMX_MIO_BOOT_DMA_INT_ENX(ocd->dma_engine),
-		       mio_boot_dma_int.u64);
-
-	/* Set the direction of the DMA */
-	mio_boot_dma_cfg.u64 = 0;
-	mio_boot_dma_cfg.s.en = 1;
-	mio_boot_dma_cfg.s.rw = ((qc->tf.flags & ATA_TFLAG_WRITE) != 0);
-
-	/*
-	 * Don't stop the DMA if the device deasserts DMARQ. Many
-	 * compact flashes deassert DMARQ for a short time between
-	 * sectors. Instead of stopping and restarting the DMA, we'll
-	 * let the hardware do it. If the DMA is really stopped early
-	 * due to an error condition, a later timeout will force us to
-	 * stop.
-	 */
-	mio_boot_dma_cfg.s.clr = 0;
-
-	/* Size is specified in 16bit words and minus one notation */
-	mio_boot_dma_cfg.s.size = sg_dma_len(sg) / 2 - 1;
-
-	/* We need to swap the high and low bytes of every 16 bits */
-	mio_boot_dma_cfg.s.swap8 = 1;
-
-	mio_boot_dma_cfg.s.adr = sg_dma_address(sg);
-
-	VPRINTK("%s %d bytes address=%p\n",
-		(mio_boot_dma_cfg.s.rw) ? "write" : "read", sg->length,
-		(void *)(unsigned long)mio_boot_dma_cfg.s.adr);
-
-	cvmx_write_csr(CVMX_MIO_BOOT_DMA_CFGX(ocd->dma_engine),
-		       mio_boot_dma_cfg.u64);
-}
-
-/**
- *
- *	LOCKING:
- *	spin_lock_irqsave(host lock)
- *
- */
-static unsigned int octeon_cf_dma_finished(struct ata_port *ap,
-					struct ata_queued_cmd *qc)
-{
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	struct octeon_cf_data *ocd = ap->dev->platform_data;
-	union cvmx_mio_boot_dma_cfgx dma_cfg;
-	union cvmx_mio_boot_dma_intx dma_int;
-	struct octeon_cf_port *cf_port;
-	u8 status;
-
-	VPRINTK("ata%u: protocol %d task_state %d\n",
-		ap->print_id, qc->tf.protocol, ap->hsm_task_state);
-
-
-	if (ap->hsm_task_state != HSM_ST_LAST)
-		return 0;
-
-	cf_port = ap->private_data;
-
-	dma_cfg.u64 = cvmx_read_csr(CVMX_MIO_BOOT_DMA_CFGX(ocd->dma_engine));
-	if (dma_cfg.s.size != 0xfffff) {
-		/* Error, the transfer was not complete.  */
-		qc->err_mask |= AC_ERR_HOST_BUS;
-		ap->hsm_task_state = HSM_ST_ERR;
-	}
-
-	/* Stop and clear the dma engine.  */
-	dma_cfg.u64 = 0;
-	dma_cfg.s.size = -1;
-	cvmx_write_csr(CVMX_MIO_BOOT_DMA_CFGX(ocd->dma_engine), dma_cfg.u64);
-
-	/* Disable the interrupt.  */
-	dma_int.u64 = 0;
-	cvmx_write_csr(CVMX_MIO_BOOT_DMA_INT_ENX(ocd->dma_engine), dma_int.u64);
-
-	/* Clear the DMA complete status */
-	dma_int.s.done = 1;
-	cvmx_write_csr(CVMX_MIO_BOOT_DMA_INTX(ocd->dma_engine), dma_int.u64);
-
-	status = ap->ops->sff_check_status(ap);
-
-	ata_sff_hsm_move(ap, qc, status, 0);
-
-	if (unlikely(qc->err_mask) && (qc->tf.protocol == ATA_PROT_DMA))
-		ata_ehi_push_desc(ehi, "DMA stat 0x%x", status);
-
-	return 1;
-}
-
-/*
- * Check if any queued commands have more DMAs, if so start the next
- * transfer, else do end of transfer handling.
- */
-static irqreturn_t octeon_cf_interrupt(int irq, void *dev_instance)
-{
-	struct ata_host *host = dev_instance;
-	struct octeon_cf_port *cf_port;
-	int i;
-	unsigned int handled = 0;
-	unsigned long flags;
-
-	spin_lock_irqsave(&host->lock, flags);
-
-	DPRINTK("ENTER\n");
-	for (i = 0; i < host->n_ports; i++) {
-		u8 status;
-		struct ata_port *ap;
-		struct ata_queued_cmd *qc;
-		union cvmx_mio_boot_dma_intx dma_int;
-		union cvmx_mio_boot_dma_cfgx dma_cfg;
-		struct octeon_cf_data *ocd;
-
-		ap = host->ports[i];
-		ocd = ap->dev->platform_data;
-
-		if (ap->flags & ATA_FLAG_DISABLED)
-			continue;
-
-		ocd = ap->dev->platform_data;
-		cf_port = ap->private_data;
-		dma_int.u64 =
-			cvmx_read_csr(CVMX_MIO_BOOT_DMA_INTX(ocd->dma_engine));
-		dma_cfg.u64 =
-			cvmx_read_csr(CVMX_MIO_BOOT_DMA_CFGX(ocd->dma_engine));
-
-		qc = ata_qc_from_tag(ap, ap->link.active_tag);
-
-		if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)) &&
-		    (qc->flags & ATA_QCFLAG_ACTIVE)) {
-			if (dma_int.s.done && !dma_cfg.s.en) {
-				if (!sg_is_last(qc->cursg)) {
-					qc->cursg = sg_next(qc->cursg);
-					handled = 1;
-					octeon_cf_dma_start(qc);
-					continue;
-				} else {
-					cf_port->dma_finished = 1;
-				}
-			}
-			if (!cf_port->dma_finished)
-				continue;
-			status = ioread8(ap->ioaddr.altstatus_addr);
-			if (status & (ATA_BUSY | ATA_DRQ)) {
-				/*
-				 * We are busy, try to handle it
-				 * later.  This is the DMA finished
-				 * interrupt, and it could take a
-				 * little while for the card to be
-				 * ready for more commands.
-				 */
-				/* Clear DMA irq. */
-				dma_int.u64 = 0;
-				dma_int.s.done = 1;
-				cvmx_write_csr(CVMX_MIO_BOOT_DMA_INTX(ocd->dma_engine),
-					       dma_int.u64);
-
-				queue_delayed_work(cf_port->wq,
-						   &cf_port->delayed_finish, 1);
-				handled = 1;
-			} else {
-				handled |= octeon_cf_dma_finished(ap, qc);
-			}
-		}
-	}
-	spin_unlock_irqrestore(&host->lock, flags);
-	DPRINTK("EXIT\n");
-	return IRQ_RETVAL(handled);
-}
-
-static void octeon_cf_delayed_finish(struct work_struct *work)
-{
-	struct octeon_cf_port *cf_port = container_of(work,
-						      struct octeon_cf_port,
-						      delayed_finish.work);
-	struct ata_port *ap = cf_port->ap;
-	struct ata_host *host = ap->host;
-	struct ata_queued_cmd *qc;
-	unsigned long flags;
-	u8 status;
-
-	spin_lock_irqsave(&host->lock, flags);
-
-	/*
-	 * If the port is not waiting for completion, it must have
-	 * handled it previously.  The hsm_task_state is
-	 * protected by host->lock.
-	 */
-	if (ap->hsm_task_state != HSM_ST_LAST || !cf_port->dma_finished)
-		goto out;
-
-	status = ioread8(ap->ioaddr.altstatus_addr);
-	if (status & (ATA_BUSY | ATA_DRQ)) {
-		/* Still busy, try again. */
-		queue_delayed_work(cf_port->wq,
-				   &cf_port->delayed_finish, 1);
-		goto out;
-	}
-	qc = ata_qc_from_tag(ap, ap->link.active_tag);
-	if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)) &&
-	    (qc->flags & ATA_QCFLAG_ACTIVE))
-		octeon_cf_dma_finished(ap, qc);
-out:
-	spin_unlock_irqrestore(&host->lock, flags);
-}
-
-static void octeon_cf_dev_config(struct ata_device *dev)
-{
-	/*
-	 * A maximum of 2^20 - 1 16 bit transfers are possible with
-	 * the bootbus DMA.  So we need to throttle max_sectors to
-	 * (2^12 - 1 == 4095) to assure that this can never happen.
-	 */
-	dev->max_sectors = min(dev->max_sectors, 4095U);
-}
-
-/*
- * Trap if driver tries to do standard bmdma commands.  They are not
- * supported.
- */
-static void unreachable_qc(struct ata_queued_cmd *qc)
-{
-	BUG();
-}
-
-static u8 unreachable_port(struct ata_port *ap)
-{
-	BUG();
-}
-
-/*
- * We don't do ATAPI DMA so return 0.
- */
-static int octeon_cf_check_atapi_dma(struct ata_queued_cmd *qc)
-{
-	return 0;
-}
-
-static unsigned int octeon_cf_qc_issue(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-
-	switch (qc->tf.protocol) {
-	case ATA_PROT_DMA:
-		WARN_ON(qc->tf.flags & ATA_TFLAG_POLLING);
-
-		ap->ops->sff_tf_load(ap, &qc->tf);  /* load tf registers */
-		octeon_cf_dma_setup(qc);	    /* set up dma */
-		octeon_cf_dma_start(qc);	    /* initiate dma */
-		ap->hsm_task_state = HSM_ST_LAST;
-		break;
-
-	case ATAPI_PROT_DMA:
-		dev_err(ap->dev, "Error, ATAPI not supported\n");
-		BUG();
-
-	default:
-		return ata_sff_qc_issue(qc);
-	}
-
-	return 0;
-}
-
-static struct ata_port_operations octeon_cf_ops = {
-	.inherits		= &ata_sff_port_ops,
-	.check_atapi_dma	= octeon_cf_check_atapi_dma,
-	.qc_prep		= ata_noop_qc_prep,
-	.qc_issue		= octeon_cf_qc_issue,
-	.sff_dev_select		= octeon_cf_dev_select,
-	.sff_irq_on		= octeon_cf_irq_on,
-	.sff_irq_clear		= octeon_cf_irq_clear,
-	.bmdma_setup		= unreachable_qc,
-	.bmdma_start		= unreachable_qc,
-	.bmdma_stop		= unreachable_qc,
-	.bmdma_status		= unreachable_port,
-	.cable_detect		= ata_cable_40wire,
-	.set_piomode		= octeon_cf_set_piomode,
-	.set_dmamode		= octeon_cf_set_dmamode,
-	.dev_config		= octeon_cf_dev_config,
-};
-
-static int __devinit octeon_cf_probe(struct platform_device *pdev)
-{
-	struct resource *res_cs0, *res_cs1;
-
-	void __iomem *cs0;
-	void __iomem *cs1 = NULL;
-	struct ata_host *host;
-	struct ata_port *ap;
-	struct octeon_cf_data *ocd;
-	int irq = 0;
-	irq_handler_t irq_handler = NULL;
-	void __iomem *base;
-	struct octeon_cf_port *cf_port;
-
-	res_cs0 = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-
-	if (!res_cs0)
-		return -EINVAL;
-
-	ocd = pdev->dev.platform_data;
-
-	cs0 = devm_ioremap_nocache(&pdev->dev, res_cs0->start,
-				   resource_size(res_cs0));
-
-	if (!cs0)
-		return -ENOMEM;
-
-	/* Determine from availability of DMA if True IDE mode or not */
-	if (ocd->dma_engine >= 0) {
-		res_cs1 = platform_get_resource(pdev, IORESOURCE_MEM, 1);
-		if (!res_cs1)
-			return -EINVAL;
-
-		cs1 = devm_ioremap_nocache(&pdev->dev, res_cs1->start,
-					   res_cs0->end - res_cs1->start + 1);
-
-		if (!cs1)
-			return -ENOMEM;
-	}
-
-	cf_port = kzalloc(sizeof(*cf_port), GFP_KERNEL);
-	if (!cf_port)
-		return -ENOMEM;
-
-	/* allocate host */
-	host = ata_host_alloc(&pdev->dev, 1);
-	if (!host)
-		goto free_cf_port;
-
-	ap = host->ports[0];
-	ap->private_data = cf_port;
-	cf_port->ap = ap;
-	ap->ops = &octeon_cf_ops;
-	ap->pio_mask = ATA_PIO6;
-	ap->flags |= ATA_FLAG_MMIO | ATA_FLAG_NO_LEGACY
-		  | ATA_FLAG_NO_ATAPI | ATA_FLAG_PIO_POLLING;
-
-	base = cs0 + ocd->base_region_bias;
-	if (!ocd->is16bit) {
-		ap->ioaddr.cmd_addr	= base;
-		ata_sff_std_ports(&ap->ioaddr);
-
-		ap->ioaddr.altstatus_addr = base + 0xe;
-		ap->ioaddr.ctl_addr	= base + 0xe;
-		octeon_cf_ops.sff_data_xfer = octeon_cf_data_xfer8;
-	} else if (cs1) {
-		/* Presence of cs1 indicates True IDE mode.  */
-		ap->ioaddr.cmd_addr	= base + (ATA_REG_CMD << 1) + 1;
-		ap->ioaddr.data_addr	= base + (ATA_REG_DATA << 1);
-		ap->ioaddr.error_addr	= base + (ATA_REG_ERR << 1) + 1;
-		ap->ioaddr.feature_addr	= base + (ATA_REG_FEATURE << 1) + 1;
-		ap->ioaddr.nsect_addr	= base + (ATA_REG_NSECT << 1) + 1;
-		ap->ioaddr.lbal_addr	= base + (ATA_REG_LBAL << 1) + 1;
-		ap->ioaddr.lbam_addr	= base + (ATA_REG_LBAM << 1) + 1;
-		ap->ioaddr.lbah_addr	= base + (ATA_REG_LBAH << 1) + 1;
-		ap->ioaddr.device_addr	= base + (ATA_REG_DEVICE << 1) + 1;
-		ap->ioaddr.status_addr	= base + (ATA_REG_STATUS << 1) + 1;
-		ap->ioaddr.command_addr	= base + (ATA_REG_CMD << 1) + 1;
-		ap->ioaddr.altstatus_addr = cs1 + (6 << 1) + 1;
-		ap->ioaddr.ctl_addr	= cs1 + (6 << 1) + 1;
-		octeon_cf_ops.sff_data_xfer = octeon_cf_data_xfer16;
-
-		ap->mwdma_mask	= ATA_MWDMA4;
-		irq = platform_get_irq(pdev, 0);
-		irq_handler = octeon_cf_interrupt;
-
-		/* True IDE mode needs delayed work to poll for not-busy.  */
-		cf_port->wq = create_singlethread_workqueue(DRV_NAME);
-		if (!cf_port->wq)
-			goto free_cf_port;
-		INIT_DELAYED_WORK(&cf_port->delayed_finish,
-				  octeon_cf_delayed_finish);
-
-	} else {
-		/* 16 bit but not True IDE */
-		octeon_cf_ops.sff_data_xfer	= octeon_cf_data_xfer16;
-		octeon_cf_ops.softreset		= octeon_cf_softreset16;
-		octeon_cf_ops.sff_check_status	= octeon_cf_check_status16;
-		octeon_cf_ops.sff_tf_read	= octeon_cf_tf_read16;
-		octeon_cf_ops.sff_tf_load	= octeon_cf_tf_load16;
-		octeon_cf_ops.sff_exec_command	= octeon_cf_exec_command16;
-
-		ap->ioaddr.data_addr	= base + ATA_REG_DATA;
-		ap->ioaddr.nsect_addr	= base + ATA_REG_NSECT;
-		ap->ioaddr.lbal_addr	= base + ATA_REG_LBAL;
-		ap->ioaddr.ctl_addr	= base + 0xe;
-		ap->ioaddr.altstatus_addr = base + 0xe;
-	}
-
-	ata_port_desc(ap, "cmd %p ctl %p", base, ap->ioaddr.ctl_addr);
-
-
-	dev_info(&pdev->dev, "version " DRV_VERSION" %d bit%s.\n",
-		 (ocd->is16bit) ? 16 : 8,
-		 (cs1) ? ", True IDE" : "");
-
-
-	return ata_host_activate(host, irq, irq_handler, 0, &octeon_cf_sht);
-
-free_cf_port:
-	kfree(cf_port);
-	return -ENOMEM;
-}
-
-static struct platform_driver octeon_cf_driver = {
-	.probe		= octeon_cf_probe,
-	.driver		= {
-		.name	= DRV_NAME,
-		.owner	= THIS_MODULE,
-	},
-};
-
-static int __init octeon_cf_init(void)
-{
-	return platform_driver_register(&octeon_cf_driver);
-}
-
-
-MODULE_AUTHOR("David Daney <ddaney@caviumnetworks.com>");
-MODULE_DESCRIPTION("low-level driver for Cavium OCTEON Compact Flash PATA");
-MODULE_LICENSE("GPL");
-MODULE_VERSION(DRV_VERSION);
-MODULE_ALIAS("platform:" DRV_NAME);
-
-module_init(octeon_cf_init);
diff -Nur linux-sh4/drivers/ata.org/pata_of_platform.c linux-sh4/drivers/ata/pata_of_platform.c
--- linux-sh4/drivers/ata.org/pata_of_platform.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_of_platform.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,114 +0,0 @@
-/*
- * OF-platform PATA driver
- *
- * Copyright (c) 2007  MontaVista Software, Inc.
- *                     Anton Vorontsov <avorontsov@ru.mvista.com>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License (Version 2) as
- * published by the Free Software Foundation.
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/of_platform.h>
-#include <linux/ata_platform.h>
-
-static int __devinit pata_of_platform_probe(struct of_device *ofdev,
-					    const struct of_device_id *match)
-{
-	int ret;
-	struct device_node *dn = ofdev->node;
-	struct resource io_res;
-	struct resource ctl_res;
-	struct resource irq_res;
-	unsigned int reg_shift = 0;
-	int pio_mode = 0;
-	int pio_mask;
-	const u32 *prop;
-
-	ret = of_address_to_resource(dn, 0, &io_res);
-	if (ret) {
-		dev_err(&ofdev->dev, "can't get IO address from "
-			"device tree\n");
-		return -EINVAL;
-	}
-
-	if (of_device_is_compatible(dn, "electra-ide")) {
-		/* Altstatus is really at offset 0x3f6 from the primary window
-		 * on electra-ide. Adjust ctl_res and io_res accordingly.
-		 */
-		ctl_res = io_res;
-		ctl_res.start = ctl_res.start+0x3f6;
-		io_res.end = ctl_res.start-1;
-	} else {
-		ret = of_address_to_resource(dn, 1, &ctl_res);
-		if (ret) {
-			dev_err(&ofdev->dev, "can't get CTL address from "
-				"device tree\n");
-			return -EINVAL;
-		}
-	}
-
-	ret = of_irq_to_resource(dn, 0, &irq_res);
-	if (ret == NO_IRQ)
-		irq_res.start = irq_res.end = 0;
-	else
-		irq_res.flags = 0;
-
-	prop = of_get_property(dn, "reg-shift", NULL);
-	if (prop)
-		reg_shift = *prop;
-
-	prop = of_get_property(dn, "pio-mode", NULL);
-	if (prop) {
-		pio_mode = *prop;
-		if (pio_mode > 6) {
-			dev_err(&ofdev->dev, "invalid pio-mode\n");
-			return -EINVAL;
-		}
-	} else {
-		dev_info(&ofdev->dev, "pio-mode unspecified, assuming PIO0\n");
-	}
-
-	pio_mask = 1 << pio_mode;
-	pio_mask |= (1 << pio_mode) - 1;
-
-	return __pata_platform_probe(&ofdev->dev, &io_res, &ctl_res, &irq_res,
-				     reg_shift, pio_mask);
-}
-
-static int __devexit pata_of_platform_remove(struct of_device *ofdev)
-{
-	return __pata_platform_remove(&ofdev->dev);
-}
-
-static struct of_device_id pata_of_platform_match[] = {
-	{ .compatible = "ata-generic", },
-	{ .compatible = "electra-ide", },
-	{},
-};
-MODULE_DEVICE_TABLE(of, pata_of_platform_match);
-
-static struct of_platform_driver pata_of_platform_driver = {
-	.name		= "pata_of_platform",
-	.match_table	= pata_of_platform_match,
-	.probe		= pata_of_platform_probe,
-	.remove		= __devexit_p(pata_of_platform_remove),
-};
-
-static int __init pata_of_platform_init(void)
-{
-	return of_register_platform_driver(&pata_of_platform_driver);
-}
-module_init(pata_of_platform_init);
-
-static void __exit pata_of_platform_exit(void)
-{
-	of_unregister_platform_driver(&pata_of_platform_driver);
-}
-module_exit(pata_of_platform_exit);
-
-MODULE_DESCRIPTION("OF-platform PATA driver");
-MODULE_AUTHOR("Anton Vorontsov <avorontsov@ru.mvista.com>");
-MODULE_LICENSE("GPL");
diff -Nur linux-sh4/drivers/ata.org/pata_oldpiix.c linux-sh4/drivers/ata/pata_oldpiix.c
--- linux-sh4/drivers/ata.org/pata_oldpiix.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_oldpiix.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  *    pata_oldpiix.c - Intel PATA/SATA controllers
  *
- *	(C) 2005 Red Hat
+ *	(C) 2005 Red Hat <alan@redhat.com>
  *
  *    Some parts based on ata_piix.c by Jeff Garzik and others.
  *
@@ -29,15 +29,14 @@
 
 /**
  *	oldpiix_pre_reset		-	probe begin
- *	@link: ATA link
+ *	@ap: ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	Set up cable type and use generic probe init
  */
 
-static int oldpiix_pre_reset(struct ata_link *link, unsigned long deadline)
+static int oldpiix_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	static const struct pci_bits oldpiix_enable_bits[] = {
 		{ 0x41U, 1U, 0x80UL, 0x80UL },	/* port 0 */
@@ -47,7 +46,21 @@
 	if (!pci_test_config_bits(pdev, &oldpiix_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	oldpiix_pata_error_handler - Probe specified port on PATA host controller
+ *	@ap: Port to probe
+ *	@classes:
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void oldpiix_pata_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, oldpiix_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -116,6 +129,7 @@
  *	oldpiix_set_dmamode - Initialize host controller PATA DMA timings
  *	@ap: Port whose timings we are configuring
  *	@adev: Device to program
+ *	@isich: True if the device is an ICH and has IOCFG registers
  *
  *	Set MWDMA mode for device, in host controller PCI config space.
  *
@@ -180,41 +194,80 @@
 }
 
 /**
- *	oldpiix_qc_issue	-	command issue
+ *	oldpiix_qc_issue_prot	-	command issue
  *	@qc: command pending
  *
  *	Called when the libata layer is about to issue a command. We wrap
  *	this interface so that we can load the correct ATA timings if
- *	necessary. Our logic also clears TIME0/TIME1 for the other device so
+ *	neccessary. Our logic also clears TIME0/TIME1 for the other device so
  *	that, even if we get this wrong, cycles to the other device will
  *	be made PIO0.
  */
 
-static unsigned int oldpiix_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int oldpiix_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
 
 	if (adev != ap->private_data) {
 		oldpiix_set_piomode(ap, adev);
-		if (ata_dma_enabled(adev))
+		if (adev->dma_mode)
 			oldpiix_set_dmamode(ap, adev);
 	}
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 
 static struct scsi_host_template oldpiix_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations oldpiix_pata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.qc_issue		= oldpiix_qc_issue,
-	.cable_detect		= ata_cable_40wire,
+static const struct ata_port_operations oldpiix_pata_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= oldpiix_set_piomode,
 	.set_dmamode		= oldpiix_set_dmamode,
-	.prereset		= oldpiix_pre_reset,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= oldpiix_pata_error_handler,
+	.post_internal_cmd 	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ata_cable_40wire,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= oldpiix_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 
@@ -237,9 +290,10 @@
 {
 	static int printed_version;
 	static const struct ata_port_info info = {
+		.sht		= &oldpiix_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma1-2 */
 		.port_ops	= &oldpiix_pata_ops,
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
@@ -248,7 +302,7 @@
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "version " DRV_VERSION "\n");
 
-	return ata_pci_sff_init_one(pdev, ppi, &oldpiix_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id oldpiix_pci_tbl[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_opti.c linux-sh4/drivers/ata/pata_opti.c
--- linux-sh4/drivers/ata.org/pata_opti.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_opti.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_opti.c 	- ATI PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  * Based on
  *  linux/drivers/ide/pci/opti621.c		Version 0.7	Sept 10, 2002
@@ -45,15 +46,14 @@
 
 /**
  *	opti_pre_reset		-	probe begin
- *	@link: ATA link
+ *	@ap: ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	Set up cable type and use generic probe init
  */
 
-static int opti_pre_reset(struct ata_link *link, unsigned long deadline)
+static int opti_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	static const struct pci_bits opti_enable_bits[] = {
 		{ 0x45, 1, 0x80, 0x00 },
@@ -63,7 +63,22 @@
 	if (!pci_test_config_bits(pdev, &opti_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	opti_probe_reset		-	probe reset
+ *	@ap: ATA port
+ *
+ *	Perform the ATA probe and bus reset sequence plus specific handling
+ *	for this hardware. The Opti needs little handling - we have no UDMA66
+ *	capability that needs cable detection. All we must do is check the port
+ *	is enabled.
+ */
+
+static void opti_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, opti_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -149,21 +164,62 @@
 }
 
 static struct scsi_host_template opti_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations opti_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= opti_set_piomode,
-	.prereset	= opti_pre_reset,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= opti_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int opti_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &opti_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
+		.pio_mask = 0x1f,
 		.port_ops = &opti_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
@@ -172,7 +228,7 @@
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &dev->dev, "version " DRV_VERSION "\n");
 
-	return ata_pci_sff_init_one(dev, ppi, &opti_sht, NULL);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id opti[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_optidma.c linux-sh4/drivers/ata/pata_optidma.c
--- linux-sh4/drivers/ata.org/pata_optidma.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_optidma.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_optidma.c 	- Opti DMA PATA for new ATA layer
  *			  (C) 2006 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  *	The Opti DMA controllers are related to the older PIO PCI controllers
  *	and indeed the VLB ones. The main differences are that the timing
@@ -46,15 +47,14 @@
 
 /**
  *	optidma_pre_reset		-	probe begin
- *	@link: ATA link
+ *	@ap: ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	Set up cable type and use generic probe init
  */
 
-static int optidma_pre_reset(struct ata_link *link, unsigned long deadline)
+static int optidma_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	static const struct pci_bits optidma_enable_bits = {
 		0x40, 1, 0x08, 0x00
@@ -63,7 +63,22 @@
 	if (ap->port_no && !pci_test_config_bits(pdev, &optidma_enable_bits))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	optidma_probe_reset		-	probe reset
+ *	@ap: ATA port
+ *
+ *	Perform the ATA probe and bus reset sequence plus specific handling
+ *	for this hardware. The Opti needs little handling - we have no UDMA66
+ *	capability that needs cable detection. All we must do is check the port
+ *	is enabled.
+ */
+
+static void optidma_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, optidma_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -308,48 +323,118 @@
 
 /**
  *	optidma_set_mode	-	mode setup
- *	@link: link to set up
+ *	@ap: port to set up
  *
  *	Use the standard setup to tune the chipset and then finalise the
  *	configuration by writing the nibble of extra bits of data into
  *	the chip.
  */
 
-static int optidma_set_mode(struct ata_link *link, struct ata_device **r_failed)
+static int optidma_set_mode(struct ata_port *ap, struct ata_device **r_failed)
 {
-	struct ata_port *ap = link->ap;
 	u8 r;
 	int nybble = 4 * ap->port_no;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	int rc  = ata_do_set_mode(link, r_failed);
+	int rc  = ata_do_set_mode(ap, r_failed);
 	if (rc == 0) {
 		pci_read_config_byte(pdev, 0x43, &r);
 
 		r &= (0x0F << nybble);
-		r |= (optidma_make_bits43(&link->device[0]) +
-		     (optidma_make_bits43(&link->device[0]) << 2)) << nybble;
+		r |= (optidma_make_bits43(&ap->device[0]) +
+		     (optidma_make_bits43(&ap->device[0]) << 2)) << nybble;
 		pci_write_config_byte(pdev, 0x43, r);
 	}
 	return rc;
 }
 
 static struct scsi_host_template optidma_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations optidma_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= optidma_set_pio_mode,
 	.set_dmamode	= optidma_set_dma_mode,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.error_handler	= optidma_error_handler,
 	.set_mode	= optidma_set_mode,
-	.prereset	= optidma_pre_reset,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations optiplus_port_ops = {
-	.inherits	= &optidma_port_ops,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= optiplus_set_pio_mode,
 	.set_dmamode	= optiplus_set_dma_mode,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.error_handler	= optidma_error_handler,
+	.set_mode	= optidma_set_mode,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -366,7 +451,7 @@
 
 	/* Find function 1 */
 	dev1 = pci_get_device(0x1045, 0xC701, NULL);
-	if (dev1 == NULL)
+	if(dev1 == NULL)
 		return 0;
 
 	/* Rev must be >= 0x10 */
@@ -398,29 +483,26 @@
 static int optidma_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info_82c700 = {
+		.sht = &optidma_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.port_ops = &optidma_port_ops
 	};
 	static const struct ata_port_info info_82c700_udma = {
+		.sht = &optidma_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
+		.udma_mask = 0x07,
 		.port_ops = &optiplus_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info_82c700, NULL };
 	static int printed_version;
-	int rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &dev->dev, "version " DRV_VERSION "\n");
 
-	rc = pcim_enable_device(dev);
-	if (rc)
-		return rc;
-
 	/* Fixed location chipset magic */
 	inw(0x1F1);
 	inw(0x1F1);
@@ -429,7 +511,7 @@
 	if (optiplus_with_udma(dev))
 		ppi[0] = &info_82c700_udma;
 
-	return ata_pci_sff_init_one(dev, ppi, &optidma_sht, NULL);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id optidma[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_palmld.c linux-sh4/drivers/ata/pata_palmld.c
--- linux-sh4/drivers/ata.org/pata_palmld.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_palmld.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,150 +0,0 @@
-/*
- * drivers/ata/pata_palmld.c
- *
- * Driver for IDE channel in Palm LifeDrive
- *
- * Based on research of:
- *		Alex Osborne <ato@meshy.org>
- *
- * Rewrite for mainline:
- *		Marek Vasut <marek.vasut@gmail.com>
- *
- * Rewritten version based on pata_ixp4xx_cf.c:
- * ixp4xx PATA/Compact Flash driver
- * Copyright (C) 2006-07 Tower Technologies
- * Author: Alessandro Zummo <a.zummo@towertech.it>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/libata.h>
-#include <linux/irq.h>
-#include <linux/platform_device.h>
-#include <linux/delay.h>
-#include <linux/gpio.h>
-
-#include <scsi/scsi_host.h>
-#include <mach/palmld.h>
-
-#define DRV_NAME "pata_palmld"
-
-static struct scsi_host_template palmld_sht = {
-	ATA_PIO_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations palmld_port_ops = {
-	.inherits		= &ata_sff_port_ops,
-	.sff_data_xfer		= ata_sff_data_xfer_noirq,
-	.cable_detect		= ata_cable_40wire,
-};
-
-static __devinit int palmld_pata_probe(struct platform_device *pdev)
-{
-	struct ata_host *host;
-	struct ata_port *ap;
-	void __iomem *mem;
-	int ret;
-
-	/* allocate host */
-	host = ata_host_alloc(&pdev->dev, 1);
-	if (!host)
-		return -ENOMEM;
-
-	/* remap drive's physical memory address */
-	mem = devm_ioremap(&pdev->dev, PALMLD_IDE_PHYS, 0x1000);
-	if (!mem)
-		return -ENOMEM;
-
-	/* request and activate power GPIO, IRQ GPIO */
-	ret = gpio_request(GPIO_NR_PALMLD_IDE_PWEN, "HDD PWR");
-	if (ret)
-		goto err1;
-	ret = gpio_direction_output(GPIO_NR_PALMLD_IDE_PWEN, 1);
-	if (ret)
-		goto err2;
-
-	ret = gpio_request(GPIO_NR_PALMLD_IDE_RESET, "HDD RST");
-	if (ret)
-		goto err2;
-	ret = gpio_direction_output(GPIO_NR_PALMLD_IDE_RESET, 0);
-	if (ret)
-		goto err3;
-
-	/* reset the drive */
-	gpio_set_value(GPIO_NR_PALMLD_IDE_RESET, 0);
-	msleep(30);
-	gpio_set_value(GPIO_NR_PALMLD_IDE_RESET, 1);
-	msleep(30);
-
-	/* setup the ata port */
-	ap = host->ports[0];
-	ap->ops	= &palmld_port_ops;
-	ap->pio_mask = ATA_PIO4;
-	ap->flags |= ATA_FLAG_MMIO | ATA_FLAG_NO_LEGACY | ATA_FLAG_PIO_POLLING;
-
-	/* memory mapping voodoo */
-	ap->ioaddr.cmd_addr = mem + 0x10;
-	ap->ioaddr.altstatus_addr = mem + 0xe;
-	ap->ioaddr.ctl_addr = mem + 0xe;
-
-	/* start the port */
-	ata_sff_std_ports(&ap->ioaddr);
-
-	/* activate host */
-	return ata_host_activate(host, 0, NULL, IRQF_TRIGGER_RISING,
-					&palmld_sht);
-
-err3:
-	gpio_free(GPIO_NR_PALMLD_IDE_RESET);
-err2:
-	gpio_free(GPIO_NR_PALMLD_IDE_PWEN);
-err1:
-	return ret;
-}
-
-static __devexit int palmld_pata_remove(struct platform_device *dev)
-{
-	struct ata_host *host = platform_get_drvdata(dev);
-
-	ata_host_detach(host);
-
-	/* power down the HDD */
-	gpio_set_value(GPIO_NR_PALMLD_IDE_PWEN, 0);
-
-	gpio_free(GPIO_NR_PALMLD_IDE_RESET);
-	gpio_free(GPIO_NR_PALMLD_IDE_PWEN);
-
-	return 0;
-}
-
-static struct platform_driver palmld_pata_platform_driver = {
-	.driver	 = {
-		.name   = DRV_NAME,
-		.owner  = THIS_MODULE,
-	},
-	.probe		= palmld_pata_probe,
-	.remove		= __devexit_p(palmld_pata_remove),
-};
-
-static int __init palmld_pata_init(void)
-{
-	return platform_driver_register(&palmld_pata_platform_driver);
-}
-
-static void __exit palmld_pata_exit(void)
-{
-	platform_driver_unregister(&palmld_pata_platform_driver);
-}
-
-MODULE_AUTHOR("Marek Vasut <marek.vasut@gmail.com>");
-MODULE_DESCRIPTION("PalmLD PATA driver");
-MODULE_LICENSE("GPL");
-MODULE_ALIAS("platform:" DRV_NAME);
-
-module_init(palmld_pata_init);
-module_exit(palmld_pata_exit);
diff -Nur linux-sh4/drivers/ata.org/pata_pcmcia.c linux-sh4/drivers/ata/pata_pcmcia.c
--- linux-sh4/drivers/ata.org/pata_pcmcia.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_pcmcia.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,6 @@
 /*
  *   pata_pcmcia.c - PCMCIA PATA controller driver.
- *   Copyright 2005-2006 Red Hat Inc, all rights reserved.
+ *   Copyright 2005-2006 Red Hat Inc <alan@redhat.com>, all rights reserved.
  *   PCMCIA ident update Copyright 2006 Marcin Juszkiewicz
  *						<openembedded@hrw.one.pl>
  *
@@ -42,7 +42,7 @@
 
 
 #define DRV_NAME "pata_pcmcia"
-#define DRV_VERSION "0.3.5"
+#define DRV_VERSION "0.3.2"
 
 /*
  *	Private data structure to glue stuff together
@@ -56,7 +56,7 @@
 
 /**
  *	pcmcia_set_mode	-	PCMCIA specific mode setup
- *	@link: link
+ *	@ap: Port
  *	@r_failed_dev: Return pointer for failed device
  *
  *	Perform the tuning and setup of the devices and timings, which
@@ -65,16 +65,17 @@
  *	decode, which alas is embarrassingly common in the PC world
  */
 
-static int pcmcia_set_mode(struct ata_link *link, struct ata_device **r_failed_dev)
+static int pcmcia_set_mode(struct ata_port *ap, struct ata_device **r_failed_dev)
 {
-	struct ata_device *master = &link->device[0];
-	struct ata_device *slave = &link->device[1];
+	struct ata_device *master = &ap->device[0];
+	struct ata_device *slave = &ap->device[1];
 
 	if (!ata_dev_enabled(master) || !ata_dev_enabled(slave))
-		return ata_do_set_mode(link, r_failed_dev);
+		return ata_do_set_mode(ap, r_failed_dev);
 
 	if (memcmp(master->id + ATA_ID_FW_REV,  slave->id + ATA_ID_FW_REV,
-			   ATA_ID_FW_REV_LEN + ATA_ID_PROD_LEN) == 0) {
+			   ATA_ID_FW_REV_LEN + ATA_ID_PROD_LEN) == 0)
+	{
 		/* Suspicious match, but could be two cards from
 		   the same vendor - check serial */
 		if (memcmp(master->id + ATA_ID_SERNO, slave->id + ATA_ID_SERNO,
@@ -83,160 +84,56 @@
 			ata_dev_disable(slave);
 		}
 	}
-	return ata_do_set_mode(link, r_failed_dev);
-}
-
-/**
- *	pcmcia_set_mode_8bit	-	PCMCIA specific mode setup
- *	@link: link
- *	@r_failed_dev: Return pointer for failed device
- *
- *	For the simple emulated 8bit stuff the less we do the better.
- */
-
-static int pcmcia_set_mode_8bit(struct ata_link *link,
-				struct ata_device **r_failed_dev)
-{
-	return 0;
-}
-
-/**
- *	ata_data_xfer_8bit	 -	Transfer data by 8bit PIO
- *	@dev: device to target
- *	@buf: data buffer
- *	@buflen: buffer length
- *	@rw: read/write
- *
- *	Transfer data from/to the device data register by 8 bit PIO.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-
-static unsigned int ata_data_xfer_8bit(struct ata_device *dev,
-				unsigned char *buf, unsigned int buflen, int rw)
-{
-	struct ata_port *ap = dev->link->ap;
-
-	if (rw == READ)
-		ioread8_rep(ap->ioaddr.data_addr, buf, buflen);
-	else
-		iowrite8_rep(ap->ioaddr.data_addr, buf, buflen);
-
-	return buflen;
-}
-
-/**
- *	pcmcia_8bit_drain_fifo - Stock FIFO drain logic for SFF controllers
- *	@qc: command
- *
- *	Drain the FIFO and device of any stuck data following a command
- *	failing to complete. In some cases this is neccessary before a
- *	reset will recover the device.
- *
- */
- 
-void pcmcia_8bit_drain_fifo(struct ata_queued_cmd *qc)
-{
-	int count;
-	struct ata_port *ap;
-
-	/* We only need to flush incoming data when a command was running */
-	if (qc == NULL || qc->dma_dir == DMA_TO_DEVICE)
-		return;
-
-	ap = qc->ap;
-
-	/* Drain up to 64K of data before we give up this recovery method */
-	for (count = 0; (ap->ops->sff_check_status(ap) & ATA_DRQ)
-							&& count++ < 65536;)
-		ioread8(ap->ioaddr.data_addr);
-
-	if (count)
-		ata_port_printk(ap, KERN_WARNING, "drained %d bytes to clear DRQ.\n",
-								count);
-
+	return ata_do_set_mode(ap, r_failed_dev);
 }
 
 static struct scsi_host_template pcmcia_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations pcmcia_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.sff_data_xfer	= ata_sff_data_xfer_noirq,
-	.cable_detect	= ata_cable_40wire,
 	.set_mode	= pcmcia_set_mode,
-};
-
-static struct ata_port_operations pcmcia_8bit_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.sff_data_xfer	= ata_data_xfer_8bit,
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
 	.cable_detect	= ata_cable_40wire,
-	.set_mode	= pcmcia_set_mode_8bit,
-	.drain_fifo	= pcmcia_8bit_drain_fifo,
-};
 
-#define CS_CHECK(fn, ret) \
-do { last_fn = (fn); if ((last_ret = (ret)) != 0) goto cs_failed; } while (0)
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
 
+	.data_xfer	= ata_data_xfer_noirq,
 
-struct pcmcia_config_check {
-	unsigned long ctl_base;
-	int skip_vcc;
-	int is_kme;
-};
-
-static int pcmcia_check_one_config(struct pcmcia_device *pdev,
-				   cistpl_cftable_entry_t *cfg,
-				   cistpl_cftable_entry_t *dflt,
-				   unsigned int vcc,
-				   void *priv_data)
-{
-	struct pcmcia_config_check *stk = priv_data;
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
 
-	/* Check for matching Vcc, unless we're desperate */
-	if (!stk->skip_vcc) {
-		if (cfg->vcc.present & (1 << CISTPL_POWER_VNOM)) {
-			if (vcc != cfg->vcc.param[CISTPL_POWER_VNOM] / 10000)
-				return -ENODEV;
-		} else if (dflt->vcc.present & (1 << CISTPL_POWER_VNOM)) {
-			if (vcc != dflt->vcc.param[CISTPL_POWER_VNOM] / 10000)
-				return -ENODEV;
-		}
-	}
+	.port_start	= ata_sff_port_start,
+};
 
-	if (cfg->vpp1.present & (1 << CISTPL_POWER_VNOM))
-		pdev->conf.Vpp = cfg->vpp1.param[CISTPL_POWER_VNOM] / 10000;
-	else if (dflt->vpp1.present & (1 << CISTPL_POWER_VNOM))
-		pdev->conf.Vpp = dflt->vpp1.param[CISTPL_POWER_VNOM] / 10000;
-
-	if ((cfg->io.nwin > 0) || (dflt->io.nwin > 0)) {
-		cistpl_io_t *io = (cfg->io.nwin) ? &cfg->io : &dflt->io;
-		pdev->io.BasePort1 = io->win[0].base;
-		pdev->io.IOAddrLines = io->flags & CISTPL_IO_LINES_MASK;
-		if (!(io->flags & CISTPL_IO_16BIT))
-			pdev->io.Attributes1 = IO_DATA_PATH_WIDTH_8;
-		if (io->nwin == 2) {
-			pdev->io.NumPorts1 = 8;
-			pdev->io.BasePort2 = io->win[1].base;
-			pdev->io.NumPorts2 = (stk->is_kme) ? 2 : 1;
-			if (pcmcia_request_io(pdev, &pdev->io) != 0)
-				return -ENODEV;
-			stk->ctl_base = pdev->io.BasePort2;
-		} else if ((io->nwin == 1) && (io->win[0].len >= 16)) {
-			pdev->io.NumPorts1 = io->win[0].len;
-			pdev->io.NumPorts2 = 0;
-			if (pcmcia_request_io(pdev, &pdev->io) != 0)
-				return -ENODEV;
-			stk->ctl_base = pdev->io.BasePort1 + 0x0e;
-		} else
-			return -ENODEV;
-		/* If we've got this far, we're done */
-		return 0;
-	}
-	return -ENODEV;
-}
+#define CS_CHECK(fn, ret) \
+do { last_fn = (fn); if ((last_ret = (ret)) != 0) goto cs_failed; } while (0)
 
 /**
  *	pcmcia_init_one		-	attach a PCMCIA interface
@@ -251,12 +148,17 @@
 	struct ata_host *host;
 	struct ata_port *ap;
 	struct ata_pcmcia_info *info;
-	struct pcmcia_config_check *stk = NULL;
-	int last_ret = 0, last_fn = 0, is_kme = 0, ret = -ENOMEM, p;
+	tuple_t tuple;
+	struct {
+		unsigned short buf[128];
+		cisparse_t parse;
+		config_info_t conf;
+		cistpl_cftable_entry_t dflt;
+	} *stk = NULL;
+	cistpl_cftable_entry_t *cfg;
+	int pass, last_ret = 0, last_fn = 0, is_kme = 0, ret = -ENOMEM;
 	unsigned long io_base, ctl_base;
 	void __iomem *io_addr, *ctl_addr;
-	int n_ports = 1;
-	struct ata_port_operations *ops = &pcmcia_port_ops;
 
 	info = kzalloc(sizeof(*info), GFP_KERNEL);
 	if (info == NULL)
@@ -275,27 +177,95 @@
 	pdev->conf.Attributes = CONF_ENABLE_IRQ;
 	pdev->conf.IntType = INT_MEMORY_AND_IO;
 
+	/* Allocate resoure probing structures */
+
+	stk = kzalloc(sizeof(*stk), GFP_KERNEL);
+	if (!stk)
+		goto out1;
+
+	cfg = &stk->parse.cftable_entry;
+
+	/* Tuples we are walking */
+	tuple.TupleData = (cisdata_t *)&stk->buf;
+	tuple.TupleOffset = 0;
+	tuple.TupleDataMax = 255;
+	tuple.Attributes = 0;
+
 	/* See if we have a manufacturer identifier. Use it to set is_kme for
 	   vendor quirks */
 	is_kme = ((pdev->manf_id == MANFID_KME) &&
 		  ((pdev->card_id == PRODID_KME_KXLC005_A) ||
 		   (pdev->card_id == PRODID_KME_KXLC005_B)));
 
-	/* Allocate resoure probing structures */
-
-	stk = kzalloc(sizeof(*stk), GFP_KERNEL);
-	if (!stk)
-		goto out1;
-	stk->is_kme = is_kme;
-	stk->skip_vcc = io_base = ctl_base = 0;
+	/* Not sure if this is right... look up the current Vcc */
+	CS_CHECK(GetConfigurationInfo, pcmcia_get_configuration_info(pdev, &stk->conf));
+/*	link->conf.Vcc = stk->conf.Vcc; */
+
+	pass = io_base = ctl_base = 0;
+	tuple.DesiredTuple = CISTPL_CFTABLE_ENTRY;
+	tuple.Attributes = 0;
+	CS_CHECK(GetFirstTuple, pcmcia_get_first_tuple(pdev, &tuple));
+
+	/* Now munch the resources looking for a suitable set */
+	while (1) {
+		if (pcmcia_get_tuple_data(pdev, &tuple) != 0)
+			goto next_entry;
+		if (pcmcia_parse_tuple(pdev, &tuple, &stk->parse) != 0)
+			goto next_entry;
+		/* Check for matching Vcc, unless we're desperate */
+		if (!pass) {
+			if (cfg->vcc.present & (1 << CISTPL_POWER_VNOM)) {
+				if (stk->conf.Vcc != cfg->vcc.param[CISTPL_POWER_VNOM] / 10000)
+					goto next_entry;
+			} else if (stk->dflt.vcc.present & (1 << CISTPL_POWER_VNOM)) {
+				if (stk->conf.Vcc != stk->dflt.vcc.param[CISTPL_POWER_VNOM] / 10000)
+					goto next_entry;
+			}
+		}
 
-	if (pcmcia_loop_config(pdev, pcmcia_check_one_config, stk)) {
-		stk->skip_vcc = 1;
-		if (pcmcia_loop_config(pdev, pcmcia_check_one_config, stk))
-			goto failed; /* No suitable config found */
+		if (cfg->vpp1.present & (1 << CISTPL_POWER_VNOM))
+			pdev->conf.Vpp = cfg->vpp1.param[CISTPL_POWER_VNOM] / 10000;
+		else if (stk->dflt.vpp1.present & (1 << CISTPL_POWER_VNOM))
+			pdev->conf.Vpp = stk->dflt.vpp1.param[CISTPL_POWER_VNOM] / 10000;
+
+		if ((cfg->io.nwin > 0) || (stk->dflt.io.nwin > 0)) {
+			cistpl_io_t *io = (cfg->io.nwin) ? &cfg->io : &stk->dflt.io;
+			pdev->conf.ConfigIndex = cfg->index;
+			pdev->io.BasePort1 = io->win[0].base;
+			pdev->io.IOAddrLines = io->flags & CISTPL_IO_LINES_MASK;
+			if (!(io->flags & CISTPL_IO_16BIT))
+				pdev->io.Attributes1 = IO_DATA_PATH_WIDTH_8;
+			if (io->nwin == 2) {
+				pdev->io.NumPorts1 = 8;
+				pdev->io.BasePort2 = io->win[1].base;
+				pdev->io.NumPorts2 = (is_kme) ? 2 : 1;
+				if (pcmcia_request_io(pdev, &pdev->io) != 0)
+					goto next_entry;
+				io_base = pdev->io.BasePort1;
+				ctl_base = pdev->io.BasePort2;
+			} else if ((io->nwin == 1) && (io->win[0].len >= 16)) {
+				pdev->io.NumPorts1 = io->win[0].len;
+				pdev->io.NumPorts2 = 0;
+				if (pcmcia_request_io(pdev, &pdev->io) != 0)
+					goto next_entry;
+				io_base = pdev->io.BasePort1;
+				ctl_base = pdev->io.BasePort1 + 0x0e;
+			} else goto next_entry;
+			/* If we've got this far, we're done */
+			break;
+		}
+next_entry:
+		if (cfg->flags & CISTPL_CFTABLE_DEFAULT)
+			memcpy(&stk->dflt, cfg, sizeof(stk->dflt));
+		if (pass) {
+			CS_CHECK(GetNextTuple, pcmcia_get_next_tuple(pdev, &tuple));
+		} else if (pcmcia_get_next_tuple(pdev, &tuple) != 0) {
+			CS_CHECK(GetFirstTuple, pcmcia_get_first_tuple(pdev, &tuple));
+			memset(&stk->dflt, 0, sizeof(stk->dflt));
+			pass++;
+		}
 	}
-	io_base = pdev->io.BasePort1;
-	ctl_base = stk->ctl_base;
+
 	CS_CHECK(RequestIRQ, pcmcia_request_irq(pdev, &pdev->irq));
 	CS_CHECK(RequestConfiguration, pcmcia_request_configuration(pdev, &pdev->conf));
 
@@ -314,35 +284,28 @@
 	/* FIXME: Could be more ports at base + 0x10 but we only deal with
 	   one right now */
 	if (pdev->io.NumPorts1 >= 0x20)
-		n_ports = 2;
+		printk(KERN_WARNING DRV_NAME ": second channel not yet supported.\n");
 
-	if (pdev->manf_id == 0x0097 && pdev->card_id == 0x1620)
-		ops = &pcmcia_8bit_port_ops;
 	/*
-	 *	Having done the PCMCIA plumbing the ATA side is relatively
-	 *	sane.
+ 	 *	Having done the PCMCIA plumbing the ATA side is relatively
+ 	 *	sane.
 	 */
 	ret = -ENOMEM;
-	host = ata_host_alloc(&pdev->dev, n_ports);
+	host = ata_host_alloc(&pdev->dev, 1);
 	if (!host)
 		goto failed;
+	ap = host->ports[0];
 
-	for (p = 0; p < n_ports; p++) {
-		ap = host->ports[p];
-
-		ap->ops = ops;
-		ap->pio_mask = ATA_PIO0;	/* ISA so PIO 0 cycles */
-		ap->flags |= ATA_FLAG_SLAVE_POSS;
-		ap->ioaddr.cmd_addr = io_addr + 0x10 * p;
-		ap->ioaddr.altstatus_addr = ctl_addr + 0x10 * p;
-		ap->ioaddr.ctl_addr = ctl_addr + 0x10 * p;
-		ata_sff_std_ports(&ap->ioaddr);
-
-		ata_port_desc(ap, "cmd 0x%lx ctl 0x%lx", io_base, ctl_base);
-	}
+	ap->ops = &pcmcia_port_ops;
+	ap->pio_mask = 1;		/* ISA so PIO 0 cycles */
+	ap->flags |= ATA_FLAG_SLAVE_POSS;
+	ap->ioaddr.cmd_addr = io_addr;
+	ap->ioaddr.altstatus_addr = ctl_addr;
+	ap->ioaddr.ctl_addr = ctl_addr;
+	ata_std_ports(&ap->ioaddr);
 
 	/* activate */
-	ret = ata_host_activate(host, pdev->irq.AssignedIRQ, ata_sff_interrupt,
+	ret = ata_host_activate(host, pdev->irq.AssignedIRQ, ata_interrupt,
 				IRQF_SHARED, &pcmcia_sht);
 	if (ret)
 		goto failed;
@@ -390,19 +353,16 @@
 
 static struct pcmcia_device_id pcmcia_devices[] = {
 	PCMCIA_DEVICE_FUNC_ID(4),
-	PCMCIA_DEVICE_MANF_CARD(0x0000, 0x0000),	/* Corsair */
 	PCMCIA_DEVICE_MANF_CARD(0x0007, 0x0000),	/* Hitachi */
 	PCMCIA_DEVICE_MANF_CARD(0x000a, 0x0000),	/* I-O Data CFA */
 	PCMCIA_DEVICE_MANF_CARD(0x001c, 0x0001),	/* Mitsubishi CFA */
 	PCMCIA_DEVICE_MANF_CARD(0x0032, 0x0704),
 	PCMCIA_DEVICE_MANF_CARD(0x0032, 0x2904),
 	PCMCIA_DEVICE_MANF_CARD(0x0045, 0x0401),	/* SanDisk CFA */
-	PCMCIA_DEVICE_MANF_CARD(0x004f, 0x0000),	/* Kingston */
-	PCMCIA_DEVICE_MANF_CARD(0x0097, 0x1620), 	/* TI emulated */
 	PCMCIA_DEVICE_MANF_CARD(0x0098, 0x0000),	/* Toshiba */
 	PCMCIA_DEVICE_MANF_CARD(0x00a4, 0x002d),
 	PCMCIA_DEVICE_MANF_CARD(0x00ce, 0x0000),	/* Samsung */
-	PCMCIA_DEVICE_MANF_CARD(0x0319, 0x0000),	/* Hitachi */
+ 	PCMCIA_DEVICE_MANF_CARD(0x0319, 0x0000),	/* Hitachi */
 	PCMCIA_DEVICE_MANF_CARD(0x2080, 0x0001),
 	PCMCIA_DEVICE_MANF_CARD(0x4e01, 0x0100),	/* Viking CFA */
 	PCMCIA_DEVICE_MANF_CARD(0x4e01, 0x0200),	/* Lexar, Viking CFA */
@@ -411,7 +371,6 @@
 	PCMCIA_DEVICE_PROD_ID123("PCMCIA", "IDE CARD", "F1", 0x281f1c5d, 0x1907960c, 0xf7fde8b9),
 	PCMCIA_DEVICE_PROD_ID12("ARGOSY", "CD-ROM", 0x78f308dc, 0x66536591),
 	PCMCIA_DEVICE_PROD_ID12("ARGOSY", "PnPIDE", 0x78f308dc, 0x0c694728),
-	PCMCIA_DEVICE_PROD_ID12("CNF   ", "CD-ROM", 0x46d7db81, 0x66536591),
 	PCMCIA_DEVICE_PROD_ID12("CNF CD-M", "CD-ROM", 0x7d93b852, 0x66536591),
 	PCMCIA_DEVICE_PROD_ID12("Creative Technology Ltd.", "PCMCIA CD-ROM Interface Card", 0xff8c8a45, 0xfe8020c4),
 	PCMCIA_DEVICE_PROD_ID12("Digital Equipment Corporation.", "Digital Mobile Media CD-ROM", 0x17692a66, 0xef1dcbde),
@@ -421,7 +380,6 @@
 	PCMCIA_DEVICE_PROD_ID12("FREECOM", "PCCARD-IDE", 0x5714cbf7, 0x48e0ab8e),
 	PCMCIA_DEVICE_PROD_ID12("HITACHI", "FLASH", 0xf4f43949, 0x9eb86aae),
 	PCMCIA_DEVICE_PROD_ID12("HITACHI", "microdrive", 0xf4f43949, 0xa6d76178),
-	PCMCIA_DEVICE_PROD_ID12("Hyperstone", "Model1", 0x3d5b9ef5, 0xca6ab420),
 	PCMCIA_DEVICE_PROD_ID12("IBM", "microdrive", 0xb569a6e5, 0xa6d76178),
 	PCMCIA_DEVICE_PROD_ID12("IBM", "IBM17JSSFP20", 0xb569a6e5, 0xf2508753),
 	PCMCIA_DEVICE_PROD_ID12("KINGSTON", "CF8GB", 0x2e6d1829, 0xacbe682e),
@@ -429,7 +387,6 @@
 	PCMCIA_DEVICE_PROD_ID12("IO DATA", "PCIDE", 0x547e66dc, 0x5c5ab149),
 	PCMCIA_DEVICE_PROD_ID12("IO DATA", "PCIDEII", 0x547e66dc, 0xb3662674),
 	PCMCIA_DEVICE_PROD_ID12("LOOKMEET", "CBIDE2      ", 0xe37be2b5, 0x8671043b),
-	PCMCIA_DEVICE_PROD_ID12("M-Systems", "CF300", 0x7ed2ad87, 0x7e9e78ee),
 	PCMCIA_DEVICE_PROD_ID12("M-Systems", "CF500", 0x7ed2ad87, 0x7a13045c),
 	PCMCIA_DEVICE_PROD_ID2("NinjaATA-", 0xebe0bd79),
 	PCMCIA_DEVICE_PROD_ID12("PCMCIA", "CD-ROM", 0x281f1c5d, 0x66536591),
@@ -440,7 +397,6 @@
 	PCMCIA_DEVICE_PROD_ID12("SMI VENDOR", "SMI PRODUCT", 0x30896c92, 0x703cc5f6),
 	PCMCIA_DEVICE_PROD_ID12("TOSHIBA", "MK2001MPL", 0xb4585a1a, 0x3489e003),
 	PCMCIA_DEVICE_PROD_ID1("TRANSCEND    512M   ", 0xd0909443),
-	PCMCIA_DEVICE_PROD_ID12("TRANSCEND", "TS1GCF45", 0x709b1bf1, 0xf68b6f32),
 	PCMCIA_DEVICE_PROD_ID12("TRANSCEND", "TS1GCF80", 0x709b1bf1, 0x2a54d4b1),
 	PCMCIA_DEVICE_PROD_ID12("TRANSCEND", "TS2GCF120", 0x709b1bf1, 0x969aa4f2),
 	PCMCIA_DEVICE_PROD_ID12("TRANSCEND", "TS4GCF120", 0x709b1bf1, 0xf54a91c8),
@@ -449,7 +405,6 @@
 	PCMCIA_DEVICE_PROD_ID1("STI Flash", 0xe4a13209),
 	PCMCIA_DEVICE_PROD_ID12("STI", "Flash 5.0", 0xbf2df18d, 0x8cb57a0e),
 	PCMCIA_MFC_DEVICE_PROD_ID12(1, "SanDisk", "ConnectPlus", 0x7a954bd9, 0x74be00c6),
-	PCMCIA_DEVICE_PROD_ID2("Flash Card", 0x5a362506),
 	PCMCIA_DEVICE_NULL,
 };
 
diff -Nur linux-sh4/drivers/ata.org/pata_pdc2027x.c linux-sh4/drivers/ata/pata_pdc2027x.c
--- linux-sh4/drivers/ata.org/pata_pdc2027x.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_pdc2027x.c	2012-01-15 06:30:15.000000000 -0800
@@ -39,7 +39,7 @@
 #undef PDC_DEBUG
 
 #ifdef PDC_DEBUG
-#define PDPRINTK(fmt, args...) printk(KERN_ERR "%s: " fmt, __func__, ## args)
+#define PDPRINTK(fmt, args...) printk(KERN_ERR "%s: " fmt, __FUNCTION__, ## args)
 #else
 #define PDPRINTK(fmt, args...)
 #endif
@@ -63,13 +63,13 @@
 };
 
 static int pdc2027x_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
-static int pdc2027x_prereset(struct ata_link *link, unsigned long deadline);
+static void pdc2027x_error_handler(struct ata_port *ap);
 static void pdc2027x_set_piomode(struct ata_port *ap, struct ata_device *adev);
 static void pdc2027x_set_dmamode(struct ata_port *ap, struct ata_device *adev);
 static int pdc2027x_check_atapi_dma(struct ata_queued_cmd *qc);
 static unsigned long pdc2027x_mode_filter(struct ata_device *adev, unsigned long mask);
 static int pdc2027x_cable_detect(struct ata_port *ap);
-static int pdc2027x_set_mode(struct ata_link *link, struct ata_device **r_failed);
+static int pdc2027x_set_mode(struct ata_port *ap, struct ata_device **r_failed);
 
 /*
  * ATA Timing Tables based on 133MHz controller clock.
@@ -129,22 +129,88 @@
 };
 
 static struct scsi_host_template pdc2027x_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations pdc2027x_pata100_ops = {
-	.inherits		= &ata_bmdma_port_ops,
+	.port_disable		= ata_port_disable,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
 	.check_atapi_dma	= pdc2027x_check_atapi_dma,
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= pdc2027x_error_handler,
+	.post_internal_cmd 	= ata_bmdma_post_internal_cmd,
 	.cable_detect		= pdc2027x_cable_detect,
-	.prereset		= pdc2027x_prereset,
+
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 static struct ata_port_operations pdc2027x_pata133_ops = {
-	.inherits		= &pdc2027x_pata100_ops,
-	.mode_filter		= pdc2027x_mode_filter,
+	.port_disable		= ata_port_disable,
 	.set_piomode		= pdc2027x_set_piomode,
 	.set_dmamode		= pdc2027x_set_dmamode,
 	.set_mode		= pdc2027x_set_mode,
+	.mode_filter		= pdc2027x_mode_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.check_atapi_dma	= pdc2027x_check_atapi_dma,
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= pdc2027x_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= pdc2027x_cable_detect,
+
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 static struct ata_port_info pdc2027x_port_info[] = {
@@ -152,18 +218,18 @@
 	{
 		.flags		= ATA_FLAG_NO_LEGACY | ATA_FLAG_SLAVE_POSS |
 		                  ATA_FLAG_MMIO,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask	= ATA_UDMA5,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
+		.udma_mask	= ATA_UDMA5, /* udma0-5 */
 		.port_ops	= &pdc2027x_pata100_ops,
 	},
 	/* PDC_UDMA_133 */
 	{
 		.flags		= ATA_FLAG_NO_LEGACY | ATA_FLAG_SLAVE_POSS |
                         	  ATA_FLAG_MMIO,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask	= ATA_UDMA6,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
+		.udma_mask	= ATA_UDMA6, /* udma0-6 */
 		.port_ops	= &pdc2027x_pata133_ops,
 	},
 };
@@ -211,7 +277,7 @@
 	u32 cgcr;
 
 	/* check cable detect results */
-	cgcr = ioread32(port_mmio(ap, PDC_GLOBAL_CTL));
+	cgcr = readl(port_mmio(ap, PDC_GLOBAL_CTL));
 	if (cgcr & (1 << 26))
 		goto cbl40;
 
@@ -229,12 +295,12 @@
  */
 static inline int pdc2027x_port_enabled(struct ata_port *ap)
 {
-	return ioread8(port_mmio(ap, PDC_ATA_CTL)) & 0x02;
+	return readb(port_mmio(ap, PDC_ATA_CTL)) & 0x02;
 }
 
 /**
  *	pdc2027x_prereset - prereset for PATA host controller
- *	@link: Target link
+ *	@ap: Target port
  *	@deadline: deadline jiffies for the operation
  *
  *	Probeinit including cable detection.
@@ -243,12 +309,27 @@
  *	None (inherited from caller).
  */
 
-static int pdc2027x_prereset(struct ata_link *link, unsigned long deadline)
+static int pdc2027x_prereset(struct ata_port *ap, unsigned long deadline)
 {
 	/* Check whether port enabled */
-	if (!pdc2027x_port_enabled(link->ap))
+	if (!pdc2027x_port_enabled(ap))
 		return -ENOENT;
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+/**
+ *	pdc2027x_error_handler - Perform reset on PATA port and classify
+ *	@ap: Port to reset
+ *
+ *	Reset PATA phy and classify attached devices.
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void pdc2027x_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, pdc2027x_prereset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 /**
@@ -265,22 +346,23 @@
 	struct ata_device *pair = ata_dev_pair(adev);
 
 	if (adev->class != ATA_DEV_ATA || adev->devno == 0 || pair == NULL)
-		return ata_bmdma_mode_filter(adev, mask);
+		return ata_pci_default_filter(adev, mask);
 
 	/* Check for slave of a Maxtor at UDMA6 */
 	ata_id_c_string(pair->id, model_num, ATA_ID_PROD,
 			  ATA_ID_PROD_LEN + 1);
 	/* If the master is a maxtor in UDMA6 then the slave should not use UDMA 6 */
-	if (strstr(model_num, "Maxtor") == NULL && pair->dma_mode == XFER_UDMA_6)
+	if(strstr(model_num, "Maxtor") == 0 && pair->dma_mode == XFER_UDMA_6)
 		mask &= ~ (1 << (6 + ATA_SHIFT_UDMA));
 
-	return ata_bmdma_mode_filter(adev, mask);
+	return ata_pci_default_filter(adev, mask);
 }
 
 /**
  *	pdc2027x_set_piomode - Initialize host controller PATA PIO timings
  *	@ap: Port to configure
  *	@adev: um
+ *	@pio: PIO mode, 0 - 4
  *
  *	Set PIO mode for device.
  *
@@ -305,16 +387,16 @@
 	/* Set the PIO timing registers using value table for 133MHz */
 	PDPRINTK("Set pio regs... \n");
 
-	ctcr0 = ioread32(dev_mmio(ap, adev, PDC_CTCR0));
+	ctcr0 = readl(dev_mmio(ap, adev, PDC_CTCR0));
 	ctcr0 &= 0xffff0000;
 	ctcr0 |= pdc2027x_pio_timing_tbl[pio].value0 |
 		(pdc2027x_pio_timing_tbl[pio].value1 << 8);
-	iowrite32(ctcr0, dev_mmio(ap, adev, PDC_CTCR0));
+	writel(ctcr0, dev_mmio(ap, adev, PDC_CTCR0));
 
-	ctcr1 = ioread32(dev_mmio(ap, adev, PDC_CTCR1));
+	ctcr1 = readl(dev_mmio(ap, adev, PDC_CTCR1));
 	ctcr1 &= 0x00ffffff;
 	ctcr1 |= (pdc2027x_pio_timing_tbl[pio].value2 << 24);
-	iowrite32(ctcr1, dev_mmio(ap, adev, PDC_CTCR1));
+	writel(ctcr1, dev_mmio(ap, adev, PDC_CTCR1));
 
 	PDPRINTK("Set pio regs done\n");
 
@@ -325,6 +407,7 @@
  *	pdc2027x_set_dmamode - Initialize host controller PATA UDMA timings
  *	@ap: Port to configure
  *	@adev: um
+ *	@udma: udma mode, XFER_UDMA_0 to XFER_UDMA_6
  *
  *	Set UDMA mode for device.
  *
@@ -347,18 +430,18 @@
 			 * If tHOLD is '1', the hardware will add half clock for data hold time.
 			 * This code segment seems to be no effect. tHOLD will be overwritten below.
 			 */
-			ctcr1 = ioread32(dev_mmio(ap, adev, PDC_CTCR1));
-			iowrite32(ctcr1 & ~(1 << 7), dev_mmio(ap, adev, PDC_CTCR1));
+			ctcr1 = readl(dev_mmio(ap, adev, PDC_CTCR1));
+			writel(ctcr1 & ~(1 << 7), dev_mmio(ap, adev, PDC_CTCR1));
 		}
 
 		PDPRINTK("Set udma regs... \n");
 
-		ctcr1 = ioread32(dev_mmio(ap, adev, PDC_CTCR1));
+		ctcr1 = readl(dev_mmio(ap, adev, PDC_CTCR1));
 		ctcr1 &= 0xff000000;
 		ctcr1 |= pdc2027x_udma_timing_tbl[udma_mode].value0 |
 			(pdc2027x_udma_timing_tbl[udma_mode].value1 << 8) |
 			(pdc2027x_udma_timing_tbl[udma_mode].value2 << 16);
-		iowrite32(ctcr1, dev_mmio(ap, adev, PDC_CTCR1));
+		writel(ctcr1, dev_mmio(ap, adev, PDC_CTCR1));
 
 		PDPRINTK("Set udma regs done\n");
 
@@ -370,13 +453,13 @@
 		unsigned int mdma_mode = dma_mode & 0x07;
 
 		PDPRINTK("Set mdma regs... \n");
-		ctcr0 = ioread32(dev_mmio(ap, adev, PDC_CTCR0));
+		ctcr0 = readl(dev_mmio(ap, adev, PDC_CTCR0));
 
 		ctcr0 &= 0x0000ffff;
 		ctcr0 |= (pdc2027x_mdma_timing_tbl[mdma_mode].value0 << 16) |
 			(pdc2027x_mdma_timing_tbl[mdma_mode].value1 << 24);
 
-		iowrite32(ctcr0, dev_mmio(ap, adev, PDC_CTCR0));
+		writel(ctcr0, dev_mmio(ap, adev, PDC_CTCR0));
 		PDPRINTK("Set mdma regs done\n");
 
 		PDPRINTK("Set to mdma mode[%u] \n", mdma_mode);
@@ -387,37 +470,40 @@
 
 /**
  *	pdc2027x_set_mode - Set the timing registers back to correct values.
- *	@link: link to configure
+ *	@ap: Port to configure
  *	@r_failed: Returned device for failure
  *
  *	The pdc2027x hardware will look at "SET FEATURES" and change the timing registers
  *	automatically. The values set by the hardware might be incorrect, under 133Mhz PLL.
  *	This function overwrites the possibly incorrect values set by the hardware to be correct.
  */
-static int pdc2027x_set_mode(struct ata_link *link, struct ata_device **r_failed)
+static int pdc2027x_set_mode(struct ata_port *ap, struct ata_device **r_failed)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_device *dev;
-	int rc;
+	int i;
 
-	rc = ata_do_set_mode(link, r_failed);
-	if (rc < 0)
-		return rc;
+	i = ata_do_set_mode(ap, r_failed);
+	if (i < 0)
+		return i;
+
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
 
-	ata_for_each_dev(dev, link, ENABLED) {
-		pdc2027x_set_piomode(ap, dev);
+		if (ata_dev_enabled(dev)) {
 
-		/*
-		 * Enable prefetch if the device support PIO only.
-		 */
-		if (dev->xfer_shift == ATA_SHIFT_PIO) {
-			u32 ctcr1 = ioread32(dev_mmio(ap, dev, PDC_CTCR1));
-			ctcr1 |= (1 << 25);
-			iowrite32(ctcr1, dev_mmio(ap, dev, PDC_CTCR1));
-
-			PDPRINTK("Turn on prefetch\n");
-		} else {
-			pdc2027x_set_dmamode(ap, dev);
+			pdc2027x_set_piomode(ap, dev);
+
+			/*
+			 * Enable prefetch if the device support PIO only.
+			 */
+			if (dev->xfer_shift == ATA_SHIFT_PIO) {
+				u32 ctcr1 = readl(dev_mmio(ap, dev, PDC_CTCR1));
+				ctcr1 |= (1 << 25);
+				writel(ctcr1, dev_mmio(ap, dev, PDC_CTCR1));
+
+				PDPRINTK("Turn on prefetch\n");
+			} else {
+				pdc2027x_set_dmamode(ap, dev);
+			}
 		}
 	}
 	return 0;
@@ -477,12 +563,14 @@
 	u32 bccrl, bccrh, bccrlv, bccrhv;
 
 retry:
-	bccrl = ioread32(mmio_base + PDC_BYTE_COUNT) & 0x7fff;
-	bccrh = ioread32(mmio_base + PDC_BYTE_COUNT + 0x100) & 0x7fff;
+	bccrl = readl(mmio_base + PDC_BYTE_COUNT) & 0x7fff;
+	bccrh = readl(mmio_base + PDC_BYTE_COUNT + 0x100) & 0x7fff;
+	rmb();
 
 	/* Read the counter values again for verification */
-	bccrlv = ioread32(mmio_base + PDC_BYTE_COUNT) & 0x7fff;
-	bccrhv = ioread32(mmio_base + PDC_BYTE_COUNT + 0x100) & 0x7fff;
+	bccrlv = readl(mmio_base + PDC_BYTE_COUNT) & 0x7fff;
+	bccrhv = readl(mmio_base + PDC_BYTE_COUNT + 0x100) & 0x7fff;
+	rmb();
 
 	counter = (bccrh << 15) | bccrl;
 
@@ -531,7 +619,7 @@
 	/* Show the current clock value of PLL control register
 	 * (maybe already configured by the firmware)
 	 */
-	pll_ctl = ioread16(mmio_base + PDC_PLL_CTL);
+	pll_ctl = readw(mmio_base + PDC_PLL_CTL);
 
 	PDPRINTK("pll_ctl[%X]\n", pll_ctl);
 #endif
@@ -571,8 +659,8 @@
 
 	PDPRINTK("Writing pll_ctl[%X]\n", pll_ctl);
 
-	iowrite16(pll_ctl, mmio_base + PDC_PLL_CTL);
-	ioread16(mmio_base + PDC_PLL_CTL); /* flush */
+	writew(pll_ctl, mmio_base + PDC_PLL_CTL);
+	readw(mmio_base + PDC_PLL_CTL); /* flush */
 
 	/* Wait the PLL circuit to be stable */
 	mdelay(30);
@@ -582,7 +670,7 @@
 	 *  Show the current clock value of PLL control register
 	 * (maybe configured by the firmware)
 	 */
-	pll_ctl = ioread16(mmio_base + PDC_PLL_CTL);
+	pll_ctl = readw(mmio_base + PDC_PLL_CTL);
 
 	PDPRINTK("pll_ctl[%X]\n", pll_ctl);
 #endif
@@ -605,10 +693,10 @@
 	long pll_clock, usec_elapsed;
 
 	/* Start the test mode */
-	scr = ioread32(mmio_base + PDC_SYS_CTL);
+	scr = readl(mmio_base + PDC_SYS_CTL);
 	PDPRINTK("scr[%X]\n", scr);
-	iowrite32(scr | (0x01 << 14), mmio_base + PDC_SYS_CTL);
-	ioread32(mmio_base + PDC_SYS_CTL); /* flush */
+	writel(scr | (0x01 << 14), mmio_base + PDC_SYS_CTL);
+	readl(mmio_base + PDC_SYS_CTL); /* flush */
 
 	/* Read current counter value */
 	start_count = pdc_read_counter(host);
@@ -622,10 +710,10 @@
 	do_gettimeofday(&end_time);
 
 	/* Stop the test mode */
-	scr = ioread32(mmio_base + PDC_SYS_CTL);
+	scr = readl(mmio_base + PDC_SYS_CTL);
 	PDPRINTK("scr[%X]\n", scr);
-	iowrite32(scr & ~(0x01 << 14), mmio_base + PDC_SYS_CTL);
-	ioread32(mmio_base + PDC_SYS_CTL); /* flush */
+	writel(scr & ~(0x01 << 14), mmio_base + PDC_SYS_CTL);
+	readl(mmio_base + PDC_SYS_CTL); /* flush */
 
 	/* calculate the input clock in Hz */
 	usec_elapsed = (end_time.tv_sec - start_time.tv_sec) * 1000000 +
@@ -657,6 +745,9 @@
 	 */
 	pll_clock = pdc_detect_pll_input_clock(host);
 
+	if (pll_clock < 0) /* counter overflow? Try again. */
+		pll_clock = pdc_detect_pll_input_clock(host);
+
 	dev_printk(KERN_INFO, host->dev, "PLL input clock %ld kHz\n", pll_clock/1000);
 
 	/* Adjust PLL control register */
@@ -700,14 +791,12 @@
 static int __devinit pdc2027x_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
-	static const unsigned long cmd_offset[] = { 0x17c0, 0x15c0 };
-	static const unsigned long bmdma_offset[] = { 0x1000, 0x1008 };
 	unsigned int board_idx = (unsigned int) ent->driver_data;
 	const struct ata_port_info *ppi[] =
 		{ &pdc2027x_port_info[board_idx], NULL };
 	struct ata_host *host;
 	void __iomem *mmio_base;
-	int i, rc;
+	int rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
@@ -737,15 +826,10 @@
 
 	mmio_base = host->iomap[PDC_MMIO_BAR];
 
-	for (i = 0; i < 2; i++) {
-		struct ata_port *ap = host->ports[i];
-
-		pdc_ata_setup_port(&ap->ioaddr, mmio_base + cmd_offset[i]);
-		ap->ioaddr.bmdma_addr = mmio_base + bmdma_offset[i];
-
-		ata_port_pbar_desc(ap, PDC_MMIO_BAR, -1, "mmio");
-		ata_port_pbar_desc(ap, PDC_MMIO_BAR, cmd_offset[i], "cmd");
-	}
+	pdc_ata_setup_port(&host->ports[0]->ioaddr, mmio_base + 0x17c0);
+	host->ports[0]->ioaddr.bmdma_addr = mmio_base + 0x1000;
+	pdc_ata_setup_port(&host->ports[1]->ioaddr, mmio_base + 0x15c0);
+	host->ports[1]->ioaddr.bmdma_addr = mmio_base + 0x1008;
 
 	//pci_enable_intx(pdev);
 
@@ -754,8 +838,8 @@
 		return -EIO;
 
 	pci_set_master(pdev);
-	return ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &pdc2027x_sht);
+	return ata_host_activate(host, pdev->irq, ata_interrupt, IRQF_SHARED,
+				 &pdc2027x_sht);
 }
 
 /**
diff -Nur linux-sh4/drivers/ata.org/pata_pdc202xx_old.c linux-sh4/drivers/ata/pata_pdc202xx_old.c
--- linux-sh4/drivers/ata.org/pata_pdc202xx_old.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_pdc202xx_old.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,15 +1,15 @@
 /*
  * pata_pdc202xx_old.c 	- Promise PDC202xx PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
- *			  Alan Cox <alan@lxorguk.ukuu.org.uk>
- *			  (C) 2007,2009,2010 Bartlomiej Zolnierkiewicz
+ *			  Alan Cox <alan@redhat.com>
+ *			  (C) 2007 Bartlomiej Zolnierkiewicz
  *
  * Based in part on linux/drivers/ide/pci/pdc202xx_old.c
  *
  * First cut with LBA48/ATAPI
  *
  * TODO:
- *	Channel interlock/reset on both required ?
+ *	Channel interlock/reset on both required
  */
 
 #include <linux/kernel.h>
@@ -22,7 +22,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "pata_pdc202xx_old"
-#define DRV_VERSION "0.4.3"
+#define DRV_VERSION "0.4.2"
 
 static int pdc2026x_cable_detect(struct ata_port *ap)
 {
@@ -35,15 +35,6 @@
 	return ATA_CBL_PATA80;
 }
 
-static void pdc202xx_exec_command(struct ata_port *ap,
-				  const struct ata_taskfile *tf)
-{
-	DPRINTK("ata%u: cmd 0x%X\n", ap->print_id, tf->command);
-
-	iowrite8(tf->command, ap->ioaddr.command_addr);
-	ndelay(400);
-}
-
 /**
  *	pdc202xx_configure_piomode	-	set chip PIO timing
  *	@ap: ATA interface
@@ -115,9 +106,9 @@
 		{ 0x20, 0x01 }
 	};
 	static u8 mdma_timing[3][2] = {
-		{ 0xe0, 0x0f },
-		{ 0x60, 0x04 },
 		{ 0x60, 0x03 },
+		{ 0x60, 0x04 },
+		{ 0xe0, 0x0f },
 	};
 	u8 r_bp, r_cp;
 
@@ -148,9 +139,6 @@
  *
  *	In UDMA3 or higher we have to clock switch for the duration of the
  *	DMA transfer sequence.
- *
- *	Note: The host lock held by the libata layer protects
- *	us from two channels both trying to set DMA bits at once
  */
 
 static void pdc2026x_bmdma_start(struct ata_queued_cmd *qc)
@@ -167,7 +155,7 @@
 	u32 len;
 
 	/* Check we keep host level locking here */
-	if (adev->dma_mode > XFER_UDMA_2)
+	if (adev->dma_mode >= XFER_UDMA_2)
 		iowrite8(ioread8(clock) | sel66, clock);
 	else
 		iowrite8(ioread8(clock) & ~sel66, clock);
@@ -177,7 +165,8 @@
 	pdc202xx_set_dmamode(ap, qc->dev);
 
 	/* Cases the state machine will not complete correctly without help */
-	if ((tf->flags & ATA_TFLAG_LBA48) ||  tf->protocol == ATAPI_PROT_DMA) {
+	if ((tf->flags & ATA_TFLAG_LBA48) ||  tf->protocol == ATA_PROT_ATAPI_DMA)
+	{
 		len = qc->nbytes / 2;
 
 		if (tf->flags & ATA_TFLAG_WRITE)
@@ -198,9 +187,6 @@
  *
  *	After a DMA completes we need to put the clock back to 33MHz for
  *	PIO timings.
- *
- *	Note: The host lock held by the libata layer protects
- *	us from two channels both trying to set DMA bits at once
  */
 
 static void pdc2026x_bmdma_stop(struct ata_queued_cmd *qc)
@@ -216,15 +202,16 @@
 	void __iomem *atapi_reg = master + 0x20 + (4 * ap->port_no);
 
 	/* Cases the state machine will not complete correctly */
-	if (tf->protocol == ATAPI_PROT_DMA || (tf->flags & ATA_TFLAG_LBA48)) {
+	if (tf->protocol == ATA_PROT_ATAPI_DMA || ( tf->flags & ATA_TFLAG_LBA48)) {
 		iowrite32(0, atapi_reg);
 		iowrite8(ioread8(clock) & ~sel66, clock);
 	}
+	/* Check we keep host level locking here */
 	/* Flip back to 33Mhz for PIO */
-	if (adev->dma_mode > XFER_UDMA_2)
+	if (adev->dma_mode >= XFER_UDMA_2)
 		iowrite8(ioread8(clock) & ~sel66, clock);
+
 	ata_bmdma_stop(qc);
-	pdc202xx_set_piomode(ap, adev);
 }
 
 /**
@@ -241,85 +228,117 @@
 	adev->max_sectors = 256;
 }
 
-static int pdc2026x_port_start(struct ata_port *ap)
-{
-	void __iomem *bmdma = ap->ioaddr.bmdma_addr;
-	if (bmdma) {
-		/* Enable burst mode */
-		u8 burst = ioread8(bmdma + 0x1f);
-		iowrite8(burst | 0x01, bmdma + 0x1f);
-	}
-	return ata_sff_port_start(ap);
-}
-
-/**
- *	pdc2026x_check_atapi_dma - Check whether ATAPI DMA can be supported for this command
- *	@qc: Metadata associated with taskfile to check
- *
- *	Just say no - not supported on older Promise.
- *
- *	LOCKING:
- *	None (inherited from caller).
- *
- *	RETURNS: 0 when ATAPI DMA can be used
- *		 1 otherwise
- */
-
-static int pdc2026x_check_atapi_dma(struct ata_queued_cmd *qc)
-{
-	return 1;
-}
-
 static struct scsi_host_template pdc202xx_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations pdc2024x_port_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-
-	.cable_detect		= ata_cable_40wire,
-	.set_piomode		= pdc202xx_set_piomode,
-	.set_dmamode		= pdc202xx_set_dmamode,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= pdc202xx_set_piomode,
+	.set_dmamode	= pdc202xx_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
 
-	.sff_exec_command	= pdc202xx_exec_command,
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations pdc2026x_port_ops = {
-	.inherits		= &pdc2024x_port_ops,
-
-	.check_atapi_dma	= pdc2026x_check_atapi_dma,
-	.bmdma_start		= pdc2026x_bmdma_start,
-	.bmdma_stop		= pdc2026x_bmdma_stop,
-
-	.cable_detect		= pdc2026x_cable_detect,
-	.dev_config		= pdc2026x_dev_config,
-
-	.port_start		= pdc2026x_port_start,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= pdc202xx_set_piomode,
+	.set_dmamode	= pdc202xx_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+	.dev_config	= pdc2026x_dev_config,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= pdc2026x_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= pdc2026x_bmdma_start,
+	.bmdma_stop	= pdc2026x_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
 
-	.sff_exec_command	= pdc202xx_exec_command,
+	.port_start	= ata_port_start,
 };
 
 static int pdc202xx_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info[3] = {
 		{
+			.sht = &pdc202xx_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.udma_mask = ATA_UDMA2,
 			.port_ops = &pdc2024x_port_ops
 		},
 		{
+			.sht = &pdc202xx_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.udma_mask = ATA_UDMA4,
 			.port_ops = &pdc2026x_port_ops
 		},
 		{
+			.sht = &pdc202xx_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.udma_mask = ATA_UDMA5,
 			.port_ops = &pdc2026x_port_ops
 		}
@@ -331,13 +350,13 @@
 		struct pci_dev *bridge = dev->bus->self;
 		/* Don't grab anything behind a Promise I2O RAID */
 		if (bridge && bridge->vendor == PCI_VENDOR_ID_INTEL) {
-			if (bridge->device == PCI_DEVICE_ID_INTEL_I960)
+			if( bridge->device == PCI_DEVICE_ID_INTEL_I960)
 				return -ENODEV;
-			if (bridge->device == PCI_DEVICE_ID_INTEL_I960RM)
+			if( bridge->device == PCI_DEVICE_ID_INTEL_I960RM)
 				return -ENODEV;
 		}
 	}
-	return ata_pci_sff_init_one(dev, ppi, &pdc202xx_sht, NULL);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id pdc202xx[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_platform.c linux-sh4/drivers/ata/pata_platform.c
--- linux-sh4/drivers/ata.org/pata_platform.c	2012-03-10 00:25:26.000000000 -0800
+++ linux-sh4/drivers/ata/pata_platform.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,11 +1,11 @@
 /*
  * Generic platform device PATA driver
  *
- * Copyright (C) 2006 - 2007  Paul Mundt
+ * Copyright (C) 2006  Paul Mundt
  *
  * Based on pata_pcmcia:
  *
- *   Copyright 2005-2006 Red Hat Inc, all rights reserved.
+ *   Copyright 2005-2006 Red Hat Inc <alan@redhat.com>, all rights reserved.
  *
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -19,10 +19,10 @@
 #include <linux/ata.h>
 #include <linux/libata.h>
 #include <linux/platform_device.h>
-#include <linux/ata_platform.h>
+#include <linux/pata_platform.h>
 
 #define DRV_NAME "pata_platform"
-#define DRV_VERSION "1.2"
+#define DRV_VERSION "1.1"
 
 static int pio_mask = 1;
 
@@ -30,16 +30,20 @@
  * Provide our own set_mode() as we don't want to change anything that has
  * already been configured..
  */
-static int pata_platform_set_mode(struct ata_link *link, struct ata_device **unused)
+static int pata_platform_set_mode(struct ata_port *ap, struct ata_device **unused)
 {
-	struct ata_device *dev;
+	int i;
 
-	ata_for_each_dev(dev, link, ENABLED) {
-		/* We don't really care */
-		dev->pio_mode = dev->xfer_mode = XFER_PIO_0;
-		dev->xfer_shift = ATA_SHIFT_PIO;
-		dev->flags |= ATA_DFLAG_PIO;
-		ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+
+		if (ata_dev_enabled(dev)) {
+			/* We don't really care */
+			dev->pio_mode = dev->xfer_mode = XFER_PIO_0;
+			dev->xfer_shift = ATA_SHIFT_PIO;
+			dev->flags |= ATA_DFLAG_PIO;
+			ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
+		}
 	}
 	return 0;
 }
@@ -48,29 +52,69 @@
 				    unsigned char *buf,
 				    unsigned int buflen, int write_data)
 {
-	ata_sff_data_xfer_noirq(adev, buf, buflen, write_data);
+	ata_data_xfer_noirq(adev, buf, buflen, write_data);
 	if (! write_data) {
 		__flush_wback_region(buf, buflen);
 	}
 }
 
+static int ata_dummy_ret0(struct ata_port *ap)	{ return 0; }
+
 static struct scsi_host_template pata_platform_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations pata_platform_port_ops = {
-	.inherits		= &ata_sff_port_ops,
-	.sff_data_xfer		= ata_sff_data_xfer_noirq,
-	.cable_detect		= ata_cable_unknown,
-	.sff_data_xfer		= pata_platform_data_xfer,
 	.set_mode		= pata_platform_set_mode,
-	.port_start		= ATA_OP_NULL,
+
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ata_cable_unknown,
+
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+
+	.data_xfer		= pata_platform_data_xfer,
+
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_dummy_ret0,
 };
 
 static void pata_platform_setup_port(struct ata_ioports *ioaddr,
-				     unsigned int shift)
+				     struct pata_platform_info *info)
 {
+	unsigned int shift = 0;
+
 	/* Fixup the port shift for platforms that need it */
+	if (info && info->ioport_shift)
+		shift = info->ioport_shift;
+
 	ioaddr->data_addr	= ioaddr->cmd_addr + (ATA_REG_DATA    << shift);
 	ioaddr->error_addr	= ioaddr->cmd_addr + (ATA_REG_ERR     << shift);
 	ioaddr->feature_addr	= ioaddr->cmd_addr + (ATA_REG_FEATURE << shift);
@@ -84,180 +128,122 @@
 }
 
 /**
- *	__pata_platform_probe		-	attach a platform interface
- *	@dev: device
- *	@io_res: Resource representing I/O base
- *	@ctl_res: Resource representing CTL base
- *	@irq_res: Resource representing IRQ and its flags
- *	@ioport_shift: I/O port shift
- *	@__pio_mask: PIO mask
+ *	pata_platform_probe		-	attach a platform interface
+ *	@pdev: platform device
  *
  *	Register a platform bus IDE interface. Such interfaces are PIO and we
  *	assume do not support IRQ sharing.
  *
- *	Platform devices are expected to contain at least 2 resources per port:
+ *	Platform devices are expected to contain 3 resources per port:
  *
  *		- I/O Base (IORESOURCE_IO or IORESOURCE_MEM)
  *		- CTL Base (IORESOURCE_IO or IORESOURCE_MEM)
- *
- *	and optionally:
- *
  *		- IRQ	   (IORESOURCE_IRQ)
  *
  *	If the base resources are both mem types, the ioremap() is handled
  *	here. For IORESOURCE_IO, it's assumed that there's no remapping
  *	necessary.
- *
- *	If no IRQ resource is present, PIO polling mode is used instead.
  */
-int __devinit __pata_platform_probe(struct device *dev,
-				    struct resource *io_res,
-				    struct resource *ctl_res,
-				    struct resource *irq_res,
-				    unsigned int ioport_shift,
-				    int __pio_mask)
+static int __devinit pata_platform_probe(struct platform_device *pdev)
 {
+	struct resource *io_res, *ctl_res;
 	struct ata_host *host;
 	struct ata_port *ap;
+	struct pata_platform_info *pp_info;
 	unsigned int mmio;
-	int irq = 0;
-	int irq_flags = 0;
 
 	/*
-	 * Check for MMIO
+	 * Simple resource validation ..
 	 */
-	mmio = (( io_res->flags == IORESOURCE_MEM) &&
-		(ctl_res->flags == IORESOURCE_MEM));
+	if (unlikely(pdev->num_resources != 3)) {
+		dev_err(&pdev->dev, "invalid number of resources\n");
+		return -EINVAL;
+	}
 
 	/*
-	 * And the IRQ
+	 * Get the I/O base first
+	 */
+	io_res = platform_get_resource(pdev, IORESOURCE_IO, 0);
+	if (io_res == NULL) {
+		io_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+		if (unlikely(io_res == NULL))
+			return -EINVAL;
+	}
+
+	/*
+	 * Then the CTL base
 	 */
-	if (irq_res && irq_res->start > 0) {
-		irq = irq_res->start;
-		irq_flags = irq_res->flags;
+	ctl_res = platform_get_resource(pdev, IORESOURCE_IO, 1);
+	if (ctl_res == NULL) {
+		ctl_res = platform_get_resource(pdev, IORESOURCE_MEM, 1);
+		if (unlikely(ctl_res == NULL))
+			return -EINVAL;
 	}
 
 	/*
+	 * Check for MMIO
+	 */
+	mmio = (( io_res->flags == IORESOURCE_MEM) &&
+		(ctl_res->flags == IORESOURCE_MEM));
+
+	/*
 	 * Now that that's out of the way, wire up the port..
 	 */
-	host = ata_host_alloc(dev, 1);
+	host = ata_host_alloc(&pdev->dev, 1);
 	if (!host)
 		return -ENOMEM;
 	ap = host->ports[0];
 
 	ap->ops = &pata_platform_port_ops;
-	ap->pio_mask = __pio_mask;
+	ap->pio_mask = pio_mask;
 	ap->flags |= ATA_FLAG_SLAVE_POSS;
 
 	/*
-	 * Use polling mode if there's no IRQ
-	 */
-	if (!irq) {
-		ap->flags |= ATA_FLAG_PIO_POLLING;
-		ata_port_desc(ap, "no IRQ, using PIO polling");
-	}
-
-	/*
 	 * Handle the MMIO case
 	 */
 	if (mmio) {
-		ap->ioaddr.cmd_addr = devm_ioremap(dev, io_res->start,
-				resource_size(io_res));
-		ap->ioaddr.ctl_addr = devm_ioremap(dev, ctl_res->start,
-				resource_size(ctl_res));
+		ap->ioaddr.cmd_addr = devm_ioremap(&pdev->dev, io_res->start,
+				io_res->end - io_res->start + 1);
+		ap->ioaddr.ctl_addr = devm_ioremap(&pdev->dev, ctl_res->start,
+				ctl_res->end - ctl_res->start + 1);
 	} else {
-		ap->ioaddr.cmd_addr = devm_ioport_map(dev, io_res->start,
-				resource_size(io_res));
-		ap->ioaddr.ctl_addr = devm_ioport_map(dev, ctl_res->start,
-				resource_size(ctl_res));
+		ap->ioaddr.cmd_addr = devm_ioport_map(&pdev->dev, io_res->start,
+				io_res->end - io_res->start + 1);
+		ap->ioaddr.ctl_addr = devm_ioport_map(&pdev->dev, ctl_res->start,
+				ctl_res->end - ctl_res->start + 1);
 	}
 	if (!ap->ioaddr.cmd_addr || !ap->ioaddr.ctl_addr) {
-		dev_err(dev, "failed to map IO/CTL base\n");
+		dev_err(&pdev->dev, "failed to map IO/CTL base\n");
 		return -ENOMEM;
 	}
 
 	ap->ioaddr.altstatus_addr = ap->ioaddr.ctl_addr;
 
-	pata_platform_setup_port(&ap->ioaddr, ioport_shift);
-
-	ata_port_desc(ap, "%s cmd 0x%llx ctl 0x%llx", mmio ? "mmio" : "ioport",
-		      (unsigned long long)io_res->start,
-		      (unsigned long long)ctl_res->start);
+	pp_info = (struct pata_platform_info *)(pdev->dev.platform_data);
+	pata_platform_setup_port(&ap->ioaddr, pp_info);
 
 	/* activate */
-	return ata_host_activate(host, irq, irq ? ata_sff_interrupt : NULL,
-				 irq_flags, &pata_platform_sht);
+	return ata_host_activate(host, platform_get_irq(pdev, 0),
+				 ata_interrupt, pp_info ? pp_info->irq_flags
+				 : 0, &pata_platform_sht);
 }
-EXPORT_SYMBOL_GPL(__pata_platform_probe);
 
 /**
- *	__pata_platform_remove		-	unplug a platform interface
- *	@dev: device
+ *	pata_platform_remove	-	unplug a platform interface
+ *	@pdev: platform device
  *
  *	A platform bus ATA device has been unplugged. Perform the needed
  *	cleanup. Also called on module unload for any active devices.
  */
-int __pata_platform_remove(struct device *dev)
+static int __devexit pata_platform_remove(struct platform_device *pdev)
 {
+	struct device *dev = &pdev->dev;
 	struct ata_host *host = dev_get_drvdata(dev);
 
 	ata_host_detach(host);
 
 	return 0;
 }
-EXPORT_SYMBOL_GPL(__pata_platform_remove);
-
-static int __devinit pata_platform_probe(struct platform_device *pdev)
-{
-	struct resource *io_res;
-	struct resource *ctl_res;
-	struct resource *irq_res;
-	struct pata_platform_info *pp_info = pdev->dev.platform_data;
-
-	/*
-	 * Simple resource validation ..
-	 */
-	if ((pdev->num_resources != 3) && (pdev->num_resources != 2)) {
-		dev_err(&pdev->dev, "invalid number of resources\n");
-		return -EINVAL;
-	}
-
-	/*
-	 * Get the I/O base first
-	 */
-	io_res = platform_get_resource(pdev, IORESOURCE_IO, 0);
-	if (io_res == NULL) {
-		io_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-		if (unlikely(io_res == NULL))
-			return -EINVAL;
-	}
-
-	/*
-	 * Then the CTL base
-	 */
-	ctl_res = platform_get_resource(pdev, IORESOURCE_IO, 1);
-	if (ctl_res == NULL) {
-		ctl_res = platform_get_resource(pdev, IORESOURCE_MEM, 1);
-		if (unlikely(ctl_res == NULL))
-			return -EINVAL;
-	}
-
-	/*
-	 * And the IRQ
-	 */
-	irq_res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
-	if (irq_res)
-		irq_res->flags = pp_info ? pp_info->irq_flags : 0;
-
-	return __pata_platform_probe(&pdev->dev, io_res, ctl_res, irq_res,
-				     pp_info ? pp_info->ioport_shift : 0,
-				     pio_mask);
-}
-
-static int __devexit pata_platform_remove(struct platform_device *pdev)
-{
-	return __pata_platform_remove(&pdev->dev);
-}
 
 static struct platform_driver pata_platform_driver = {
 	.probe		= pata_platform_probe,
@@ -286,4 +272,3 @@
 MODULE_DESCRIPTION("low-level driver for platform device ATA");
 MODULE_LICENSE("GPL");
 MODULE_VERSION(DRV_VERSION);
-MODULE_ALIAS("platform:" DRV_NAME);
diff -Nur linux-sh4/drivers/ata.org/pata_qdi.c linux-sh4/drivers/ata/pata_qdi.c
--- linux-sh4/drivers/ata.org/pata_qdi.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_qdi.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,6 @@
 /*
  *    pata_qdi.c - QDI VLB ATA controllers
- *	(C) 2006 Red Hat
+ *	(C) 2006 Red Hat <alan@redhat.com>
  *
  * This driver mostly exists as a proof of concept for non PCI devices under
  * libata. While the QDI6580 was 'neat' in 1993 it is no longer terribly
@@ -12,7 +12,7 @@
  *
  * Probe code based on drivers/ide/legacy/qd65xx.c
  * Rewritten from the work of Colten Edwards <pje120@cs.usask.ca> by
- * Samuel Thibault <samuel.thibault@ens-lyon.org>
+ * Samuel Thibault <samuel.thibault@fnac.net>
  */
 
 #include <linux/kernel.h>
@@ -60,11 +60,11 @@
 	ata_timing_compute(adev, adev->pio_mode, &t, 30303, 1000);
 
 	if (qdi->fast) {
-		active = 8 - clamp_val(t.active, 1, 8);
-		recovery = 18 - clamp_val(t.recover, 3, 18);
+		active = 8 - FIT(t.active, 1, 8);
+		recovery = 18 - FIT(t.recover, 3, 18);
 	} else {
-		active = 9 - clamp_val(t.active, 2, 9);
-		recovery = 15 - clamp_val(t.recover, 0, 15);
+		active = 9 - FIT(t.active, 2, 9);
+		recovery = 15 - FIT(t.recover, 0, 15);
 	}
 	timing = (recovery << 4) | active | 0x08;
 
@@ -84,11 +84,11 @@
 	ata_timing_compute(adev, adev->pio_mode, &t, 30303, 1000);
 
 	if (qdi->fast) {
-		active = 8 - clamp_val(t.active, 1, 8);
-		recovery = 18 - clamp_val(t.recover, 3, 18);
+		active = 8 - FIT(t.active, 1, 8);
+		recovery = 18 - FIT(t.recover, 3, 18);
 	} else {
-		active = 9 - clamp_val(t.active, 2, 9);
-		recovery = 15 - clamp_val(t.recover, 0, 15);
+		active = 9 - FIT(t.active, 2, 9);
+		recovery = 15 - FIT(t.recover, 0, 15);
 	}
 	timing = (recovery << 4) | active | 0x08;
 
@@ -102,14 +102,14 @@
 }
 
 /**
- *	qdi_qc_issue		-	command issue
+ *	qdi_qc_issue_prot	-	command issue
  *	@qc: command pending
  *
  *	Called when the libata layer is about to issue a command. We wrap
  *	this interface so that we can load the correct ATA timings.
  */
 
-static unsigned int qdi_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int qdi_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
@@ -121,53 +121,108 @@
 			outb(qdi->clock[adev->devno], qdi->timing);
 		}
 	}
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
-static unsigned int qdi_data_xfer(struct ata_device *dev, unsigned char *buf,
-				  unsigned int buflen, int rw)
+static void qdi_data_xfer(struct ata_device *adev, unsigned char *buf, unsigned int buflen, int write_data)
 {
-	if (ata_id_has_dword_io(dev->id)) {
-		struct ata_port *ap = dev->link->ap;
-		int slop = buflen & 3;
+	struct ata_port *ap = adev->ap;
+	int slop = buflen & 3;
 
-		if (rw == READ)
-			ioread32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
-		else
+	if (ata_id_has_dword_io(adev->id)) {
+		if (write_data)
 			iowrite32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
+		else
+			ioread32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
 
 		if (unlikely(slop)) {
-			__le32 pad;
-			if (rw == READ) {
-				pad = cpu_to_le32(ioread32(ap->ioaddr.data_addr));
-				memcpy(buf + buflen - slop, &pad, slop);
-			} else {
+			u32 pad;
+			if (write_data) {
 				memcpy(&pad, buf + buflen - slop, slop);
-				iowrite32(le32_to_cpu(pad), ap->ioaddr.data_addr);
+				pad = le32_to_cpu(pad);
+				iowrite32(pad, ap->ioaddr.data_addr);
+			} else {
+				pad = ioread32(ap->ioaddr.data_addr);
+				pad = cpu_to_le32(pad);
+				memcpy(buf + buflen - slop, &pad, slop);
 			}
-			buflen += 4 - slop;
 		}
 	} else
-		buflen = ata_sff_data_xfer(dev, buf, buflen, rw);
-
-	return buflen;
+		ata_data_xfer(adev, buf, buflen, write_data);
 }
 
 static struct scsi_host_template qdi_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations qdi6500_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.qc_issue	= qdi_qc_issue,
-	.sff_data_xfer	= qdi_data_xfer,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= qdi6500_set_piomode,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= qdi_qc_issue_prot,
+
+	.data_xfer	= qdi_data_xfer,
+
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations qdi6580_port_ops = {
-	.inherits	= &qdi6500_port_ops,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= qdi6580_set_piomode,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= qdi_qc_issue_prot,
+
+	.data_xfer	= qdi_data_xfer,
+
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -183,7 +238,6 @@
 
 static __init int qdi_init_one(unsigned long port, int type, unsigned long io, int irq, int fast)
 {
-	unsigned long ctl = io + 0x206;
 	struct platform_device *pdev;
 	struct ata_host *host;
 	struct ata_port *ap;
@@ -200,7 +254,7 @@
 
 	ret = -ENOMEM;
 	io_addr = devm_ioport_map(&pdev->dev, io, 8);
-	ctl_addr = devm_ioport_map(&pdev->dev, ctl, 1);
+	ctl_addr = devm_ioport_map(&pdev->dev, io + 0x206, 1);
 	if (!io_addr || !ctl_addr)
 		goto fail;
 
@@ -212,20 +266,18 @@
 
 	if (type == 6580) {
 		ap->ops = &qdi6580_port_ops;
-		ap->pio_mask = ATA_PIO4;
+		ap->pio_mask = 0x1F;
 		ap->flags |= ATA_FLAG_SLAVE_POSS;
 	} else {
 		ap->ops = &qdi6500_port_ops;
-		ap->pio_mask = ATA_PIO2; /* Actually PIO3 !IORDY is possible */
+		ap->pio_mask = 0x07;	/* Actually PIO3 !IORDY is possible */
 		ap->flags = ATA_FLAG_SLAVE_POSS | ATA_FLAG_NO_IORDY;
 	}
 
 	ap->ioaddr.cmd_addr = io_addr;
 	ap->ioaddr.altstatus_addr = ctl_addr;
 	ap->ioaddr.ctl_addr = ctl_addr;
-	ata_sff_std_ports(&ap->ioaddr);
-
-	ata_port_desc(ap, "cmd %lx ctl %lx", io, ctl);
+	ata_std_ports(&ap->ioaddr);
 
 	/*
 	 *	Hook in a private data structure per channel
@@ -239,7 +291,7 @@
 	printk(KERN_INFO DRV_NAME": qd%d at 0x%lx.\n", type, io);
 
 	/* activate */
-	ret = ata_host_activate(host, irq, ata_sff_interrupt, 0, &qdi_sht);
+	ret = ata_host_activate(host, irq, ata_interrupt, 0, &qdi_sht);
 	if (ret)
 		goto fail;
 
diff -Nur linux-sh4/drivers/ata.org/pata_radisys.c linux-sh4/drivers/ata/pata_radisys.c
--- linux-sh4/drivers/ata.org/pata_radisys.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_radisys.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  *    pata_radisys.c - Intel PATA/SATA controllers
  *
- *	(C) 2006 Red Hat <alan@lxorguk.ukuu.org.uk>
+ *	(C) 2006 Red Hat <alan@redhat.com>
  *
  *    Some parts based on ata_piix.c by Jeff Garzik and others.
  *
@@ -81,6 +81,7 @@
  *	radisys_set_dmamode - Initialize host controller PATA DMA timings
  *	@ap: Port whose timings we are configuring
  *	@adev: Device to program
+ *	@isich: True if the device is an ICH and has IOCFG registers
  *
  *	Set MWDMA mode for device, in host controller PCI config space.
  *
@@ -155,17 +156,17 @@
 }
 
 /**
- *	radisys_qc_issue	-	command issue
+ *	radisys_qc_issue_prot	-	command issue
  *	@qc: command pending
  *
  *	Called when the libata layer is about to issue a command. We wrap
  *	this interface so that we can load the correct ATA timings if
- *	necessary. Our logic also clears TIME0/TIME1 for the other device so
+ *	neccessary. Our logic also clears TIME0/TIME1 for the other device so
  *	that, even if we get this wrong, cycles to the other device will
  *	be made PIO0.
  */
 
-static unsigned int radisys_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int radisys_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
@@ -179,20 +180,60 @@
 				radisys_set_piomode(ap, adev);
 		}
 	}
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 
 static struct scsi_host_template radisys_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations radisys_pata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.qc_issue		= radisys_qc_issue,
-	.cable_detect		= ata_cable_unknown,
+static const struct ata_port_operations radisys_pata_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= radisys_set_piomode,
 	.set_dmamode		= radisys_set_dmamode,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ata_cable_unknown,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= radisys_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 
@@ -215,10 +256,11 @@
 {
 	static int printed_version;
 	static const struct ata_port_info info = {
+		.sht		= &radisys_sht,
 		.flags		= ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA12_ONLY,
-		.udma_mask	= ATA_UDMA24_ONLY,
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma1-2 */
+		.udma_mask	= 0x14, /* UDMA33/66 only */
 		.port_ops	= &radisys_pata_ops,
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
@@ -227,7 +269,7 @@
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "version " DRV_VERSION "\n");
 
-	return ata_pci_sff_init_one(pdev, ppi, &radisys_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id radisys_pci_tbl[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_rb532_cf.c linux-sh4/drivers/ata/pata_rb532_cf.c
--- linux-sh4/drivers/ata.org/pata_rb532_cf.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_rb532_cf.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,226 +0,0 @@
-/*
- *  A low-level PATA driver to handle a Compact Flash connected on the
- *  Mikrotik's RouterBoard 532 board.
- *
- *  Copyright (C) 2007 Gabor Juhos <juhosg at openwrt.org>
- *  Copyright (C) 2008 Florian Fainelli <florian@openwrt.org>
- *
- *  This file was based on: drivers/ata/pata_ixp4xx_cf.c
- *	Copyright (C) 2006-07 Tower Technologies
- *	Author: Alessandro Zummo <a.zummo@towertech.it>
- *
- *  Also was based on the driver for Linux 2.4.xx published by Mikrotik for
- *  their RouterBoard 1xx and 5xx series devices. The original Mikrotik code
- *  seems not to have a license.
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License version 2 as
- *  published by the Free Software Foundation.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/platform_device.h>
-
-#include <linux/io.h>
-#include <linux/interrupt.h>
-#include <linux/irq.h>
-
-#include <linux/libata.h>
-#include <scsi/scsi_host.h>
-
-#include <asm/gpio.h>
-
-#define DRV_NAME	"pata-rb532-cf"
-#define DRV_VERSION	"0.1.0"
-#define DRV_DESC	"PATA driver for RouterBOARD 532 Compact Flash"
-
-#define RB500_CF_MAXPORTS	1
-#define RB500_CF_IO_DELAY	400
-
-#define RB500_CF_REG_BASE	0x0800
-#define RB500_CF_REG_ERR	0x080D
-#define RB500_CF_REG_CTRL	0x080E
-/* 32bit buffered data register offset */
-#define RB500_CF_REG_DBUF32	0x0C00
-
-struct rb532_cf_info {
-	void __iomem	*iobase;
-	unsigned int	gpio_line;
-	unsigned int	irq;
-};
-
-/* ------------------------------------------------------------------------ */
-
-static irqreturn_t rb532_pata_irq_handler(int irq, void *dev_instance)
-{
-	struct ata_host *ah = dev_instance;
-	struct rb532_cf_info *info = ah->private_data;
-
-	if (gpio_get_value(info->gpio_line)) {
-		set_irq_type(info->irq, IRQ_TYPE_LEVEL_LOW);
-		ata_sff_interrupt(info->irq, dev_instance);
-	} else {
-		set_irq_type(info->irq, IRQ_TYPE_LEVEL_HIGH);
-	}
-
-	return IRQ_HANDLED;
-}
-
-static struct ata_port_operations rb532_pata_port_ops = {
-	.inherits		= &ata_sff_port_ops,
-	.sff_data_xfer		= ata_sff_data_xfer32,
-};
-
-/* ------------------------------------------------------------------------ */
-
-static struct scsi_host_template rb532_pata_sht = {
-	ATA_PIO_SHT(DRV_NAME),
-};
-
-/* ------------------------------------------------------------------------ */
-
-static void rb532_pata_setup_ports(struct ata_host *ah)
-{
-	struct rb532_cf_info *info = ah->private_data;
-	struct ata_port *ap;
-
-	ap = ah->ports[0];
-
-	ap->ops		= &rb532_pata_port_ops;
-	ap->pio_mask	= ATA_PIO4;
-	ap->flags	= ATA_FLAG_NO_LEGACY | ATA_FLAG_MMIO;
-
-	ap->ioaddr.cmd_addr	= info->iobase + RB500_CF_REG_BASE;
-	ap->ioaddr.ctl_addr	= info->iobase + RB500_CF_REG_CTRL;
-	ap->ioaddr.altstatus_addr = info->iobase + RB500_CF_REG_CTRL;
-
-	ata_sff_std_ports(&ap->ioaddr);
-
-	ap->ioaddr.data_addr	= info->iobase + RB500_CF_REG_DBUF32;
-	ap->ioaddr.error_addr	= info->iobase + RB500_CF_REG_ERR;
-}
-
-static __devinit int rb532_pata_driver_probe(struct platform_device *pdev)
-{
-	int irq;
-	int gpio;
-	struct resource *res;
-	struct ata_host *ah;
-	struct rb532_cf_info *info;
-	int ret;
-
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	if (!res) {
-		dev_err(&pdev->dev, "no IOMEM resource found\n");
-		return -EINVAL;
-	}
-
-	irq = platform_get_irq(pdev, 0);
-	if (irq <= 0) {
-		dev_err(&pdev->dev, "no IRQ resource found\n");
-		return -ENOENT;
-	}
-
-	gpio = irq_to_gpio(irq);
-	if (gpio < 0) {
-		dev_err(&pdev->dev, "no GPIO found for irq%d\n", irq);
-		return -ENOENT;
-	}
-
-	ret = gpio_request(gpio, DRV_NAME);
-	if (ret) {
-		dev_err(&pdev->dev, "GPIO request failed\n");
-		return ret;
-	}
-
-	/* allocate host */
-	ah = ata_host_alloc(&pdev->dev, RB500_CF_MAXPORTS);
-	if (!ah)
-		return -ENOMEM;
-
-	platform_set_drvdata(pdev, ah);
-
-	info = devm_kzalloc(&pdev->dev, sizeof(*info), GFP_KERNEL);
-	if (!info)
-		return -ENOMEM;
-
-	ah->private_data = info;
-	info->gpio_line = gpio;
-	info->irq = irq;
-
-	info->iobase = devm_ioremap_nocache(&pdev->dev, res->start,
-				resource_size(res));
-	if (!info->iobase)
-		return -ENOMEM;
-
-	ret = gpio_direction_input(gpio);
-	if (ret) {
-		dev_err(&pdev->dev, "unable to set GPIO direction, err=%d\n",
-				ret);
-		goto err_free_gpio;
-	}
-
-	rb532_pata_setup_ports(ah);
-
-	ret = ata_host_activate(ah, irq, rb532_pata_irq_handler,
-				IRQF_TRIGGER_LOW, &rb532_pata_sht);
-	if (ret)
-		goto err_free_gpio;
-
-	return 0;
-
-err_free_gpio:
-	gpio_free(gpio);
-
-	return ret;
-}
-
-static __devexit int rb532_pata_driver_remove(struct platform_device *pdev)
-{
-	struct ata_host *ah = platform_get_drvdata(pdev);
-	struct rb532_cf_info *info = ah->private_data;
-
-	ata_host_detach(ah);
-	gpio_free(info->gpio_line);
-
-	return 0;
-}
-
-/* work with hotplug and coldplug */
-MODULE_ALIAS("platform:" DRV_NAME);
-
-static struct platform_driver rb532_pata_platform_driver = {
-	.probe		= rb532_pata_driver_probe,
-	.remove		= __devexit_p(rb532_pata_driver_remove),
-	.driver	 = {
-		.name   = DRV_NAME,
-		.owner  = THIS_MODULE,
-	},
-};
-
-/* ------------------------------------------------------------------------ */
-
-#define DRV_INFO DRV_DESC " version " DRV_VERSION
-
-static int __init rb532_pata_module_init(void)
-{
-	printk(KERN_INFO DRV_INFO "\n");
-
-	return platform_driver_register(&rb532_pata_platform_driver);
-}
-
-static void __exit rb532_pata_module_exit(void)
-{
-	platform_driver_unregister(&rb532_pata_platform_driver);
-}
-
-MODULE_AUTHOR("Gabor Juhos <juhosg at openwrt.org>");
-MODULE_AUTHOR("Florian Fainelli <florian@openwrt.org>");
-MODULE_DESCRIPTION(DRV_DESC);
-MODULE_VERSION(DRV_VERSION);
-MODULE_LICENSE("GPL");
-
-module_init(rb532_pata_module_init);
-module_exit(rb532_pata_module_exit);
diff -Nur linux-sh4/drivers/ata.org/pata_rdc.c linux-sh4/drivers/ata/pata_rdc.c
--- linux-sh4/drivers/ata.org/pata_rdc.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_rdc.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,400 +0,0 @@
-/*
- *  pata_rdc		-	Driver for later RDC PATA controllers
- *
- *  This is actually a driver for hardware meeting
- *  INCITS 370-2004 (1510D): ATA Host Adapter Standards
- *
- *  Based on ata_piix.
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License as published by
- *  the Free Software Foundation; either version 2, or (at your option)
- *  any later version.
- *
- *  This program is distributed in the hope that it will be useful,
- *  but WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *  GNU General Public License for more details.
- *
- *  You should have received a copy of the GNU General Public License
- *  along with this program; see the file COPYING.  If not, write to
- *  the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <linux/delay.h>
-#include <linux/device.h>
-#include <scsi/scsi_host.h>
-#include <linux/libata.h>
-#include <linux/dmi.h>
-
-#define DRV_NAME	"pata_rdc"
-#define DRV_VERSION	"0.01"
-
-struct rdc_host_priv {
-	u32 saved_iocfg;
-};
-
-/**
- *	rdc_pata_cable_detect - Probe host controller cable detect info
- *	@ap: Port for which cable detect info is desired
- *
- *	Read 80c cable indicator from ATA PCI device's PCI config
- *	register.  This register is normally set by firmware (BIOS).
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static int rdc_pata_cable_detect(struct ata_port *ap)
-{
-	struct rdc_host_priv *hpriv = ap->host->private_data;
-	u8 mask;
-
-	/* check BIOS cable detect results */
-	mask = 0x30 << (2 * ap->port_no);
-	if ((hpriv->saved_iocfg & mask) == 0)
-		return ATA_CBL_PATA40;
-	return ATA_CBL_PATA80;
-}
-
-/**
- *	rdc_pata_prereset - prereset for PATA host controller
- *	@link: Target link
- *	@deadline: deadline jiffies for the operation
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-static int rdc_pata_prereset(struct ata_link *link, unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-
-	static const struct pci_bits rdc_enable_bits[] = {
-		{ 0x41U, 1U, 0x80UL, 0x80UL },	/* port 0 */
-		{ 0x43U, 1U, 0x80UL, 0x80UL },	/* port 1 */
-	};
-
-	if (!pci_test_config_bits(pdev, &rdc_enable_bits[ap->port_no]))
-		return -ENOENT;
-	return ata_sff_prereset(link, deadline);
-}
-
-/**
- *	rdc_set_piomode - Initialize host controller PATA PIO timings
- *	@ap: Port whose timings we are configuring
- *	@adev: um
- *
- *	Set PIO mode for device, in host controller PCI config space.
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static void rdc_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	unsigned int pio	= adev->pio_mode - XFER_PIO_0;
-	struct pci_dev *dev	= to_pci_dev(ap->host->dev);
-	unsigned int is_slave	= (adev->devno != 0);
-	unsigned int master_port= ap->port_no ? 0x42 : 0x40;
-	unsigned int slave_port	= 0x44;
-	u16 master_data;
-	u8 slave_data;
-	u8 udma_enable;
-	int control = 0;
-
-	static const	 /* ISP  RTC */
-	u8 timings[][2]	= { { 0, 0 },
-			    { 0, 0 },
-			    { 1, 0 },
-			    { 2, 1 },
-			    { 2, 3 }, };
-
-	if (pio >= 2)
-		control |= 1;	/* TIME1 enable */
-	if (ata_pio_need_iordy(adev))
-		control |= 2;	/* IE enable */
-
-	if (adev->class == ATA_DEV_ATA)
-		control |= 4;	/* PPE enable */
-
-	/* PIO configuration clears DTE unconditionally.  It will be
-	 * programmed in set_dmamode which is guaranteed to be called
-	 * after set_piomode if any DMA mode is available.
-	 */
-	pci_read_config_word(dev, master_port, &master_data);
-	if (is_slave) {
-		/* clear TIME1|IE1|PPE1|DTE1 */
-		master_data &= 0xff0f;
-		/* Enable SITRE (separate slave timing register) */
-		master_data |= 0x4000;
-		/* enable PPE1, IE1 and TIME1 as needed */
-		master_data |= (control << 4);
-		pci_read_config_byte(dev, slave_port, &slave_data);
-		slave_data &= (ap->port_no ? 0x0f : 0xf0);
-		/* Load the timing nibble for this slave */
-		slave_data |= ((timings[pio][0] << 2) | timings[pio][1])
-						<< (ap->port_no ? 4 : 0);
-	} else {
-		/* clear ISP|RCT|TIME0|IE0|PPE0|DTE0 */
-		master_data &= 0xccf0;
-		/* Enable PPE, IE and TIME as appropriate */
-		master_data |= control;
-		/* load ISP and RCT */
-		master_data |=
-			(timings[pio][0] << 12) |
-			(timings[pio][1] << 8);
-	}
-	pci_write_config_word(dev, master_port, master_data);
-	if (is_slave)
-		pci_write_config_byte(dev, slave_port, slave_data);
-
-	/* Ensure the UDMA bit is off - it will be turned back on if
-	   UDMA is selected */
-
-	pci_read_config_byte(dev, 0x48, &udma_enable);
-	udma_enable &= ~(1 << (2 * ap->port_no + adev->devno));
-	pci_write_config_byte(dev, 0x48, udma_enable);
-}
-
-/**
- *	rdc_set_dmamode - Initialize host controller PATA PIO timings
- *	@ap: Port whose timings we are configuring
- *	@adev: Drive in question
- *
- *	Set UDMA mode for device, in host controller PCI config space.
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static void rdc_set_dmamode(struct ata_port *ap, struct ata_device *adev)
-{
-	struct pci_dev *dev	= to_pci_dev(ap->host->dev);
-	u8 master_port		= ap->port_no ? 0x42 : 0x40;
-	u16 master_data;
-	u8 speed		= adev->dma_mode;
-	int devid		= adev->devno + 2 * ap->port_no;
-	u8 udma_enable		= 0;
-
-	static const	 /* ISP  RTC */
-	u8 timings[][2]	= { { 0, 0 },
-			    { 0, 0 },
-			    { 1, 0 },
-			    { 2, 1 },
-			    { 2, 3 }, };
-
-	pci_read_config_word(dev, master_port, &master_data);
-	pci_read_config_byte(dev, 0x48, &udma_enable);
-
-	if (speed >= XFER_UDMA_0) {
-		unsigned int udma = adev->dma_mode - XFER_UDMA_0;
-		u16 udma_timing;
-		u16 ideconf;
-		int u_clock, u_speed;
-
-		/*
-		 * UDMA is handled by a combination of clock switching and
-		 * selection of dividers
-		 *
-		 * Handy rule: Odd modes are UDMATIMx 01, even are 02
-		 *	       except UDMA0 which is 00
-		 */
-		u_speed = min(2 - (udma & 1), udma);
-		if (udma == 5)
-			u_clock = 0x1000;	/* 100Mhz */
-		else if (udma > 2)
-			u_clock = 1;		/* 66Mhz */
-		else
-			u_clock = 0;		/* 33Mhz */
-
-		udma_enable |= (1 << devid);
-
-		/* Load the CT/RP selection */
-		pci_read_config_word(dev, 0x4A, &udma_timing);
-		udma_timing &= ~(3 << (4 * devid));
-		udma_timing |= u_speed << (4 * devid);
-		pci_write_config_word(dev, 0x4A, udma_timing);
-
-		/* Select a 33/66/100Mhz clock */
-		pci_read_config_word(dev, 0x54, &ideconf);
-		ideconf &= ~(0x1001 << devid);
-		ideconf |= u_clock << devid;
-		pci_write_config_word(dev, 0x54, ideconf);
-	} else {
-		/*
-		 * MWDMA is driven by the PIO timings. We must also enable
-		 * IORDY unconditionally along with TIME1. PPE has already
-		 * been set when the PIO timing was set.
-		 */
-		unsigned int mwdma	= adev->dma_mode - XFER_MW_DMA_0;
-		unsigned int control;
-		u8 slave_data;
-		const unsigned int needed_pio[3] = {
-			XFER_PIO_0, XFER_PIO_3, XFER_PIO_4
-		};
-		int pio = needed_pio[mwdma] - XFER_PIO_0;
-
-		control = 3;	/* IORDY|TIME1 */
-
-		/* If the drive MWDMA is faster than it can do PIO then
-		   we must force PIO into PIO0 */
-
-		if (adev->pio_mode < needed_pio[mwdma])
-			/* Enable DMA timing only */
-			control |= 8;	/* PIO cycles in PIO0 */
-
-		if (adev->devno) {	/* Slave */
-			master_data &= 0xFF4F;  /* Mask out IORDY|TIME1|DMAONLY */
-			master_data |= control << 4;
-			pci_read_config_byte(dev, 0x44, &slave_data);
-			slave_data &= (ap->port_no ? 0x0f : 0xf0);
-			/* Load the matching timing */
-			slave_data |= ((timings[pio][0] << 2) | timings[pio][1]) << (ap->port_no ? 4 : 0);
-			pci_write_config_byte(dev, 0x44, slave_data);
-		} else { 	/* Master */
-			master_data &= 0xCCF4;	/* Mask out IORDY|TIME1|DMAONLY
-						   and master timing bits */
-			master_data |= control;
-			master_data |=
-				(timings[pio][0] << 12) |
-				(timings[pio][1] << 8);
-		}
-
-		udma_enable &= ~(1 << devid);
-		pci_write_config_word(dev, master_port, master_data);
-	}
-	pci_write_config_byte(dev, 0x48, udma_enable);
-}
-
-static struct ata_port_operations rdc_pata_ops = {
-	.inherits		= &ata_bmdma32_port_ops,
-	.cable_detect		= rdc_pata_cable_detect,
-	.set_piomode		= rdc_set_piomode,
-	.set_dmamode		= rdc_set_dmamode,
-	.prereset		= rdc_pata_prereset,
-};
-
-static struct ata_port_info rdc_port_info = {
-
-	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	.mwdma_mask	= ATA_MWDMA2,
-	.udma_mask	= ATA_UDMA5,
-	.port_ops	= &rdc_pata_ops,
-};
-
-static struct scsi_host_template rdc_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-/**
- *	rdc_init_one - Register PIIX ATA PCI device with kernel services
- *	@pdev: PCI device to register
- *	@ent: Entry in rdc_pci_tbl matching with @pdev
- *
- *	Called from kernel PCI layer.  We probe for combined mode (sigh),
- *	and then hand over control to libata, for it to do the rest.
- *
- *	LOCKING:
- *	Inherited from PCI layer (may sleep).
- *
- *	RETURNS:
- *	Zero on success, or -ERRNO value.
- */
-
-static int __devinit rdc_init_one(struct pci_dev *pdev,
-				   const struct pci_device_id *ent)
-{
-	static int printed_version;
-	struct device *dev = &pdev->dev;
-	struct ata_port_info port_info[2];
-	const struct ata_port_info *ppi[] = { &port_info[0], &port_info[1] };
-	unsigned long port_flags;
-	struct ata_host *host;
-	struct rdc_host_priv *hpriv;
-	int rc;
-
-	if (!printed_version++)
-		dev_printk(KERN_DEBUG, &pdev->dev,
-			   "version " DRV_VERSION "\n");
-
-	port_info[0] = rdc_port_info;
-	port_info[1] = rdc_port_info;
-
-	port_flags = port_info[0].flags;
-
-	/* enable device and prepare host */
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
-	hpriv = devm_kzalloc(dev, sizeof(*hpriv), GFP_KERNEL);
-	if (!hpriv)
-		return -ENOMEM;
-
-	/* Save IOCFG, this will be used for cable detection, quirk
-	 * detection and restoration on detach.
-	 */
-	pci_read_config_dword(pdev, 0x54, &hpriv->saved_iocfg);
-
-	rc = ata_pci_sff_prepare_host(pdev, ppi, &host);
-	if (rc)
-		return rc;
-	host->private_data = hpriv;
-
-	pci_intx(pdev, 1);
-
-	host->flags |= ATA_HOST_PARALLEL_SCAN;
-
-	pci_set_master(pdev);
-	return ata_pci_sff_activate_host(host, ata_sff_interrupt, &rdc_sht);
-}
-
-static void rdc_remove_one(struct pci_dev *pdev)
-{
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	struct rdc_host_priv *hpriv = host->private_data;
-
-	pci_write_config_dword(pdev, 0x54, hpriv->saved_iocfg);
-
-	ata_pci_remove_one(pdev);
-}
-
-static const struct pci_device_id rdc_pci_tbl[] = {
-	{ PCI_DEVICE(0x17F3, 0x1011), },
-	{ PCI_DEVICE(0x17F3, 0x1012), },
-	{ }	/* terminate list */
-};
-
-static struct pci_driver rdc_pci_driver = {
-	.name			= DRV_NAME,
-	.id_table		= rdc_pci_tbl,
-	.probe			= rdc_init_one,
-	.remove			= rdc_remove_one,
-};
-
-
-static int __init rdc_init(void)
-{
-	return pci_register_driver(&rdc_pci_driver);
-}
-
-static void __exit rdc_exit(void)
-{
-	pci_unregister_driver(&rdc_pci_driver);
-}
-
-module_init(rdc_init);
-module_exit(rdc_exit);
-
-MODULE_AUTHOR("Alan Cox (based on ata_piix)");
-MODULE_DESCRIPTION("SCSI low-level driver for RDC PATA controllers");
-MODULE_LICENSE("GPL");
-MODULE_DEVICE_TABLE(pci, rdc_pci_tbl);
-MODULE_VERSION(DRV_VERSION);
diff -Nur linux-sh4/drivers/ata.org/pata_rz1000.c linux-sh4/drivers/ata/pata_rz1000.c
--- linux-sh4/drivers/ata.org/pata_rz1000.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_rz1000.c	2012-01-15 06:30:15.000000000 -0800
@@ -26,7 +26,7 @@
 
 /**
  *	rz1000_set_mode		-	mode setting function
- *	@link: ATA link
+ *	@ap: ATA interface
  *	@unused: returned device on set_mode failure
  *
  *	Use a non standard set_mode function. We don't want to be tuned. We
@@ -34,30 +34,75 @@
  *	whacked out.
  */
 
-static int rz1000_set_mode(struct ata_link *link, struct ata_device **unused)
+static int rz1000_set_mode(struct ata_port *ap, struct ata_device **unused)
 {
-	struct ata_device *dev;
+	int i;
 
-	ata_for_each_dev(dev, link, ENABLED) {
-		/* We don't really care */
-		dev->pio_mode = XFER_PIO_0;
-		dev->xfer_mode = XFER_PIO_0;
-		dev->xfer_shift = ATA_SHIFT_PIO;
-		dev->flags |= ATA_DFLAG_PIO;
-		ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
+	for (i = 0; i < ATA_MAX_DEVICES; i++) {
+		struct ata_device *dev = &ap->device[i];
+		if (ata_dev_enabled(dev)) {
+			/* We don't really care */
+			dev->pio_mode = XFER_PIO_0;
+			dev->xfer_mode = XFER_PIO_0;
+			dev->xfer_shift = ATA_SHIFT_PIO;
+			dev->flags |= ATA_DFLAG_PIO;
+			ata_dev_printk(dev, KERN_INFO, "configured for PIO\n");
+		}
 	}
 	return 0;
 }
 
 
 static struct scsi_host_template rz1000_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations rz1000_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.cable_detect	= ata_cable_40wire,
 	.set_mode	= rz1000_set_mode,
+
+	.port_disable	= ata_port_disable,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int rz1000_fifo_disable(struct pci_dev *pdev)
@@ -85,17 +130,20 @@
 
 static int rz1000_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
+	static int printed_version;
 	static const struct ata_port_info info = {
+		.sht = &rz1000_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
+		.pio_mask = 0x1f,
 		.port_ops = &rz1000_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
 
-	printk_once(KERN_DEBUG DRV_NAME " version " DRV_VERSION "\n");
+	if (!printed_version++)
+		printk(KERN_DEBUG DRV_NAME " version " DRV_VERSION "\n");
 
 	if (rz1000_fifo_disable(pdev) == 0)
-		return ata_pci_sff_init_one(pdev, ppi, &rz1000_sht, NULL);
+		return ata_pci_init_one(pdev, ppi);
 
 	printk(KERN_ERR DRV_NAME ": failed to disable read-ahead on chipset..\n");
 	/* Not safe to use so skip */
diff -Nur linux-sh4/drivers/ata.org/pata_sc1200.c linux-sh4/drivers/ata/pata_sc1200.c
--- linux-sh4/drivers/ata.org/pata_sc1200.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_sc1200.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,8 @@
 /*
- * New ATA layer SC1200 driver		Alan Cox <alan@lxorguk.ukuu.org.uk>
+ * New ATA layer SC1200 driver		Alan Cox <alan@redhat.com>
  *
  * TODO: Mode selection filtering
+ * TODO: Can't enable second channel until ATA core has serialize
  * TODO: Needs custom DMA cleanup code
  *
  * Based very heavily on
@@ -150,71 +151,85 @@
 }
 
 /**
- *	sc1200_qc_issue		-	command issue
+ *	sc1200_qc_issue_prot	-	command issue
  *	@qc: command pending
  *
  *	Called when the libata layer is about to issue a command. We wrap
  *	this interface so that we can load the correct ATA timings if
- *	necessary.  Specifically we have a problem that there is only
+ *	neccessary.  Specifically we have a problem that there is only
  *	one MWDMA/UDMA bit.
  */
 
-static unsigned int sc1200_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int sc1200_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct ata_device *adev = qc->dev;
 	struct ata_device *prev = ap->private_data;
 
 	/* See if the DMA settings could be wrong */
-	if (ata_dma_enabled(adev) && adev != prev && prev != NULL) {
+	if (adev->dma_mode != 0 && adev != prev && prev != NULL) {
 		/* Maybe, but do the channels match MWDMA/UDMA ? */
-		if ((ata_using_udma(adev) && !ata_using_udma(prev)) ||
-		    (ata_using_udma(prev) && !ata_using_udma(adev)))
+		if ((adev->dma_mode >= XFER_UDMA_0 && prev->dma_mode < XFER_UDMA_0) ||
+		    (adev->dma_mode < XFER_UDMA_0 && prev->dma_mode >= XFER_UDMA_0))
 		    	/* Switch the mode bits */
 		    	sc1200_set_dmamode(ap, adev);
 	}
 
-	return ata_sff_qc_issue(qc);
-}
-
-/**
- *	sc1200_qc_defer	-	implement serialization
- *	@qc: command
- *
- *	Serialize command issue on this controller.
- */
-
-static int sc1200_qc_defer(struct ata_queued_cmd *qc)
-{
-	struct ata_host *host = qc->ap->host;
-	struct ata_port *alt = host->ports[1 ^ qc->ap->port_no];
-	int rc;
-
-	/* First apply the usual rules */
-	rc = ata_std_qc_defer(qc);
-	if (rc != 0)
-		return rc;
-
-	/* Now apply serialization rules. Only allow a command if the
-	   other channel state machine is idle */
-	if (alt && alt->qc_active)
-		return	ATA_DEFER_PORT;
-	return 0;
+	return ata_qc_issue_prot(qc);
 }
 
 static struct scsi_host_template sc1200_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-	.sg_tablesize	= LIBATA_DUMB_MAX_PRD,
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_DUMB_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations sc1200_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.qc_prep 	= ata_sff_dumb_qc_prep,
-	.qc_issue	= sc1200_qc_issue,
-	.qc_defer	= sc1200_qc_defer,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= sc1200_set_piomode,
 	.set_dmamode	= sc1200_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_dumb_qc_prep,
+	.qc_issue	= sc1200_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -229,15 +244,17 @@
 static int sc1200_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &sc1200_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
-		.udma_mask = ATA_UDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
+		.udma_mask = 0x07,
 		.port_ops = &sc1200_port_ops
 	};
-	const struct ata_port_info *ppi[] = { &info, NULL };
+	/* Can't enable port 2 yet, see top comments */
+	const struct ata_port_info *ppi[] = { &info, &ata_dummy_port_info };
 
-	return ata_pci_sff_init_one(dev, ppi, &sc1200_sht, NULL);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id sc1200[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_scc.c linux-sh4/drivers/ata/pata_scc.c
--- linux-sh4/drivers/ata.org/pata_scc.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_scc.c	2012-01-15 06:30:15.000000000 -0800
@@ -8,7 +8,7 @@
  *  Copyright 2003-2005 Jeff Garzik
  *  Copyright (C) 1998-1999 Andrzej Krzysztofowicz, Author and Maintainer
  *  Copyright (C) 1998-2000 Andre Hedrick <andre@linux-ide.org>
- *  Copyright (C) 2003 Red Hat Inc
+ *  Copyright (C) 2003 Red Hat Inc <alan@redhat.com>
  *
  * and drivers/ata/ahci.c:
  *  Copyright 2004-2005 Red Hat, Inc.
@@ -210,6 +210,7 @@
  *	scc_set_dmamode - Initialize host controller PATA DMA timings
  *	@ap: Port whose timings we are configuring
  *	@adev: um
+ *	@udma: udma mode, 0 - 6
  *
  *	Set UDMA mode for device.
  *
@@ -265,7 +266,7 @@
 		printk(KERN_INFO "%s: limit ATAPI UDMA to UDMA4\n", DRV_NAME);
 		mask &= ~(0xE0 << ATA_SHIFT_UDMA);
 	}
-	return ata_bmdma_mode_filter(adev, mask);
+	return ata_pci_default_filter(adev, mask);
 }
 
 /**
@@ -273,7 +274,7 @@
  *	@ap: Port to which output is sent
  *	@tf: ATA taskfile register set
  *
- *	Note: Original code is ata_sff_tf_load().
+ *	Note: Original code is ata_tf_load().
  */
 
 static void scc_tf_load (struct ata_port *ap, const struct ata_taskfile *tf)
@@ -340,7 +341,7 @@
  *	@ap: Port from which input is read
  *	@tf: ATA taskfile register set for storing input
  *
- *	Note: Original code is ata_sff_tf_read().
+ *	Note: Original code is ata_tf_read().
  */
 
 static void scc_tf_read (struct ata_port *ap, struct ata_taskfile *tf)
@@ -372,7 +373,7 @@
  *	@ap: port to which command is being issued
  *	@tf: ATA taskfile register set
  *
- *	Note: Original code is ata_sff_exec_command().
+ *	Note: Original code is ata_exec_command().
  */
 
 static void scc_exec_command (struct ata_port *ap,
@@ -381,7 +382,7 @@
 	DPRINTK("ata%u: cmd 0x%X\n", ap->print_id, tf->command);
 
 	out_be32(ap->ioaddr.command_addr, tf->command);
-	ata_sff_pause(ap);
+	ata_pause(ap);
 }
 
 /**
@@ -395,14 +396,14 @@
 }
 
 /**
- *	scc_dev_select - Select device 0/1 on ATA bus
+ *	scc_std_dev_select - Select device 0/1 on ATA bus
  *	@ap: ATA channel to manipulate
  *	@device: ATA device (numbered from zero) to select
  *
- *	Note: Original code is ata_sff_dev_select().
+ *	Note: Original code is ata_std_dev_select().
  */
 
-static void scc_dev_select (struct ata_port *ap, unsigned int device)
+static void scc_std_dev_select (struct ata_port *ap, unsigned int device)
 {
 	u8 tmp;
 
@@ -412,7 +413,7 @@
 		tmp = ATA_DEVICE_OBS | ATA_DEV1;
 
 	out_be32(ap->ioaddr.device_addr, tmp);
-	ata_sff_pause(ap);
+	ata_pause(ap);
 }
 
 /**
@@ -440,7 +441,7 @@
 	out_be32(mmio + SCC_DMA_CMD, dmactl);
 
 	/* issue r/w command */
-	ap->ops->sff_exec_command(ap, &qc->tf);
+	ap->ops->exec_command(ap, &qc->tf);
 }
 
 /**
@@ -475,7 +476,7 @@
 	struct ata_ioports *ioaddr = &ap->ioaddr;
 	u8 nsect, lbal;
 
-	ap->ops->sff_dev_select(ap, device);
+	ap->ops->dev_select(ap, device);
 
 	out_be32(ioaddr->nsect_addr, 0x55);
 	out_be32(ioaddr->lbal_addr, 0xaa);
@@ -496,78 +497,57 @@
 }
 
 /**
- *	scc_wait_after_reset - wait for devices to become ready after reset
+ *	scc_bus_post_reset - PATA device post reset
  *
- *	Note: Original code is ata_sff_wait_after_reset
+ *	Note: Original code is ata_bus_post_reset().
  */
 
-int scc_wait_after_reset(struct ata_link *link, unsigned int devmask,
-			 unsigned long deadline)
+static int scc_bus_post_reset(struct ata_port *ap, unsigned int devmask,
+                              unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	struct ata_ioports *ioaddr = &ap->ioaddr;
 	unsigned int dev0 = devmask & (1 << 0);
 	unsigned int dev1 = devmask & (1 << 1);
-	int rc, ret = 0;
+	int rc;
 
-	/* Spec mandates ">= 2ms" before checking status.  We wait
-	 * 150ms, because that was the magic delay used for ATAPI
-	 * devices in Hale Landis's ATADRVR, for the period of time
-	 * between when the ATA command register is written, and then
-	 * status is checked.  Because waiting for "a while" before
-	 * checking status is fine, post SRST, we perform this magic
-	 * delay here as well.
-	 *
-	 * Old drivers/ide uses the 2mS rule and then waits for ready.
+	/* if device 0 was found in ata_devchk, wait for its
+	 * BSY bit to clear
 	 */
-	msleep(150);
+	if (dev0) {
+		rc = ata_wait_ready(ap, deadline);
+		if (rc && rc != -ENODEV)
+			return rc;
+	}
 
-	/* always check readiness of the master device */
-	rc = ata_sff_wait_ready(link, deadline);
-	/* -ENODEV means the odd clown forgot the D7 pulldown resistor
-	 * and TF status is 0xff, bail out on it too.
+	/* if device 1 was found in ata_devchk, wait for
+	 * register access, then wait for BSY to clear
 	 */
-	if (rc)
-		return rc;
+	while (dev1) {
+		u8 nsect, lbal;
 
-	/* if device 1 was found in ata_devchk, wait for register
-	 * access briefly, then wait for BSY to clear.
-	 */
+		ap->ops->dev_select(ap, 1);
+		nsect = in_be32(ioaddr->nsect_addr);
+		lbal = in_be32(ioaddr->lbal_addr);
+		if ((nsect == 1) && (lbal == 1))
+			break;
+		if (time_after(jiffies, deadline))
+			return -EBUSY;
+		msleep(50);	/* give drive a breather */
+	}
 	if (dev1) {
-		int i;
-
-		ap->ops->sff_dev_select(ap, 1);
-
-		/* Wait for register access.  Some ATAPI devices fail
-		 * to set nsect/lbal after reset, so don't waste too
-		 * much time on it.  We're gonna wait for !BSY anyway.
-		 */
-		for (i = 0; i < 2; i++) {
-			u8 nsect, lbal;
-
-			nsect = in_be32(ioaddr->nsect_addr);
-			lbal = in_be32(ioaddr->lbal_addr);
-			if ((nsect == 1) && (lbal == 1))
-				break;
-			msleep(50);	/* give drive a breather */
-		}
-
-		rc = ata_sff_wait_ready(link, deadline);
-		if (rc) {
-			if (rc != -ENODEV)
-				return rc;
-			ret = rc;
-		}
+		rc = ata_wait_ready(ap, deadline);
+		if (rc && rc != -ENODEV)
+			return rc;
 	}
 
 	/* is all this really necessary? */
-	ap->ops->sff_dev_select(ap, 0);
+	ap->ops->dev_select(ap, 0);
 	if (dev1)
-		ap->ops->sff_dev_select(ap, 1);
+		ap->ops->dev_select(ap, 1);
 	if (dev0)
-		ap->ops->sff_dev_select(ap, 0);
+		ap->ops->dev_select(ap, 0);
 
-	return ret;
+	return 0;
 }
 
 /**
@@ -590,30 +570,53 @@
 	udelay(20);
 	out_be32(ioaddr->ctl_addr, ap->ctl);
 
-	scc_wait_after_reset(&ap->link, devmask, deadline);
+	/* spec mandates ">= 2ms" before checking status.
+	 * We wait 150ms, because that was the magic delay used for
+	 * ATAPI devices in Hale Landis's ATADRVR, for the period of time
+	 * between when the ATA command register is written, and then
+	 * status is checked.  Because waiting for "a while" before
+	 * checking status is fine, post SRST, we perform this magic
+	 * delay here as well.
+	 *
+	 * Old drivers/ide uses the 2mS rule and then waits for ready
+	 */
+	msleep(150);
+
+	/* Before we perform post reset processing we want to see if
+	 * the bus shows 0xFF because the odd clown forgets the D7
+	 * pulldown resistor.
+	 */
+	if (scc_check_status(ap) == 0xFF)
+		return 0;
+
+	scc_bus_post_reset(ap, devmask, deadline);
 
 	return 0;
 }
 
 /**
- *	scc_softreset - reset host port via ATA SRST
+ *	scc_std_softreset - reset host port via ATA SRST
  *	@ap: port to reset
  *	@classes: resulting classes of attached devices
  *	@deadline: deadline jiffies for the operation
  *
- *	Note: Original code is ata_sff_softreset().
+ *	Note: Original code is ata_std_softreset().
  */
 
-static int scc_softreset(struct ata_link *link, unsigned int *classes,
-			 unsigned long deadline)
+static int scc_std_softreset (struct ata_port *ap, unsigned int *classes,
+                              unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	unsigned int slave_possible = ap->flags & ATA_FLAG_SLAVE_POSS;
 	unsigned int devmask = 0, err_mask;
 	u8 err;
 
 	DPRINTK("ENTER\n");
 
+	if (ata_port_offline(ap)) {
+		classes[0] = ATA_DEV_NONE;
+		goto out;
+	}
+
 	/* determine if device 0/1 are present */
 	if (scc_devchk(ap, 0))
 		devmask |= (1 << 0);
@@ -621,7 +624,7 @@
 		devmask |= (1 << 1);
 
 	/* select device 0 again */
-	ap->ops->sff_dev_select(ap, 0);
+	ap->ops->dev_select(ap, 0);
 
 	/* issue bus reset */
 	DPRINTK("about to softreset, devmask=%x\n", devmask);
@@ -633,12 +636,11 @@
 	}
 
 	/* determine by signature whether we have ATA or ATAPI devices */
-	classes[0] = ata_sff_dev_classify(&ap->link.device[0],
-					  devmask & (1 << 0), &err);
+	classes[0] = ata_dev_try_classify(ap, 0, &err);
 	if (slave_possible && err != 0x81)
-		classes[1] = ata_sff_dev_classify(&ap->link.device[1],
-						  devmask & (1 << 1), &err);
+		classes[1] = ata_dev_try_classify(ap, 1, &err);
 
+ out:
 	DPRINTK("EXIT, classes[0]=%u [1]=%u\n", classes[0], classes[1]);
 	return 0;
 }
@@ -695,11 +697,11 @@
 
 		if (reg & INTSTS_BMSINT) {
 			unsigned int classes;
-			unsigned long deadline = ata_deadline(jiffies, ATA_TMOUT_BOOT);
+			unsigned long deadline = jiffies + ATA_TMOUT_BOOT;
 			printk(KERN_WARNING "%s: Internal Bus Error\n", DRV_NAME);
 			out_be32(bmid_base + SCC_DMA_INTST, INTSTS_BMSINT);
 			/* TBD: SW reset */
-			scc_softreset(&ap->link, &classes, deadline);
+			scc_std_softreset(ap, &classes, deadline);
 			continue;
 		}
 
@@ -725,7 +727,7 @@
 		 in_be32(bmid_base + SCC_DMA_CMD) & ~ATA_DMA_START);
 
 	/* one-PIO-cycle guaranteed wait, per spec, for HDMA1:0 transition */
-	ata_sff_dma_pause(ap);	/* dummy read */
+	ata_altstatus(ap);	/* dummy read */
 }
 
 /**
@@ -738,7 +740,7 @@
 	void __iomem *mmio = ap->ioaddr.bmdma_addr;
 	u8 host_stat = in_be32(mmio + SCC_DMA_STATUS);
 	u32 int_status = in_be32(mmio + SCC_DMA_INTST);
-	struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->link.active_tag);
+	struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->active_tag);
 	static int retry = 0;
 
 	/* return if IOS_SS is cleared */
@@ -746,8 +748,7 @@
 		return host_stat;
 
 	/* errata A252,A308 workaround: Step4 */
-	if ((scc_check_altstatus(ap) & ATA_ERR)
-					&& (int_status & INTSTS_INTRQ))
+	if ((ata_altstatus(ap) & ATA_ERR) && (int_status & INTSTS_INTRQ))
 		return (host_stat | ATA_DMA_INTR);
 
 	/* errata A308 workaround Step5 */
@@ -773,54 +774,52 @@
 
 /**
  *	scc_data_xfer - Transfer data by PIO
- *	@dev: device for this I/O
+ *	@adev: device for this I/O
  *	@buf: data buffer
  *	@buflen: buffer length
- *	@rw: read/write
+ *	@write_data: read/write
  *
- *	Note: Original code is ata_sff_data_xfer().
+ *	Note: Original code is ata_data_xfer().
  */
 
-static unsigned int scc_data_xfer (struct ata_device *dev, unsigned char *buf,
-				   unsigned int buflen, int rw)
+static void scc_data_xfer (struct ata_device *adev, unsigned char *buf,
+			   unsigned int buflen, int write_data)
 {
-	struct ata_port *ap = dev->link->ap;
+	struct ata_port *ap = adev->ap;
 	unsigned int words = buflen >> 1;
 	unsigned int i;
-	__le16 *buf16 = (__le16 *) buf;
+	u16 *buf16 = (u16 *) buf;
 	void __iomem *mmio = ap->ioaddr.data_addr;
 
 	/* Transfer multiple of 2 bytes */
-	if (rw == READ)
+	if (write_data) {
 		for (i = 0; i < words; i++)
-			buf16[i] = cpu_to_le16(in_be32(mmio));
-	else
+			out_be32(mmio, cpu_to_le16(buf16[i]));
+	} else {
 		for (i = 0; i < words; i++)
-			out_be32(mmio, le16_to_cpu(buf16[i]));
+			buf16[i] = le16_to_cpu(in_be32(mmio));
+	}
 
 	/* Transfer trailing 1 byte, if any. */
 	if (unlikely(buflen & 0x01)) {
-		__le16 align_buf[1] = { 0 };
+		u16 align_buf[1] = { 0 };
 		unsigned char *trailing_buf = buf + buflen - 1;
 
-		if (rw == READ) {
-			align_buf[0] = cpu_to_le16(in_be32(mmio));
-			memcpy(trailing_buf, align_buf, 1);
-		} else {
+		if (write_data) {
 			memcpy(align_buf, trailing_buf, 1);
-			out_be32(mmio, le16_to_cpu(align_buf[0]));
+			out_be32(mmio, cpu_to_le16(align_buf[0]));
+		} else {
+			align_buf[0] = le16_to_cpu(in_be32(mmio));
+			memcpy(trailing_buf, align_buf, 1);
 		}
-		words++;
 	}
-
-	return words << 1;
 }
 
 /**
  *	scc_irq_on - Enable interrupts on a port.
  *	@ap: Port on which interrupts are enabled.
  *
- *	Note: Original code is ata_sff_irq_on().
+ *	Note: Original code is ata_irq_on().
  */
 
 static u8 scc_irq_on (struct ata_port *ap)
@@ -834,19 +833,51 @@
 	out_be32(ioaddr->ctl_addr, ap->ctl);
 	tmp = ata_wait_idle(ap);
 
-	ap->ops->sff_irq_clear(ap);
+	ap->ops->irq_clear(ap);
 
 	return tmp;
 }
 
 /**
- *	scc_freeze - Freeze BMDMA controller port
+ *	scc_irq_ack - Acknowledge a device interrupt.
+ *	@ap: Port on which interrupts are enabled.
+ *
+ *	Note: Original code is ata_irq_ack().
+ */
+
+static u8 scc_irq_ack (struct ata_port *ap, unsigned int chk_drq)
+{
+	unsigned int bits = chk_drq ? ATA_BUSY | ATA_DRQ : ATA_BUSY;
+	u8 host_stat, post_stat, status;
+
+	status = ata_busy_wait(ap, bits, 1000);
+	if (status & bits)
+		if (ata_msg_err(ap))
+			printk(KERN_ERR "abnormal status 0x%X\n", status);
+
+	/* get controller status; clear intr, err bits */
+	host_stat = in_be32(ap->ioaddr.bmdma_addr + SCC_DMA_STATUS);
+	out_be32(ap->ioaddr.bmdma_addr + SCC_DMA_STATUS,
+		 host_stat | ATA_DMA_INTR | ATA_DMA_ERR);
+
+	post_stat = in_be32(ap->ioaddr.bmdma_addr + SCC_DMA_STATUS);
+
+	if (ata_msg_intr(ap))
+		printk(KERN_INFO "%s: irq ack: host_stat 0x%X, new host_stat 0x%X, drv_stat 0x%X\n",
+		       __FUNCTION__,
+		       host_stat, post_stat, status);
+
+	return status;
+}
+
+/**
+ *	scc_bmdma_freeze - Freeze BMDMA controller port
  *	@ap: port to freeze
  *
- *	Note: Original code is ata_sff_freeze().
+ *	Note: Original code is ata_bmdma_freeze().
  */
 
-static void scc_freeze (struct ata_port *ap)
+static void scc_bmdma_freeze (struct ata_port *ap)
 {
 	struct ata_ioports *ioaddr = &ap->ioaddr;
 
@@ -859,9 +890,9 @@
 	 * ATA_NIEN manipulation.  Also, many controllers fail to mask
 	 * previously pending IRQ on ATA_NIEN assertion.  Clear it.
 	 */
-	ap->ops->sff_check_status(ap);
+	ata_chk_status(ap);
 
-	ap->ops->sff_irq_clear(ap);
+	ap->ops->irq_clear(ap);
 }
 
 /**
@@ -870,31 +901,29 @@
  *	@deadline: deadline jiffies for the operation
  */
 
-static int scc_pata_prereset(struct ata_link *link, unsigned long deadline)
+static int scc_pata_prereset(struct ata_port *ap, unsigned long deadline)
 {
-	link->ap->cbl = ATA_CBL_PATA80;
-	return ata_sff_prereset(link, deadline);
+	ap->cbl = ATA_CBL_PATA80;
+	return ata_std_prereset(ap, deadline);
 }
 
 /**
- *	scc_postreset - standard postreset callback
+ *	scc_std_postreset - standard postreset callback
  *	@ap: the target ata_port
  *	@classes: classes of attached devices
  *
- *	Note: Original code is ata_sff_postreset().
+ *	Note: Original code is ata_std_postreset().
  */
 
-static void scc_postreset(struct ata_link *link, unsigned int *classes)
+static void scc_std_postreset (struct ata_port *ap, unsigned int *classes)
 {
-	struct ata_port *ap = link->ap;
-
 	DPRINTK("ENTER\n");
 
 	/* is double-select really necessary? */
 	if (classes[0] != ATA_DEV_NONE)
-		ap->ops->sff_dev_select(ap, 1);
+		ap->ops->dev_select(ap, 1);
 	if (classes[1] != ATA_DEV_NONE)
-		ap->ops->sff_dev_select(ap, 0);
+		ap->ops->dev_select(ap, 0);
 
 	/* bail out if no device is present */
 	if (classes[0] == ATA_DEV_NONE && classes[1] == ATA_DEV_NONE) {
@@ -910,13 +939,24 @@
 }
 
 /**
- *	scc_irq_clear - Clear PCI IDE BMDMA interrupt.
+ *	scc_error_handler - Stock error handler for BMDMA controller
+ *	@ap: port to handle error for
+ */
+
+static void scc_error_handler (struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, scc_pata_prereset, scc_std_softreset, NULL,
+			   scc_std_postreset);
+}
+
+/**
+ *	scc_bmdma_irq_clear - Clear PCI IDE BMDMA interrupt.
  *	@ap: Port associated with this ATA transaction.
  *
- *	Note: Original code is ata_sff_irq_clear().
+ *	Note: Original code is ata_bmdma_irq_clear().
  */
 
-static void scc_irq_clear (struct ata_port *ap)
+static void scc_bmdma_irq_clear (struct ata_port *ap)
 {
 	void __iomem *mmio = ap->ioaddr.bmdma_addr;
 
@@ -962,37 +1002,52 @@
 }
 
 static struct scsi_host_template scc_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations scc_pata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-
+static const struct ata_port_operations scc_pata_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= scc_set_piomode,
 	.set_dmamode		= scc_set_dmamode,
 	.mode_filter		= scc_mode_filter,
 
-	.sff_tf_load		= scc_tf_load,
-	.sff_tf_read		= scc_tf_read,
-	.sff_exec_command	= scc_exec_command,
-	.sff_check_status	= scc_check_status,
-	.sff_check_altstatus	= scc_check_altstatus,
-	.sff_dev_select		= scc_dev_select,
+	.tf_load		= scc_tf_load,
+	.tf_read		= scc_tf_read,
+	.exec_command		= scc_exec_command,
+	.check_status		= scc_check_status,
+	.check_altstatus	= scc_check_altstatus,
+	.dev_select		= scc_std_dev_select,
 
 	.bmdma_setup		= scc_bmdma_setup,
 	.bmdma_start		= scc_bmdma_start,
 	.bmdma_stop		= scc_bmdma_stop,
 	.bmdma_status		= scc_bmdma_status,
-	.sff_data_xfer		= scc_data_xfer,
+	.data_xfer		= scc_data_xfer,
+
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
 
-	.freeze			= scc_freeze,
-	.prereset		= scc_pata_prereset,
-	.softreset		= scc_softreset,
-	.postreset		= scc_postreset,
+	.freeze			= scc_bmdma_freeze,
+	.error_handler		= scc_error_handler,
 	.post_internal_cmd	= scc_bmdma_stop,
 
-	.sff_irq_clear		= scc_irq_clear,
-	.sff_irq_on		= scc_irq_on,
+	.irq_clear		= scc_bmdma_irq_clear,
+	.irq_on			= scc_irq_on,
+	.irq_ack		= scc_irq_ack,
 
 	.port_start		= scc_port_start,
 	.port_stop		= scc_port_stop,
@@ -1001,8 +1056,8 @@
 static struct ata_port_info scc_port_info[] = {
 	{
 		.flags		= ATA_FLAG_SLAVE_POSS | ATA_FLAG_MMIO | ATA_FLAG_NO_LEGACY,
-		.pio_mask	= ATA_PIO4,
-		/* No MWDMA */
+		.pio_mask	= 0x1f,	/* pio0-4 */
+		.mwdma_mask	= 0x00,
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &scc_pata_ops,
 	},
@@ -1138,15 +1193,12 @@
 		return rc;
 	host->iomap = pcim_iomap_table(pdev);
 
-	ata_port_pbar_desc(host->ports[0], SCC_CTRL_BAR, -1, "ctrl");
-	ata_port_pbar_desc(host->ports[0], SCC_BMID_BAR, -1, "bmid");
-
 	rc = scc_host_init(host);
 	if (rc)
 		return rc;
 
-	return ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &scc_sht);
+	return ata_host_activate(host, pdev->irq, ata_interrupt, IRQF_SHARED,
+				 &scc_sht);
 }
 
 static struct pci_driver scc_pci_driver = {
diff -Nur linux-sh4/drivers/ata.org/pata_sch.c linux-sh4/drivers/ata/pata_sch.c
--- linux-sh4/drivers/ata.org/pata_sch.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_sch.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,206 +0,0 @@
-/*
- *  pata_sch.c - Intel SCH PATA controllers
- *
- *  Copyright (c) 2008 Alek Du <alek.du@intel.com>
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License 2 as published
- *  by the Free Software Foundation.
- *
- *  This program is distributed in the hope that it will be useful,
- *  but WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *  GNU General Public License for more details.
- *
- *  You should have received a copy of the GNU General Public License
- *  along with this program; see the file COPYING.  If not, write to
- *  the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
- *
- */
-
-/*
- *  Supports:
- *    Intel SCH (AF82US15W, AF82US15L, AF82UL11L) chipsets -- see spec at:
- *    http://download.intel.com/design/chipsets/embedded/datashts/319537.pdf
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/init.h>
-#include <linux/blkdev.h>
-#include <linux/delay.h>
-#include <linux/device.h>
-#include <scsi/scsi_host.h>
-#include <linux/libata.h>
-#include <linux/dmi.h>
-
-#define DRV_NAME	"pata_sch"
-#define DRV_VERSION	"0.2"
-
-/* see SCH datasheet page 351 */
-enum {
-	D0TIM	= 0x80,		/* Device 0 Timing Register */
-	D1TIM	= 0x84,		/* Device 1 Timing Register */
-	PM	= 0x07,		/* PIO Mode Bit Mask */
-	MDM	= (0x03 << 8),	/* Multi-word DMA Mode Bit Mask */
-	UDM	= (0x07 << 16), /* Ultra DMA Mode Bit Mask */
-	PPE	= (1 << 30),	/* Prefetch/Post Enable */
-	USD	= (1 << 31),	/* Use Synchronous DMA */
-};
-
-static int sch_init_one(struct pci_dev *pdev,
-			 const struct pci_device_id *ent);
-static void sch_set_piomode(struct ata_port *ap, struct ata_device *adev);
-static void sch_set_dmamode(struct ata_port *ap, struct ata_device *adev);
-
-static const struct pci_device_id sch_pci_tbl[] = {
-	/* Intel SCH PATA Controller */
-	{ PCI_VDEVICE(INTEL, PCI_DEVICE_ID_INTEL_SCH_IDE), 0 },
-	{ }	/* terminate list */
-};
-
-static struct pci_driver sch_pci_driver = {
-	.name			= DRV_NAME,
-	.id_table		= sch_pci_tbl,
-	.probe			= sch_init_one,
-	.remove			= ata_pci_remove_one,
-#ifdef CONFIG_PM
-	.suspend		= ata_pci_device_suspend,
-	.resume			= ata_pci_device_resume,
-#endif
-};
-
-static struct scsi_host_template sch_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations sch_pata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.cable_detect		= ata_cable_unknown,
-	.set_piomode		= sch_set_piomode,
-	.set_dmamode		= sch_set_dmamode,
-};
-
-static struct ata_port_info sch_port_info = {
-	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	.mwdma_mask	= ATA_MWDMA2,
-	.udma_mask	= ATA_UDMA5,
-	.port_ops	= &sch_pata_ops,
-};
-
-MODULE_AUTHOR("Alek Du <alek.du@intel.com>");
-MODULE_DESCRIPTION("SCSI low-level driver for Intel SCH PATA controllers");
-MODULE_LICENSE("GPL");
-MODULE_DEVICE_TABLE(pci, sch_pci_tbl);
-MODULE_VERSION(DRV_VERSION);
-
-/**
- *	sch_set_piomode - Initialize host controller PATA PIO timings
- *	@ap: Port whose timings we are configuring
- *	@adev: ATA device
- *
- *	Set PIO mode for device, in host controller PCI config space.
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static void sch_set_piomode(struct ata_port *ap, struct ata_device *adev)
-{
-	unsigned int pio	= adev->pio_mode - XFER_PIO_0;
-	struct pci_dev *dev	= to_pci_dev(ap->host->dev);
-	unsigned int port	= adev->devno ? D1TIM : D0TIM;
-	unsigned int data;
-
-	pci_read_config_dword(dev, port, &data);
-	/* see SCH datasheet page 351 */
-	/* set PIO mode */
-	data &= ~(PM | PPE);
-	data |= pio;
-	/* enable PPE for block device */
-	if (adev->class == ATA_DEV_ATA)
-		data |= PPE;
-	pci_write_config_dword(dev, port, data);
-}
-
-/**
- *	sch_set_dmamode - Initialize host controller PATA DMA timings
- *	@ap: Port whose timings we are configuring
- *	@adev: ATA device
- *
- *	Set MW/UDMA mode for device, in host controller PCI config space.
- *
- *	LOCKING:
- *	None (inherited from caller).
- */
-
-static void sch_set_dmamode(struct ata_port *ap, struct ata_device *adev)
-{
-	unsigned int dma_mode	= adev->dma_mode;
-	struct pci_dev *dev	= to_pci_dev(ap->host->dev);
-	unsigned int port	= adev->devno ? D1TIM : D0TIM;
-	unsigned int data;
-
-	pci_read_config_dword(dev, port, &data);
-	/* see SCH datasheet page 351 */
-	if (dma_mode >= XFER_UDMA_0) {
-		/* enable Synchronous DMA mode */
-		data |= USD;
-		data &= ~UDM;
-		data |= (dma_mode - XFER_UDMA_0) << 16;
-	} else { /* must be MWDMA mode, since we masked SWDMA already */
-		data &= ~(USD | MDM);
-		data |= (dma_mode - XFER_MW_DMA_0) << 8;
-	}
-	pci_write_config_dword(dev, port, data);
-}
-
-/**
- *	sch_init_one - Register SCH ATA PCI device with kernel services
- *	@pdev: PCI device to register
- *	@ent: Entry in sch_pci_tbl matching with @pdev
- *
- *	LOCKING:
- *	Inherited from PCI layer (may sleep).
- *
- *	RETURNS:
- *	Zero on success, or -ERRNO value.
- */
-
-static int __devinit sch_init_one(struct pci_dev *pdev,
-				   const struct pci_device_id *ent)
-{
-	static int printed_version;
-	const struct ata_port_info *ppi[] = { &sch_port_info, NULL };
-	struct ata_host *host;
-	int rc;
-
-	if (!printed_version++)
-		dev_printk(KERN_DEBUG, &pdev->dev,
-			   "version " DRV_VERSION "\n");
-
-	/* enable device and prepare host */
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-	rc = ata_pci_sff_prepare_host(pdev, ppi, &host);
-	if (rc)
-		return rc;
-	pci_set_master(pdev);
-	return ata_pci_sff_activate_host(host, ata_sff_interrupt, &sch_sht);
-}
-
-static int __init sch_init(void)
-{
-	return pci_register_driver(&sch_pci_driver);
-}
-
-static void __exit sch_exit(void)
-{
-	pci_unregister_driver(&sch_pci_driver);
-}
-
-module_init(sch_init);
-module_exit(sch_exit);
diff -Nur linux-sh4/drivers/ata.org/pata_serverworks.c linux-sh4/drivers/ata/pata_serverworks.c
--- linux-sh4/drivers/ata.org/pata_serverworks.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_serverworks.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_serverworks.c 	- Serverworks PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  * based upon
  *
@@ -40,7 +41,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "pata_serverworks"
-#define DRV_VERSION "0.4.3"
+#define DRV_VERSION "0.4.2"
 
 #define SVWKS_CSB5_REVISION_NEW	0x92 /* min PCI_REVISION_ID for UDMA5 (A2.0) */
 #define SVWKS_CSB6_REVISION	0xa0 /* min PCI_REVISION_ID for UDMA4 (A1.0) */
@@ -101,7 +102,7 @@
 }
 
 /**
- *	csb_cable	-	CSB5/6 cable detect
+ *	csb4_cable	-	CSB5/6 cable detect
  *	@ap: ATA port to check
  *
  *	Serverworks default arrangement is to use the drive side detection
@@ -109,7 +110,7 @@
  */
 
 static int csb_cable(struct ata_port *ap) {
-	return ATA_CBL_PATA_UNK;
+	return ATA_CBL_PATA80;
 }
 
 struct sv_cable_table {
@@ -138,6 +139,7 @@
 /**
  *	serverworks_cable_detect	-	cable detection
  *	@ap: ATA port
+ *	@deadline: deadline jiffies for the operation
  *
  *	Perform cable detection according to the device and subvendor
  *	identifications
@@ -197,7 +199,7 @@
 {
 	if (adev->class == ATA_DEV_ATA)
 		mask &= ~ATA_MASK_UDMA;
-	return ata_bmdma_mode_filter(adev, mask);
+	return ata_pci_default_filter(adev, mask);
 }
 
 
@@ -217,18 +219,19 @@
 
 	/* Disk, UDMA */
 	if (adev->class != ATA_DEV_ATA)
-		return ata_bmdma_mode_filter(adev, mask);
+		return ata_pci_default_filter(adev, mask);
 
 	/* Actually do need to check */
 	ata_id_c_string(adev->id, model_num, ATA_ID_PROD, sizeof(model_num));
 
 	for (i = 0; (p = csb_bad_ata100[i]) != NULL; i++) {
 		if (!strcmp(p, model_num))
-			mask &= ~(0xE0 << ATA_SHIFT_UDMA);
+			mask &= ~(0x1F << ATA_SHIFT_UDMA);
 	}
-	return ata_bmdma_mode_filter(adev, mask);
+	return ata_pci_default_filter(adev, mask);
 }
 
+
 /**
  *	serverworks_set_piomode	-	set initial PIO mode data
  *	@ap: ATA interface
@@ -240,7 +243,7 @@
 static void serverworks_set_piomode(struct ata_port *ap, struct ata_device *adev)
 {
 	static const u8 pio_mode[] = { 0x5d, 0x47, 0x34, 0x22, 0x20 };
-	int offset = 1 + 2 * ap->port_no - adev->devno;
+	int offset = 1 + (2 * ap->port_no) - adev->devno;
 	int devbits = (2 * ap->port_no + adev->devno) * 4;
 	u16 csb5_pio;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
@@ -271,45 +274,119 @@
 {
 	static const u8 dma_mode[] = { 0x77, 0x21, 0x20 };
 	int offset = 1 + 2 * ap->port_no - adev->devno;
-	int devbits = 2 * ap->port_no + adev->devno;
+	int devbits = (2 * ap->port_no + adev->devno);
 	u8 ultra;
 	u8 ultra_cfg;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	pci_read_config_byte(pdev, 0x54, &ultra_cfg);
-	pci_read_config_byte(pdev, 0x56 + ap->port_no, &ultra);
-	ultra &= ~(0x0F << (adev->devno * 4));
 
 	if (adev->dma_mode >= XFER_UDMA_0) {
 		pci_write_config_byte(pdev, 0x44 + offset,  0x20);
 
+		pci_read_config_byte(pdev, 0x56 + ap->port_no, &ultra);
+		ultra &= ~(0x0F << (ap->port_no * 4));
 		ultra |= (adev->dma_mode - XFER_UDMA_0)
-					<< (adev->devno * 4);
+					<< (ap->port_no * 4);
+		pci_write_config_byte(pdev, 0x56 + ap->port_no, ultra);
+
 		ultra_cfg |=  (1 << devbits);
 	} else {
 		pci_write_config_byte(pdev, 0x44 + offset,
 			dma_mode[adev->dma_mode - XFER_MW_DMA_0]);
 		ultra_cfg &= ~(1 << devbits);
 	}
-	pci_write_config_byte(pdev, 0x56 + ap->port_no, ultra);
 	pci_write_config_byte(pdev, 0x54, ultra_cfg);
 }
 
 static struct scsi_host_template serverworks_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations serverworks_osb4_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= serverworks_cable_detect,
-	.mode_filter	= serverworks_osb4_filter,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= serverworks_set_piomode,
 	.set_dmamode	= serverworks_set_dmamode,
+	.mode_filter	= serverworks_osb4_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= serverworks_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations serverworks_csb_port_ops = {
-	.inherits	= &serverworks_osb4_port_ops,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= serverworks_set_piomode,
+	.set_dmamode	= serverworks_set_dmamode,
 	.mode_filter	= serverworks_csb_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= serverworks_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int serverworks_fixup_osb4(struct pci_dev *pdev)
@@ -397,37 +474,36 @@
 {
 	static const struct ata_port_info info[4] = {
 		{ /* OSB4 */
+			.sht = &serverworks_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			.udma_mask = ATA_UDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = 0x07,
 			.port_ops = &serverworks_osb4_port_ops
 		}, { /* OSB4 no UDMA */
+			.sht = &serverworks_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
-			/* No UDMA */
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
+			.udma_mask = 0x00,
 			.port_ops = &serverworks_osb4_port_ops
 		}, { /* CSB5 */
+			.sht = &serverworks_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.udma_mask = ATA_UDMA4,
 			.port_ops = &serverworks_csb_port_ops
 		}, { /* CSB5 - later revisions*/
+			.sht = &serverworks_sht,
 			.flags = ATA_FLAG_SLAVE_POSS,
-			.pio_mask = ATA_PIO4,
-			.mwdma_mask = ATA_MWDMA2,
+			.pio_mask = 0x1f,
+			.mwdma_mask = 0x07,
 			.udma_mask = ATA_UDMA5,
 			.port_ops = &serverworks_csb_port_ops
 		}
 	};
 	const struct ata_port_info *ppi[] = { &info[id->driver_data], NULL };
-	int rc;
-
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
 
 	/* Force master latency timer to 64 PCI clocks */
 	pci_write_config_byte(pdev, PCI_LATENCY_TIMER, 0x40);
@@ -457,30 +533,24 @@
 		serverworks_fixup_ht1000(pdev);
 
 	if (pdev->device == PCI_DEVICE_ID_SERVERWORKS_CSB5IDE)
-		ata_pci_bmdma_clear_simplex(pdev);
+		ata_pci_clear_simplex(pdev);
 
-	return ata_pci_sff_init_one(pdev, ppi, &serverworks_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 #ifdef CONFIG_PM
 static int serverworks_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
-
 	/* Force master latency timer to 64 PCI clocks */
 	pci_write_config_byte(pdev, PCI_LATENCY_TIMER, 0x40);
 
-	switch (pdev->device) {
+	switch (pdev->device)
+	{
 		case PCI_DEVICE_ID_SERVERWORKS_OSB4IDE:
 			serverworks_fixup_osb4(pdev);
 			break;
 		case PCI_DEVICE_ID_SERVERWORKS_CSB5IDE:
-			ata_pci_bmdma_clear_simplex(pdev);
+			ata_pci_clear_simplex(pdev);
 			/* fall through */
 		case PCI_DEVICE_ID_SERVERWORKS_CSB6IDE:
 		case PCI_DEVICE_ID_SERVERWORKS_CSB6IDE2:
@@ -490,9 +560,7 @@
 			serverworks_fixup_ht1000(pdev);
 			break;
 	}
-
-	ata_host_resume(host);
-	return 0;
+	return ata_pci_device_resume(pdev);
 }
 #endif
 
diff -Nur linux-sh4/drivers/ata.org/pata_sil680.c linux-sh4/drivers/ata/pata_sil680.c
--- linux-sh4/drivers/ata.org/pata_sil680.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_sil680.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_sil680.c 	- SIL680 PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  * based upon
  *
@@ -15,7 +16,7 @@
  *
  *	If you have strange problems with nVidia chipset systems please
  *	see the SI support documentation and update your system BIOS
- *	if necessary
+ *	if neccessary
  *
  * TODO
  *	If we know all our devices are LBA28 (or LBA28 sized)  we could use
@@ -32,7 +33,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "pata_sil680"
-#define DRV_VERSION "0.4.9"
+#define DRV_VERSION "0.4.7"
 
 #define SIL680_MMIO_BAR		5
 
@@ -93,6 +94,33 @@
 }
 
 /**
+ *	sil680_bus_reset	-	reset the SIL680 bus
+ *	@ap: ATA port to reset
+ *	@deadline: deadline jiffies for the operation
+ *
+ *	Perform the SIL680 housekeeping when doing an ATA bus reset
+ */
+
+static int sil680_bus_reset(struct ata_port *ap,unsigned int *classes,
+			    unsigned long deadline)
+{
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	unsigned long addr = sil680_selreg(ap, 0);
+	u8 reset;
+
+	pci_read_config_byte(pdev, addr, &reset);
+	pci_write_config_byte(pdev, addr, reset | 0x03);
+	udelay(25);
+	pci_write_config_byte(pdev, addr, reset);
+	return ata_std_softreset(ap, classes, deadline);
+}
+
+static void sil680_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, ata_std_prereset, sil680_bus_reset, NULL, ata_std_postreset);
+}
+
+/**
  *	sil680_set_piomode	-	set initial PIO mode data
  *	@ap: ATA interface
  *	@adev: ATA device
@@ -191,14 +219,56 @@
 }
 
 static struct scsi_host_template sil680_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations sil680_port_ops = {
-	.inherits	= &ata_bmdma32_port_ops,
-	.cable_detect	= sil680_cable_detect,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= sil680_set_piomode,
 	.set_dmamode	= sil680_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= sil680_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= sil680_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -210,13 +280,15 @@
  *	Returns the final clock settings.
  */
 
-static u8 sil680_init_chip(struct pci_dev *pdev, int *try_mmio)
+static u8 sil680_init_chip(struct pci_dev *pdev)
 {
+	u32 class_rev	= 0;
 	u8 tmpbyte	= 0;
 
+        pci_read_config_dword(pdev, PCI_CLASS_REVISION, &class_rev);
+        class_rev &= 0xff;
         /* FIXME: double check */
-	pci_write_config_byte(pdev, PCI_CACHE_LINE_SIZE,
-			      pdev->revision ? 1 : 255);
+	pci_write_config_byte(pdev, PCI_CACHE_LINE_SIZE, (class_rev) ? 1 : 255);
 
 	pci_write_config_byte(pdev, 0x80, 0x00);
 	pci_write_config_byte(pdev, 0x84, 0x00);
@@ -226,12 +298,6 @@
 	dev_dbg(&pdev->dev, "sil680: BA5_EN = %d clock = %02X\n",
 		tmpbyte & 1, tmpbyte & 0x30);
 
-	*try_mmio = 0;
-#ifdef CONFIG_PPC
-	if (machine_is(cell))
-		*try_mmio = (tmpbyte & 1) || pci_resource_start(pdev, 5);
-#endif
-
 	switch(tmpbyte & 0x30) {
 		case 0x00:
 			/* 133 clock attempt to force it on */
@@ -279,98 +345,43 @@
 				     const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &sil680_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA6,
 		.port_ops = &sil680_port_ops
 	};
 	static const struct ata_port_info info_slow = {
+		.sht = &sil680_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA5,
 		.port_ops = &sil680_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
 	static int printed_version;
-	struct ata_host *host;
-	void __iomem *mmio_base;
-	int rc, try_mmio;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
 
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
-	switch (sil680_init_chip(pdev, &try_mmio)) {
+	switch(sil680_init_chip(pdev))
+	{
 		case 0:
 			ppi[0] = &info_slow;
 			break;
 		case 0x30:
 			return -ENODEV;
 	}
-
-	if (!try_mmio)
-		goto use_ioports;
-
-	/* Try to acquire MMIO resources and fallback to PIO if
-	 * that fails
-	 */
-	rc = pcim_iomap_regions(pdev, 1 << SIL680_MMIO_BAR, DRV_NAME);
-	if (rc)
-		goto use_ioports;
-
-	/* Allocate host and set it up */
-	host = ata_host_alloc_pinfo(&pdev->dev, ppi, 2);
-	if (!host)
-		return -ENOMEM;
-	host->iomap = pcim_iomap_table(pdev);
-
-	/* Setup DMA masks */
-	rc = pci_set_dma_mask(pdev, ATA_DMA_MASK);
-	if (rc)
-		return rc;
-	rc = pci_set_consistent_dma_mask(pdev, ATA_DMA_MASK);
-	if (rc)
-		return rc;
-	pci_set_master(pdev);
-
-	/* Get MMIO base and initialize port addresses */
-	mmio_base = host->iomap[SIL680_MMIO_BAR];
-	host->ports[0]->ioaddr.bmdma_addr = mmio_base + 0x00;
-	host->ports[0]->ioaddr.cmd_addr = mmio_base + 0x80;
-	host->ports[0]->ioaddr.ctl_addr = mmio_base + 0x8a;
-	host->ports[0]->ioaddr.altstatus_addr = mmio_base + 0x8a;
-	ata_sff_std_ports(&host->ports[0]->ioaddr);
-	host->ports[1]->ioaddr.bmdma_addr = mmio_base + 0x08;
-	host->ports[1]->ioaddr.cmd_addr = mmio_base + 0xc0;
-	host->ports[1]->ioaddr.ctl_addr = mmio_base + 0xca;
-	host->ports[1]->ioaddr.altstatus_addr = mmio_base + 0xca;
-	ata_sff_std_ports(&host->ports[1]->ioaddr);
-
-	/* Register & activate */
-	return ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &sil680_sht);
-
-use_ioports:
-	return ata_pci_sff_init_one(pdev, ppi, &sil680_sht, NULL);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 #ifdef CONFIG_PM
 static int sil680_reinit_one(struct pci_dev *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	int try_mmio, rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
-	sil680_init_chip(pdev, &try_mmio);
-	ata_host_resume(host);
-	return 0;
+	sil680_init_chip(pdev);
+	return ata_pci_device_resume(pdev);
 }
 #endif
 
diff -Nur linux-sh4/drivers/ata.org/pata_sis.c linux-sh4/drivers/ata/pata_sis.c
--- linux-sh4/drivers/ata.org/pata_sis.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_sis.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  *    pata_sis.c - SiS ATA driver
  *
- *	(C) 2005 Red Hat
+ *	(C) 2005 Red Hat <alan@redhat.com>
  *	(C) 2007 Bartlomiej Zolnierkiewicz
  *
  *    Based upon linux/drivers/ide/pci/sis5513.c
@@ -55,7 +55,6 @@
 	/* devid, subvendor, subdev */
 	{ 0x5513, 0x1043, 0x1107 },	/* ASUS A6K */
 	{ 0x5513, 0x1734, 0x105F },	/* FSC Amilo A1630 */
-	{ 0x5513, 0x1071, 0x8640 },     /* EasyNote K5305 */
 	/* end marker */
 	{ 0, }
 };
@@ -85,7 +84,7 @@
 
 static int sis_old_port_base(struct ata_device *adev)
 {
-	return  0x40 + (4 * adev->link->ap->port_no) +  (2 * adev->devno);
+	return  0x40 + (4 * adev->ap->port_no) +  (2 * adev->devno);
 }
 
 /**
@@ -112,6 +111,7 @@
 /**
  *	sis_66_cable_detect	-	check for 40/80 pin
  *	@ap: Port
+ *	@deadline: deadline jiffies for the operation
  *
  *	Perform cable detection on the UDMA66, UDMA100 and early UDMA133
  *	SiS IDE controllers.
@@ -133,20 +133,19 @@
 
 /**
  *	sis_pre_reset		-	probe begin
- *	@link: ATA link
+ *	@ap: ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	Set up cable type and use generic probe init
  */
 
-static int sis_pre_reset(struct ata_link *link, unsigned long deadline)
+static int sis_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits sis_enable_bits[] = {
 		{ 0x4aU, 1U, 0x02UL, 0x02UL },	/* port 0 */
 		{ 0x4aU, 1U, 0x04UL, 0x04UL },	/* port 1 */
 	};
 
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	if (!pci_test_config_bits(pdev, &sis_enable_bits[ap->port_no]))
@@ -155,11 +154,24 @@
 	/* Clear the FIFO settings. We can't enable the FIFO until
 	   we know we are poking at a disk */
 	pci_write_config_byte(pdev, 0x4B, 0);
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
 }
 
 
 /**
+ *	sis_error_handler - Probe specified port on PATA host controller
+ *	@ap: Port to probe
+ *
+ *	LOCKING:
+ *	None (inherited from caller).
+ */
+
+static void sis_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, sis_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
+}
+
+/**
  *	sis_set_fifo	-	Set RWP fifo bits for this device
  *	@ap: Port
  *	@adev: Device
@@ -331,7 +343,7 @@
 
 	if (adev->dma_mode < XFER_UDMA_0) {
 		/* bits 3-0 hold recovery timing bits 8-10 active timing and
-		   the higher bits are dependant on the device */
+		   the higer bits are dependant on the device */
 		timing &= ~0x870F;
 		timing |= mwdma_bits[speed];
 	} else {
@@ -371,7 +383,7 @@
 
 	if (adev->dma_mode < XFER_UDMA_0) {
 		/* bits 3-0 hold recovery timing bits 8-10 active timing and
-		   the higher bits are dependant on the device, bit 15 udma */
+		   the higer bits are dependant on the device, bit 15 udma */
 		timing &= ~0x870F;
 		timing |= mwdma_bits[speed];
 	} else {
@@ -500,109 +512,282 @@
 }
 
 static struct scsi_host_template sis_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations sis_133_for_sata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
+static const struct ata_port_operations sis_133_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= sis_133_set_piomode,
 	.set_dmamode		= sis_133_set_dmamode,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= sis_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
 	.cable_detect		= sis_133_cable_detect,
-};
 
-static struct ata_port_operations sis_base_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.prereset		= sis_pre_reset,
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations sis_133_ops = {
-	.inherits		= &sis_base_ops,
+static const struct ata_port_operations sis_133_for_sata_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= sis_133_set_piomode,
 	.set_dmamode		= sis_133_set_dmamode,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
 	.cable_detect		= sis_133_cable_detect,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations sis_133_early_ops = {
-	.inherits		= &sis_base_ops,
+static const struct ata_port_operations sis_133_early_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= sis_100_set_piomode,
 	.set_dmamode		= sis_133_early_set_dmamode,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= sis_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
 	.cable_detect		= sis_66_cable_detect,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations sis_100_ops = {
-	.inherits		= &sis_base_ops,
+static const struct ata_port_operations sis_100_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= sis_100_set_piomode,
 	.set_dmamode		= sis_100_set_dmamode,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= sis_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
 	.cable_detect		= sis_66_cable_detect,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations sis_66_ops = {
-	.inherits		= &sis_base_ops,
+static const struct ata_port_operations sis_66_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= sis_old_set_piomode,
 	.set_dmamode		= sis_66_set_dmamode,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
 	.cable_detect		= sis_66_cable_detect,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= sis_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations sis_old_ops = {
-	.inherits		= &sis_base_ops,
+static const struct ata_port_operations sis_old_ops = {
+	.port_disable		= ata_port_disable,
 	.set_piomode		= sis_old_set_piomode,
 	.set_dmamode		= sis_old_set_dmamode,
+	.mode_filter		= ata_pci_default_filter,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= sis_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
 	.cable_detect		= ata_cable_40wire,
+
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_handler		= ata_interrupt,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
 static const struct ata_port_info sis_info = {
+	.sht		= &sis_sht,
 	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	.mwdma_mask	= ATA_MWDMA2,
-	/* No UDMA */
+	.pio_mask	= 0x1f,	/* pio0-4 */
+	.mwdma_mask	= 0x07,
+	.udma_mask	= 0,
 	.port_ops	= &sis_old_ops,
 };
 static const struct ata_port_info sis_info33 = {
+	.sht		= &sis_sht,
 	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	.mwdma_mask	= ATA_MWDMA2,
-	.udma_mask	= ATA_UDMA2,
+	.pio_mask	= 0x1f,	/* pio0-4 */
+	.mwdma_mask	= 0x07,
+	.udma_mask	= ATA_UDMA2,	/* UDMA 33 */
 	.port_ops	= &sis_old_ops,
 };
 static const struct ata_port_info sis_info66 = {
+	.sht		= &sis_sht,
 	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	/* No MWDMA */
-	.udma_mask	= ATA_UDMA4,
+	.pio_mask	= 0x1f,	/* pio0-4 */
+	.udma_mask	= ATA_UDMA4,	/* UDMA 66 */
 	.port_ops	= &sis_66_ops,
 };
 static const struct ata_port_info sis_info100 = {
+	.sht		= &sis_sht,
 	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	/* No MWDMA */
+	.pio_mask	= 0x1f,	/* pio0-4 */
 	.udma_mask	= ATA_UDMA5,
 	.port_ops	= &sis_100_ops,
 };
 static const struct ata_port_info sis_info100_early = {
+	.sht		= &sis_sht,
 	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	/* No MWDMA */
 	.udma_mask	= ATA_UDMA5,
+	.pio_mask	= 0x1f,	/* pio0-4 */
 	.port_ops	= &sis_66_ops,
 };
 static const struct ata_port_info sis_info133 = {
+	.sht		= &sis_sht,
 	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	/* No MWDMA */
+	.pio_mask	= 0x1f,	/* pio0-4 */
 	.udma_mask	= ATA_UDMA6,
 	.port_ops	= &sis_133_ops,
 };
 const struct ata_port_info sis_info133_for_sata = {
+	.sht		= &sis_sht,
 	.flags		= ATA_FLAG_SLAVE_POSS | ATA_FLAG_SRST,
-	.pio_mask	= ATA_PIO4,
-	/* No MWDMA */
+	.pio_mask	= 0x1f,	/* pio0-4 */
 	.udma_mask	= ATA_UDMA6,
 	.port_ops	= &sis_133_for_sata_ops,
 };
 static const struct ata_port_info sis_info133_early = {
+	.sht		= &sis_sht,
 	.flags		= ATA_FLAG_SLAVE_POSS,
-	.pio_mask	= ATA_PIO4,
-	/* No MWDMA */
+	.pio_mask	= 0x1f,	/* pio0-4 */
 	.udma_mask	= ATA_UDMA6,
 	.port_ops	= &sis_133_early_ops,
 };
@@ -682,11 +867,11 @@
 static int sis_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
-	const struct ata_port_info *ppi[] = { NULL, NULL };
+	struct ata_port_info port;
+	const struct ata_port_info *ppi[] = { &port, NULL };
 	struct pci_dev *host = NULL;
 	struct sis_chipset *chipset = NULL;
 	struct sis_chipset *sets;
-	int rc;
 
 	static struct sis_chipset sis_chipsets[] = {
 
@@ -739,11 +924,8 @@
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "version " DRV_VERSION "\n");
 
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
 	/* We have to find the bridge first */
+
 	for (sets = &sis_chipsets[0]; sets->device; sets++) {
 		host = pci_get_device(PCI_VENDOR_ID_SI, sets->device, NULL);
 		if (host != NULL) {
@@ -822,11 +1004,12 @@
 	if (chipset == NULL)
 		return -ENODEV;
 
-	ppi[0] = chipset->info;
+	port = *chipset->info;
+	port.private_data = chipset;
 
 	sis_fixup(pdev, chipset);
 
-	return ata_pci_sff_init_one(pdev, ppi, &sis_sht, chipset);
+	return ata_pci_init_one(pdev, ppi);
 }
 
 static const struct pci_device_id sis_pci_tbl[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_sl82c105.c linux-sh4/drivers/ata/pata_sl82c105.c
--- linux-sh4/drivers/ata.org/pata_sl82c105.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_sl82c105.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_sl82c105.c 	- SL82C105 PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  * Based in part on linux/drivers/ide/pci/sl82c105.c
  * 		SL82C105/Winbond 553 IDE driver
@@ -25,7 +26,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME "pata_sl82c105"
-#define DRV_VERSION "0.3.3"
+#define DRV_VERSION "0.3.2"
 
 enum {
 	/*
@@ -42,24 +43,29 @@
 
 /**
  *	sl82c105_pre_reset		-	probe begin
- *	@link: ATA link
+ *	@ap: ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	Set up cable type and use generic probe init
  */
 
-static int sl82c105_pre_reset(struct ata_link *link, unsigned long deadline)
+static int sl82c105_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits sl82c105_enable_bits[] = {
 		{ 0x40, 1, 0x01, 0x01 },
 		{ 0x40, 1, 0x10, 0x10 }
 	};
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	if (ap->port_no && !pci_test_config_bits(pdev, &sl82c105_enable_bits[ap->port_no]))
 		return -ENOENT;
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
+}
+
+
+static void sl82c105_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, sl82c105_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
 }
 
 
@@ -199,46 +205,57 @@
 	sl82c105_set_piomode(ap, qc->dev);
 }
 
-/**
- *	sl82c105_qc_defer	-	implement serialization
- *	@qc: command
- *
- *	We must issue one command per host not per channel because
- *	of the reset bug.
- *
- *	Q: is the scsi host lock sufficient ?
- */
-
-static int sl82c105_qc_defer(struct ata_queued_cmd *qc)
-{
-	struct ata_host *host = qc->ap->host;
-	struct ata_port *alt = host->ports[1 ^ qc->ap->port_no];
-	int rc;
-
-	/* First apply the usual rules */
-	rc = ata_std_qc_defer(qc);
-	if (rc != 0)
-		return rc;
-
-	/* Now apply serialization rules. Only allow a command if the
-	   other channel state machine is idle */
-	if (alt && alt->qc_active)
-		return	ATA_DEFER_PORT;
-	return 0;
-}
-
 static struct scsi_host_template sl82c105_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations sl82c105_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.qc_defer	= sl82c105_qc_defer,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= sl82c105_set_piomode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= sl82c105_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
 	.bmdma_start 	= sl82c105_bmdma_start,
 	.bmdma_stop	= sl82c105_bmdma_stop,
-	.cable_detect	= ata_cable_40wire,
-	.set_piomode	= sl82c105_set_piomode,
-	.prereset	= sl82c105_pre_reset,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -282,26 +299,23 @@
 static int sl82c105_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info_dma = {
+		.sht = &sl82c105_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.port_ops = &sl82c105_port_ops
 	};
 	static const struct ata_port_info info_early = {
+		.sht = &sl82c105_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
+		.pio_mask = 0x1f,
 		.port_ops = &sl82c105_port_ops
 	};
 	/* for now use only the first port */
 	const struct ata_port_info *ppi[] = { &info_early,
-					       NULL };
+					       &ata_dummy_port_info };
 	u32 val;
 	int rev;
-	int rc;
-
-	rc = pcim_enable_device(dev);
-	if (rc)
-		return rc;
 
 	rev = sl82c105_bridge_revision(dev);
 
@@ -316,7 +330,7 @@
 	val |= CTRL_P0EN | CTRL_P0F16 | CTRL_P1F16;
 	pci_write_config_dword(dev, 0x40, val);
 
-	return ata_pci_sff_init_one(dev, ppi, &sl82c105_sht, NULL);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id sl82c105[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_triflex.c linux-sh4/drivers/ata/pata_triflex.c
--- linux-sh4/drivers/ata.org/pata_triflex.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_triflex.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,7 +1,7 @@
 /*
  * pata_triflex.c 	- Compaq PATA for new ATA layer
  *			  (C) 2005 Red Hat Inc
- *			  Alan Cox <alan@lxorguk.ukuu.org.uk>
+ *			  Alan Cox <alan@redhat.com>
  *
  * based upon
  *
@@ -47,30 +47,34 @@
 
 /**
  *	triflex_prereset		-	probe begin
- *	@link: ATA link
+ *	@ap: ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	Set up cable type and use generic probe init
  */
 
-static int triflex_prereset(struct ata_link *link, unsigned long deadline)
+static int triflex_prereset(struct ata_port *ap, unsigned long deadline)
 {
 	static const struct pci_bits triflex_enable_bits[] = {
 		{ 0x80, 1, 0x01, 0x01 },
 		{ 0x80, 1, 0x02, 0x02 }
 	};
 
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 
 	if (!pci_test_config_bits(pdev, &triflex_enable_bits[ap->port_no]))
 		return -ENOENT;
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
 }
 
 
 
+static void triflex_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, triflex_prereset, ata_std_softreset, NULL, ata_std_postreset);
+}
+
 /**
  *	triflex_load_timing		-	timing configuration
  *	@ap: ATA interface
@@ -175,24 +179,65 @@
 }
 
 static struct scsi_host_template triflex_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations triflex_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= triflex_set_piomode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= triflex_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.bmdma_setup 	= ata_bmdma_setup,
 	.bmdma_start 	= triflex_bmdma_start,
 	.bmdma_stop	= triflex_bmdma_stop,
-	.cable_detect	= ata_cable_40wire,
-	.set_piomode	= triflex_set_piomode,
-	.prereset	= triflex_prereset,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static int triflex_init_one(struct pci_dev *dev, const struct pci_device_id *id)
 {
 	static const struct ata_port_info info = {
+		.sht = &triflex_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.port_ops = &triflex_port_ops
 	};
 	const struct ata_port_info *ppi[] = { &info, NULL };
@@ -201,7 +246,7 @@
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &dev->dev, "version " DRV_VERSION "\n");
 
-	return ata_pci_sff_init_one(dev, ppi, &triflex_sht, NULL);
+	return ata_pci_init_one(dev, ppi);
 }
 
 static const struct pci_device_id triflex[] = {
diff -Nur linux-sh4/drivers/ata.org/pata_via.c linux-sh4/drivers/ata/pata_via.c
--- linux-sh4/drivers/ata.org/pata_via.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/pata_via.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,7 @@
 /*
  * pata_via.c 	- VIA PATA for new ATA layer
  *			  (C) 2005-2006 Red Hat Inc
+ *			  Alan Cox <alan@redhat.com>
  *
  *  Documentation
  *	Most chipset documentation available under NDA only
@@ -62,7 +63,7 @@
 #include <linux/dmi.h>
 
 #define DRV_NAME "pata_via"
-#define DRV_VERSION "0.3.4"
+#define DRV_VERSION "0.3.2"
 
 /*
  *	The following comes directly from Vojtech Pavlik's ide/pci/via82cxxx
@@ -83,11 +84,6 @@
 	VIA_BAD_ID	= 0x100, /* Has wrong vendor ID (0x1107) */
 	VIA_BAD_AST	= 0x200, /* Don't touch Address Setup Timing */
 	VIA_NO_ENABLES	= 0x400, /* Has no enablebits */
-	VIA_SATA_PATA	= 0x800, /* SATA/PATA combined configuration */
-};
-
-enum {
-	VIA_IDFLAG_SINGLE = (1 << 0), /* single channel controller) */
 };
 
 /*
@@ -101,17 +97,11 @@
 	u8 rev_max;
 	u16 flags;
 } via_isa_bridges[] = {
-	{ "vx855",	PCI_DEVICE_ID_VIA_VX855,    0x00, 0x2f,
-	  VIA_UDMA_133 | VIA_BAD_AST | VIA_SATA_PATA },
-	{ "vx800",	PCI_DEVICE_ID_VIA_VX800,    0x00, 0x2f, VIA_UDMA_133 |
-	VIA_BAD_AST | VIA_SATA_PATA },
-	{ "vt8261",	PCI_DEVICE_ID_VIA_8261,     0x00, 0x2f,
-	  VIA_UDMA_133 | VIA_BAD_AST },
+	{ "vx800",	PCI_DEVICE_ID_VIA_VX800,    0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST },
 	{ "vt8237s",	PCI_DEVICE_ID_VIA_8237S,    0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST },
 	{ "vt8251",	PCI_DEVICE_ID_VIA_8251,     0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST },
-	{ "cx700",	PCI_DEVICE_ID_VIA_CX700,    0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST | VIA_SATA_PATA },
-	{ "vt6410",	PCI_DEVICE_ID_VIA_6410,     0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST | VIA_NO_ENABLES },
-	{ "vt6415",	PCI_DEVICE_ID_VIA_6415,     0x00, 0xff, VIA_UDMA_133 | VIA_BAD_AST | VIA_NO_ENABLES },
+	{ "cx700",	PCI_DEVICE_ID_VIA_CX700,    0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST },
+	{ "vt6410",	PCI_DEVICE_ID_VIA_6410,     0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST | VIA_NO_ENABLES},
 	{ "vt8237a",	PCI_DEVICE_ID_VIA_8237A,    0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST },
 	{ "vt8237",	PCI_DEVICE_ID_VIA_8237,     0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST },
 	{ "vt8235",	PCI_DEVICE_ID_VIA_8235,     0x00, 0x2f, VIA_UDMA_133 | VIA_BAD_AST },
@@ -131,20 +121,15 @@
 	{ "vt82c586",	PCI_DEVICE_ID_VIA_82C586_0, 0x00, 0x0f, VIA_UDMA_NONE | VIA_SET_FIFO },
 	{ "vt82c576",	PCI_DEVICE_ID_VIA_82C576,   0x00, 0x2f, VIA_UDMA_NONE | VIA_SET_FIFO | VIA_NO_UNMASK },
 	{ "vt82c576",	PCI_DEVICE_ID_VIA_82C576,   0x00, 0x2f, VIA_UDMA_NONE | VIA_SET_FIFO | VIA_NO_UNMASK | VIA_BAD_ID },
-	{ "vtxxxx",	PCI_DEVICE_ID_VIA_ANON,    0x00, 0x2f,
-	  VIA_UDMA_133 | VIA_BAD_AST },
 	{ NULL }
 };
 
-struct via_port {
-	u8 cached_device;
-};
 
 /*
  *	Cable special cases
  */
 
-static const struct dmi_system_id cable_dmi_table[] = {
+static struct dmi_system_id cable_dmi_table[] = {
 	{
 		.ident = "Acer Ferrari 3400",
 		.matches = {
@@ -187,14 +172,11 @@
 	if (via_cable_override(pdev))
 		return ATA_CBL_PATA40_SHORT;
 
-	if ((config->flags & VIA_SATA_PATA) && ap->port_no == 0)
-		return ATA_CBL_SATA;
-
 	/* Early chips are 40 wire */
 	if ((config->flags & VIA_UDMA) < VIA_UDMA_66)
 		return ATA_CBL_PATA40;
 	/* UDMA 66 chips have only drive side logic */
-	else if ((config->flags & VIA_UDMA) < VIA_UDMA_100)
+	else if((config->flags & VIA_UDMA) < VIA_UDMA_100)
 		return ATA_CBL_PATA_UNK;
 	/* UDMA 100 or later */
 	pci_read_config_dword(pdev, 0x50, &ata66);
@@ -202,16 +184,11 @@
 	   two drives */
 	if (ata66 & (0x10100000 >> (16 * ap->port_no)))
 		return ATA_CBL_PATA80;
-	/* Check with ACPI so we can spot BIOS reported SATA bridges */
-	if (ata_acpi_init_gtm(ap) &&
-	    ata_acpi_cbl_80wire(ap, ata_acpi_init_gtm(ap)))
-		return ATA_CBL_PATA80;
 	return ATA_CBL_PATA40;
 }
 
-static int via_pre_reset(struct ata_link *link, unsigned long deadline)
+static int via_pre_reset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	const struct via_isa_bridge *config = ap->host->private_data;
 
 	if (!(config->flags & VIA_NO_ENABLES)) {
@@ -224,11 +201,23 @@
 			return -ENOENT;
 	}
 
-	return ata_sff_prereset(link, deadline);
+	return ata_std_prereset(ap, deadline);
 }
 
 
 /**
+ *	via_error_handler		-	reset for VIA chips
+ *	@ap: ATA port
+ *
+ *	Handle the reset callback for the later chips with cable detect
+ */
+
+static void via_error_handler(struct ata_port *ap)
+{
+	ata_bmdma_drive_eh(ap, via_pre_reset, ata_std_softreset, NULL, ata_std_postreset);
+}
+
+/**
  *	via_do_set_mode	-	set initial PIO mode data
  *	@ap: ATA interface
  *	@adev: ATA device
@@ -273,15 +262,15 @@
 
 		pci_read_config_byte(pdev, 0x4C, &setup);
 		setup &= ~(3 << shift);
-		setup |= clamp_val(t.setup, 1, 4) << shift;	/* 1,4 or 1,4 - 1  FIXME */
+		setup |= FIT(t.setup, 1, 4) << shift;	/* 1,4 or 1,4 - 1  FIXME */
 		pci_write_config_byte(pdev, 0x4C, setup);
 	}
 
 	/* Load the PIO mode bits */
 	pci_write_config_byte(pdev, 0x4F - ap->port_no,
-		((clamp_val(t.act8b, 1, 16) - 1) << 4) | (clamp_val(t.rec8b, 1, 16) - 1));
+		((FIT(t.act8b, 1, 16) - 1) << 4) | (FIT(t.rec8b, 1, 16) - 1));
 	pci_write_config_byte(pdev, 0x48 + offset,
-		((clamp_val(t.active, 1, 16) - 1) << 4) | (clamp_val(t.recover, 1, 16) - 1));
+		((FIT(t.active, 1, 16) - 1) << 4) | (FIT(t.recover, 1, 16) - 1));
 
 	/* Load the UDMA bits according to type */
 	switch(udma_type) {
@@ -289,21 +278,21 @@
 			/* BUG() ? */
 			/* fall through */
 		case 33:
-			ut = t.udma ? (0xe0 | (clamp_val(t.udma, 2, 5) - 2)) : 0x03;
+			ut = t.udma ? (0xe0 | (FIT(t.udma, 2, 5) - 2)) : 0x03;
 			break;
 		case 66:
-			ut = t.udma ? (0xe8 | (clamp_val(t.udma, 2, 9) - 2)) : 0x0f;
+			ut = t.udma ? (0xe8 | (FIT(t.udma, 2, 9) - 2)) : 0x0f;
 			break;
 		case 100:
-			ut = t.udma ? (0xe0 | (clamp_val(t.udma, 2, 9) - 2)) : 0x07;
+			ut = t.udma ? (0xe0 | (FIT(t.udma, 2, 9) - 2)) : 0x07;
 			break;
 		case 133:
-			ut = t.udma ? (0xe0 | (clamp_val(t.udma, 2, 9) - 2)) : 0x07;
+			ut = t.udma ? (0xe0 | (FIT(t.udma, 2, 9) - 2)) : 0x07;
 			break;
 	}
 
 	/* Set UDMA unless device is not UDMA capable */
-	if (udma_type && t.udma) {
+	if (udma_type) {
 		u8 cable80_status;
 
 		/* Get 80-wire cable detection bit */
@@ -336,102 +325,94 @@
 	via_do_set_mode(ap, adev, adev->dma_mode, tclock[mode], set_ast, udma[mode]);
 }
 
-/**
- *	via_tf_load - send taskfile registers to host controller
- *	@ap: Port to which output is sent
- *	@tf: ATA taskfile register set
- *
- *	Outputs ATA taskfile to standard ATA host controller.
- *
- *	Note: This is to fix the internal bug of via chipsets, which
- *	will reset the device register after changing the IEN bit on
- *	ctl register
- */
-static void via_tf_load(struct ata_port *ap, const struct ata_taskfile *tf)
-{
-	struct ata_ioports *ioaddr = &ap->ioaddr;
-	struct via_port *vp = ap->private_data;
-	unsigned int is_addr = tf->flags & ATA_TFLAG_ISADDR;
-	int newctl = 0;
-
-	if (tf->ctl != ap->last_ctl) {
-		iowrite8(tf->ctl, ioaddr->ctl_addr);
-		ap->last_ctl = tf->ctl;
-		ata_wait_idle(ap);
-		newctl = 1;
-	}
-
-	if (tf->flags & ATA_TFLAG_DEVICE) {
-		iowrite8(tf->device, ioaddr->device_addr);
-		vp->cached_device = tf->device;
-	} else if (newctl)
-		iowrite8(vp->cached_device, ioaddr->device_addr);
-
-	if (is_addr && (tf->flags & ATA_TFLAG_LBA48)) {
-		WARN_ON_ONCE(!ioaddr->ctl_addr);
-		iowrite8(tf->hob_feature, ioaddr->feature_addr);
-		iowrite8(tf->hob_nsect, ioaddr->nsect_addr);
-		iowrite8(tf->hob_lbal, ioaddr->lbal_addr);
-		iowrite8(tf->hob_lbam, ioaddr->lbam_addr);
-		iowrite8(tf->hob_lbah, ioaddr->lbah_addr);
-		VPRINTK("hob: feat 0x%X nsect 0x%X, lba 0x%X 0x%X 0x%X\n",
-			tf->hob_feature,
-			tf->hob_nsect,
-			tf->hob_lbal,
-			tf->hob_lbam,
-			tf->hob_lbah);
-	}
-
-	if (is_addr) {
-		iowrite8(tf->feature, ioaddr->feature_addr);
-		iowrite8(tf->nsect, ioaddr->nsect_addr);
-		iowrite8(tf->lbal, ioaddr->lbal_addr);
-		iowrite8(tf->lbam, ioaddr->lbam_addr);
-		iowrite8(tf->lbah, ioaddr->lbah_addr);
-		VPRINTK("feat 0x%X nsect 0x%X lba 0x%X 0x%X 0x%X\n",
-			tf->feature,
-			tf->nsect,
-			tf->lbal,
-			tf->lbam,
-			tf->lbah);
-	}
-
-	ata_wait_idle(ap);
-}
-
-static int via_port_start(struct ata_port *ap)
-{
-	struct via_port *vp;
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-
-	int ret = ata_sff_port_start(ap);
-	if (ret < 0)
-		return ret;
-
-	vp = devm_kzalloc(&pdev->dev, sizeof(struct via_port), GFP_KERNEL);
-	if (vp == NULL)
-		return -ENOMEM;
-	ap->private_data = vp;
-	return 0;
-}
-
 static struct scsi_host_template via_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations via_port_ops = {
-	.inherits	= &ata_bmdma_port_ops,
-	.cable_detect	= via_cable_detect,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= via_set_piomode,
 	.set_dmamode	= via_set_dmamode,
-	.prereset	= via_pre_reset,
-	.sff_tf_load	= via_tf_load,
-	.port_start	= via_port_start,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= via_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= via_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 static struct ata_port_operations via_port_ops_noirq = {
-	.inherits	= &via_port_ops,
-	.sff_data_xfer	= ata_sff_data_xfer_noirq,
+	.port_disable	= ata_port_disable,
+	.set_piomode	= via_set_piomode,
+	.set_dmamode	= via_set_dmamode,
+	.mode_filter	= ata_pci_default_filter,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= via_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= via_cable_detect,
+
+	.bmdma_setup 	= ata_bmdma_setup,
+	.bmdma_start 	= ata_bmdma_start,
+	.bmdma_stop	= ata_bmdma_stop,
+	.bmdma_status 	= ata_bmdma_status,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= ata_data_xfer_noirq,
+
+	.irq_handler	= ata_interrupt,
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -439,7 +420,7 @@
  *	@pdev: PCI device
  *	@flags: configuration flags
  *
- *	Set the FIFO properties for this device if necessary. Used both on
+ *	Set the FIFO properties for this device if neccessary. Used both on
  *	set up and on and the resume path
  */
 
@@ -481,73 +462,70 @@
 {
 	/* Early VIA without UDMA support */
 	static const struct ata_port_info via_mwdma_info = {
+		.sht = &via_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.port_ops = &via_port_ops
 	};
 	/* Ditto with IRQ masking required */
 	static const struct ata_port_info via_mwdma_info_borked = {
+		.sht = &via_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.port_ops = &via_port_ops_noirq,
 	};
 	/* VIA UDMA 33 devices (and borked 66) */
 	static const struct ata_port_info via_udma33_info = {
+		.sht = &via_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA2,
 		.port_ops = &via_port_ops
 	};
 	/* VIA UDMA 66 devices */
 	static const struct ata_port_info via_udma66_info = {
+		.sht = &via_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA4,
 		.port_ops = &via_port_ops
 	};
 	/* VIA UDMA 100 devices */
 	static const struct ata_port_info via_udma100_info = {
+		.sht = &via_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA5,
 		.port_ops = &via_port_ops
 	};
 	/* UDMA133 with bad AST (All current 133) */
 	static const struct ata_port_info via_udma133_info = {
+		.sht = &via_sht,
 		.flags = ATA_FLAG_SLAVE_POSS,
-		.pio_mask = ATA_PIO4,
-		.mwdma_mask = ATA_MWDMA2,
+		.pio_mask = 0x1f,
+		.mwdma_mask = 0x07,
 		.udma_mask = ATA_UDMA6,	/* FIXME: should check north bridge */
 		.port_ops = &via_port_ops
 	};
-	const struct ata_port_info *ppi[] = { NULL, NULL };
+	struct ata_port_info type;
+	const struct ata_port_info *ppi[] = { &type, NULL };
 	struct pci_dev *isa = NULL;
 	const struct via_isa_bridge *config;
 	static int printed_version;
 	u8 enable;
 	u32 timing;
-	unsigned long flags = id->driver_data;
-	int rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
 
-	rc = pcim_enable_device(pdev);
-	if (rc)
-		return rc;
-
-	if (flags & VIA_IDFLAG_SINGLE)
-		ppi[1] = &ata_dummy_port_info;
-
 	/* To find out how the IDE will behave and what features we
 	   actually have to look at the bridge not the IDE controller */
-	for (config = via_isa_bridges; config->id != PCI_DEVICE_ID_VIA_ANON;
-	     config++)
+	for (config = via_isa_bridges; config->id; config++)
 		if ((isa = pci_get_device(PCI_VENDOR_ID_VIA +
 			!!(config->flags & VIA_BAD_ID),
 			config->id, NULL))) {
@@ -558,14 +536,17 @@
 			pci_dev_put(isa);
 		}
 
+	if (!config->id) {
+		printk(KERN_WARNING "via: Unknown VIA SouthBridge, disabling.\n");
+		return -ENODEV;
+	}
 	pci_dev_put(isa);
 
-	if (!(config->flags & VIA_NO_ENABLES)) {
-		/* 0x40 low bits indicate enabled channels */
-		pci_read_config_byte(pdev, 0x40 , &enable);
-		enable &= 3;
-		if (enable == 0)
-			return -ENODEV;
+	/* 0x40 low bits indicate enabled channels */
+	pci_read_config_byte(pdev, 0x40 , &enable);
+	enable &= 3;
+	if (enable == 0) {
+		return -ENODEV;
 	}
 
 	/* Initialise the FIFO for the enabled channels. */
@@ -575,25 +556,25 @@
 	switch(config->flags & VIA_UDMA) {
 		case VIA_UDMA_NONE:
 			if (config->flags & VIA_NO_UNMASK)
-				ppi[0] = &via_mwdma_info_borked;
+				type = via_mwdma_info_borked;
 			else
-				ppi[0] = &via_mwdma_info;
+				type = via_mwdma_info;
 			break;
 		case VIA_UDMA_33:
-			ppi[0] = &via_udma33_info;
+			type = via_udma33_info;
 			break;
 		case VIA_UDMA_66:
-			ppi[0] = &via_udma66_info;
+			type = via_udma66_info;
 			/* The 66 MHz devices require we enable the clock */
 			pci_read_config_dword(pdev, 0x50, &timing);
 			timing |= 0x80008;
 			pci_write_config_dword(pdev, 0x50, timing);
 			break;
 		case VIA_UDMA_100:
-			ppi[0] = &via_udma100_info;
+			type = via_udma100_info;
 			break;
 		case VIA_UDMA_133:
-			ppi[0] = &via_udma133_info;
+			type = via_udma133_info;
 			break;
 		default:
 			WARN_ON(1);
@@ -608,7 +589,9 @@
 	}
 
 	/* We have established the device type, now fire it up */
-	return ata_pci_sff_init_one(pdev, ppi, &via_sht, (void *)config);
+	type.private_data = (void *)config;
+
+	return ata_pci_init_one(pdev, ppi);
 }
 
 #ifdef CONFIG_PM
@@ -627,11 +610,6 @@
 	u32 timing;
 	struct ata_host *host = dev_get_drvdata(&pdev->dev);
 	const struct via_isa_bridge *config = host->private_data;
-	int rc;
-
-	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
-		return rc;
 
 	via_config_fifo(pdev, config->flags);
 
@@ -647,21 +625,16 @@
 		timing &= ~0x80008;
 		pci_write_config_dword(pdev, 0x50, timing);
 	}
-
-	ata_host_resume(host);
-	return 0;
+	return ata_pci_device_resume(pdev);
 }
 #endif
 
 static const struct pci_device_id via[] = {
-	{ PCI_VDEVICE(VIA, 0x0415), },
 	{ PCI_VDEVICE(VIA, 0x0571), },
 	{ PCI_VDEVICE(VIA, 0x0581), },
 	{ PCI_VDEVICE(VIA, 0x1571), },
 	{ PCI_VDEVICE(VIA, 0x3164), },
 	{ PCI_VDEVICE(VIA, 0x5324), },
-	{ PCI_VDEVICE(VIA, 0xC409), VIA_IDFLAG_SINGLE },
-	{ PCI_VDEVICE(VIA, 0x9001), VIA_IDFLAG_SINGLE },
 
 	{ },
 };
diff -Nur linux-sh4/drivers/ata.org/pata_winbond.c linux-sh4/drivers/ata/pata_winbond.c
--- linux-sh4/drivers/ata.org/pata_winbond.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pata_winbond.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,6 +1,6 @@
 /*
  *    pata_winbond.c - Winbond VLB ATA controllers
- *	(C) 2006 Red Hat
+ *	(C) 2006 Red Hat <alan@redhat.com>
  *
  *    Support for the Winbond 83759A when operating in advanced mode.
  *    Multichip mode is not currently supported.
@@ -75,8 +75,8 @@
 	else
 		ata_timing_compute(adev, adev->pio_mode, &t, 30303, 1000);
 
-	active = (clamp_val(t.active, 3, 17) - 1) & 0x0F;
-	recovery = (clamp_val(t.recover, 1, 15) + 1) & 0x0F;
+	active = (FIT(t.active, 3, 17) - 1) & 0x0F;
+	recovery = (FIT(t.recover, 1, 15) + 1) & 0x0F;
 	timing = (active << 4) | recovery;
 	winbond_writecfg(winbond->config, timing, reg);
 
@@ -87,49 +87,82 @@
 		reg |= 0x08;	/* FIFO off */
 	if (!ata_pio_need_iordy(adev))
 		reg |= 0x02;	/* IORDY off */
-	reg |= (clamp_val(t.setup, 0, 3) << 6);
+	reg |= (FIT(t.setup, 0, 3) << 6);
 	winbond_writecfg(winbond->config, timing + 1, reg);
 }
 
 
-static unsigned int winbond_data_xfer(struct ata_device *dev,
-			unsigned char *buf, unsigned int buflen, int rw)
+static void winbond_data_xfer(struct ata_device *adev, unsigned char *buf, unsigned int buflen, int write_data)
 {
-	struct ata_port *ap = dev->link->ap;
+	struct ata_port *ap = adev->ap;
 	int slop = buflen & 3;
 
-	if (ata_id_has_dword_io(dev->id)) {
-		if (rw == READ)
-			ioread32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
-		else
+	if (ata_id_has_dword_io(adev->id)) {
+		if (write_data)
 			iowrite32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
+		else
+			ioread32_rep(ap->ioaddr.data_addr, buf, buflen >> 2);
 
 		if (unlikely(slop)) {
-			__le32 pad;
-			if (rw == READ) {
-				pad = cpu_to_le32(ioread32(ap->ioaddr.data_addr));
-				memcpy(buf + buflen - slop, &pad, slop);
-			} else {
+			u32 pad;
+			if (write_data) {
 				memcpy(&pad, buf + buflen - slop, slop);
-				iowrite32(le32_to_cpu(pad), ap->ioaddr.data_addr);
+				pad = le32_to_cpu(pad);
+				iowrite32(pad, ap->ioaddr.data_addr);
+			} else {
+				pad = ioread32(ap->ioaddr.data_addr);
+				pad = cpu_to_le16(pad);
+				memcpy(buf + buflen - slop, &pad, slop);
 			}
-			buflen += 4 - slop;
 		}
 	} else
-		buflen = ata_sff_data_xfer(dev, buf, buflen, rw);
-
-	return buflen;
+		ata_data_xfer(adev, buf, buflen, write_data);
 }
 
 static struct scsi_host_template winbond_sht = {
-	ATA_PIO_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct ata_port_operations winbond_port_ops = {
-	.inherits	= &ata_sff_port_ops,
-	.sff_data_xfer	= winbond_data_xfer,
-	.cable_detect	= ata_cable_40wire,
+	.port_disable	= ata_port_disable,
 	.set_piomode	= winbond_set_piomode,
+
+	.tf_load	= ata_tf_load,
+	.tf_read	= ata_tf_read,
+	.check_status 	= ata_check_status,
+	.exec_command	= ata_exec_command,
+	.dev_select 	= ata_std_dev_select,
+
+	.freeze		= ata_bmdma_freeze,
+	.thaw		= ata_bmdma_thaw,
+	.error_handler	= ata_bmdma_error_handler,
+	.post_internal_cmd = ata_bmdma_post_internal_cmd,
+	.cable_detect	= ata_cable_40wire,
+
+	.qc_prep 	= ata_qc_prep,
+	.qc_issue	= ata_qc_issue_prot,
+
+	.data_xfer	= winbond_data_xfer,
+
+	.irq_clear	= ata_bmdma_irq_clear,
+	.irq_on		= ata_irq_on,
+	.irq_ack	= ata_irq_ack,
+
+	.port_start	= ata_port_start,
 };
 
 /**
@@ -162,11 +195,10 @@
 	reg = winbond_readcfg(port, 0x81);
 
 	if (!(reg & 0x03))		/* Disabled */
-		return -ENODEV;
+		return 0;
 
 	for (i = 0; i < 2 ; i ++) {
 		unsigned long cmd_port = 0x1F0 - (0x80 * i);
-		unsigned long ctl_port = cmd_port + 0x206;
 		struct ata_host *host;
 		struct ata_port *ap;
 		void __iomem *cmd_addr, *ctl_addr;
@@ -182,23 +214,21 @@
 		host = ata_host_alloc(&pdev->dev, 1);
 		if (!host)
 			goto err_unregister;
-		ap = host->ports[0];
 
 		rc = -ENOMEM;
 		cmd_addr = devm_ioport_map(&pdev->dev, cmd_port, 8);
-		ctl_addr = devm_ioport_map(&pdev->dev, ctl_port, 1);
+		ctl_addr = devm_ioport_map(&pdev->dev, cmd_port + 0x0206, 1);
 		if (!cmd_addr || !ctl_addr)
 			goto err_unregister;
 
-		ata_port_desc(ap, "cmd 0x%lx ctl 0x%lx", cmd_port, ctl_port);
-
+		ap = host->ports[0];
 		ap->ops = &winbond_port_ops;
-		ap->pio_mask = ATA_PIO4;
+		ap->pio_mask = 0x1F;
 		ap->flags |= ATA_FLAG_SLAVE_POSS;
 		ap->ioaddr.cmd_addr = cmd_addr;
 		ap->ioaddr.altstatus_addr = ctl_addr;
 		ap->ioaddr.ctl_addr = ctl_addr;
-		ata_sff_std_ports(&ap->ioaddr);
+		ata_std_ports(&ap->ioaddr);
 
 		/* hook in a private data structure per channel */
 		host->private_data = &winbond_data[nr_winbond_host];
@@ -206,7 +236,7 @@
 		winbond_data[nr_winbond_host].platform_dev = pdev;
 
 		/* activate */
-		rc = ata_host_activate(host, 14 + i, ata_sff_interrupt, 0,
+		rc = ata_host_activate(host, 14 + i, ata_interrupt, 0,
 				       &winbond_sht);
 		if (rc)
 			goto err_unregister;
@@ -248,7 +278,7 @@
 
 			if (request_region(port, 2, "pata_winbond")) {
 				ret = winbond_init_one(port);
-				if (ret <= 0)
+				if(ret <= 0)
 					release_region(port, 2);
 				else ct+= ret;
 			}
diff -Nur linux-sh4/drivers/ata.org/pdc_adma.c linux-sh4/drivers/ata/pdc_adma.c
--- linux-sh4/drivers/ata.org/pdc_adma.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/pdc_adma.c	2012-01-15 06:30:15.000000000 -0800
@@ -47,10 +47,10 @@
 #define DRV_VERSION	"1.0"
 
 /* macro to calculate base address for ATA regs */
-#define ADMA_ATA_REGS(base, port_no)	((base) + ((port_no) * 0x40))
+#define ADMA_ATA_REGS(base,port_no)	((base) + ((port_no) * 0x40))
 
 /* macro to calculate base address for ADMA regs */
-#define ADMA_REGS(base, port_no)	((base) + 0x80 + ((port_no) * 0x20))
+#define ADMA_REGS(base,port_no)		((base) + 0x80 + ((port_no) * 0x20))
 
 /* macro to obtain addresses from ata_port */
 #define ADMA_PORT_REGS(ap) \
@@ -92,8 +92,6 @@
 
 	/* CPB bits */
 	cDONE			= (1 << 0),
-	cATERR			= (1 << 3),
-
 	cVLD			= (1 << 0),
 	cDAT			= (1 << 2),
 	cIEN			= (1 << 3),
@@ -128,47 +126,68 @@
 	adma_state_t		state;
 };
 
-static int adma_ata_init_one(struct pci_dev *pdev,
+static int adma_ata_init_one (struct pci_dev *pdev,
 				const struct pci_device_id *ent);
 static int adma_port_start(struct ata_port *ap);
+static void adma_host_stop(struct ata_host *host);
 static void adma_port_stop(struct ata_port *ap);
+static void adma_phy_reset(struct ata_port *ap);
 static void adma_qc_prep(struct ata_queued_cmd *qc);
 static unsigned int adma_qc_issue(struct ata_queued_cmd *qc);
 static int adma_check_atapi_dma(struct ata_queued_cmd *qc);
-static void adma_freeze(struct ata_port *ap);
-static void adma_thaw(struct ata_port *ap);
-static int adma_prereset(struct ata_link *link, unsigned long deadline);
+static void adma_bmdma_stop(struct ata_queued_cmd *qc);
+static u8 adma_bmdma_status(struct ata_port *ap);
+static void adma_irq_clear(struct ata_port *ap);
+static void adma_eng_timeout(struct ata_port *ap);
 
 static struct scsi_host_template adma_ata_sht = {
-	ATA_BASE_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
+	.proc_name		= DRV_NAME,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= LIBATA_MAX_PRD,
 	.dma_boundary		= ADMA_DMA_BOUNDARY,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.use_clustering		= ENABLE_CLUSTERING,
+	.emulated		= ATA_SHT_EMULATED,
 };
 
-static struct ata_port_operations adma_ata_ops = {
-	.inherits		= &ata_sff_port_ops,
-
-	.lost_interrupt		= ATA_OP_NULL,
-
+static const struct ata_port_operations adma_ata_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.exec_command		= ata_exec_command,
+	.check_status		= ata_check_status,
+	.dev_select		= ata_std_dev_select,
+	.phy_reset		= adma_phy_reset,
 	.check_atapi_dma	= adma_check_atapi_dma,
+	.data_xfer		= ata_data_xfer,
 	.qc_prep		= adma_qc_prep,
 	.qc_issue		= adma_qc_issue,
-
-	.freeze			= adma_freeze,
-	.thaw			= adma_thaw,
-	.prereset		= adma_prereset,
-
+	.eng_timeout		= adma_eng_timeout,
+	.irq_clear		= adma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 	.port_start		= adma_port_start,
 	.port_stop		= adma_port_stop,
+	.host_stop		= adma_host_stop,
+	.bmdma_stop		= adma_bmdma_stop,
+	.bmdma_status		= adma_bmdma_status,
 };
 
 static struct ata_port_info adma_port_info[] = {
 	/* board_1841_idx */
 	{
-		.flags		= ATA_FLAG_SLAVE_POSS |
+		.flags		= ATA_FLAG_SLAVE_POSS | ATA_FLAG_SRST |
 				  ATA_FLAG_NO_LEGACY | ATA_FLAG_MMIO |
 				  ATA_FLAG_PIO_POLLING,
-		.pio_mask	= ATA_PIO4_ONLY,
+		.pio_mask	= 0x10, /* pio4 */
 		.udma_mask	= ATA_UDMA4,
 		.port_ops	= &adma_ata_ops,
 	},
@@ -192,6 +211,21 @@
 	return 1;	/* ATAPI DMA not yet supported */
 }
 
+static void adma_bmdma_stop(struct ata_queued_cmd *qc)
+{
+	/* nothing */
+}
+
+static u8 adma_bmdma_status(struct ata_port *ap)
+{
+	return 0;
+}
+
+static void adma_irq_clear(struct ata_port *ap)
+{
+	/* nothing */
+}
+
 static void adma_reset_engine(struct ata_port *ap)
 {
 	void __iomem *chan = ADMA_PORT_REGS(ap);
@@ -210,7 +244,7 @@
 
 	/* mask/clear ATA interrupts */
 	writeb(ATA_NIEN, ap->ioaddr.ctl_addr);
-	ata_sff_check_status(ap);
+	ata_check_status(ap);
 
 	/* reset the ADMA engine */
 	adma_reset_engine(ap);
@@ -239,36 +273,24 @@
 	readb(chan + ADMA_STATUS);	/* flush */
 }
 
-static void adma_freeze(struct ata_port *ap)
+static void adma_phy_reset(struct ata_port *ap)
 {
-	void __iomem *chan = ADMA_PORT_REGS(ap);
-
-	/* mask/clear ATA interrupts */
-	writeb(ATA_NIEN, ap->ioaddr.ctl_addr);
-	ata_sff_check_status(ap);
-
-	/* reset ADMA to idle state */
-	writew(aPIOMD4 | aNIEN | aRSTADM, chan + ADMA_CONTROL);
-	udelay(2);
-	writew(aPIOMD4 | aNIEN, chan + ADMA_CONTROL);
-	udelay(2);
-}
+	struct adma_port_priv *pp = ap->private_data;
 
-static void adma_thaw(struct ata_port *ap)
-{
+	pp->state = adma_state_idle;
 	adma_reinit_engine(ap);
+	ata_port_probe(ap);
+	ata_bus_reset(ap);
 }
 
-static int adma_prereset(struct ata_link *link, unsigned long deadline)
+static void adma_eng_timeout(struct ata_port *ap)
 {
-	struct ata_port *ap = link->ap;
 	struct adma_port_priv *pp = ap->private_data;
 
 	if (pp->state != adma_state_idle) /* healthy paranoia */
 		pp->state = adma_state_mmio;
 	adma_reinit_engine(ap);
-
-	return ata_sff_prereset(link, deadline);
+	ata_eng_timeout(ap);
 }
 
 static int adma_fill_sg(struct ata_queued_cmd *qc)
@@ -276,12 +298,11 @@
 	struct scatterlist *sg;
 	struct ata_port *ap = qc->ap;
 	struct adma_port_priv *pp = ap->private_data;
-	u8  *buf = pp->pkt, *last_buf = NULL;
+	u8  *buf = pp->pkt;
 	int i = (2 + buf[3]) * 8;
 	u8 pFLAGS = pORD | ((qc->tf.flags & ATA_TFLAG_WRITE) ? pDIRO : 0);
-	unsigned int si;
 
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
+	ata_for_each_sg(sg, qc) {
 		u32 addr;
 		u32 len;
 
@@ -293,23 +314,20 @@
 		*(__le32 *)(buf + i) = cpu_to_le32(len);
 		i += 4;
 
-		last_buf = &buf[i];
+		if (ata_sg_is_last(sg, qc))
+			pFLAGS |= pEND;
 		buf[i++] = pFLAGS;
 		buf[i++] = qc->dev->dma_mode & 0xf;
 		buf[i++] = 0;	/* pPKLW */
 		buf[i++] = 0;	/* reserved */
 
-		*(__le32 *)(buf + i) =
-			(pFLAGS & pEND) ? 0 : cpu_to_le32(pp->pkt_dma + i + 4);
+		*(__le32 *)(buf + i)
+			= (pFLAGS & pEND) ? 0 : cpu_to_le32(pp->pkt_dma + i + 4);
 		i += 4;
 
 		VPRINTK("PRD[%u] = (0x%lX, 0x%X)\n", i/4,
 					(unsigned long)addr, len);
 	}
-
-	if (likely(last_buf))
-		*last_buf |= pEND;
-
 	return i;
 }
 
@@ -324,7 +342,7 @@
 
 	adma_enter_reg_mode(qc->ap);
 	if (qc->tf.protocol != ATA_PROT_DMA) {
-		ata_sff_qc_prep(qc);
+		ata_qc_prep(qc);
 		return;
 	}
 
@@ -414,7 +432,7 @@
 		adma_packet_start(qc);
 		return 0;
 
-	case ATAPI_PROT_DMA:
+	case ATA_PROT_ATAPI_DMA:
 		BUG();
 		break;
 
@@ -423,7 +441,7 @@
 	}
 
 	pp->state = adma_state_mmio;
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
 static inline unsigned int adma_intr_pkt(struct ata_host *host)
@@ -446,33 +464,14 @@
 		pp = ap->private_data;
 		if (!pp || pp->state != adma_state_pkt)
 			continue;
-		qc = ata_qc_from_tag(ap, ap->link.active_tag);
+		qc = ata_qc_from_tag(ap, ap->active_tag);
 		if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING))) {
-			if (status & aPERR)
-				qc->err_mask |= AC_ERR_HOST_BUS;
-			else if ((status & (aPSD | aUIRQ)))
+			if ((status & (aPERR | aPSD | aUIRQ)))
 				qc->err_mask |= AC_ERR_OTHER;
-
-			if (pp->pkt[0] & cATERR)
-				qc->err_mask |= AC_ERR_DEV;
 			else if (pp->pkt[0] != cDONE)
 				qc->err_mask |= AC_ERR_OTHER;
 
-			if (!qc->err_mask)
-				ata_qc_complete(qc);
-			else {
-				struct ata_eh_info *ehi = &ap->link.eh_info;
-				ata_ehi_clear_desc(ehi);
-				ata_ehi_push_desc(ehi,
-					"ADMA-status 0x%02X", status);
-				ata_ehi_push_desc(ehi,
-					"pkt[0] 0x%02X", pp->pkt[0]);
-
-				if (qc->err_mask == AC_ERR_DEV)
-					ata_port_abort(ap);
-				else
-					ata_port_freeze(ap);
-			}
+			ata_qc_complete(qc);
 		}
 	}
 	return handled;
@@ -490,11 +489,11 @@
 			struct adma_port_priv *pp = ap->private_data;
 			if (!pp || pp->state != adma_state_mmio)
 				continue;
-			qc = ata_qc_from_tag(ap, ap->link.active_tag);
+			qc = ata_qc_from_tag(ap, ap->active_tag);
 			if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING))) {
 
 				/* check main status, clearing INTRQ */
-				u8 status = ata_sff_check_status(ap);
+				u8 status = ata_check_status(ap);
 				if ((status & ATA_BUSY))
 					continue;
 				DPRINTK("ata%u: protocol %d (dev_stat 0x%X)\n",
@@ -503,20 +502,7 @@
 				/* complete taskfile transaction */
 				pp->state = adma_state_idle;
 				qc->err_mask |= ac_err_mask(status);
-				if (!qc->err_mask)
-					ata_qc_complete(qc);
-				else {
-					struct ata_eh_info *ehi =
-						&ap->link.eh_info;
-					ata_ehi_clear_desc(ehi);
-					ata_ehi_push_desc(ehi,
-						"status 0x%02X", status);
-
-					if (qc->err_mask == AC_ERR_DEV)
-						ata_port_abort(ap);
-					else
-						ata_port_freeze(ap);
-				}
+				ata_qc_complete(qc);
 				handled = 1;
 			}
 		}
@@ -576,7 +562,7 @@
 		return -ENOMEM;
 	/* paranoia? */
 	if ((pp->pkt_dma & 7) != 0) {
-		printk(KERN_ERR "bad alignment for pp->pkt_dma: %08x\n",
+		printk("bad alignment for pp->pkt_dma: %08x\n",
 						(u32)pp->pkt_dma);
 		return -ENOMEM;
 	}
@@ -591,6 +577,14 @@
 	adma_reset_engine(ap);
 }
 
+static void adma_host_stop(struct ata_host *host)
+{
+	unsigned int port_no;
+
+	for (port_no = 0; port_no < ADMA_PORTS; ++port_no)
+		adma_reset_engine(host->ports[port_no]);
+}
+
 static void adma_host_init(struct ata_host *host, unsigned int chip_id)
 {
 	unsigned int port_no;
@@ -607,13 +601,13 @@
 {
 	int rc;
 
-	rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
+	rc = pci_set_dma_mask(pdev, DMA_32BIT_MASK);
 	if (rc) {
 		dev_printk(KERN_ERR, &pdev->dev,
 			"32-bit DMA enable failed\n");
 		return rc;
 	}
-	rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+	rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 	if (rc) {
 		dev_printk(KERN_ERR, &pdev->dev,
 			"32-bit consistent DMA enable failed\n");
@@ -658,16 +652,9 @@
 	if (rc)
 		return rc;
 
-	for (port_no = 0; port_no < ADMA_PORTS; ++port_no) {
-		struct ata_port *ap = host->ports[port_no];
-		void __iomem *port_base = ADMA_ATA_REGS(mmio_base, port_no);
-		unsigned int offset = port_base - mmio_base;
-
-		adma_ata_setup_port(&ap->ioaddr, port_base);
-
-		ata_port_pbar_desc(ap, ADMA_MMIO_BAR, -1, "mmio");
-		ata_port_pbar_desc(ap, ADMA_MMIO_BAR, offset, "port");
-	}
+	for (port_no = 0; port_no < ADMA_PORTS; ++port_no)
+		adma_ata_setup_port(&host->ports[port_no]->ioaddr,
+				    ADMA_ATA_REGS(mmio_base, port_no));
 
 	/* initialize adapter */
 	adma_host_init(host, board_idx);
diff -Nur linux-sh4/drivers/ata.org/sata_fsl.c linux-sh4/drivers/ata/sata_fsl.c
--- linux-sh4/drivers/ata.org/sata_fsl.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_fsl.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,1454 +0,0 @@
-/*
- * drivers/ata/sata_fsl.c
- *
- * Freescale 3.0Gbps SATA device driver
- *
- * Author: Ashish Kalra <ashish.kalra@freescale.com>
- * Li Yang <leoli@freescale.com>
- *
- * Copyright (c) 2006-2007 Freescale Semiconductor, Inc.
- *
- * This program is free software; you can redistribute  it and/or modify it
- * under  the terms of  the GNU General  Public License as published by the
- * Free Software Foundation;  either version 2 of the  License, or (at your
- * option) any later version.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/platform_device.h>
-
-#include <scsi/scsi_host.h>
-#include <scsi/scsi_cmnd.h>
-#include <linux/libata.h>
-#include <asm/io.h>
-#include <linux/of_platform.h>
-
-/* Controller information */
-enum {
-	SATA_FSL_QUEUE_DEPTH	= 16,
-	SATA_FSL_MAX_PRD	= 63,
-	SATA_FSL_MAX_PRD_USABLE	= SATA_FSL_MAX_PRD - 1,
-	SATA_FSL_MAX_PRD_DIRECT	= 16,	/* Direct PRDT entries */
-
-	SATA_FSL_HOST_FLAGS	= (ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
-				ATA_FLAG_MMIO | ATA_FLAG_PIO_DMA |
-				ATA_FLAG_PMP | ATA_FLAG_NCQ),
-
-	SATA_FSL_MAX_CMDS	= SATA_FSL_QUEUE_DEPTH,
-	SATA_FSL_CMD_HDR_SIZE	= 16,	/* 4 DWORDS */
-	SATA_FSL_CMD_SLOT_SIZE  = (SATA_FSL_MAX_CMDS * SATA_FSL_CMD_HDR_SIZE),
-
-	/*
-	 * SATA-FSL host controller supports a max. of (15+1) direct PRDEs, and
-	 * chained indirect PRDEs upto a max count of 63.
-	 * We are allocating an array of 63 PRDEs contigiously, but PRDE#15 will
-	 * be setup as an indirect descriptor, pointing to it's next
-	 * (contigious) PRDE. Though chained indirect PRDE arrays are
-	 * supported,it will be more efficient to use a direct PRDT and
-	 * a single chain/link to indirect PRDE array/PRDT.
-	 */
-
-	SATA_FSL_CMD_DESC_CFIS_SZ	= 32,
-	SATA_FSL_CMD_DESC_SFIS_SZ	= 32,
-	SATA_FSL_CMD_DESC_ACMD_SZ	= 16,
-	SATA_FSL_CMD_DESC_RSRVD		= 16,
-
-	SATA_FSL_CMD_DESC_SIZE	= (SATA_FSL_CMD_DESC_CFIS_SZ +
-				 SATA_FSL_CMD_DESC_SFIS_SZ +
-				 SATA_FSL_CMD_DESC_ACMD_SZ +
-				 SATA_FSL_CMD_DESC_RSRVD +
-				 SATA_FSL_MAX_PRD * 16),
-
-	SATA_FSL_CMD_DESC_OFFSET_TO_PRDT	=
-				(SATA_FSL_CMD_DESC_CFIS_SZ +
-				 SATA_FSL_CMD_DESC_SFIS_SZ +
-				 SATA_FSL_CMD_DESC_ACMD_SZ +
-				 SATA_FSL_CMD_DESC_RSRVD),
-
-	SATA_FSL_CMD_DESC_AR_SZ	= (SATA_FSL_CMD_DESC_SIZE * SATA_FSL_MAX_CMDS),
-	SATA_FSL_PORT_PRIV_DMA_SZ = (SATA_FSL_CMD_SLOT_SIZE +
-					SATA_FSL_CMD_DESC_AR_SZ),
-
-	/*
-	 * MPC8315 has two SATA controllers, SATA1 & SATA2
-	 * (one port per controller)
-	 * MPC837x has 2/4 controllers, one port per controller
-	 */
-
-	SATA_FSL_MAX_PORTS	= 1,
-
-	SATA_FSL_IRQ_FLAG	= IRQF_SHARED,
-};
-
-/*
-* Host Controller command register set - per port
-*/
-enum {
-	CQ = 0,
-	CA = 8,
-	CC = 0x10,
-	CE = 0x18,
-	DE = 0x20,
-	CHBA = 0x24,
-	HSTATUS = 0x28,
-	HCONTROL = 0x2C,
-	CQPMP = 0x30,
-	SIGNATURE = 0x34,
-	ICC = 0x38,
-
-	/*
-	 * Host Status Register (HStatus) bitdefs
-	 */
-	ONLINE = (1 << 31),
-	GOING_OFFLINE = (1 << 30),
-	BIST_ERR = (1 << 29),
-
-	FATAL_ERR_HC_MASTER_ERR = (1 << 18),
-	FATAL_ERR_PARITY_ERR_TX = (1 << 17),
-	FATAL_ERR_PARITY_ERR_RX = (1 << 16),
-	FATAL_ERR_DATA_UNDERRUN = (1 << 13),
-	FATAL_ERR_DATA_OVERRUN = (1 << 12),
-	FATAL_ERR_CRC_ERR_TX = (1 << 11),
-	FATAL_ERR_CRC_ERR_RX = (1 << 10),
-	FATAL_ERR_FIFO_OVRFL_TX = (1 << 9),
-	FATAL_ERR_FIFO_OVRFL_RX = (1 << 8),
-
-	FATAL_ERROR_DECODE = FATAL_ERR_HC_MASTER_ERR |
-	    FATAL_ERR_PARITY_ERR_TX |
-	    FATAL_ERR_PARITY_ERR_RX |
-	    FATAL_ERR_DATA_UNDERRUN |
-	    FATAL_ERR_DATA_OVERRUN |
-	    FATAL_ERR_CRC_ERR_TX |
-	    FATAL_ERR_CRC_ERR_RX |
-	    FATAL_ERR_FIFO_OVRFL_TX | FATAL_ERR_FIFO_OVRFL_RX,
-
-	INT_ON_FATAL_ERR = (1 << 5),
-	INT_ON_PHYRDY_CHG = (1 << 4),
-
-	INT_ON_SIGNATURE_UPDATE = (1 << 3),
-	INT_ON_SNOTIFY_UPDATE = (1 << 2),
-	INT_ON_SINGL_DEVICE_ERR = (1 << 1),
-	INT_ON_CMD_COMPLETE = 1,
-
-	INT_ON_ERROR = INT_ON_FATAL_ERR |
-	    INT_ON_PHYRDY_CHG | INT_ON_SINGL_DEVICE_ERR,
-
-	/*
-	 * Host Control Register (HControl) bitdefs
-	 */
-	HCONTROL_ONLINE_PHY_RST = (1 << 31),
-	HCONTROL_FORCE_OFFLINE = (1 << 30),
-	HCONTROL_PARITY_PROT_MOD = (1 << 14),
-	HCONTROL_DPATH_PARITY = (1 << 12),
-	HCONTROL_SNOOP_ENABLE = (1 << 10),
-	HCONTROL_PMP_ATTACHED = (1 << 9),
-	HCONTROL_COPYOUT_STATFIS = (1 << 8),
-	IE_ON_FATAL_ERR = (1 << 5),
-	IE_ON_PHYRDY_CHG = (1 << 4),
-	IE_ON_SIGNATURE_UPDATE = (1 << 3),
-	IE_ON_SNOTIFY_UPDATE = (1 << 2),
-	IE_ON_SINGL_DEVICE_ERR = (1 << 1),
-	IE_ON_CMD_COMPLETE = 1,
-
-	DEFAULT_PORT_IRQ_ENABLE_MASK = IE_ON_FATAL_ERR | IE_ON_PHYRDY_CHG |
-	    IE_ON_SIGNATURE_UPDATE |
-	    IE_ON_SINGL_DEVICE_ERR | IE_ON_CMD_COMPLETE,
-
-	EXT_INDIRECT_SEG_PRD_FLAG = (1 << 31),
-	DATA_SNOOP_ENABLE = (1 << 22),
-};
-
-/*
- * SATA Superset Registers
- */
-enum {
-	SSTATUS = 0,
-	SERROR = 4,
-	SCONTROL = 8,
-	SNOTIFY = 0xC,
-};
-
-/*
- * Control Status Register Set
- */
-enum {
-	TRANSCFG = 0,
-	TRANSSTATUS = 4,
-	LINKCFG = 8,
-	LINKCFG1 = 0xC,
-	LINKCFG2 = 0x10,
-	LINKSTATUS = 0x14,
-	LINKSTATUS1 = 0x18,
-	PHYCTRLCFG = 0x1C,
-	COMMANDSTAT = 0x20,
-};
-
-/* PHY (link-layer) configuration control */
-enum {
-	PHY_BIST_ENABLE = 0x01,
-};
-
-/*
- * Command Header Table entry, i.e, command slot
- * 4 Dwords per command slot, command header size ==  64 Dwords.
- */
-struct cmdhdr_tbl_entry {
-	u32 cda;
-	u32 prde_fis_len;
-	u32 ttl;
-	u32 desc_info;
-};
-
-/*
- * Description information bitdefs
- */
-enum {
-	CMD_DESC_RES = (1 << 11),
-	VENDOR_SPECIFIC_BIST = (1 << 10),
-	CMD_DESC_SNOOP_ENABLE = (1 << 9),
-	FPDMA_QUEUED_CMD = (1 << 8),
-	SRST_CMD = (1 << 7),
-	BIST = (1 << 6),
-	ATAPI_CMD = (1 << 5),
-};
-
-/*
- * Command Descriptor
- */
-struct command_desc {
-	u8 cfis[8 * 4];
-	u8 sfis[8 * 4];
-	u8 acmd[4 * 4];
-	u8 fill[4 * 4];
-	u32 prdt[SATA_FSL_MAX_PRD_DIRECT * 4];
-	u32 prdt_indirect[(SATA_FSL_MAX_PRD - SATA_FSL_MAX_PRD_DIRECT) * 4];
-};
-
-/*
- * Physical region table descriptor(PRD)
- */
-
-struct prde {
-	u32 dba;
-	u8 fill[2 * 4];
-	u32 ddc_and_ext;
-};
-
-/*
- * ata_port private data
- * This is our per-port instance data.
- */
-struct sata_fsl_port_priv {
-	struct cmdhdr_tbl_entry *cmdslot;
-	dma_addr_t cmdslot_paddr;
-	struct command_desc *cmdentry;
-	dma_addr_t cmdentry_paddr;
-};
-
-/*
- * ata_port->host_set private data
- */
-struct sata_fsl_host_priv {
-	void __iomem *hcr_base;
-	void __iomem *ssr_base;
-	void __iomem *csr_base;
-	int irq;
-};
-
-static inline unsigned int sata_fsl_tag(unsigned int tag,
-					void __iomem *hcr_base)
-{
-	/* We let libATA core do actual (queue) tag allocation */
-
-	/* all non NCQ/queued commands should have tag#0 */
-	if (ata_tag_internal(tag)) {
-		DPRINTK("mapping internal cmds to tag#0\n");
-		return 0;
-	}
-
-	if (unlikely(tag >= SATA_FSL_QUEUE_DEPTH)) {
-		DPRINTK("tag %d invalid : out of range\n", tag);
-		return 0;
-	}
-
-	if (unlikely((ioread32(hcr_base + CQ)) & (1 << tag))) {
-		DPRINTK("tag %d invalid : in use!!\n", tag);
-		return 0;
-	}
-
-	return tag;
-}
-
-static void sata_fsl_setup_cmd_hdr_entry(struct sata_fsl_port_priv *pp,
-					 unsigned int tag, u32 desc_info,
-					 u32 data_xfer_len, u8 num_prde,
-					 u8 fis_len)
-{
-	dma_addr_t cmd_descriptor_address;
-
-	cmd_descriptor_address = pp->cmdentry_paddr +
-	    tag * SATA_FSL_CMD_DESC_SIZE;
-
-	/* NOTE: both data_xfer_len & fis_len are Dword counts */
-
-	pp->cmdslot[tag].cda = cpu_to_le32(cmd_descriptor_address);
-	pp->cmdslot[tag].prde_fis_len =
-	    cpu_to_le32((num_prde << 16) | (fis_len << 2));
-	pp->cmdslot[tag].ttl = cpu_to_le32(data_xfer_len & ~0x03);
-	pp->cmdslot[tag].desc_info = cpu_to_le32(desc_info | (tag & 0x1F));
-
-	VPRINTK("cda=0x%x, prde_fis_len=0x%x, ttl=0x%x, di=0x%x\n",
-		pp->cmdslot[tag].cda,
-		pp->cmdslot[tag].prde_fis_len,
-		pp->cmdslot[tag].ttl, pp->cmdslot[tag].desc_info);
-
-}
-
-static unsigned int sata_fsl_fill_sg(struct ata_queued_cmd *qc, void *cmd_desc,
-				     u32 *ttl, dma_addr_t cmd_desc_paddr)
-{
-	struct scatterlist *sg;
-	unsigned int num_prde = 0;
-	u32 ttl_dwords = 0;
-
-	/*
-	 * NOTE : direct & indirect prdt's are contigiously allocated
-	 */
-	struct prde *prd = (struct prde *)&((struct command_desc *)
-					    cmd_desc)->prdt;
-
-	struct prde *prd_ptr_to_indirect_ext = NULL;
-	unsigned indirect_ext_segment_sz = 0;
-	dma_addr_t indirect_ext_segment_paddr;
-	unsigned int si;
-
-	VPRINTK("SATA FSL : cd = 0x%p, prd = 0x%p\n", cmd_desc, prd);
-
-	indirect_ext_segment_paddr = cmd_desc_paddr +
-	    SATA_FSL_CMD_DESC_OFFSET_TO_PRDT + SATA_FSL_MAX_PRD_DIRECT * 16;
-
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		dma_addr_t sg_addr = sg_dma_address(sg);
-		u32 sg_len = sg_dma_len(sg);
-
-		VPRINTK("SATA FSL : fill_sg, sg_addr = 0x%llx, sg_len = %d\n",
-			(unsigned long long)sg_addr, sg_len);
-
-		/* warn if each s/g element is not dword aligned */
-		if (sg_addr & 0x03)
-			ata_port_printk(qc->ap, KERN_ERR,
-					"s/g addr unaligned : 0x%llx\n",
-					(unsigned long long)sg_addr);
-		if (sg_len & 0x03)
-			ata_port_printk(qc->ap, KERN_ERR,
-					"s/g len unaligned : 0x%x\n", sg_len);
-
-		if (num_prde == (SATA_FSL_MAX_PRD_DIRECT - 1) &&
-		    sg_next(sg) != NULL) {
-			VPRINTK("setting indirect prde\n");
-			prd_ptr_to_indirect_ext = prd;
-			prd->dba = cpu_to_le32(indirect_ext_segment_paddr);
-			indirect_ext_segment_sz = 0;
-			++prd;
-			++num_prde;
-		}
-
-		ttl_dwords += sg_len;
-		prd->dba = cpu_to_le32(sg_addr);
-		prd->ddc_and_ext =
-		    cpu_to_le32(DATA_SNOOP_ENABLE | (sg_len & ~0x03));
-
-		VPRINTK("sg_fill, ttl=%d, dba=0x%x, ddc=0x%x\n",
-			ttl_dwords, prd->dba, prd->ddc_and_ext);
-
-		++num_prde;
-		++prd;
-		if (prd_ptr_to_indirect_ext)
-			indirect_ext_segment_sz += sg_len;
-	}
-
-	if (prd_ptr_to_indirect_ext) {
-		/* set indirect extension flag along with indirect ext. size */
-		prd_ptr_to_indirect_ext->ddc_and_ext =
-		    cpu_to_le32((EXT_INDIRECT_SEG_PRD_FLAG |
-				 DATA_SNOOP_ENABLE |
-				 (indirect_ext_segment_sz & ~0x03)));
-	}
-
-	*ttl = ttl_dwords;
-	return num_prde;
-}
-
-static void sata_fsl_qc_prep(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct sata_fsl_port_priv *pp = ap->private_data;
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	unsigned int tag = sata_fsl_tag(qc->tag, hcr_base);
-	struct command_desc *cd;
-	u32 desc_info = CMD_DESC_RES | CMD_DESC_SNOOP_ENABLE;
-	u32 num_prde = 0;
-	u32 ttl_dwords = 0;
-	dma_addr_t cd_paddr;
-
-	cd = (struct command_desc *)pp->cmdentry + tag;
-	cd_paddr = pp->cmdentry_paddr + tag * SATA_FSL_CMD_DESC_SIZE;
-
-	ata_tf_to_fis(&qc->tf, qc->dev->link->pmp, 1, (u8 *) &cd->cfis);
-
-	VPRINTK("Dumping cfis : 0x%x, 0x%x, 0x%x\n",
-		cd->cfis[0], cd->cfis[1], cd->cfis[2]);
-
-	if (qc->tf.protocol == ATA_PROT_NCQ) {
-		VPRINTK("FPDMA xfer,Sctor cnt[0:7],[8:15] = %d,%d\n",
-			cd->cfis[3], cd->cfis[11]);
-	}
-
-	/* setup "ACMD - atapi command" in cmd. desc. if this is ATAPI cmd */
-	if (ata_is_atapi(qc->tf.protocol)) {
-		desc_info |= ATAPI_CMD;
-		memset((void *)&cd->acmd, 0, 32);
-		memcpy((void *)&cd->acmd, qc->cdb, qc->dev->cdb_len);
-	}
-
-	if (qc->flags & ATA_QCFLAG_DMAMAP)
-		num_prde = sata_fsl_fill_sg(qc, (void *)cd,
-					    &ttl_dwords, cd_paddr);
-
-	if (qc->tf.protocol == ATA_PROT_NCQ)
-		desc_info |= FPDMA_QUEUED_CMD;
-
-	sata_fsl_setup_cmd_hdr_entry(pp, tag, desc_info, ttl_dwords,
-				     num_prde, 5);
-
-	VPRINTK("SATA FSL : xx_qc_prep, di = 0x%x, ttl = %d, num_prde = %d\n",
-		desc_info, ttl_dwords, num_prde);
-}
-
-static unsigned int sata_fsl_qc_issue(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	unsigned int tag = sata_fsl_tag(qc->tag, hcr_base);
-
-	VPRINTK("xx_qc_issue called,CQ=0x%x,CA=0x%x,CE=0x%x,CC=0x%x\n",
-		ioread32(CQ + hcr_base),
-		ioread32(CA + hcr_base),
-		ioread32(CE + hcr_base), ioread32(CC + hcr_base));
-
-	iowrite32(qc->dev->link->pmp, CQPMP + hcr_base);
-
-	/* Simply queue command to the controller/device */
-	iowrite32(1 << tag, CQ + hcr_base);
-
-	VPRINTK("xx_qc_issue called, tag=%d, CQ=0x%x, CA=0x%x\n",
-		tag, ioread32(CQ + hcr_base), ioread32(CA + hcr_base));
-
-	VPRINTK("CE=0x%x, DE=0x%x, CC=0x%x, CmdStat = 0x%x\n",
-		ioread32(CE + hcr_base),
-		ioread32(DE + hcr_base),
-		ioread32(CC + hcr_base),
-		ioread32(COMMANDSTAT + host_priv->csr_base));
-
-	return 0;
-}
-
-static bool sata_fsl_qc_fill_rtf(struct ata_queued_cmd *qc)
-{
-	struct sata_fsl_port_priv *pp = qc->ap->private_data;
-	struct sata_fsl_host_priv *host_priv = qc->ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	unsigned int tag = sata_fsl_tag(qc->tag, hcr_base);
-	struct command_desc *cd;
-
-	cd = pp->cmdentry + tag;
-
-	ata_tf_from_fis(cd->sfis, &qc->result_tf);
-	return true;
-}
-
-static int sata_fsl_scr_write(struct ata_link *link,
-			      unsigned int sc_reg_in, u32 val)
-{
-	struct sata_fsl_host_priv *host_priv = link->ap->host->private_data;
-	void __iomem *ssr_base = host_priv->ssr_base;
-	unsigned int sc_reg;
-
-	switch (sc_reg_in) {
-	case SCR_STATUS:
-	case SCR_ERROR:
-	case SCR_CONTROL:
-	case SCR_ACTIVE:
-		sc_reg = sc_reg_in;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	VPRINTK("xx_scr_write, reg_in = %d\n", sc_reg);
-
-	iowrite32(val, ssr_base + (sc_reg * 4));
-	return 0;
-}
-
-static int sata_fsl_scr_read(struct ata_link *link,
-			     unsigned int sc_reg_in, u32 *val)
-{
-	struct sata_fsl_host_priv *host_priv = link->ap->host->private_data;
-	void __iomem *ssr_base = host_priv->ssr_base;
-	unsigned int sc_reg;
-
-	switch (sc_reg_in) {
-	case SCR_STATUS:
-	case SCR_ERROR:
-	case SCR_CONTROL:
-	case SCR_ACTIVE:
-		sc_reg = sc_reg_in;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	VPRINTK("xx_scr_read, reg_in = %d\n", sc_reg);
-
-	*val = ioread32(ssr_base + (sc_reg * 4));
-	return 0;
-}
-
-static void sata_fsl_freeze(struct ata_port *ap)
-{
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 temp;
-
-	VPRINTK("xx_freeze, CQ=0x%x, CA=0x%x, CE=0x%x, DE=0x%x\n",
-		ioread32(CQ + hcr_base),
-		ioread32(CA + hcr_base),
-		ioread32(CE + hcr_base), ioread32(DE + hcr_base));
-	VPRINTK("CmdStat = 0x%x\n",
-		ioread32(host_priv->csr_base + COMMANDSTAT));
-
-	/* disable interrupts on the controller/port */
-	temp = ioread32(hcr_base + HCONTROL);
-	iowrite32((temp & ~0x3F), hcr_base + HCONTROL);
-
-	VPRINTK("in xx_freeze : HControl = 0x%x, HStatus = 0x%x\n",
-		ioread32(hcr_base + HCONTROL), ioread32(hcr_base + HSTATUS));
-}
-
-static void sata_fsl_thaw(struct ata_port *ap)
-{
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 temp;
-
-	/* ack. any pending IRQs for this controller/port */
-	temp = ioread32(hcr_base + HSTATUS);
-
-	VPRINTK("xx_thaw, pending IRQs = 0x%x\n", (temp & 0x3F));
-
-	if (temp & 0x3F)
-		iowrite32((temp & 0x3F), hcr_base + HSTATUS);
-
-	/* enable interrupts on the controller/port */
-	temp = ioread32(hcr_base + HCONTROL);
-	iowrite32((temp | DEFAULT_PORT_IRQ_ENABLE_MASK), hcr_base + HCONTROL);
-
-	VPRINTK("xx_thaw : HControl = 0x%x, HStatus = 0x%x\n",
-		ioread32(hcr_base + HCONTROL), ioread32(hcr_base + HSTATUS));
-}
-
-static void sata_fsl_pmp_attach(struct ata_port *ap)
-{
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 temp;
-
-	temp = ioread32(hcr_base + HCONTROL);
-	iowrite32((temp | HCONTROL_PMP_ATTACHED), hcr_base + HCONTROL);
-}
-
-static void sata_fsl_pmp_detach(struct ata_port *ap)
-{
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 temp;
-
-	temp = ioread32(hcr_base + HCONTROL);
-	temp &= ~HCONTROL_PMP_ATTACHED;
-	iowrite32(temp, hcr_base + HCONTROL);
-
-	/* enable interrupts on the controller/port */
-	temp = ioread32(hcr_base + HCONTROL);
-	iowrite32((temp | DEFAULT_PORT_IRQ_ENABLE_MASK), hcr_base + HCONTROL);
-
-}
-
-static int sata_fsl_port_start(struct ata_port *ap)
-{
-	struct device *dev = ap->host->dev;
-	struct sata_fsl_port_priv *pp;
-	void *mem;
-	dma_addr_t mem_dma;
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 temp;
-
-	pp = kzalloc(sizeof(*pp), GFP_KERNEL);
-	if (!pp)
-		return -ENOMEM;
-
-	mem = dma_alloc_coherent(dev, SATA_FSL_PORT_PRIV_DMA_SZ, &mem_dma,
-				 GFP_KERNEL);
-	if (!mem) {
-		kfree(pp);
-		return -ENOMEM;
-	}
-	memset(mem, 0, SATA_FSL_PORT_PRIV_DMA_SZ);
-
-	pp->cmdslot = mem;
-	pp->cmdslot_paddr = mem_dma;
-
-	mem += SATA_FSL_CMD_SLOT_SIZE;
-	mem_dma += SATA_FSL_CMD_SLOT_SIZE;
-
-	pp->cmdentry = mem;
-	pp->cmdentry_paddr = mem_dma;
-
-	ap->private_data = pp;
-
-	VPRINTK("CHBA = 0x%x, cmdentry_phys = 0x%x\n",
-		pp->cmdslot_paddr, pp->cmdentry_paddr);
-
-	/* Now, update the CHBA register in host controller cmd register set */
-	iowrite32(pp->cmdslot_paddr & 0xffffffff, hcr_base + CHBA);
-
-	/*
-	 * Now, we can bring the controller on-line & also initiate
-	 * the COMINIT sequence, we simply return here and the boot-probing
-	 * & device discovery process is re-initiated by libATA using a
-	 * Softreset EH (dummy) session. Hence, boot probing and device
-	 * discovey will be part of sata_fsl_softreset() callback.
-	 */
-
-	temp = ioread32(hcr_base + HCONTROL);
-	iowrite32((temp | HCONTROL_ONLINE_PHY_RST), hcr_base + HCONTROL);
-
-	VPRINTK("HStatus = 0x%x\n", ioread32(hcr_base + HSTATUS));
-	VPRINTK("HControl = 0x%x\n", ioread32(hcr_base + HCONTROL));
-	VPRINTK("CHBA  = 0x%x\n", ioread32(hcr_base + CHBA));
-
-#ifdef CONFIG_MPC8315_DS
-	/*
-	 * Workaround for 8315DS board 3gbps link-up issue,
-	 * currently limit SATA port to GEN1 speed
-	 */
-	sata_fsl_scr_read(&ap->link, SCR_CONTROL, &temp);
-	temp &= ~(0xF << 4);
-	temp |= (0x1 << 4);
-	sata_fsl_scr_write(&ap->link, SCR_CONTROL, temp);
-
-	sata_fsl_scr_read(&ap->link, SCR_CONTROL, &temp);
-	dev_printk(KERN_WARNING, dev, "scr_control, speed limited to %x\n",
-			temp);
-#endif
-
-	return 0;
-}
-
-static void sata_fsl_port_stop(struct ata_port *ap)
-{
-	struct device *dev = ap->host->dev;
-	struct sata_fsl_port_priv *pp = ap->private_data;
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 temp;
-
-	/*
-	 * Force host controller to go off-line, aborting current operations
-	 */
-	temp = ioread32(hcr_base + HCONTROL);
-	temp &= ~HCONTROL_ONLINE_PHY_RST;
-	temp |= HCONTROL_FORCE_OFFLINE;
-	iowrite32(temp, hcr_base + HCONTROL);
-
-	/* Poll for controller to go offline - should happen immediately */
-	ata_wait_register(hcr_base + HSTATUS, ONLINE, ONLINE, 1, 1);
-
-	ap->private_data = NULL;
-	dma_free_coherent(dev, SATA_FSL_PORT_PRIV_DMA_SZ,
-			  pp->cmdslot, pp->cmdslot_paddr);
-
-	kfree(pp);
-}
-
-static unsigned int sata_fsl_dev_classify(struct ata_port *ap)
-{
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	struct ata_taskfile tf;
-	u32 temp;
-
-	temp = ioread32(hcr_base + SIGNATURE);
-
-	VPRINTK("raw sig = 0x%x\n", temp);
-	VPRINTK("HStatus = 0x%x\n", ioread32(hcr_base + HSTATUS));
-	VPRINTK("HControl = 0x%x\n", ioread32(hcr_base + HCONTROL));
-
-	tf.lbah = (temp >> 24) & 0xff;
-	tf.lbam = (temp >> 16) & 0xff;
-	tf.lbal = (temp >> 8) & 0xff;
-	tf.nsect = temp & 0xff;
-
-	return ata_dev_classify(&tf);
-}
-
-static int sata_fsl_hardreset(struct ata_link *link, unsigned int *class,
-					unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 temp;
-	int i = 0;
-	unsigned long start_jiffies;
-
-	DPRINTK("in xx_hardreset\n");
-
-try_offline_again:
-	/*
-	 * Force host controller to go off-line, aborting current operations
-	 */
-	temp = ioread32(hcr_base + HCONTROL);
-	temp &= ~HCONTROL_ONLINE_PHY_RST;
-	iowrite32(temp, hcr_base + HCONTROL);
-
-	/* Poll for controller to go offline */
-	temp = ata_wait_register(hcr_base + HSTATUS, ONLINE, ONLINE, 1, 500);
-
-	if (temp & ONLINE) {
-		ata_port_printk(ap, KERN_ERR,
-				"Hardreset failed, not off-lined %d\n", i);
-
-		/*
-		 * Try to offline controller atleast twice
-		 */
-		i++;
-		if (i == 2)
-			goto err;
-		else
-			goto try_offline_again;
-	}
-
-	DPRINTK("hardreset, controller off-lined\n");
-	VPRINTK("HStatus = 0x%x\n", ioread32(hcr_base + HSTATUS));
-	VPRINTK("HControl = 0x%x\n", ioread32(hcr_base + HCONTROL));
-
-	/*
-	 * PHY reset should remain asserted for atleast 1ms
-	 */
-	msleep(1);
-
-	/*
-	 * Now, bring the host controller online again, this can take time
-	 * as PHY reset and communication establishment, 1st D2H FIS and
-	 * device signature update is done, on safe side assume 500ms
-	 * NOTE : Host online status may be indicated immediately!!
-	 */
-
-	temp = ioread32(hcr_base + HCONTROL);
-	temp |= (HCONTROL_ONLINE_PHY_RST | HCONTROL_SNOOP_ENABLE);
-	temp |= HCONTROL_PMP_ATTACHED;
-	iowrite32(temp, hcr_base + HCONTROL);
-
-	temp = ata_wait_register(hcr_base + HSTATUS, ONLINE, 0, 1, 500);
-
-	if (!(temp & ONLINE)) {
-		ata_port_printk(ap, KERN_ERR,
-				"Hardreset failed, not on-lined\n");
-		goto err;
-	}
-
-	DPRINTK("hardreset, controller off-lined & on-lined\n");
-	VPRINTK("HStatus = 0x%x\n", ioread32(hcr_base + HSTATUS));
-	VPRINTK("HControl = 0x%x\n", ioread32(hcr_base + HCONTROL));
-
-	/*
-	 * First, wait for the PHYRDY change to occur before waiting for
-	 * the signature, and also verify if SStatus indicates device
-	 * presence
-	 */
-
-	temp = ata_wait_register(hcr_base + HSTATUS, 0xFF, 0, 1, 500);
-	if ((!(temp & 0x10)) || ata_link_offline(link)) {
-		ata_port_printk(ap, KERN_WARNING,
-				"No Device OR PHYRDY change,Hstatus = 0x%x\n",
-				ioread32(hcr_base + HSTATUS));
-		*class = ATA_DEV_NONE;
-		return 0;
-	}
-
-	/*
-	 * Wait for the first D2H from device,i.e,signature update notification
-	 */
-	start_jiffies = jiffies;
-	temp = ata_wait_register(hcr_base + HSTATUS, 0xFF, 0x10,
-			500, jiffies_to_msecs(deadline - start_jiffies));
-
-	if ((temp & 0xFF) != 0x18) {
-		ata_port_printk(ap, KERN_WARNING, "No Signature Update\n");
-		*class = ATA_DEV_NONE;
-		goto do_followup_srst;
-	} else {
-		ata_port_printk(ap, KERN_INFO,
-				"Signature Update detected @ %d msecs\n",
-				jiffies_to_msecs(jiffies - start_jiffies));
-		*class = sata_fsl_dev_classify(ap);
-		return 0;
-	}
-
-do_followup_srst:
-	/*
-	 * request libATA to perform follow-up softreset
-	 */
-	return -EAGAIN;
-
-err:
-	return -EIO;
-}
-
-static int sata_fsl_softreset(struct ata_link *link, unsigned int *class,
-					unsigned long deadline)
-{
-	struct ata_port *ap = link->ap;
-	struct sata_fsl_port_priv *pp = ap->private_data;
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	int pmp = sata_srst_pmp(link);
-	u32 temp;
-	struct ata_taskfile tf;
-	u8 *cfis;
-	u32 Serror;
-
-	DPRINTK("in xx_softreset\n");
-
-	if (ata_link_offline(link)) {
-		DPRINTK("PHY reports no device\n");
-		*class = ATA_DEV_NONE;
-		return 0;
-	}
-
-	/*
-	 * Send a device reset (SRST) explicitly on command slot #0
-	 * Check : will the command queue (reg) be cleared during offlining ??
-	 * Also we will be online only if Phy commn. has been established
-	 * and device presence has been detected, therefore if we have
-	 * reached here, we can send a command to the target device
-	 */
-
-	DPRINTK("Sending SRST/device reset\n");
-
-	ata_tf_init(link->device, &tf);
-	cfis = (u8 *) &pp->cmdentry->cfis;
-
-	/* device reset/SRST is a control register update FIS, uses tag0 */
-	sata_fsl_setup_cmd_hdr_entry(pp, 0,
-		SRST_CMD | CMD_DESC_RES | CMD_DESC_SNOOP_ENABLE, 0, 0, 5);
-
-	tf.ctl |= ATA_SRST;	/* setup SRST bit in taskfile control reg */
-	ata_tf_to_fis(&tf, pmp, 0, cfis);
-
-	DPRINTK("Dumping cfis : 0x%x, 0x%x, 0x%x, 0x%x\n",
-		cfis[0], cfis[1], cfis[2], cfis[3]);
-
-	/*
-	 * Queue SRST command to the controller/device, ensure that no
-	 * other commands are active on the controller/device
-	 */
-
-	DPRINTK("@Softreset, CQ = 0x%x, CA = 0x%x, CC = 0x%x\n",
-		ioread32(CQ + hcr_base),
-		ioread32(CA + hcr_base), ioread32(CC + hcr_base));
-
-	iowrite32(0xFFFF, CC + hcr_base);
-	if (pmp != SATA_PMP_CTRL_PORT)
-		iowrite32(pmp, CQPMP + hcr_base);
-	iowrite32(1, CQ + hcr_base);
-
-	temp = ata_wait_register(CQ + hcr_base, 0x1, 0x1, 1, 5000);
-	if (temp & 0x1) {
-		ata_port_printk(ap, KERN_WARNING, "ATA_SRST issue failed\n");
-
-		DPRINTK("Softreset@5000,CQ=0x%x,CA=0x%x,CC=0x%x\n",
-			ioread32(CQ + hcr_base),
-			ioread32(CA + hcr_base), ioread32(CC + hcr_base));
-
-		sata_fsl_scr_read(&ap->link, SCR_ERROR, &Serror);
-
-		DPRINTK("HStatus = 0x%x\n", ioread32(hcr_base + HSTATUS));
-		DPRINTK("HControl = 0x%x\n", ioread32(hcr_base + HCONTROL));
-		DPRINTK("Serror = 0x%x\n", Serror);
-		goto err;
-	}
-
-	msleep(1);
-
-	/*
-	 * SATA device enters reset state after receving a Control register
-	 * FIS with SRST bit asserted and it awaits another H2D Control reg.
-	 * FIS with SRST bit cleared, then the device does internal diags &
-	 * initialization, followed by indicating it's initialization status
-	 * using ATA signature D2H register FIS to the host controller.
-	 */
-
-	sata_fsl_setup_cmd_hdr_entry(pp, 0, CMD_DESC_RES | CMD_DESC_SNOOP_ENABLE,
-				      0, 0, 5);
-
-	tf.ctl &= ~ATA_SRST;	/* 2nd H2D Ctl. register FIS */
-	ata_tf_to_fis(&tf, pmp, 0, cfis);
-
-	if (pmp != SATA_PMP_CTRL_PORT)
-		iowrite32(pmp, CQPMP + hcr_base);
-	iowrite32(1, CQ + hcr_base);
-	msleep(150);		/* ?? */
-
-	/*
-	 * The above command would have signalled an interrupt on command
-	 * complete, which needs special handling, by clearing the Nth
-	 * command bit of the CCreg
-	 */
-	iowrite32(0x01, CC + hcr_base);	/* We know it will be cmd#0 always */
-
-	DPRINTK("SATA FSL : Now checking device signature\n");
-
-	*class = ATA_DEV_NONE;
-
-	/* Verify if SStatus indicates device presence */
-	if (ata_link_online(link)) {
-		/*
-		 * if we are here, device presence has been detected,
-		 * 1st D2H FIS would have been received, but sfis in
-		 * command desc. is not updated, but signature register
-		 * would have been updated
-		 */
-
-		*class = sata_fsl_dev_classify(ap);
-
-		DPRINTK("class = %d\n", *class);
-		VPRINTK("ccreg = 0x%x\n", ioread32(hcr_base + CC));
-		VPRINTK("cereg = 0x%x\n", ioread32(hcr_base + CE));
-	}
-
-	return 0;
-
-err:
-	return -EIO;
-}
-
-static void sata_fsl_error_handler(struct ata_port *ap)
-{
-
-	DPRINTK("in xx_error_handler\n");
-	sata_pmp_error_handler(ap);
-
-}
-
-static void sata_fsl_post_internal_cmd(struct ata_queued_cmd *qc)
-{
-	if (qc->flags & ATA_QCFLAG_FAILED)
-		qc->err_mask |= AC_ERR_OTHER;
-
-	if (qc->err_mask) {
-		/* make DMA engine forget about the failed command */
-
-	}
-}
-
-static void sata_fsl_error_intr(struct ata_port *ap)
-{
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 hstatus, dereg=0, cereg = 0, SError = 0;
-	unsigned int err_mask = 0, action = 0;
-	int freeze = 0, abort=0;
-	struct ata_link *link = NULL;
-	struct ata_queued_cmd *qc = NULL;
-	struct ata_eh_info *ehi;
-
-	hstatus = ioread32(hcr_base + HSTATUS);
-	cereg = ioread32(hcr_base + CE);
-
-	/* first, analyze and record host port events */
-	link = &ap->link;
-	ehi = &link->eh_info;
-	ata_ehi_clear_desc(ehi);
-
-	/*
-	 * Handle & Clear SError
-	 */
-
-	sata_fsl_scr_read(&ap->link, SCR_ERROR, &SError);
-	if (unlikely(SError & 0xFFFF0000)) {
-		sata_fsl_scr_write(&ap->link, SCR_ERROR, SError);
-	}
-
-	DPRINTK("error_intr,hStat=0x%x,CE=0x%x,DE =0x%x,SErr=0x%x\n",
-		hstatus, cereg, ioread32(hcr_base + DE), SError);
-
-	/* handle fatal errors */
-	if (hstatus & FATAL_ERROR_DECODE) {
-		ehi->err_mask |= AC_ERR_ATA_BUS;
-		ehi->action |= ATA_EH_SOFTRESET;
-
-		freeze = 1;
-	}
-
-	/* Handle PHYRDY change notification */
-	if (hstatus & INT_ON_PHYRDY_CHG) {
-		DPRINTK("SATA FSL: PHYRDY change indication\n");
-
-		/* Setup a soft-reset EH action */
-		ata_ehi_hotplugged(ehi);
-		ata_ehi_push_desc(ehi, "%s", "PHY RDY changed");
-		freeze = 1;
-	}
-
-	/* handle single device errors */
-	if (cereg) {
-		/*
-		 * clear the command error, also clears queue to the device
-		 * in error, and we can (re)issue commands to this device.
-		 * When a device is in error all commands queued into the
-		 * host controller and at the device are considered aborted
-		 * and the queue for that device is stopped. Now, after
-		 * clearing the device error, we can issue commands to the
-		 * device to interrogate it to find the source of the error.
-		 */
-		abort = 1;
-
-		DPRINTK("single device error, CE=0x%x, DE=0x%x\n",
-			ioread32(hcr_base + CE), ioread32(hcr_base + DE));
-
-		/* find out the offending link and qc */
-		if (ap->nr_pmp_links) {
-			dereg = ioread32(hcr_base + DE);
-			iowrite32(dereg, hcr_base + DE);
-			iowrite32(cereg, hcr_base + CE);
-
-			if (dereg < ap->nr_pmp_links) {
-				link = &ap->pmp_link[dereg];
-				ehi = &link->eh_info;
-				qc = ata_qc_from_tag(ap, link->active_tag);
-				/*
-				 * We should consider this as non fatal error,
-                                 * and TF must be updated as done below.
-		                 */
-
-				err_mask |= AC_ERR_DEV;
-
-			} else {
-				err_mask |= AC_ERR_HSM;
-				action |= ATA_EH_HARDRESET;
-				freeze = 1;
-			}
-		} else {
-			dereg = ioread32(hcr_base + DE);
-			iowrite32(dereg, hcr_base + DE);
-			iowrite32(cereg, hcr_base + CE);
-
-			qc = ata_qc_from_tag(ap, link->active_tag);
-			/*
-			 * We should consider this as non fatal error,
-                         * and TF must be updated as done below.
-	                */
-			err_mask |= AC_ERR_DEV;
-		}
-	}
-
-	/* record error info */
-	if (qc) {
-		qc->err_mask |= err_mask;
-	} else
-		ehi->err_mask |= err_mask;
-
-	ehi->action |= action;
-
-	/* freeze or abort */
-	if (freeze)
-		ata_port_freeze(ap);
-	else if (abort) {
-		if (qc)
-			ata_link_abort(qc->dev->link);
-		else
-			ata_port_abort(ap);
-	}
-}
-
-static void sata_fsl_host_intr(struct ata_port *ap)
-{
-	struct sata_fsl_host_priv *host_priv = ap->host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 hstatus, qc_active = 0;
-	struct ata_queued_cmd *qc;
-	u32 SError;
-
-	hstatus = ioread32(hcr_base + HSTATUS);
-
-	sata_fsl_scr_read(&ap->link, SCR_ERROR, &SError);
-
-	if (unlikely(SError & 0xFFFF0000)) {
-		DPRINTK("serror @host_intr : 0x%x\n", SError);
-		sata_fsl_error_intr(ap);
-
-	}
-
-	if (unlikely(hstatus & INT_ON_ERROR)) {
-		DPRINTK("error interrupt!!\n");
-		sata_fsl_error_intr(ap);
-		return;
-	}
-
-	/* Read command completed register */
-	qc_active = ioread32(hcr_base + CC);
-
-	VPRINTK("Status of all queues :\n");
-	VPRINTK("qc_active/CC = 0x%x, CA = 0x%x, CE=0x%x,CQ=0x%x,apqa=0x%x\n",
-		qc_active,
-		ioread32(hcr_base + CA),
-		ioread32(hcr_base + CE),
-		ioread32(hcr_base + CQ),
-		ap->qc_active);
-
-	if (qc_active & ap->qc_active) {
-		int i;
-		/* clear CC bit, this will also complete the interrupt */
-		iowrite32(qc_active, hcr_base + CC);
-
-		DPRINTK("Status of all queues :\n");
-		DPRINTK("qc_active/CC = 0x%x, CA = 0x%x, CE=0x%x\n",
-			qc_active, ioread32(hcr_base + CA),
-			ioread32(hcr_base + CE));
-
-		for (i = 0; i < SATA_FSL_QUEUE_DEPTH; i++) {
-			if (qc_active & (1 << i)) {
-				qc = ata_qc_from_tag(ap, i);
-				if (qc) {
-					ata_qc_complete(qc);
-				}
-				DPRINTK
-				    ("completing ncq cmd,tag=%d,CC=0x%x,CA=0x%x\n",
-				     i, ioread32(hcr_base + CC),
-				     ioread32(hcr_base + CA));
-			}
-		}
-		return;
-
-	} else if ((ap->qc_active & (1 << ATA_TAG_INTERNAL))) {
-		iowrite32(1, hcr_base + CC);
-		qc = ata_qc_from_tag(ap, ATA_TAG_INTERNAL);
-
-		DPRINTK("completing non-ncq cmd, CC=0x%x\n",
-			 ioread32(hcr_base + CC));
-
-		if (qc) {
-			ata_qc_complete(qc);
-		}
-	} else {
-		/* Spurious Interrupt!! */
-		DPRINTK("spurious interrupt!!, CC = 0x%x\n",
-			ioread32(hcr_base + CC));
-		iowrite32(qc_active, hcr_base + CC);
-		return;
-	}
-}
-
-static irqreturn_t sata_fsl_interrupt(int irq, void *dev_instance)
-{
-	struct ata_host *host = dev_instance;
-	struct sata_fsl_host_priv *host_priv = host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 interrupt_enables;
-	unsigned handled = 0;
-	struct ata_port *ap;
-
-	/* ack. any pending IRQs for this controller/port */
-	interrupt_enables = ioread32(hcr_base + HSTATUS);
-	interrupt_enables &= 0x3F;
-
-	DPRINTK("interrupt status 0x%x\n", interrupt_enables);
-
-	if (!interrupt_enables)
-		return IRQ_NONE;
-
-	spin_lock(&host->lock);
-
-	/* Assuming one port per host controller */
-
-	ap = host->ports[0];
-	if (ap) {
-		sata_fsl_host_intr(ap);
-	} else {
-		dev_printk(KERN_WARNING, host->dev,
-			   "interrupt on disabled port 0\n");
-	}
-
-	iowrite32(interrupt_enables, hcr_base + HSTATUS);
-	handled = 1;
-
-	spin_unlock(&host->lock);
-
-	return IRQ_RETVAL(handled);
-}
-
-/*
- * Multiple ports are represented by multiple SATA controllers with
- * one port per controller
- */
-static int sata_fsl_init_controller(struct ata_host *host)
-{
-	struct sata_fsl_host_priv *host_priv = host->private_data;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	u32 temp;
-
-	/*
-	 * NOTE : We cannot bring the controller online before setting
-	 * the CHBA, hence main controller initialization is done as
-	 * part of the port_start() callback
-	 */
-
-	/* ack. any pending IRQs for this controller/port */
-	temp = ioread32(hcr_base + HSTATUS);
-	if (temp & 0x3F)
-		iowrite32((temp & 0x3F), hcr_base + HSTATUS);
-
-	/* Keep interrupts disabled on the controller */
-	temp = ioread32(hcr_base + HCONTROL);
-	iowrite32((temp & ~0x3F), hcr_base + HCONTROL);
-
-	/* Disable interrupt coalescing control(icc), for the moment */
-	DPRINTK("icc = 0x%x\n", ioread32(hcr_base + ICC));
-	iowrite32(0x01000000, hcr_base + ICC);
-
-	/* clear error registers, SError is cleared by libATA  */
-	iowrite32(0x00000FFFF, hcr_base + CE);
-	iowrite32(0x00000FFFF, hcr_base + DE);
-
-	/*
-	 * host controller will be brought on-line, during xx_port_start()
-	 * callback, that should also initiate the OOB, COMINIT sequence
-	 */
-
-	DPRINTK("HStatus = 0x%x\n", ioread32(hcr_base + HSTATUS));
-	DPRINTK("HControl = 0x%x\n", ioread32(hcr_base + HCONTROL));
-
-	return 0;
-}
-
-/*
- * scsi mid-layer and libata interface structures
- */
-static struct scsi_host_template sata_fsl_sht = {
-	ATA_NCQ_SHT("sata_fsl"),
-	.can_queue = SATA_FSL_QUEUE_DEPTH,
-	.sg_tablesize = SATA_FSL_MAX_PRD_USABLE,
-	.dma_boundary = ATA_DMA_BOUNDARY,
-};
-
-static struct ata_port_operations sata_fsl_ops = {
-	.inherits		= &sata_pmp_port_ops,
-
-	.qc_defer = ata_std_qc_defer,
-	.qc_prep = sata_fsl_qc_prep,
-	.qc_issue = sata_fsl_qc_issue,
-	.qc_fill_rtf = sata_fsl_qc_fill_rtf,
-
-	.scr_read = sata_fsl_scr_read,
-	.scr_write = sata_fsl_scr_write,
-
-	.freeze = sata_fsl_freeze,
-	.thaw = sata_fsl_thaw,
-	.softreset = sata_fsl_softreset,
-	.hardreset = sata_fsl_hardreset,
-	.pmp_softreset = sata_fsl_softreset,
-	.error_handler = sata_fsl_error_handler,
-	.post_internal_cmd = sata_fsl_post_internal_cmd,
-
-	.port_start = sata_fsl_port_start,
-	.port_stop = sata_fsl_port_stop,
-
-	.pmp_attach = sata_fsl_pmp_attach,
-	.pmp_detach = sata_fsl_pmp_detach,
-};
-
-static const struct ata_port_info sata_fsl_port_info[] = {
-	{
-	 .flags = SATA_FSL_HOST_FLAGS,
-	 .pio_mask = ATA_PIO4,
-	 .udma_mask = ATA_UDMA6,
-	 .port_ops = &sata_fsl_ops,
-	 },
-};
-
-static int sata_fsl_probe(struct of_device *ofdev,
-			const struct of_device_id *match)
-{
-	int retval = -ENXIO;
-	void __iomem *hcr_base = NULL;
-	void __iomem *ssr_base = NULL;
-	void __iomem *csr_base = NULL;
-	struct sata_fsl_host_priv *host_priv = NULL;
-	int irq;
-	struct ata_host *host;
-
-	struct ata_port_info pi = sata_fsl_port_info[0];
-	const struct ata_port_info *ppi[] = { &pi, NULL };
-
-	dev_printk(KERN_INFO, &ofdev->dev,
-		   "Sata FSL Platform/CSB Driver init\n");
-
-	hcr_base = of_iomap(ofdev->node, 0);
-	if (!hcr_base)
-		goto error_exit_with_cleanup;
-
-	ssr_base = hcr_base + 0x100;
-	csr_base = hcr_base + 0x140;
-
-	DPRINTK("@reset i/o = 0x%x\n", ioread32(csr_base + TRANSCFG));
-	DPRINTK("sizeof(cmd_desc) = %d\n", sizeof(struct command_desc));
-	DPRINTK("sizeof(#define cmd_desc) = %d\n", SATA_FSL_CMD_DESC_SIZE);
-
-	host_priv = kzalloc(sizeof(struct sata_fsl_host_priv), GFP_KERNEL);
-	if (!host_priv)
-		goto error_exit_with_cleanup;
-
-	host_priv->hcr_base = hcr_base;
-	host_priv->ssr_base = ssr_base;
-	host_priv->csr_base = csr_base;
-
-	irq = irq_of_parse_and_map(ofdev->node, 0);
-	if (irq < 0) {
-		dev_printk(KERN_ERR, &ofdev->dev, "invalid irq from platform\n");
-		goto error_exit_with_cleanup;
-	}
-	host_priv->irq = irq;
-
-	/* allocate host structure */
-	host = ata_host_alloc_pinfo(&ofdev->dev, ppi, SATA_FSL_MAX_PORTS);
-
-	/* host->iomap is not used currently */
-	host->private_data = host_priv;
-
-	/* initialize host controller */
-	sata_fsl_init_controller(host);
-
-	/*
-	 * Now, register with libATA core, this will also initiate the
-	 * device discovery process, invoking our port_start() handler &
-	 * error_handler() to execute a dummy Softreset EH session
-	 */
-	ata_host_activate(host, irq, sata_fsl_interrupt, SATA_FSL_IRQ_FLAG,
-			  &sata_fsl_sht);
-
-	dev_set_drvdata(&ofdev->dev, host);
-
-	return 0;
-
-error_exit_with_cleanup:
-
-	if (hcr_base)
-		iounmap(hcr_base);
-	if (host_priv)
-		kfree(host_priv);
-
-	return retval;
-}
-
-static int sata_fsl_remove(struct of_device *ofdev)
-{
-	struct ata_host *host = dev_get_drvdata(&ofdev->dev);
-	struct sata_fsl_host_priv *host_priv = host->private_data;
-
-	ata_host_detach(host);
-
-	dev_set_drvdata(&ofdev->dev, NULL);
-
-	irq_dispose_mapping(host_priv->irq);
-	iounmap(host_priv->hcr_base);
-	kfree(host_priv);
-
-	return 0;
-}
-
-#ifdef CONFIG_PM
-static int sata_fsl_suspend(struct of_device *op, pm_message_t state)
-{
-	struct ata_host *host = dev_get_drvdata(&op->dev);
-	return ata_host_suspend(host, state);
-}
-
-static int sata_fsl_resume(struct of_device *op)
-{
-	struct ata_host *host = dev_get_drvdata(&op->dev);
-	struct sata_fsl_host_priv *host_priv = host->private_data;
-	int ret;
-	void __iomem *hcr_base = host_priv->hcr_base;
-	struct ata_port *ap = host->ports[0];
-	struct sata_fsl_port_priv *pp = ap->private_data;
-
-	ret = sata_fsl_init_controller(host);
-	if (ret) {
-		dev_printk(KERN_ERR, &op->dev,
-			"Error initialize hardware\n");
-		return ret;
-	}
-
-	/* Recovery the CHBA register in host controller cmd register set */
-	iowrite32(pp->cmdslot_paddr & 0xffffffff, hcr_base + CHBA);
-
-	ata_host_resume(host);
-	return 0;
-}
-#endif
-
-static struct of_device_id fsl_sata_match[] = {
-	{
-		.compatible = "fsl,pq-sata",
-	},
-	{},
-};
-
-MODULE_DEVICE_TABLE(of, fsl_sata_match);
-
-static struct of_platform_driver fsl_sata_driver = {
-	.name		= "fsl-sata",
-	.match_table	= fsl_sata_match,
-	.probe		= sata_fsl_probe,
-	.remove		= sata_fsl_remove,
-#ifdef CONFIG_PM
-	.suspend	= sata_fsl_suspend,
-	.resume		= sata_fsl_resume,
-#endif
-};
-
-static int __init sata_fsl_init(void)
-{
-	of_register_platform_driver(&fsl_sata_driver);
-	return 0;
-}
-
-static void __exit sata_fsl_exit(void)
-{
-	of_unregister_platform_driver(&fsl_sata_driver);
-}
-
-MODULE_LICENSE("GPL");
-MODULE_AUTHOR("Ashish Kalra, Freescale Semiconductor");
-MODULE_DESCRIPTION("Freescale 3.0Gbps SATA controller low level driver");
-MODULE_VERSION("1.10");
-
-module_init(sata_fsl_init);
-module_exit(sata_fsl_exit);
diff -Nur linux-sh4/drivers/ata.org/sata_inic162x.c linux-sh4/drivers/ata/sata_inic162x.c
--- linux-sh4/drivers/ata.org/sata_inic162x.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_inic162x.c	2012-01-15 06:30:15.000000000 -0800
@@ -10,33 +10,13 @@
  * right.  Documentation is available at initio's website but it only
  * documents registers (not programming model).
  *
- * This driver has interesting history.  The first version was written
- * from the documentation and a 2.4 IDE driver posted on a Taiwan
- * company, which didn't use any IDMA features and couldn't handle
- * LBA48.  The resulting driver couldn't handle LBA48 devices either
- * making it pretty useless.
- *
- * After a while, initio picked the driver up, renamed it to
- * sata_initio162x, updated it to use IDMA for ATA DMA commands and
- * posted it on their website.  It only used ATA_PROT_DMA for IDMA and
- * attaching both devices and issuing IDMA and !IDMA commands
- * simultaneously broke it due to PIRQ masking interaction but it did
- * show how to use the IDMA (ADMA + some initio specific twists)
- * engine.
- *
- * Then, I picked up their changes again and here's the usable driver
- * which uses IDMA for everything.  Everything works now including
- * LBA48, CD/DVD burning, suspend/resume and hotplug.  There are some
- * issues tho.  Result Tf is not resported properly, NCQ isn't
- * supported yet and CD/DVD writing works with DMA assisted PIO
- * protocol (which, for native SATA devices, shouldn't cause any
- * noticeable difference).
- *
- * Anyways, so, here's finally a working driver for inic162x.  Enjoy!
- *
- * initio: If you guys wanna improve the driver regarding result TF
- * access and other stuff, please feel free to contact me.  I'll be
- * happy to assist.
+ * - ATA disks work.
+ * - Hotplug works.
+ * - ATAPI read works but burning doesn't.  This thing is really
+ *   peculiar about ATAPI and I couldn't figure out how ATAPI PIO and
+ *   ATAPI DMA WRITE should be programmed.  If you've got a clue, be
+ *   my guest.
+ * - Both STR and STD work.
  */
 
 #include <linux/kernel.h>
@@ -48,19 +28,13 @@
 #include <scsi/scsi_device.h>
 
 #define DRV_NAME	"sata_inic162x"
-#define DRV_VERSION	"0.4"
+#define DRV_VERSION	"0.3"
 
 enum {
-	MMIO_BAR_PCI		= 5,
-	MMIO_BAR_CARDBUS	= 1,
+	MMIO_BAR		= 5,
 
 	NR_PORTS		= 2,
 
-	IDMA_CPB_TBL_SIZE	= 4 * 32,
-
-	INIC_DMA_BOUNDARY	= 0xffffff,
-
-	HOST_ACTRL		= 0x08,
 	HOST_CTL		= 0x7c,
 	HOST_STAT		= 0x7e,
 	HOST_IRQ_STAT		= 0xbc,
@@ -69,38 +43,22 @@
 	PORT_SIZE		= 0x40,
 
 	/* registers for ATA TF operation */
-	PORT_TF_DATA		= 0x00,
-	PORT_TF_FEATURE		= 0x01,
-	PORT_TF_NSECT		= 0x02,
-	PORT_TF_LBAL		= 0x03,
-	PORT_TF_LBAM		= 0x04,
-	PORT_TF_LBAH		= 0x05,
-	PORT_TF_DEVICE		= 0x06,
-	PORT_TF_COMMAND		= 0x07,
-	PORT_TF_ALT_STAT	= 0x08,
+	PORT_TF			= 0x00,
+	PORT_ALT_STAT		= 0x08,
 	PORT_IRQ_STAT		= 0x09,
 	PORT_IRQ_MASK		= 0x0a,
 	PORT_PRD_CTL		= 0x0b,
 	PORT_PRD_ADDR		= 0x0c,
 	PORT_PRD_XFERLEN	= 0x10,
-	PORT_CPB_CPBLAR		= 0x18,
-	PORT_CPB_PTQFIFO	= 0x1c,
 
 	/* IDMA register */
 	PORT_IDMA_CTL		= 0x14,
-	PORT_IDMA_STAT		= 0x16,
-
-	PORT_RPQ_FIFO		= 0x1e,
-	PORT_RPQ_CNT		= 0x1f,
 
 	PORT_SCR		= 0x20,
 
 	/* HOST_CTL bits */
-	HCTL_LEDEN		= (1 << 3),  /* enable LED operation */
 	HCTL_IRQOFF		= (1 << 8),  /* global IRQ off */
-	HCTL_FTHD0		= (1 << 10), /* fifo threshold 0 */
-	HCTL_FTHD1		= (1 << 11), /* fifo threshold 1*/
-	HCTL_PWRDWN		= (1 << 12), /* power down PHYs */
+	HCTL_PWRDWN		= (1 << 13), /* power down PHYs */
 	HCTL_SOFTRST		= (1 << 13), /* global reset (no phy reset) */
 	HCTL_RPGSEL		= (1 << 15), /* register page select */
 
@@ -123,7 +81,9 @@
 	PIRQ_PENDING		= (1 << 7),  /* port IRQ pending (STAT only) */
 
 	PIRQ_ERR		= PIRQ_OFFLINE | PIRQ_ONLINE | PIRQ_FATAL,
-	PIRQ_MASK_DEFAULT	= PIRQ_REPLY | PIRQ_ATA,
+
+	PIRQ_MASK_DMA_READ	= PIRQ_REPLY | PIRQ_ATA,
+	PIRQ_MASK_OTHER		= PIRQ_REPLY | PIRQ_COMPLETE,
 	PIRQ_MASK_FREEZE	= 0xff,
 
 	/* PORT_PRD_CTL bits */
@@ -136,104 +96,45 @@
 	IDMA_CTL_RST_IDMA	= (1 << 5),  /* reset IDMA machinary */
 	IDMA_CTL_GO		= (1 << 7),  /* IDMA mode go */
 	IDMA_CTL_ATA_NIEN	= (1 << 8),  /* ATA IRQ disable */
-
-	/* PORT_IDMA_STAT bits */
-	IDMA_STAT_PERR		= (1 << 0),  /* PCI ERROR MODE */
-	IDMA_STAT_CPBERR	= (1 << 1),  /* ADMA CPB error */
-	IDMA_STAT_LGCY		= (1 << 3),  /* ADMA legacy */
-	IDMA_STAT_UIRQ		= (1 << 4),  /* ADMA unsolicited irq */
-	IDMA_STAT_STPD		= (1 << 5),  /* ADMA stopped */
-	IDMA_STAT_PSD		= (1 << 6),  /* ADMA pause */
-	IDMA_STAT_DONE		= (1 << 7),  /* ADMA done */
-
-	IDMA_STAT_ERR		= IDMA_STAT_PERR | IDMA_STAT_CPBERR,
-
-	/* CPB Control Flags*/
-	CPB_CTL_VALID		= (1 << 0),  /* CPB valid */
-	CPB_CTL_QUEUED		= (1 << 1),  /* queued command */
-	CPB_CTL_DATA		= (1 << 2),  /* data, rsvd in datasheet */
-	CPB_CTL_IEN		= (1 << 3),  /* PCI interrupt enable */
-	CPB_CTL_DEVDIR		= (1 << 4),  /* device direction control */
-
-	/* CPB Response Flags */
-	CPB_RESP_DONE		= (1 << 0),  /* ATA command complete */
-	CPB_RESP_REL		= (1 << 1),  /* ATA release */
-	CPB_RESP_IGNORED	= (1 << 2),  /* CPB ignored */
-	CPB_RESP_ATA_ERR	= (1 << 3),  /* ATA command error */
-	CPB_RESP_SPURIOUS	= (1 << 4),  /* ATA spurious interrupt error */
-	CPB_RESP_UNDERFLOW	= (1 << 5),  /* APRD deficiency length error */
-	CPB_RESP_OVERFLOW	= (1 << 6),  /* APRD exccess length error */
-	CPB_RESP_CPB_ERR	= (1 << 7),  /* CPB error flag */
-
-	/* PRD Control Flags */
-	PRD_DRAIN		= (1 << 1),  /* ignore data excess */
-	PRD_CDB			= (1 << 2),  /* atapi packet command pointer */
-	PRD_DIRECT_INTR		= (1 << 3),  /* direct interrupt */
-	PRD_DMA			= (1 << 4),  /* data transfer method */
-	PRD_WRITE		= (1 << 5),  /* data dir, rsvd in datasheet */
-	PRD_IOM			= (1 << 6),  /* io/memory transfer */
-	PRD_END			= (1 << 7),  /* APRD chain end */
 };
 
-/* Comman Parameter Block */
-struct inic_cpb {
-	u8		resp_flags;	/* Response Flags */
-	u8		error;		/* ATA Error */
-	u8		status;		/* ATA Status */
-	u8		ctl_flags;	/* Control Flags */
-	__le32		len;		/* Total Transfer Length */
-	__le32		prd;		/* First PRD pointer */
-	u8		rsvd[4];
-	/* 16 bytes */
-	u8		feature;	/* ATA Feature */
-	u8		hob_feature;	/* ATA Ex. Feature */
-	u8		device;		/* ATA Device/Head */
-	u8		mirctl;		/* Mirror Control */
-	u8		nsect;		/* ATA Sector Count */
-	u8		hob_nsect;	/* ATA Ex. Sector Count */
-	u8		lbal;		/* ATA Sector Number */
-	u8		hob_lbal;	/* ATA Ex. Sector Number */
-	u8		lbam;		/* ATA Cylinder Low */
-	u8		hob_lbam;	/* ATA Ex. Cylinder Low */
-	u8		lbah;		/* ATA Cylinder High */
-	u8		hob_lbah;	/* ATA Ex. Cylinder High */
-	u8		command;	/* ATA Command */
-	u8		ctl;		/* ATA Control */
-	u8		slave_error;	/* Slave ATA Error */
-	u8		slave_status;	/* Slave ATA Status */
-	/* 32 bytes */
-} __packed;
-
-/* Physical Region Descriptor */
-struct inic_prd {
-	__le32		mad;		/* Physical Memory Address */
-	__le16		len;		/* Transfer Length */
-	u8		rsvd;
-	u8		flags;		/* Control Flags */
-} __packed;
-
-struct inic_pkt {
-	struct inic_cpb	cpb;
-	struct inic_prd	prd[LIBATA_MAX_PRD + 1];	/* + 1 for cdb */
-	u8		cdb[ATAPI_CDB_LEN];
-} __packed;
-
 struct inic_host_priv {
-	void __iomem	*mmio_base;
-	u16		cached_hctl;
+	u16	cached_hctl;
 };
 
 struct inic_port_priv {
-	struct inic_pkt	*pkt;
-	dma_addr_t	pkt_dma;
-	u32		*cpb_tbl;
-	dma_addr_t	cpb_tbl_dma;
+	u8	dfl_prdctl;
+	u8	cached_prdctl;
+	u8	cached_pirq_mask;
 };
 
+static int inic_slave_config(struct scsi_device *sdev)
+{
+	/* This controller is braindamaged.  dma_boundary is 0xffff
+	 * like others but it will lock up the whole machine HARD if
+	 * 65536 byte PRD entry is fed.  Reduce maximum segment size.
+	 */
+	blk_queue_max_segment_size(sdev->request_queue, 65536 - 512);
+
+	return ata_scsi_slave_config(sdev);
+}
+
 static struct scsi_host_template inic_sht = {
-	ATA_BASE_SHT(DRV_NAME),
-	.sg_tablesize	= LIBATA_MAX_PRD,	/* maybe it can be larger? */
-	.dma_boundary	= INIC_DMA_BOUNDARY,
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= inic_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static const int scr_map[] = {
@@ -242,36 +143,56 @@
 	[SCR_CONTROL]	= 2,
 };
 
-static void __iomem *inic_port_base(struct ata_port *ap)
+static void __iomem * inic_port_base(struct ata_port *ap)
 {
-	struct inic_host_priv *hpriv = ap->host->private_data;
+	return ap->host->iomap[MMIO_BAR] + ap->port_no * PORT_SIZE;
+}
+
+static void __inic_set_pirq_mask(struct ata_port *ap, u8 mask)
+{
+	void __iomem *port_base = inic_port_base(ap);
+	struct inic_port_priv *pp = ap->private_data;
 
-	return hpriv->mmio_base + ap->port_no * PORT_SIZE;
+	writeb(mask, port_base + PORT_IRQ_MASK);
+	pp->cached_pirq_mask = mask;
+}
+
+static void inic_set_pirq_mask(struct ata_port *ap, u8 mask)
+{
+	struct inic_port_priv *pp = ap->private_data;
+
+	if (pp->cached_pirq_mask != mask)
+		__inic_set_pirq_mask(ap, mask);
 }
 
 static void inic_reset_port(void __iomem *port_base)
 {
 	void __iomem *idma_ctl = port_base + PORT_IDMA_CTL;
+	u16 ctl;
 
-	/* stop IDMA engine */
-	readw(idma_ctl); /* flush */
-	msleep(1);
+	ctl = readw(idma_ctl);
+	ctl &= ~(IDMA_CTL_RST_IDMA | IDMA_CTL_ATA_NIEN | IDMA_CTL_GO);
 
 	/* mask IRQ and assert reset */
-	writew(IDMA_CTL_RST_IDMA, idma_ctl);
+	writew(ctl | IDMA_CTL_RST_IDMA | IDMA_CTL_ATA_NIEN, idma_ctl);
 	readw(idma_ctl); /* flush */
+
+	/* give it some time */
 	msleep(1);
 
 	/* release reset */
-	writew(0, idma_ctl);
+	writew(ctl | IDMA_CTL_ATA_NIEN, idma_ctl);
 
 	/* clear irq */
 	writeb(0xff, port_base + PORT_IRQ_STAT);
+
+	/* reenable ATA IRQ, turn off IDMA mode */
+	writew(ctl, idma_ctl);
 }
 
-static int inic_scr_read(struct ata_link *link, unsigned sc_reg, u32 *val)
+static int inic_scr_read(struct ata_port *ap, unsigned sc_reg, u32 *val)
 {
-	void __iomem *scr_addr = inic_port_base(link->ap) + PORT_SCR;
+	void __iomem *scr_addr = ap->ioaddr.scr_addr;
 	void __iomem *addr;
 
 	if (unlikely(sc_reg >= ARRAY_SIZE(scr_map)))
@@ -286,128 +207,126 @@
 	return 0;
 }
 
-static int inic_scr_write(struct ata_link *link, unsigned sc_reg, u32 val)
+static int inic_scr_write(struct ata_port *ap, unsigned sc_reg, u32 val)
 {
-	void __iomem *scr_addr = inic_port_base(link->ap) + PORT_SCR;
+	void __iomem *scr_addr = ap->ioaddr.scr_addr;
+	void __iomem *addr;
 
 	if (unlikely(sc_reg >= ARRAY_SIZE(scr_map)))
 		return -EINVAL;
 
+	addr = scr_addr + scr_map[sc_reg] * 4;
 	writel(val, scr_addr + scr_map[sc_reg] * 4);
 	return 0;
 }
 
-static void inic_stop_idma(struct ata_port *ap)
+/*
+ * In TF mode, inic162x is very similar to SFF device.  TF registers
+ * function the same.  DMA engine behaves similary using the same PRD
+ * format as BMDMA but different command register, interrupt and event
+ * notification methods are used.  The following inic_bmdma_*()
+ * functions do the impedance matching.
+ */
+static void inic_bmdma_setup(struct ata_queued_cmd *qc)
 {
+	struct ata_port *ap = qc->ap;
+	struct inic_port_priv *pp = ap->private_data;
 	void __iomem *port_base = inic_port_base(ap);
+	int rw = qc->tf.flags & ATA_TFLAG_WRITE;
 
-	readb(port_base + PORT_RPQ_FIFO);
-	readb(port_base + PORT_RPQ_CNT);
-	writew(0, port_base + PORT_IDMA_CTL);
-}
+	/* make sure device sees PRD table writes */
+	wmb();
 
-static void inic_host_err_intr(struct ata_port *ap, u8 irq_stat, u16 idma_stat)
-{
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	struct inic_port_priv *pp = ap->private_data;
-	struct inic_cpb *cpb = &pp->pkt->cpb;
-	bool freeze = false;
+	/* load transfer length */
+	writel(qc->nbytes, port_base + PORT_PRD_XFERLEN);
 
-	ata_ehi_clear_desc(ehi);
-	ata_ehi_push_desc(ehi, "irq_stat=0x%x idma_stat=0x%x",
-			  irq_stat, idma_stat);
+	/* turn on DMA and specify data direction */
+	pp->cached_prdctl = pp->dfl_prdctl | PRD_CTL_DMAEN;
+	if (!rw)
+		pp->cached_prdctl |= PRD_CTL_WR;
+	writeb(pp->cached_prdctl, port_base + PORT_PRD_CTL);
 
-	inic_stop_idma(ap);
-
-	if (irq_stat & (PIRQ_OFFLINE | PIRQ_ONLINE)) {
-		ata_ehi_push_desc(ehi, "hotplug");
-		ata_ehi_hotplugged(ehi);
-		freeze = true;
-	}
-
-	if (idma_stat & IDMA_STAT_PERR) {
-		ata_ehi_push_desc(ehi, "PCI error");
-		freeze = true;
-	}
+	/* issue r/w command */
+	ap->ops->exec_command(ap, &qc->tf);
+}
 
-	if (idma_stat & IDMA_STAT_CPBERR) {
-		ata_ehi_push_desc(ehi, "CPB error");
+static void inic_bmdma_start(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	struct inic_port_priv *pp = ap->private_data;
+	void __iomem *port_base = inic_port_base(ap);
 
-		if (cpb->resp_flags & CPB_RESP_IGNORED) {
-			__ata_ehi_push_desc(ehi, " ignored");
-			ehi->err_mask |= AC_ERR_INVALID;
-			freeze = true;
-		}
+	/* start host DMA transaction */
+	pp->cached_prdctl |= PRD_CTL_START;
+	writeb(pp->cached_prdctl, port_base + PORT_PRD_CTL);
+}
 
-		if (cpb->resp_flags & CPB_RESP_ATA_ERR)
-			ehi->err_mask |= AC_ERR_DEV;
+static void inic_bmdma_stop(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	struct inic_port_priv *pp = ap->private_data;
+	void __iomem *port_base = inic_port_base(ap);
 
-		if (cpb->resp_flags & CPB_RESP_SPURIOUS) {
-			__ata_ehi_push_desc(ehi, " spurious-intr");
-			ehi->err_mask |= AC_ERR_HSM;
-			freeze = true;
-		}
+	/* stop DMA engine */
+	writeb(pp->dfl_prdctl, port_base + PORT_PRD_CTL);
+}
 
-		if (cpb->resp_flags &
-		    (CPB_RESP_UNDERFLOW | CPB_RESP_OVERFLOW)) {
-			__ata_ehi_push_desc(ehi, " data-over/underflow");
-			ehi->err_mask |= AC_ERR_HSM;
-			freeze = true;
-		}
-	}
+static u8 inic_bmdma_status(struct ata_port *ap)
+{
+	/* event is already verified by the interrupt handler */
+	return ATA_DMA_INTR;
+}
 
-	if (freeze)
-		ata_port_freeze(ap);
-	else
-		ata_port_abort(ap);
+static void inic_irq_clear(struct ata_port *ap)
+{
+	/* noop */
 }
 
 static void inic_host_intr(struct ata_port *ap)
 {
 	void __iomem *port_base = inic_port_base(ap);
-	struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->link.active_tag);
+	struct ata_eh_info *ehi = &ap->eh_info;
 	u8 irq_stat;
-	u16 idma_stat;
 
-	/* read and clear IRQ status */
+	/* fetch and clear irq */
 	irq_stat = readb(port_base + PORT_IRQ_STAT);
 	writeb(irq_stat, port_base + PORT_IRQ_STAT);
-	idma_stat = readw(port_base + PORT_IDMA_STAT);
 
-	if (unlikely((irq_stat & PIRQ_ERR) || (idma_stat & IDMA_STAT_ERR)))
-		inic_host_err_intr(ap, irq_stat, idma_stat);
+	if (likely(!(irq_stat & PIRQ_ERR))) {
+		struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->active_tag);
 
-	if (unlikely(!qc))
-		goto spurious;
-
-	if (likely(idma_stat & IDMA_STAT_DONE)) {
-		inic_stop_idma(ap);
+		if (unlikely(!qc || (qc->tf.flags & ATA_TFLAG_POLLING))) {
+			ata_chk_status(ap);	/* clear ATA interrupt */
+			return;
+		}
 
-		/* Depending on circumstances, device error
-		 * isn't reported by IDMA, check it explicitly.
-		 */
-		if (unlikely(readb(port_base + PORT_TF_COMMAND) &
-			     (ATA_DF | ATA_ERR)))
-			qc->err_mask |= AC_ERR_DEV;
+		if (likely(ata_host_intr(ap, qc)))
+			return;
 
-		ata_qc_complete(qc);
+		ata_chk_status(ap);	/* clear ATA interrupt */
+		ata_port_printk(ap, KERN_WARNING, "unhandled "
+				"interrupt, irq_stat=%x\n", irq_stat);
 		return;
 	}
 
- spurious:
-	ata_port_printk(ap, KERN_WARNING, "unhandled interrupt: "
-			"cmd=0x%x irq_stat=0x%x idma_stat=0x%x\n",
-			qc ? qc->tf.command : 0xff, irq_stat, idma_stat);
+	/* error */
+	ata_ehi_push_desc(ehi, "irq_stat=0x%x", irq_stat);
+
+	if (irq_stat & (PIRQ_OFFLINE | PIRQ_ONLINE)) {
+		ata_ehi_hotplugged(ehi);
+		ata_port_freeze(ap);
+	} else
+		ata_port_abort(ap);
 }
 
 static irqreturn_t inic_interrupt(int irq, void *dev_instance)
 {
 	struct ata_host *host = dev_instance;
-	struct inic_host_priv *hpriv = host->private_data;
+	void __iomem *mmio_base = host->iomap[MMIO_BAR];
 	u16 host_irq_stat;
-	int i, handled = 0;
+	int i, handled = 0;;
 
-	host_irq_stat = readw(hpriv->mmio_base + HOST_IRQ_STAT);
+	host_irq_stat = readw(mmio_base + HOST_IRQ_STAT);
 
 	if (unlikely(!(host_irq_stat & HIRQ_GLOBAL)))
 		goto out;
@@ -437,218 +356,110 @@
 	return IRQ_RETVAL(handled);
 }
 
-static int inic_check_atapi_dma(struct ata_queued_cmd *qc)
-{
-	/* For some reason ATAPI_PROT_DMA doesn't work for some
-	 * commands including writes and other misc ops.  Use PIO
-	 * protocol instead, which BTW is driven by the DMA engine
-	 * anyway, so it shouldn't make much difference for native
-	 * SATA devices.
-	 */
-	if (atapi_cmd_type(qc->cdb[0]) == READ)
-		return 0;
-	return 1;
-}
-
-static void inic_fill_sg(struct inic_prd *prd, struct ata_queued_cmd *qc)
-{
-	struct scatterlist *sg;
-	unsigned int si;
-	u8 flags = 0;
-
-	if (qc->tf.flags & ATA_TFLAG_WRITE)
-		flags |= PRD_WRITE;
-
-	if (ata_is_dma(qc->tf.protocol))
-		flags |= PRD_DMA;
-
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		prd->mad = cpu_to_le32(sg_dma_address(sg));
-		prd->len = cpu_to_le16(sg_dma_len(sg));
-		prd->flags = flags;
-		prd++;
-	}
-
-	WARN_ON(!si);
-	prd[-1].flags |= PRD_END;
-}
-
-static void inic_qc_prep(struct ata_queued_cmd *qc)
-{
-	struct inic_port_priv *pp = qc->ap->private_data;
-	struct inic_pkt *pkt = pp->pkt;
-	struct inic_cpb *cpb = &pkt->cpb;
-	struct inic_prd *prd = pkt->prd;
-	bool is_atapi = ata_is_atapi(qc->tf.protocol);
-	bool is_data = ata_is_data(qc->tf.protocol);
-	unsigned int cdb_len = 0;
-
-	VPRINTK("ENTER\n");
-
-	if (is_atapi)
-		cdb_len = qc->dev->cdb_len;
-
-	/* prepare packet, based on initio driver */
-	memset(pkt, 0, sizeof(struct inic_pkt));
-
-	cpb->ctl_flags = CPB_CTL_VALID | CPB_CTL_IEN;
-	if (is_atapi || is_data)
-		cpb->ctl_flags |= CPB_CTL_DATA;
-
-	cpb->len = cpu_to_le32(qc->nbytes + cdb_len);
-	cpb->prd = cpu_to_le32(pp->pkt_dma + offsetof(struct inic_pkt, prd));
-
-	cpb->device = qc->tf.device;
-	cpb->feature = qc->tf.feature;
-	cpb->nsect = qc->tf.nsect;
-	cpb->lbal = qc->tf.lbal;
-	cpb->lbam = qc->tf.lbam;
-	cpb->lbah = qc->tf.lbah;
-
-	if (qc->tf.flags & ATA_TFLAG_LBA48) {
-		cpb->hob_feature = qc->tf.hob_feature;
-		cpb->hob_nsect = qc->tf.hob_nsect;
-		cpb->hob_lbal = qc->tf.hob_lbal;
-		cpb->hob_lbam = qc->tf.hob_lbam;
-		cpb->hob_lbah = qc->tf.hob_lbah;
-	}
-
-	cpb->command = qc->tf.command;
-	/* don't load ctl - dunno why.  it's like that in the initio driver */
-
-	/* setup PRD for CDB */
-	if (is_atapi) {
-		memcpy(pkt->cdb, qc->cdb, ATAPI_CDB_LEN);
-		prd->mad = cpu_to_le32(pp->pkt_dma +
-				       offsetof(struct inic_pkt, cdb));
-		prd->len = cpu_to_le16(cdb_len);
-		prd->flags = PRD_CDB | PRD_WRITE;
-		if (!is_data)
-			prd->flags |= PRD_END;
-		prd++;
-	}
-
-	/* setup sg table */
-	if (is_data)
-		inic_fill_sg(prd, qc);
-
-	pp->cpb_tbl[0] = pp->pkt_dma;
-}
-
 static unsigned int inic_qc_issue(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
-	void __iomem *port_base = inic_port_base(ap);
-
-	/* fire up the ADMA engine */
-	writew(HCTL_FTHD0 | HCTL_LEDEN, port_base + HOST_CTL);
-	writew(IDMA_CTL_GO, port_base + PORT_IDMA_CTL);
-	writeb(0, port_base + PORT_CPB_PTQFIFO);
-
-	return 0;
-}
-
-static void inic_tf_read(struct ata_port *ap, struct ata_taskfile *tf)
-{
-	void __iomem *port_base = inic_port_base(ap);
-
-	tf->feature	= readb(port_base + PORT_TF_FEATURE);
-	tf->nsect	= readb(port_base + PORT_TF_NSECT);
-	tf->lbal	= readb(port_base + PORT_TF_LBAL);
-	tf->lbam	= readb(port_base + PORT_TF_LBAM);
-	tf->lbah	= readb(port_base + PORT_TF_LBAH);
-	tf->device	= readb(port_base + PORT_TF_DEVICE);
-	tf->command	= readb(port_base + PORT_TF_COMMAND);
-}
 
-static bool inic_qc_fill_rtf(struct ata_queued_cmd *qc)
-{
-	struct ata_taskfile *rtf = &qc->result_tf;
-	struct ata_taskfile tf;
-
-	/* FIXME: Except for status and error, result TF access
-	 * doesn't work.  I tried reading from BAR0/2, CPB and BAR5.
-	 * None works regardless of which command interface is used.
-	 * For now return true iff status indicates device error.
-	 * This means that we're reporting bogus sector for RW
-	 * failures.  Eeekk....
+	/* ATA IRQ doesn't wait for DMA transfer completion and vice
+	 * versa.  Mask IRQ selectively to detect command completion.
+	 * Without it, ATA DMA read command can cause data corruption.
+	 *
+	 * Something similar might be needed for ATAPI writes.  I
+	 * tried a lot of combinations but couldn't find the solution.
 	 */
-	inic_tf_read(qc->ap, &tf);
+	if (qc->tf.protocol == ATA_PROT_DMA &&
+	    !(qc->tf.flags & ATA_TFLAG_WRITE))
+		inic_set_pirq_mask(ap, PIRQ_MASK_DMA_READ);
+	else
+		inic_set_pirq_mask(ap, PIRQ_MASK_OTHER);
 
-	if (!(tf.command & ATA_ERR))
-		return false;
+	/* Issuing a command to yet uninitialized port locks up the
+	 * controller.  Most of the time, this happens for the first
+	 * command after reset which are ATA and ATAPI IDENTIFYs.
+	 * Fast fail if stat is 0x7f or 0xff for those commands.
+	 */
+	if (unlikely(qc->tf.command == ATA_CMD_ID_ATA ||
+		     qc->tf.command == ATA_CMD_ID_ATAPI)) {
+		u8 stat = ata_chk_status(ap);
+		if (stat == 0x7f || stat == 0xff)
+			return AC_ERR_HSM;
+	}
 
-	rtf->command = tf.command;
-	rtf->feature = tf.feature;
-	return true;
+	return ata_qc_issue_prot(qc);
 }
 
 static void inic_freeze(struct ata_port *ap)
 {
 	void __iomem *port_base = inic_port_base(ap);
 
-	writeb(PIRQ_MASK_FREEZE, port_base + PORT_IRQ_MASK);
+	__inic_set_pirq_mask(ap, PIRQ_MASK_FREEZE);
+
+	ata_chk_status(ap);
 	writeb(0xff, port_base + PORT_IRQ_STAT);
+
+	readb(port_base + PORT_IRQ_STAT); /* flush */
 }
 
 static void inic_thaw(struct ata_port *ap)
 {
 	void __iomem *port_base = inic_port_base(ap);
 
+	ata_chk_status(ap);
 	writeb(0xff, port_base + PORT_IRQ_STAT);
-	writeb(PIRQ_MASK_DEFAULT, port_base + PORT_IRQ_MASK);
-}
 
-static int inic_check_ready(struct ata_link *link)
-{
-	void __iomem *port_base = inic_port_base(link->ap);
+	__inic_set_pirq_mask(ap, PIRQ_MASK_OTHER);
 
-	return ata_check_ready(readb(port_base + PORT_TF_COMMAND));
+	readb(port_base + PORT_IRQ_STAT); /* flush */
 }
 
 /*
  * SRST and SControl hardreset don't give valid signature on this
  * controller.  Only controller specific hardreset mechanism works.
  */
-static int inic_hardreset(struct ata_link *link, unsigned int *class,
+static int inic_hardreset(struct ata_port *ap, unsigned int *class,
 			  unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
 	void __iomem *port_base = inic_port_base(ap);
 	void __iomem *idma_ctl = port_base + PORT_IDMA_CTL;
-	const unsigned long *timing = sata_ehc_deb_timing(&link->eh_context);
+	const unsigned long *timing = sata_ehc_deb_timing(&ap->eh_context);
+	u16 val;
 	int rc;
 
 	/* hammer it into sane state */
 	inic_reset_port(port_base);
 
-	writew(IDMA_CTL_RST_ATA, idma_ctl);
+	val = readw(idma_ctl);
+	writew(val | IDMA_CTL_RST_ATA, idma_ctl);
 	readw(idma_ctl);	/* flush */
 	msleep(1);
-	writew(0, idma_ctl);
+	writew(val & ~IDMA_CTL_RST_ATA, idma_ctl);
 
-	rc = sata_link_resume(link, timing, deadline);
+	rc = sata_phy_resume(ap, timing, deadline);
 	if (rc) {
-		ata_link_printk(link, KERN_WARNING, "failed to resume "
+		ata_port_printk(ap, KERN_WARNING, "failed to resume "
 				"link after reset (errno=%d)\n", rc);
 		return rc;
 	}
 
 	*class = ATA_DEV_NONE;
-	if (ata_link_online(link)) {
+	if (ata_port_online(ap)) {
 		struct ata_taskfile tf;
 
-		/* wait for link to become ready */
-		rc = ata_wait_after_reset(link, deadline, inic_check_ready);
+		/* wait a while before checking status */
+		msleep(150);
+
+		rc = ata_wait_ready(ap, deadline);
 		/* link occupied, -ENODEV too is an error */
 		if (rc) {
-			ata_link_printk(link, KERN_WARNING, "device not ready "
+			ata_port_printk(ap, KERN_WARNING, "device not ready "
 					"after hardreset (errno=%d)\n", rc);
 			return rc;
 		}
 
-		inic_tf_read(ap, &tf);
+		ata_tf_read(ap, &tf);
 		*class = ata_dev_classify(&tf);
+		if (*class == ATA_DEV_UNKNOWN)
+			*class = ATA_DEV_NONE;
 	}
 
 	return 0;
@@ -657,9 +468,20 @@
 static void inic_error_handler(struct ata_port *ap)
 {
 	void __iomem *port_base = inic_port_base(ap);
+	struct inic_port_priv *pp = ap->private_data;
+	unsigned long flags;
 
+	/* reset PIO HSM and stop DMA engine */
 	inic_reset_port(port_base);
-	ata_std_error_handler(ap);
+
+	spin_lock_irqsave(ap->lock, flags);
+	ap->hsm_task_state = HSM_ST_IDLE;
+	writeb(pp->dfl_prdctl, port_base + PORT_PRD_CTL);
+	spin_unlock_irqrestore(ap->lock, flags);
+
+	/* PIO and DMA engines have been stopped, perform recovery */
+	ata_do_eh(ap, ata_std_prereset, NULL, inic_hardreset,
+		  ata_std_postreset);
 }
 
 static void inic_post_internal_cmd(struct ata_queued_cmd *qc)
@@ -669,18 +491,26 @@
 		inic_reset_port(inic_port_base(qc->ap));
 }
 
+static void inic_dev_config(struct ata_device *dev)
+{
+	/* inic can only handle upto LBA28 max sectors */
+	if (dev->max_sectors > ATA_MAX_SECTORS)
+		dev->max_sectors = ATA_MAX_SECTORS;
+
+	if (dev->n_sectors >= 1 << 28) {
+		ata_dev_printk(dev, KERN_ERR,
+	"ERROR: This driver doesn't support LBA48 yet and may cause\n"
+	"                data corruption on such devices.  Disabling.\n");
+		ata_dev_disable(dev);
+	}
+}
+
 static void init_port(struct ata_port *ap)
 {
 	void __iomem *port_base = inic_port_base(ap);
-	struct inic_port_priv *pp = ap->private_data;
 
-	/* clear packet and CPB table */
-	memset(pp->pkt, 0, sizeof(struct inic_pkt));
-	memset(pp->cpb_tbl, 0, IDMA_CPB_TBL_SIZE);
-
-	/* setup PRD and CPB lookup table addresses */
+	/* Setup PRD address */
 	writel(ap->prd_dma, port_base + PORT_PRD_ADDR);
-	writel(pp->cpb_tbl_dma, port_base + PORT_CPB_CPBLAR);
 }
 
 static int inic_port_resume(struct ata_port *ap)
@@ -691,30 +521,28 @@
 
 static int inic_port_start(struct ata_port *ap)
 {
-	struct device *dev = ap->host->dev;
+	void __iomem *port_base = inic_port_base(ap);
 	struct inic_port_priv *pp;
+	u8 tmp;
 	int rc;
 
 	/* alloc and initialize private data */
-	pp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);
+	pp = devm_kzalloc(ap->host->dev, sizeof(*pp), GFP_KERNEL);
 	if (!pp)
 		return -ENOMEM;
 	ap->private_data = pp;
 
+	/* default PRD_CTL value, DMAEN, WR and START off */
+	tmp = readb(port_base + PORT_PRD_CTL);
+	tmp &= ~(PRD_CTL_DMAEN | PRD_CTL_WR | PRD_CTL_START);
+	pp->dfl_prdctl = tmp;
+
 	/* Alloc resources */
 	rc = ata_port_start(ap);
-	if (rc)
+	if (rc) {
+		kfree(pp);
 		return rc;
-
-	pp->pkt = dmam_alloc_coherent(dev, sizeof(struct inic_pkt),
-				      &pp->pkt_dma, GFP_KERNEL);
-	if (!pp->pkt)
-		return -ENOMEM;
-
-	pp->cpb_tbl = dmam_alloc_coherent(dev, IDMA_CPB_TBL_SIZE,
-					  &pp->cpb_tbl_dma, GFP_KERNEL);
-	if (!pp->cpb_tbl)
-		return -ENOMEM;
+	}
 
 	init_port(ap);
 
@@ -722,30 +550,50 @@
 }
 
 static struct ata_port_operations inic_port_ops = {
-	.inherits		= &sata_port_ops,
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.scr_read		= inic_scr_read,
+	.scr_write		= inic_scr_write,
+
+	.bmdma_setup		= inic_bmdma_setup,
+	.bmdma_start		= inic_bmdma_start,
+	.bmdma_stop		= inic_bmdma_stop,
+	.bmdma_status		= inic_bmdma_status,
+
+	.irq_clear		= inic_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 
-	.check_atapi_dma	= inic_check_atapi_dma,
-	.qc_prep		= inic_qc_prep,
+	.qc_prep	 	= ata_qc_prep,
 	.qc_issue		= inic_qc_issue,
-	.qc_fill_rtf		= inic_qc_fill_rtf,
+	.data_xfer		= ata_data_xfer,
 
 	.freeze			= inic_freeze,
 	.thaw			= inic_thaw,
-	.hardreset		= inic_hardreset,
 	.error_handler		= inic_error_handler,
 	.post_internal_cmd	= inic_post_internal_cmd,
-
-	.scr_read		= inic_scr_read,
-	.scr_write		= inic_scr_write,
+	.dev_config		= inic_dev_config,
 
 	.port_resume		= inic_port_resume,
+
 	.port_start		= inic_port_start,
 };
 
 static struct ata_port_info inic_port_info = {
+	/* For some reason, ATA_PROT_ATAPI is broken on this
+	 * controller, and no, PIO_POLLING does't fix it.  It somehow
+	 * manages to report the wrong ireason and ignoring ireason
+	 * results in machine lock up.  Tell libata to always prefer
+	 * DMA.
+	 */
 	.flags			= ATA_FLAG_SATA | ATA_FLAG_PIO_DMA,
-	.pio_mask		= ATA_PIO4,
-	.mwdma_mask		= ATA_MWDMA2,
+	.pio_mask		= 0x1f,	/* pio0-4 */
+	.mwdma_mask		= 0x07, /* mwdma0-2 */
 	.udma_mask		= ATA_UDMA6,
 	.port_ops		= &inic_port_ops
 };
@@ -795,6 +643,7 @@
 {
 	struct ata_host *host = dev_get_drvdata(&pdev->dev);
 	struct inic_host_priv *hpriv = host->private_data;
+	void __iomem *mmio_base = host->iomap[MMIO_BAR];
 	int rc;
 
 	rc = ata_pci_device_do_resume(pdev);
@@ -802,7 +651,7 @@
 		return rc;
 
 	if (pdev->dev.power.power_state.event == PM_EVENT_SUSPEND) {
-		rc = init_controller(hpriv->mmio_base, hpriv->cached_hctl);
+		rc = init_controller(mmio_base, hpriv->cached_hctl);
 		if (rc)
 			return rc;
 	}
@@ -820,7 +669,6 @@
 	struct ata_host *host;
 	struct inic_host_priv *hpriv;
 	void __iomem * const *iomap;
-	int mmio_bar;
 	int i, rc;
 
 	if (!printed_version++)
@@ -834,60 +682,47 @@
 
 	host->private_data = hpriv;
 
-	/* Acquire resources and fill host.  Note that PCI and cardbus
-	 * use different BARs.
-	 */
+	/* acquire resources and fill host */
 	rc = pcim_enable_device(pdev);
 	if (rc)
 		return rc;
 
-	if (pci_resource_flags(pdev, MMIO_BAR_PCI) & IORESOURCE_MEM)
-		mmio_bar = MMIO_BAR_PCI;
-	else
-		mmio_bar = MMIO_BAR_CARDBUS;
-
-	rc = pcim_iomap_regions(pdev, 1 << mmio_bar, DRV_NAME);
+	rc = pcim_iomap_regions(pdev, 0x3f, DRV_NAME);
 	if (rc)
 		return rc;
 	host->iomap = iomap = pcim_iomap_table(pdev);
-	hpriv->mmio_base = iomap[mmio_bar];
-	hpriv->cached_hctl = readw(hpriv->mmio_base + HOST_CTL);
 
 	for (i = 0; i < NR_PORTS; i++) {
-		struct ata_port *ap = host->ports[i];
+		struct ata_ioports *port = &host->ports[i]->ioaddr;
+		void __iomem *port_base = iomap[MMIO_BAR] + i * PORT_SIZE;
+
+		port->cmd_addr = iomap[2 * i];
+		port->altstatus_addr =
+		port->ctl_addr = (void __iomem *)
+			((unsigned long)iomap[2 * i + 1] | ATA_PCI_CTL_OFS);
+		port->scr_addr = port_base + PORT_SCR;
 
-		ata_port_pbar_desc(ap, mmio_bar, -1, "mmio");
-		ata_port_pbar_desc(ap, mmio_bar, i * PORT_SIZE, "port");
+		ata_std_ports(port);
 	}
 
+	hpriv->cached_hctl = readw(iomap[MMIO_BAR] + HOST_CTL);
+
 	/* Set dma_mask.  This devices doesn't support 64bit addressing. */
-	rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
+	rc = pci_set_dma_mask(pdev, DMA_32BIT_MASK);
 	if (rc) {
 		dev_printk(KERN_ERR, &pdev->dev,
 			   "32-bit DMA enable failed\n");
 		return rc;
 	}
 
-	rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+	rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 	if (rc) {
 		dev_printk(KERN_ERR, &pdev->dev,
 			   "32-bit consistent DMA enable failed\n");
 		return rc;
 	}
 
-	/*
-	 * This controller is braindamaged.  dma_boundary is 0xffff
-	 * like others but it will lock up the whole machine HARD if
-	 * 65536 byte PRD entry is fed. Reduce maximum segment size.
-	 */
-	rc = pci_set_dma_max_seg_size(pdev, 65536 - 512);
-	if (rc) {
-		dev_printk(KERN_ERR, &pdev->dev,
-			   "failed to set the maximum segment size.\n");
-		return rc;
-	}
-
-	rc = init_controller(hpriv->mmio_base, hpriv->cached_hctl);
+	rc = init_controller(iomap[MMIO_BAR], hpriv->cached_hctl);
 	if (rc) {
 		dev_printk(KERN_ERR, &pdev->dev,
 			   "failed to initialize controller\n");
diff -Nur linux-sh4/drivers/ata.org/sata_mv.c linux-sh4/drivers/ata/sata_mv.c
--- linux-sh4/drivers/ata.org/sata_mv.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/sata_mv.c	2012-01-15 06:30:15.000000000 -0800
@@ -1,13 +1,9 @@
 /*
  * sata_mv.c - Marvell SATA support
  *
- * Copyright 2008-2009: Marvell Corporation, all rights reserved.
  * Copyright 2005: EMC Corporation, all rights reserved.
  * Copyright 2005 Red Hat, Inc.  All rights reserved.
  *
- * Originally written by Brett Russ.
- * Extensive overhaul and enhancement by Mark Lord <mlord@pobox.com>.
- *
  * Please ALWAYS copy linux-ide@vger.kernel.org on emails.
  *
  * This program is free software; you can redistribute it and/or modify
@@ -26,28 +22,41 @@
  */
 
 /*
- * sata_mv TODO list:
- *
- * --> Develop a low-power-consumption strategy, and implement it.
- *
- * --> Add sysfs attributes for per-chip / per-HC IRQ coalescing thresholds.
- *
- * --> [Experiment, Marvell value added] Is it possible to use target
- *       mode to cross-connect two Linux boxes with Marvell cards?  If so,
- *       creating LibATA target mode support would be very interesting.
- *
- *       Target mode, for those without docs, is the ability to directly
- *       connect two SATA ports.
- */
+  sata_mv TODO list:
+
+  1) Needs a full errata audit for all chipsets.  I implemented most
+  of the errata workarounds found in the Marvell vendor driver, but
+  I distinctly remember a couple workarounds (one related to PCI-X)
+  are still needed.
+
+  4) Add NCQ support (easy to intermediate, once new-EH support appears)
+
+  5) Investigate problems with PCI Message Signalled Interrupts (MSI).
+
+  6) Add port multiplier support (intermediate)
+
+  8) Develop a low-power-consumption strategy, and implement it.
+
+  9) [Experiment, low priority] See if ATAPI can be supported using
+  "unknown FIS" or "vendor-specific FIS" support, or something creative
+  like that.
+
+  10) [Experiment, low priority] Investigate interrupt coalescing.
+  Quite often, especially with PCI Message Signalled Interrupts (MSI),
+  the overhead reduced by interrupt mitigation is quite often not
+  worth the latency cost.
+
+  11) [Experiment, Marvell value added] Is it possible to use target
+  mode to cross-connect two Linux boxes with Marvell cards?  If so,
+  creating LibATA target mode support would be very interesting.
+
+  Target mode, for those without docs, is the ability to directly
+  connect two SATA controllers.
+
+  13) Verify that 7042 is fully supported.  I only have a 6042.
+
+*/
 
-/*
- * 80x1-B2 errata PCI#11:
- *
- * Users of the 6041/6081 Rev.B2 chips (current is C0)
- * should be careful to insert those cards only onto PCI-X bus #0,
- * and only in device slots 0..7, not higher.  The chips may not
- * work correctly otherwise  (note: this is a pretty rare condition).
- */
 
 #include <linux/kernel.h>
 #include <linux/module.h>
@@ -56,40 +65,15 @@
 #include <linux/blkdev.h>
 #include <linux/delay.h>
 #include <linux/interrupt.h>
-#include <linux/dmapool.h>
 #include <linux/dma-mapping.h>
 #include <linux/device.h>
-#include <linux/platform_device.h>
-#include <linux/ata_platform.h>
-#include <linux/mbus.h>
-#include <linux/bitops.h>
 #include <scsi/scsi_host.h>
 #include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_device.h>
 #include <linux/libata.h>
 
 #define DRV_NAME	"sata_mv"
-#define DRV_VERSION	"1.28"
-
-/*
- * module options
- */
-
-static int msi;
-#ifdef CONFIG_PCI
-module_param(msi, int, S_IRUGO);
-MODULE_PARM_DESC(msi, "Enable use of PCI MSI (0=off, 1=on)");
-#endif
-
-static int irq_coalescing_io_count;
-module_param(irq_coalescing_io_count, int, S_IRUGO);
-MODULE_PARM_DESC(irq_coalescing_io_count,
-		 "IRQ coalescing I/O count threshold (0..255)");
-
-static int irq_coalescing_usecs;
-module_param(irq_coalescing_usecs, int, S_IRUGO);
-MODULE_PARM_DESC(irq_coalescing_usecs,
-		 "IRQ coalescing time threshold in usecs");
+#define DRV_VERSION	"1.01"
 
 enum {
 	/* BAR's are enumerated in terms of pci_resource_start() terms */
@@ -100,37 +84,18 @@
 	MV_MAJOR_REG_AREA_SZ	= 0x10000,	/* 64KB */
 	MV_MINOR_REG_AREA_SZ	= 0x2000,	/* 8KB */
 
-	/* For use with both IRQ coalescing methods ("all ports" or "per-HC" */
-	COAL_CLOCKS_PER_USEC	= 150,		/* for calculating COAL_TIMEs */
-	MAX_COAL_TIME_THRESHOLD	= ((1 << 24) - 1), /* internal clocks count */
-	MAX_COAL_IO_COUNT	= 255,		/* completed I/O count */
-
 	MV_PCI_REG_BASE		= 0,
-
-	/*
-	 * Per-chip ("all ports") interrupt coalescing feature.
-	 * This is only for GEN_II / GEN_IIE hardware.
-	 *
-	 * Coalescing defers the interrupt until either the IO_THRESHOLD
-	 * (count of completed I/Os) is met, or the TIME_THRESHOLD is met.
-	 */
-	COAL_REG_BASE		= 0x18000,
-	IRQ_COAL_CAUSE		= (COAL_REG_BASE + 0x08),
-	ALL_PORTS_COAL_IRQ	= (1 << 4),	/* all ports irq event */
-
-	IRQ_COAL_IO_THRESHOLD   = (COAL_REG_BASE + 0xcc),
-	IRQ_COAL_TIME_THRESHOLD = (COAL_REG_BASE + 0xd0),
-
-	/*
-	 * Registers for the (unused here) transaction coalescing feature:
-	 */
-	TRAN_COAL_CAUSE_LO	= (COAL_REG_BASE + 0x88),
-	TRAN_COAL_CAUSE_HI	= (COAL_REG_BASE + 0x8c),
-
-	SATAHC0_REG_BASE	= 0x20000,
-	FLASH_CTL		= 0x1046c,
-	GPIO_PORT_CTL		= 0x104f0,
-	RESET_CFG		= 0x180d8,
+	MV_IRQ_COAL_REG_BASE	= 0x18000,	/* 6xxx part only */
+	MV_IRQ_COAL_CAUSE		= (MV_IRQ_COAL_REG_BASE + 0x08),
+	MV_IRQ_COAL_CAUSE_LO		= (MV_IRQ_COAL_REG_BASE + 0x88),
+	MV_IRQ_COAL_CAUSE_HI		= (MV_IRQ_COAL_REG_BASE + 0x8c),
+	MV_IRQ_COAL_THRESHOLD		= (MV_IRQ_COAL_REG_BASE + 0xcc),
+	MV_IRQ_COAL_TIME_THRESHOLD	= (MV_IRQ_COAL_REG_BASE + 0xd0),
+
+	MV_SATAHC0_REG_BASE	= 0x20000,
+	MV_FLASH_CTL		= 0x1046c,
+	MV_GPIO_PORT_CTL	= 0x104f0,
+	MV_RESET_CFG		= 0x180d8,
 
 	MV_PCI_REG_SZ		= MV_MAJOR_REG_AREA_SZ,
 	MV_SATAHC_REG_SZ	= MV_MAJOR_REG_AREA_SZ,
@@ -142,36 +107,32 @@
 
 	/* CRQB needs alignment on a 1KB boundary. Size == 1KB
 	 * CRPB needs alignment on a 256B boundary. Size == 256B
+	 * SG count of 176 leads to MV_PORT_PRIV_DMA_SZ == 4KB
 	 * ePRD (SG) entries need alignment on a 16B boundary. Size == 16B
 	 */
 	MV_CRQB_Q_SZ		= (32 * MV_MAX_Q_DEPTH),
 	MV_CRPB_Q_SZ		= (8 * MV_MAX_Q_DEPTH),
-	MV_MAX_SG_CT		= 256,
+	MV_MAX_SG_CT		= 176,
 	MV_SG_TBL_SZ		= (16 * MV_MAX_SG_CT),
+	MV_PORT_PRIV_DMA_SZ	= (MV_CRQB_Q_SZ + MV_CRPB_Q_SZ + MV_SG_TBL_SZ),
 
-	/* Determine hc from 0-7 port: hc = port >> MV_PORT_HC_SHIFT */
+	MV_PORTS_PER_HC		= 4,
+	/* == (port / MV_PORTS_PER_HC) to determine HC from 0-7 port */
 	MV_PORT_HC_SHIFT	= 2,
-	MV_PORTS_PER_HC		= (1 << MV_PORT_HC_SHIFT), /* 4 */
-	/* Determine hc port from 0-7 port: hardport = port & MV_PORT_MASK */
-	MV_PORT_MASK		= (MV_PORTS_PER_HC - 1),   /* 3 */
+	/* == (port % MV_PORTS_PER_HC) to determine hard port from 0-7 port */
+	MV_PORT_MASK		= 3,
 
 	/* Host Flags */
 	MV_FLAG_DUAL_HC		= (1 << 30),  /* two SATA Host Controllers */
-
+	MV_FLAG_IRQ_COALESCE	= (1 << 29),  /* IRQ coalescing capability */
 	MV_COMMON_FLAGS		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
-				  ATA_FLAG_MMIO | ATA_FLAG_PIO_POLLING,
-
-	MV_GEN_I_FLAGS		= MV_COMMON_FLAGS | ATA_FLAG_NO_ATAPI,
-
-	MV_GEN_II_FLAGS		= MV_COMMON_FLAGS | ATA_FLAG_NCQ |
-				  ATA_FLAG_PMP | ATA_FLAG_ACPI_SATA,
-
-	MV_GEN_IIE_FLAGS	= MV_GEN_II_FLAGS | ATA_FLAG_AN,
+				  ATA_FLAG_MMIO | ATA_FLAG_NO_ATAPI |
+				  ATA_FLAG_PIO_POLLING,
+	MV_6XXX_FLAGS		= MV_FLAG_IRQ_COALESCE,
 
 	CRQB_FLAG_READ		= (1 << 0),
 	CRQB_TAG_SHIFT		= 1,
 	CRQB_IOID_SHIFT		= 6,	/* CRQB Gen-II/IIE IO Id shift */
-	CRQB_PMP_SHIFT		= 12,	/* CRQB Gen-II/IIE PMP shift */
 	CRQB_HOSTQ_SHIFT	= 17,	/* CRQB Gen-II/IIE HostQueTag shift */
 	CRQB_CMD_ADDR_SHIFT	= 8,
 	CRQB_CMD_CS		= (0x2 << 11),
@@ -185,18 +146,14 @@
 
 	/* PCI interface registers */
 
-	MV_PCI_COMMAND		= 0xc00,
-	MV_PCI_COMMAND_MWRCOM	= (1 << 4),	/* PCI Master Write Combining */
-	MV_PCI_COMMAND_MRDTRIG	= (1 << 7),	/* PCI Master Read Trigger */
+	PCI_COMMAND_OFS		= 0xc00,
 
-	PCI_MAIN_CMD_STS	= 0xd30,
+	PCI_MAIN_CMD_STS_OFS	= 0xd30,
 	STOP_PCI_MASTER		= (1 << 2),
 	PCI_MASTER_EMPTY	= (1 << 3),
 	GLOB_SFT_RST		= (1 << 4),
 
 	MV_PCI_MODE		= 0xd00,
-	MV_PCI_MODE_MASK	= 0x30,
-
 	MV_PCI_EXP_ROM_BAR_CTL	= 0xd2c,
 	MV_PCI_DISC_TIMER	= 0xd04,
 	MV_PCI_MSI_TRIGGER	= 0xc38,
@@ -207,115 +164,68 @@
 	MV_PCI_ERR_ATTRIBUTE	= 0x1d48,
 	MV_PCI_ERR_COMMAND	= 0x1d50,
 
-	PCI_IRQ_CAUSE		= 0x1d58,
-	PCI_IRQ_MASK		= 0x1d5c,
+	PCI_IRQ_CAUSE_OFS		= 0x1d58,
+	PCI_IRQ_MASK_OFS		= 0x1d5c,
 	PCI_UNMASK_ALL_IRQS	= 0x7fffff,	/* bits 22-0 */
 
-	PCIE_IRQ_CAUSE		= 0x1900,
-	PCIE_IRQ_MASK		= 0x1910,
-	PCIE_UNMASK_ALL_IRQS	= 0x40a,	/* assorted bits */
-
-	/* Host Controller Main Interrupt Cause/Mask registers (1 per-chip) */
-	PCI_HC_MAIN_IRQ_CAUSE	= 0x1d60,
-	PCI_HC_MAIN_IRQ_MASK	= 0x1d64,
-	SOC_HC_MAIN_IRQ_CAUSE	= 0x20020,
-	SOC_HC_MAIN_IRQ_MASK	= 0x20024,
-	ERR_IRQ			= (1 << 0),	/* shift by (2 * port #) */
-	DONE_IRQ		= (1 << 1),	/* shift by (2 * port #) */
+	HC_MAIN_IRQ_CAUSE_OFS	= 0x1d60,
+	HC_MAIN_IRQ_MASK_OFS	= 0x1d64,
+	PORT0_ERR		= (1 << 0),	/* shift by port # */
+	PORT0_DONE		= (1 << 1),	/* shift by port # */
 	HC0_IRQ_PEND		= 0x1ff,	/* bits 0-8 = HC0's ports */
 	HC_SHIFT		= 9,		/* bits 9-17 = HC1's ports */
-	DONE_IRQ_0_3		= 0x000000aa,	/* DONE_IRQ ports 0,1,2,3 */
-	DONE_IRQ_4_7		= (DONE_IRQ_0_3 << HC_SHIFT),  /* 4,5,6,7 */
 	PCI_ERR			= (1 << 18),
-	TRAN_COAL_LO_DONE	= (1 << 19),	/* transaction coalescing */
-	TRAN_COAL_HI_DONE	= (1 << 20),	/* transaction coalescing */
-	PORTS_0_3_COAL_DONE	= (1 << 8),	/* HC0 IRQ coalescing */
-	PORTS_4_7_COAL_DONE	= (1 << 17),	/* HC1 IRQ coalescing */
-	ALL_PORTS_COAL_DONE	= (1 << 21),	/* GEN_II(E) IRQ coalescing */
+	TRAN_LO_DONE		= (1 << 19),	/* 6xxx: IRQ coalescing */
+	TRAN_HI_DONE		= (1 << 20),	/* 6xxx: IRQ coalescing */
+	PORTS_0_3_COAL_DONE	= (1 << 8),
+	PORTS_4_7_COAL_DONE	= (1 << 17),
+	PORTS_0_7_COAL_DONE	= (1 << 21),	/* 6xxx: IRQ coalescing */
 	GPIO_INT		= (1 << 22),
 	SELF_INT		= (1 << 23),
 	TWSI_INT		= (1 << 24),
 	HC_MAIN_RSVD		= (0x7f << 25),	/* bits 31-25 */
 	HC_MAIN_RSVD_5		= (0x1fff << 19), /* bits 31-19 */
-	HC_MAIN_RSVD_SOC	= (0x3fffffb << 6),     /* bits 31-9, 7-6 */
+	HC_MAIN_MASKED_IRQS	= (TRAN_LO_DONE | TRAN_HI_DONE |
+				   PORTS_0_7_COAL_DONE | GPIO_INT | TWSI_INT |
+				   HC_MAIN_RSVD),
+	HC_MAIN_MASKED_IRQS_5	= (PORTS_0_3_COAL_DONE | PORTS_4_7_COAL_DONE |
+				   HC_MAIN_RSVD_5),
 
 	/* SATAHC registers */
-	HC_CFG			= 0x00,
+	HC_CFG_OFS		= 0,
 
-	HC_IRQ_CAUSE		= 0x14,
-	DMA_IRQ			= (1 << 0),	/* shift by port # */
-	HC_COAL_IRQ		= (1 << 4),	/* IRQ coalescing */
+	HC_IRQ_CAUSE_OFS	= 0x14,
+	CRPB_DMA_DONE		= (1 << 0),	/* shift by port # */
+	HC_IRQ_COAL		= (1 << 4),	/* IRQ coalescing */
 	DEV_IRQ			= (1 << 8),	/* shift by port # */
 
-	/*
-	 * Per-HC (Host-Controller) interrupt coalescing feature.
-	 * This is present on all chip generations.
-	 *
-	 * Coalescing defers the interrupt until either the IO_THRESHOLD
-	 * (count of completed I/Os) is met, or the TIME_THRESHOLD is met.
-	 */
-	HC_IRQ_COAL_IO_THRESHOLD	= 0x000c,
-	HC_IRQ_COAL_TIME_THRESHOLD	= 0x0010,
-
-	SOC_LED_CTRL		= 0x2c,
-	SOC_LED_CTRL_BLINK	= (1 << 0),	/* Active LED blink */
-	SOC_LED_CTRL_ACT_PRESENCE = (1 << 2),	/* Multiplex dev presence */
-						/*  with dev activity LED */
-
 	/* Shadow block registers */
-	SHD_BLK			= 0x100,
-	SHD_CTL_AST		= 0x20,		/* ofs from SHD_BLK */
+	SHD_BLK_OFS		= 0x100,
+	SHD_CTL_AST_OFS		= 0x20,		/* ofs from SHD_BLK_OFS */
 
 	/* SATA registers */
-	SATA_STATUS		= 0x300,  /* ctrl, err regs follow status */
-	SATA_ACTIVE		= 0x350,
-	FIS_IRQ_CAUSE		= 0x364,
-	FIS_IRQ_CAUSE_AN	= (1 << 9),	/* async notification */
-
-	LTMODE			= 0x30c,	/* requires read-after-write */
-	LTMODE_BIT8		= (1 << 8),	/* unknown, but necessary */
-
-	PHY_MODE2		= 0x330,
+	SATA_STATUS_OFS		= 0x300,  /* ctrl, err regs follow status */
+	SATA_ACTIVE_OFS		= 0x350,
 	PHY_MODE3		= 0x310,
-
-	PHY_MODE4		= 0x314,	/* requires read-after-write */
-	PHY_MODE4_CFG_MASK	= 0x00000003,	/* phy internal config field */
-	PHY_MODE4_CFG_VALUE	= 0x00000001,	/* phy internal config field */
-	PHY_MODE4_RSVD_ZEROS	= 0x5de3fffa,	/* Gen2e always write zeros */
-	PHY_MODE4_RSVD_ONES	= 0x00000005,	/* Gen2e always write ones */
-
-	SATA_IFCTL		= 0x344,
-	SATA_TESTCTL		= 0x348,
-	SATA_IFSTAT		= 0x34c,
-	VENDOR_UNIQUE_FIS	= 0x35c,
-
-	FISCFG			= 0x360,
-	FISCFG_WAIT_DEV_ERR	= (1 << 8),	/* wait for host on DevErr */
-	FISCFG_SINGLE_SYNC	= (1 << 16),	/* SYNC on DMA activation */
-
-	PHY_MODE9_GEN2		= 0x398,
-	PHY_MODE9_GEN1		= 0x39c,
-	PHYCFG_OFS		= 0x3a0,	/* only in 65n devices */
-
+	PHY_MODE4		= 0x314,
+	PHY_MODE2		= 0x330,
 	MV5_PHY_MODE		= 0x74,
-	MV5_LTMODE		= 0x30,
+	MV5_LT_MODE		= 0x30,
 	MV5_PHY_CTL		= 0x0C,
-	SATA_IFCFG		= 0x050,
+	SATA_INTERFACE_CTL	= 0x050,
 
 	MV_M2_PREAMP_MASK	= 0x7e0,
 
 	/* Port registers */
-	EDMA_CFG		= 0,
-	EDMA_CFG_Q_DEPTH	= 0x1f,		/* max device queue depth */
-	EDMA_CFG_NCQ		= (1 << 5),	/* for R/W FPDMA queued */
-	EDMA_CFG_NCQ_GO_ON_ERR	= (1 << 14),	/* continue on error */
-	EDMA_CFG_RD_BRST_EXT	= (1 << 11),	/* read burst 512B */
-	EDMA_CFG_WR_BUFF_LEN	= (1 << 13),	/* write buffer 512B */
-	EDMA_CFG_EDMA_FBS	= (1 << 16),	/* EDMA FIS-Based Switching */
-	EDMA_CFG_FBS		= (1 << 26),	/* FIS-Based Switching */
+	EDMA_CFG_OFS		= 0,
+	EDMA_CFG_Q_DEPTH	= 0,			/* queueing disabled */
+	EDMA_CFG_NCQ		= (1 << 5),
+	EDMA_CFG_NCQ_GO_ON_ERR	= (1 << 14),		/* continue on error */
+	EDMA_CFG_RD_BRST_EXT	= (1 << 11),		/* read burst 512B */
+	EDMA_CFG_WR_BUFF_LEN	= (1 << 13),		/* write buffer 512B */
 
-	EDMA_ERR_IRQ_CAUSE	= 0x8,
-	EDMA_ERR_IRQ_MASK	= 0xc,
+	EDMA_ERR_IRQ_CAUSE_OFS	= 0x8,
+	EDMA_ERR_IRQ_MASK_OFS	= 0xc,
 	EDMA_ERR_D_PAR		= (1 << 0),	/* UDMA data parity err */
 	EDMA_ERR_PRD_PAR	= (1 << 1),	/* UDMA PRD parity err */
 	EDMA_ERR_DEV		= (1 << 2),	/* device error */
@@ -330,33 +240,14 @@
 	EDMA_ERR_CRPB_PAR	= (1 << 10),	/* CRPB parity error */
 	EDMA_ERR_INTRL_PAR	= (1 << 11),	/* internal parity error */
 	EDMA_ERR_IORDY		= (1 << 12),	/* IORdy timeout */
-
 	EDMA_ERR_LNK_CTRL_RX	= (0xf << 13),	/* link ctrl rx error */
-	EDMA_ERR_LNK_CTRL_RX_0	= (1 << 13),	/* transient: CRC err */
-	EDMA_ERR_LNK_CTRL_RX_1	= (1 << 14),	/* transient: FIFO err */
-	EDMA_ERR_LNK_CTRL_RX_2	= (1 << 15),	/* fatal: caught SYNC */
-	EDMA_ERR_LNK_CTRL_RX_3	= (1 << 16),	/* transient: FIS rx err */
-
+	EDMA_ERR_LNK_CTRL_RX_2	= (1 << 15),
 	EDMA_ERR_LNK_DATA_RX	= (0xf << 17),	/* link data rx error */
-
 	EDMA_ERR_LNK_CTRL_TX	= (0x1f << 21),	/* link ctrl tx error */
-	EDMA_ERR_LNK_CTRL_TX_0	= (1 << 21),	/* transient: CRC err */
-	EDMA_ERR_LNK_CTRL_TX_1	= (1 << 22),	/* transient: FIFO err */
-	EDMA_ERR_LNK_CTRL_TX_2	= (1 << 23),	/* transient: caught SYNC */
-	EDMA_ERR_LNK_CTRL_TX_3	= (1 << 24),	/* transient: caught DMAT */
-	EDMA_ERR_LNK_CTRL_TX_4	= (1 << 25),	/* transient: FIS collision */
-
 	EDMA_ERR_LNK_DATA_TX	= (0x1f << 26),	/* link data tx error */
-
 	EDMA_ERR_TRANS_PROTO	= (1 << 31),	/* transport protocol error */
 	EDMA_ERR_OVERRUN_5	= (1 << 5),
 	EDMA_ERR_UNDERRUN_5	= (1 << 6),
-
-	EDMA_ERR_IRQ_TRANSIENT  = EDMA_ERR_LNK_CTRL_RX_0 |
-				  EDMA_ERR_LNK_CTRL_RX_1 |
-				  EDMA_ERR_LNK_CTRL_RX_3 |
-				  EDMA_ERR_LNK_CTRL_TX,
-
 	EDMA_EH_FREEZE		= EDMA_ERR_D_PAR |
 				  EDMA_ERR_PRD_PAR |
 				  EDMA_ERR_DEV_DCON |
@@ -371,7 +262,6 @@
 				  EDMA_ERR_LNK_DATA_RX |
 				  EDMA_ERR_LNK_DATA_TX |
 				  EDMA_ERR_TRANS_PROTO,
-
 	EDMA_EH_FREEZE_5	= EDMA_ERR_D_PAR |
 				  EDMA_ERR_PRD_PAR |
 				  EDMA_ERR_DEV_DCON |
@@ -384,67 +274,44 @@
 				  EDMA_ERR_INTRL_PAR |
 				  EDMA_ERR_IORDY,
 
-	EDMA_REQ_Q_BASE_HI	= 0x10,
-	EDMA_REQ_Q_IN_PTR	= 0x14,		/* also contains BASE_LO */
+	EDMA_REQ_Q_BASE_HI_OFS	= 0x10,
+	EDMA_REQ_Q_IN_PTR_OFS	= 0x14,		/* also contains BASE_LO */
 
-	EDMA_REQ_Q_OUT_PTR	= 0x18,
+	EDMA_REQ_Q_OUT_PTR_OFS	= 0x18,
 	EDMA_REQ_Q_PTR_SHIFT	= 5,
 
-	EDMA_RSP_Q_BASE_HI	= 0x1c,
-	EDMA_RSP_Q_IN_PTR	= 0x20,
-	EDMA_RSP_Q_OUT_PTR	= 0x24,		/* also contains BASE_LO */
+	EDMA_RSP_Q_BASE_HI_OFS	= 0x1c,
+	EDMA_RSP_Q_IN_PTR_OFS	= 0x20,
+	EDMA_RSP_Q_OUT_PTR_OFS	= 0x24,		/* also contains BASE_LO */
 	EDMA_RSP_Q_PTR_SHIFT	= 3,
 
-	EDMA_CMD		= 0x28,		/* EDMA command register */
+	EDMA_CMD_OFS		= 0x28,		/* EDMA command register */
 	EDMA_EN			= (1 << 0),	/* enable EDMA */
 	EDMA_DS			= (1 << 1),	/* disable EDMA; self-negated */
-	EDMA_RESET		= (1 << 2),	/* reset eng/trans/link/phy */
-
-	EDMA_STATUS		= 0x30,		/* EDMA engine status */
-	EDMA_STATUS_CACHE_EMPTY	= (1 << 6),	/* GenIIe command cache empty */
-	EDMA_STATUS_IDLE	= (1 << 7),	/* GenIIe EDMA enabled/idle */
+	ATA_RST			= (1 << 2),	/* reset trans/link/phy */
 
 	EDMA_IORDY_TMOUT	= 0x34,
 	EDMA_ARB_CFG		= 0x38,
 
-	EDMA_HALTCOND		= 0x60,		/* GenIIe halt conditions */
-	EDMA_UNKNOWN_RSVD	= 0x6C,		/* GenIIe unknown/reserved */
-
-	BMDMA_CMD		= 0x224,	/* bmdma command register */
-	BMDMA_STATUS		= 0x228,	/* bmdma status register */
-	BMDMA_PRD_LOW		= 0x22c,	/* bmdma PRD addr 31:0 */
-	BMDMA_PRD_HIGH		= 0x230,	/* bmdma PRD addr 63:32 */
-
 	/* Host private flags (hp_flags) */
 	MV_HP_FLAG_MSI		= (1 << 0),
 	MV_HP_ERRATA_50XXB0	= (1 << 1),
 	MV_HP_ERRATA_50XXB2	= (1 << 2),
 	MV_HP_ERRATA_60X1B2	= (1 << 3),
 	MV_HP_ERRATA_60X1C0	= (1 << 4),
+	MV_HP_ERRATA_XX42A0	= (1 << 5),
 	MV_HP_GEN_I		= (1 << 6),	/* Generation I: 50xx */
 	MV_HP_GEN_II		= (1 << 7),	/* Generation II: 60xx */
 	MV_HP_GEN_IIE		= (1 << 8),	/* Generation IIE: 6042/7042 */
-	MV_HP_PCIE		= (1 << 9),	/* PCIe bus/regs: 7042 */
-	MV_HP_CUT_THROUGH	= (1 << 10),	/* can use EDMA cut-through */
-	MV_HP_FLAG_SOC		= (1 << 11),	/* SystemOnChip, no PCI */
-	MV_HP_QUIRK_LED_BLINK_EN = (1 << 12),	/* is led blinking enabled? */
 
 	/* Port private flags (pp_flags) */
 	MV_PP_FLAG_EDMA_EN	= (1 << 0),	/* is EDMA engine enabled? */
-	MV_PP_FLAG_NCQ_EN	= (1 << 1),	/* is EDMA set up for NCQ? */
-	MV_PP_FLAG_FBS_EN	= (1 << 2),	/* is EDMA set up for FBS? */
-	MV_PP_FLAG_DELAYED_EH	= (1 << 3),	/* delayed dev err handling */
-	MV_PP_FLAG_FAKE_ATA_BUSY = (1 << 4),	/* ignore initial ATA_DRDY */
+	MV_PP_FLAG_HAD_A_RESET	= (1 << 2),	/* 1st hard reset complete? */
 };
 
 #define IS_GEN_I(hpriv) ((hpriv)->hp_flags & MV_HP_GEN_I)
 #define IS_GEN_II(hpriv) ((hpriv)->hp_flags & MV_HP_GEN_II)
 #define IS_GEN_IIE(hpriv) ((hpriv)->hp_flags & MV_HP_GEN_IIE)
-#define IS_PCIE(hpriv) ((hpriv)->hp_flags & MV_HP_PCIE)
-#define IS_SOC(hpriv) ((hpriv)->hp_flags & MV_HP_FLAG_SOC)
-
-#define WINDOW_CTRL(i)		(0x20030 + ((i) << 4))
-#define WINDOW_BASE(i)		(0x20034 + ((i) << 4))
 
 enum {
 	/* DMA boundary 0xffff is required by the s/g splitting
@@ -469,7 +336,6 @@
 	chip_608x,
 	chip_6042,
 	chip_7042,
-	chip_soc,
 };
 
 /* Command ReQuest Block: 32B */
@@ -503,32 +369,18 @@
 	__le32			reserved;
 };
 
-/*
- * We keep a local cache of a few frequently accessed port
- * registers here, to avoid having to read them (very slow)
- * when switching between EDMA and non-EDMA modes.
- */
-struct mv_cached_regs {
-	u32			fiscfg;
-	u32			ltmode;
-	u32			haltcond;
-	u32			unknown_rsvd;
-};
-
 struct mv_port_priv {
 	struct mv_crqb		*crqb;
 	dma_addr_t		crqb_dma;
 	struct mv_crpb		*crpb;
 	dma_addr_t		crpb_dma;
-	struct mv_sg		*sg_tbl[MV_MAX_Q_DEPTH];
-	dma_addr_t		sg_tbl_dma[MV_MAX_Q_DEPTH];
+	struct mv_sg		*sg_tbl;
+	dma_addr_t		sg_tbl_dma;
 
 	unsigned int		req_idx;
 	unsigned int		resp_idx;
 
 	u32			pp_flags;
-	struct mv_cached_regs	cached;
-	unsigned int		delayed_eh_pmp_map;
 };
 
 struct mv_port_signal {
@@ -536,28 +388,7 @@
 	u32			pre;
 };
 
-struct mv_host_priv {
-	u32			hp_flags;
-	u32			main_irq_mask;
-	struct mv_port_signal	signal[8];
-	const struct mv_hw_ops	*ops;
-	int			n_ports;
-	void __iomem		*base;
-	void __iomem		*main_irq_cause_addr;
-	void __iomem		*main_irq_mask_addr;
-	u32			irq_cause_offset;
-	u32			irq_mask_offset;
-	u32			unmask_all_irqs;
-	/*
-	 * These consistent DMA memory pools give us guaranteed
-	 * alignment for hardware-accessed data structures,
-	 * and less memory waste in accomplishing the alignment.
-	 */
-	struct dma_pool		*crqb_pool;
-	struct dma_pool		*crpb_pool;
-	struct dma_pool		*sg_tbl_pool;
-};
-
+struct mv_host_priv;
 struct mv_hw_ops {
 	void (*phy_errata)(struct mv_host_priv *hpriv, void __iomem *mmio,
 			   unsigned int port);
@@ -567,24 +398,31 @@
 	int (*reset_hc)(struct mv_host_priv *hpriv, void __iomem *mmio,
 			unsigned int n_hc);
 	void (*reset_flash)(struct mv_host_priv *hpriv, void __iomem *mmio);
-	void (*reset_bus)(struct ata_host *host, void __iomem *mmio);
+	void (*reset_bus)(struct pci_dev *pdev, void __iomem *mmio);
+};
+
+struct mv_host_priv {
+	u32			hp_flags;
+	struct mv_port_signal	signal[8];
+	const struct mv_hw_ops	*ops;
 };
 
-static int mv_scr_read(struct ata_link *link, unsigned int sc_reg_in, u32 *val);
-static int mv_scr_write(struct ata_link *link, unsigned int sc_reg_in, u32 val);
-static int mv5_scr_read(struct ata_link *link, unsigned int sc_reg_in, u32 *val);
-static int mv5_scr_write(struct ata_link *link, unsigned int sc_reg_in, u32 val);
+static void mv_irq_clear(struct ata_port *ap);
+static int mv_scr_read(struct ata_port *ap, unsigned int sc_reg_in, u32 *val);
+static int mv_scr_write(struct ata_port *ap, unsigned int sc_reg_in, u32 val);
+static int mv5_scr_read(struct ata_port *ap, unsigned int sc_reg_in, u32 *val);
+static int mv5_scr_write(struct ata_port *ap, unsigned int sc_reg_in, u32 val);
 static int mv_port_start(struct ata_port *ap);
 static void mv_port_stop(struct ata_port *ap);
-static int mv_qc_defer(struct ata_queued_cmd *qc);
 static void mv_qc_prep(struct ata_queued_cmd *qc);
 static void mv_qc_prep_iie(struct ata_queued_cmd *qc);
 static unsigned int mv_qc_issue(struct ata_queued_cmd *qc);
-static int mv_hardreset(struct ata_link *link, unsigned int *class,
-			unsigned long deadline);
+static void mv_error_handler(struct ata_port *ap);
+static void mv_post_int_cmd(struct ata_queued_cmd *qc);
 static void mv_eh_freeze(struct ata_port *ap);
 static void mv_eh_thaw(struct ata_port *ap);
-static void mv6_dev_config(struct ata_device *dev);
+static int mv_slave_config(struct scsi_device *sdev);
+static int mv_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
 
 static void mv5_phy_errata(struct mv_host_priv *hpriv, void __iomem *mmio,
 			   unsigned int port);
@@ -594,7 +432,7 @@
 static int mv5_reset_hc(struct mv_host_priv *hpriv, void __iomem *mmio,
 			unsigned int n_hc);
 static void mv5_reset_flash(struct mv_host_priv *hpriv, void __iomem *mmio);
-static void mv5_reset_bus(struct ata_host *host, void __iomem *mmio);
+static void mv5_reset_bus(struct pci_dev *pdev, void __iomem *mmio);
 
 static void mv6_phy_errata(struct mv_host_priv *hpriv, void __iomem *mmio,
 			   unsigned int port);
@@ -604,72 +442,69 @@
 static int mv6_reset_hc(struct mv_host_priv *hpriv, void __iomem *mmio,
 			unsigned int n_hc);
 static void mv6_reset_flash(struct mv_host_priv *hpriv, void __iomem *mmio);
-static void mv_soc_enable_leds(struct mv_host_priv *hpriv,
-				      void __iomem *mmio);
-static void mv_soc_read_preamp(struct mv_host_priv *hpriv, int idx,
-				      void __iomem *mmio);
-static int mv_soc_reset_hc(struct mv_host_priv *hpriv,
-				  void __iomem *mmio, unsigned int n_hc);
-static void mv_soc_reset_flash(struct mv_host_priv *hpriv,
-				      void __iomem *mmio);
-static void mv_soc_reset_bus(struct ata_host *host, void __iomem *mmio);
-static void mv_soc_65n_phy_errata(struct mv_host_priv *hpriv,
-				  void __iomem *mmio, unsigned int port);
-static void mv_reset_pci_bus(struct ata_host *host, void __iomem *mmio);
-static void mv_reset_channel(struct mv_host_priv *hpriv, void __iomem *mmio,
+static void mv_reset_pci_bus(struct pci_dev *pdev, void __iomem *mmio);
+static void mv_channel_reset(struct mv_host_priv *hpriv, void __iomem *mmio,
 			     unsigned int port_no);
-static int mv_stop_edma(struct ata_port *ap);
-static int mv_stop_edma_engine(void __iomem *port_mmio);
-static void mv_edma_cfg(struct ata_port *ap, int want_ncq, int want_edma);
-
-static void mv_pmp_select(struct ata_port *ap, int pmp);
-static int mv_pmp_hardreset(struct ata_link *link, unsigned int *class,
-				unsigned long deadline);
-static int  mv_softreset(struct ata_link *link, unsigned int *class,
-				unsigned long deadline);
-static void mv_pmp_error_handler(struct ata_port *ap);
-static void mv_process_crpb_entries(struct ata_port *ap,
-					struct mv_port_priv *pp);
-
-static void mv_sff_irq_clear(struct ata_port *ap);
-static int mv_check_atapi_dma(struct ata_queued_cmd *qc);
-static void mv_bmdma_setup(struct ata_queued_cmd *qc);
-static void mv_bmdma_start(struct ata_queued_cmd *qc);
-static void mv_bmdma_stop(struct ata_queued_cmd *qc);
-static u8   mv_bmdma_status(struct ata_port *ap);
-static u8 mv_sff_check_status(struct ata_port *ap);
-
-/* .sg_tablesize is (MV_MAX_SG_CT / 2) in the structures below
- * because we have to allow room for worst case splitting of
- * PRDs for 64K boundaries in mv_fill_sg().
- */
+
 static struct scsi_host_template mv5_sht = {
-	ATA_BASE_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= MV_MAX_SG_CT / 2,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= 1,
+	.proc_name		= DRV_NAME,
 	.dma_boundary		= MV_DMA_BOUNDARY,
+	.slave_configure	= mv_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct scsi_host_template mv6_sht = {
-	ATA_NCQ_SHT(DRV_NAME),
-	.can_queue		= MV_MAX_Q_DEPTH - 1,
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= MV_MAX_SG_CT / 2,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= 1,
+	.proc_name		= DRV_NAME,
 	.dma_boundary		= MV_DMA_BOUNDARY,
+	.slave_configure	= mv_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations mv5_ops = {
-	.inherits		= &ata_sff_port_ops,
+static const struct ata_port_operations mv5_ops = {
+	.port_disable		= ata_port_disable,
 
-	.lost_interrupt		= ATA_OP_NULL,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.cable_detect		= ata_cable_sata,
 
-	.qc_defer		= mv_qc_defer,
 	.qc_prep		= mv_qc_prep,
 	.qc_issue		= mv_qc_issue,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_clear		= mv_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 
+	.error_handler		= mv_error_handler,
+	.post_internal_cmd	= mv_post_int_cmd,
 	.freeze			= mv_eh_freeze,
 	.thaw			= mv_eh_thaw,
-	.hardreset		= mv_hardreset,
-	.error_handler		= ata_std_error_handler, /* avoid SFF EH */
-	.post_internal_cmd	= ATA_OP_NULL,
 
 	.scr_read		= mv5_scr_read,
 	.scr_write		= mv5_scr_write,
@@ -678,78 +513,109 @@
 	.port_stop		= mv_port_stop,
 };
 
-static struct ata_port_operations mv6_ops = {
-	.inherits		= &mv5_ops,
-	.dev_config             = mv6_dev_config,
+static const struct ata_port_operations mv6_ops = {
+	.port_disable		= ata_port_disable,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.cable_detect		= ata_cable_sata,
+
+	.qc_prep		= mv_qc_prep,
+	.qc_issue		= mv_qc_issue,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_clear		= mv_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.error_handler		= mv_error_handler,
+	.post_internal_cmd	= mv_post_int_cmd,
+	.freeze			= mv_eh_freeze,
+	.thaw			= mv_eh_thaw,
+
 	.scr_read		= mv_scr_read,
 	.scr_write		= mv_scr_write,
 
-	.pmp_hardreset		= mv_pmp_hardreset,
-	.pmp_softreset		= mv_softreset,
-	.softreset		= mv_softreset,
-	.error_handler		= mv_pmp_error_handler,
-
-	.sff_check_status	= mv_sff_check_status,
-	.sff_irq_clear		= mv_sff_irq_clear,
-	.check_atapi_dma	= mv_check_atapi_dma,
-	.bmdma_setup		= mv_bmdma_setup,
-	.bmdma_start		= mv_bmdma_start,
-	.bmdma_stop		= mv_bmdma_stop,
-	.bmdma_status		= mv_bmdma_status,
+	.port_start		= mv_port_start,
+	.port_stop		= mv_port_stop,
 };
 
-static struct ata_port_operations mv_iie_ops = {
-	.inherits		= &mv6_ops,
-	.dev_config		= ATA_OP_NULL,
+static const struct ata_port_operations mv_iie_ops = {
+	.port_disable		= ata_port_disable,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.cable_detect		= ata_cable_sata,
+
 	.qc_prep		= mv_qc_prep_iie,
+	.qc_issue		= mv_qc_issue,
+	.data_xfer		= ata_data_xfer,
+
+	.irq_clear		= mv_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.error_handler		= mv_error_handler,
+	.post_internal_cmd	= mv_post_int_cmd,
+	.freeze			= mv_eh_freeze,
+	.thaw			= mv_eh_thaw,
+
+	.scr_read		= mv_scr_read,
+	.scr_write		= mv_scr_write,
+
+	.port_start		= mv_port_start,
+	.port_stop		= mv_port_stop,
 };
 
 static const struct ata_port_info mv_port_info[] = {
 	{  /* chip_504x */
-		.flags		= MV_GEN_I_FLAGS,
-		.pio_mask	= ATA_PIO4,
+		.flags		= MV_COMMON_FLAGS,
+		.pio_mask	= 0x1f,	/* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &mv5_ops,
 	},
 	{  /* chip_508x */
-		.flags		= MV_GEN_I_FLAGS | MV_FLAG_DUAL_HC,
-		.pio_mask	= ATA_PIO4,
+		.flags		= MV_COMMON_FLAGS | MV_FLAG_DUAL_HC,
+		.pio_mask	= 0x1f,	/* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &mv5_ops,
 	},
 	{  /* chip_5080 */
-		.flags		= MV_GEN_I_FLAGS | MV_FLAG_DUAL_HC,
-		.pio_mask	= ATA_PIO4,
+		.flags		= MV_COMMON_FLAGS | MV_FLAG_DUAL_HC,
+		.pio_mask	= 0x1f,	/* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &mv5_ops,
 	},
 	{  /* chip_604x */
-		.flags		= MV_GEN_II_FLAGS,
-		.pio_mask	= ATA_PIO4,
+		.flags		= MV_COMMON_FLAGS | MV_6XXX_FLAGS,
+		.pio_mask	= 0x1f,	/* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &mv6_ops,
 	},
 	{  /* chip_608x */
-		.flags		= MV_GEN_II_FLAGS | MV_FLAG_DUAL_HC,
-		.pio_mask	= ATA_PIO4,
+		.flags		= MV_COMMON_FLAGS | MV_6XXX_FLAGS |
+				  MV_FLAG_DUAL_HC,
+		.pio_mask	= 0x1f,	/* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &mv6_ops,
 	},
 	{  /* chip_6042 */
-		.flags		= MV_GEN_IIE_FLAGS,
-		.pio_mask	= ATA_PIO4,
+		.flags		= MV_COMMON_FLAGS | MV_6XXX_FLAGS,
+		.pio_mask	= 0x1f,	/* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &mv_iie_ops,
 	},
 	{  /* chip_7042 */
-		.flags		= MV_GEN_IIE_FLAGS,
-		.pio_mask	= ATA_PIO4,
-		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &mv_iie_ops,
-	},
-	{  /* chip_soc */
-		.flags		= MV_GEN_IIE_FLAGS,
-		.pio_mask	= ATA_PIO4,
+		.flags		= MV_COMMON_FLAGS | MV_6XXX_FLAGS,
+		.pio_mask	= 0x1f,	/* pio0-4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &mv_iie_ops,
 	},
@@ -760,10 +626,9 @@
 	{ PCI_VDEVICE(MARVELL, 0x5041), chip_504x },
 	{ PCI_VDEVICE(MARVELL, 0x5080), chip_5080 },
 	{ PCI_VDEVICE(MARVELL, 0x5081), chip_508x },
-	/* RocketRAID 1720/174x have different identifiers */
-	{ PCI_VDEVICE(TTI, 0x1720), chip_6042 },
-	{ PCI_VDEVICE(TTI, 0x1740), chip_6042 },
-	{ PCI_VDEVICE(TTI, 0x1742), chip_6042 },
+	/* RocketRAID 1740/174x have different identifiers */
+	{ PCI_VDEVICE(TTI, 0x1740), chip_508x },
+	{ PCI_VDEVICE(TTI, 0x1742), chip_508x },
 
 	{ PCI_VDEVICE(MARVELL, 0x6040), chip_604x },
 	{ PCI_VDEVICE(MARVELL, 0x6041), chip_604x },
@@ -776,16 +641,21 @@
 	/* Adaptec 1430SA */
 	{ PCI_VDEVICE(ADAPTEC2, 0x0243), chip_7042 },
 
-	/* Marvell 7042 support */
-	{ PCI_VDEVICE(MARVELL, 0x7042), chip_7042 },
-
-	/* Highpoint RocketRAID PCIe series */
-	{ PCI_VDEVICE(TTI, 0x2300), chip_7042 },
 	{ PCI_VDEVICE(TTI, 0x2310), chip_7042 },
 
+	/* add Marvell 7042 support */
+	{ PCI_VDEVICE(MARVELL, 0x7042), chip_7042 },
+
 	{ }			/* terminate list */
 };
 
+static struct pci_driver mv_pci_driver = {
+	.name			= DRV_NAME,
+	.id_table		= mv_pci_tbl,
+	.probe			= mv_init_one,
+	.remove			= ata_pci_remove_one,
+};
+
 static const struct mv_hw_ops mv5xxx_ops = {
 	.phy_errata		= mv5_phy_errata,
 	.enable_leds		= mv5_enable_leds,
@@ -804,22 +674,44 @@
 	.reset_bus		= mv_reset_pci_bus,
 };
 
-static const struct mv_hw_ops mv_soc_ops = {
-	.phy_errata		= mv6_phy_errata,
-	.enable_leds		= mv_soc_enable_leds,
-	.read_preamp		= mv_soc_read_preamp,
-	.reset_hc		= mv_soc_reset_hc,
-	.reset_flash		= mv_soc_reset_flash,
-	.reset_bus		= mv_soc_reset_bus,
-};
+/*
+ * module options
+ */
+static int msi;	      /* Use PCI msi; either zero (off, default) or non-zero */
 
-static const struct mv_hw_ops mv_soc_65n_ops = {
-	.phy_errata		= mv_soc_65n_phy_errata,
-	.enable_leds		= mv_soc_enable_leds,
-	.reset_hc		= mv_soc_reset_hc,
-	.reset_flash		= mv_soc_reset_flash,
-	.reset_bus		= mv_soc_reset_bus,
-};
+
+/* move to PCI layer or libata core? */
+static int pci_go_64(struct pci_dev *pdev)
+{
+	int rc;
+
+	if (!pci_set_dma_mask(pdev, DMA_64BIT_MASK)) {
+		rc = pci_set_consistent_dma_mask(pdev, DMA_64BIT_MASK);
+		if (rc) {
+			rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
+			if (rc) {
+				dev_printk(KERN_ERR, &pdev->dev,
+					   "64-bit DMA enable failed\n");
+				return rc;
+			}
+		}
+	} else {
+		rc = pci_set_dma_mask(pdev, DMA_32BIT_MASK);
+		if (rc) {
+			dev_printk(KERN_ERR, &pdev->dev,
+				   "32-bit DMA enable failed\n");
+			return rc;
+		}
+		rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
+		if (rc) {
+			dev_printk(KERN_ERR, &pdev->dev,
+				   "32-bit consistent DMA enable failed\n");
+			return rc;
+		}
+	}
+
+	return rc;
+}
 
 /*
  * Functions
@@ -831,6 +723,11 @@
 	(void) readl(addr);	/* flush to avoid PCI posted write */
 }
 
+static inline void __iomem *mv_hc_base(void __iomem *base, unsigned int hc)
+{
+	return (base + MV_SATAHC0_REG_BASE + (hc * MV_SATAHC_REG_SZ));
+}
+
 static inline unsigned int mv_hc_from_port(unsigned int port)
 {
 	return port >> MV_PORT_HC_SHIFT;
@@ -841,29 +738,6 @@
 	return port & MV_PORT_MASK;
 }
 
-/*
- * Consolidate some rather tricky bit shift calculations.
- * This is hot-path stuff, so not a function.
- * Simple code, with two return values, so macro rather than inline.
- *
- * port is the sole input, in range 0..7.
- * shift is one output, for use with main_irq_cause / main_irq_mask registers.
- * hardport is the other output, in range 0..3.
- *
- * Note that port and hardport may be the same variable in some cases.
- */
-#define MV_PORT_TO_SHIFT_AND_HARDPORT(port, shift, hardport)	\
-{								\
-	shift    = mv_hc_from_port(port) * HC_SHIFT;		\
-	hardport = mv_hardport_from_port(port);			\
-	shift   += hardport * 2;				\
-}
-
-static inline void __iomem *mv_hc_base(void __iomem *base, unsigned int hc)
-{
-	return (base + SATAHC0_REG_BASE + (hc * MV_SATAHC_REG_SZ));
-}
-
 static inline void __iomem *mv_hc_base_from_port(void __iomem *base,
 						 unsigned int port)
 {
@@ -877,23 +751,9 @@
 		(mv_hardport_from_port(port) * MV_PORT_REG_SZ);
 }
 
-static void __iomem *mv5_phy_base(void __iomem *mmio, unsigned int port)
-{
-	void __iomem *hc_mmio = mv_hc_base_from_port(mmio, port);
-	unsigned long ofs = (mv_hardport_from_port(port) + 1) * 0x100UL;
-
-	return hc_mmio + ofs;
-}
-
-static inline void __iomem *mv_host_base(struct ata_host *host)
-{
-	struct mv_host_priv *hpriv = host->private_data;
-	return hpriv->base;
-}
-
 static inline void __iomem *mv_ap_base(struct ata_port *ap)
 {
-	return mv_port_base(mv_host_base(ap->host), ap->port_no);
+	return mv_port_base(ap->host->iomap[MV_PRIMARY_BAR], ap->port_no);
 }
 
 static inline int mv_get_hc_count(unsigned long port_flags)
@@ -901,60 +761,19 @@
 	return ((port_flags & MV_FLAG_DUAL_HC) ? 2 : 1);
 }
 
-/**
- *      mv_save_cached_regs - (re-)initialize cached port registers
- *      @ap: the port whose registers we are caching
- *
- *	Initialize the local cache of port registers,
- *	so that reading them over and over again can
- *	be avoided on the hotter paths of this driver.
- *	This saves a few microseconds each time we switch
- *	to/from EDMA mode to perform (eg.) a drive cache flush.
- */
-static void mv_save_cached_regs(struct ata_port *ap)
+static void mv_irq_clear(struct ata_port *ap)
 {
-	void __iomem *port_mmio = mv_ap_base(ap);
-	struct mv_port_priv *pp = ap->private_data;
-
-	pp->cached.fiscfg = readl(port_mmio + FISCFG);
-	pp->cached.ltmode = readl(port_mmio + LTMODE);
-	pp->cached.haltcond = readl(port_mmio + EDMA_HALTCOND);
-	pp->cached.unknown_rsvd = readl(port_mmio + EDMA_UNKNOWN_RSVD);
 }
 
-/**
- *      mv_write_cached_reg - write to a cached port register
- *      @addr: hardware address of the register
- *      @old: pointer to cached value of the register
- *      @new: new value for the register
- *
- *	Write a new value to a cached register,
- *	but only if the value is different from before.
- */
-static inline void mv_write_cached_reg(void __iomem *addr, u32 *old, u32 new)
+static int mv_slave_config(struct scsi_device *sdev)
 {
-	if (new != *old) {
-		unsigned long laddr;
-		*old = new;
-		/*
-		 * Workaround for 88SX60x1-B2 FEr SATA#13:
-		 * Read-after-write is needed to prevent generating 64-bit
-		 * write cycles on the PCI bus for SATA interface registers
-		 * at offsets ending in 0x4 or 0xc.
-		 *
-		 * Looks like a lot of fuss, but it avoids an unnecessary
-		 * +1 usec read-after-write delay for unaffected registers.
-		 */
-		laddr = (long)addr & 0xffff;
-		if (laddr >= 0x300 && laddr <= 0x33c) {
-			laddr &= 0x000f;
-			if (laddr == 0x4 || laddr == 0xc) {
-				writelfl(new, addr); /* read after write */
-				return;
-			}
-		}
-		writel(new, addr); /* unaffected by the errata */
-	}
+	int rc = ata_scsi_slave_config(sdev);
+	if (rc)
+		return rc;
+
+	blk_queue_max_phys_segments(sdev->request_queue, MV_MAX_SG_CT / 2);
+
+	return 0;	/* scsi layer doesn't check return value, sigh */
 }
 
 static void mv_set_edma_ptrs(void __iomem *port_mmio,
@@ -966,160 +785,39 @@
 	/*
 	 * initialize request queue
 	 */
-	pp->req_idx &= MV_MAX_Q_DEPTH_MASK;	/* paranoia */
-	index = pp->req_idx << EDMA_REQ_Q_PTR_SHIFT;
+	index = (pp->req_idx & MV_MAX_Q_DEPTH_MASK) << EDMA_REQ_Q_PTR_SHIFT;
 
 	WARN_ON(pp->crqb_dma & 0x3ff);
-	writel((pp->crqb_dma >> 16) >> 16, port_mmio + EDMA_REQ_Q_BASE_HI);
+	writel((pp->crqb_dma >> 16) >> 16, port_mmio + EDMA_REQ_Q_BASE_HI_OFS);
 	writelfl((pp->crqb_dma & EDMA_REQ_Q_BASE_LO_MASK) | index,
-		 port_mmio + EDMA_REQ_Q_IN_PTR);
-	writelfl(index, port_mmio + EDMA_REQ_Q_OUT_PTR);
+		 port_mmio + EDMA_REQ_Q_IN_PTR_OFS);
+
+	if (hpriv->hp_flags & MV_HP_ERRATA_XX42A0)
+		writelfl((pp->crqb_dma & 0xffffffff) | index,
+			 port_mmio + EDMA_REQ_Q_OUT_PTR_OFS);
+	else
+		writelfl(index, port_mmio + EDMA_REQ_Q_OUT_PTR_OFS);
 
 	/*
 	 * initialize response queue
 	 */
-	pp->resp_idx &= MV_MAX_Q_DEPTH_MASK;	/* paranoia */
-	index = pp->resp_idx << EDMA_RSP_Q_PTR_SHIFT;
+	index = (pp->resp_idx & MV_MAX_Q_DEPTH_MASK) << EDMA_RSP_Q_PTR_SHIFT;
 
 	WARN_ON(pp->crpb_dma & 0xff);
-	writel((pp->crpb_dma >> 16) >> 16, port_mmio + EDMA_RSP_Q_BASE_HI);
-	writelfl(index, port_mmio + EDMA_RSP_Q_IN_PTR);
-	writelfl((pp->crpb_dma & EDMA_RSP_Q_BASE_LO_MASK) | index,
-		 port_mmio + EDMA_RSP_Q_OUT_PTR);
-}
-
-static void mv_write_main_irq_mask(u32 mask, struct mv_host_priv *hpriv)
-{
-	/*
-	 * When writing to the main_irq_mask in hardware,
-	 * we must ensure exclusivity between the interrupt coalescing bits
-	 * and the corresponding individual port DONE_IRQ bits.
-	 *
-	 * Note that this register is really an "IRQ enable" register,
-	 * not an "IRQ mask" register as Marvell's naming might suggest.
-	 */
-	if (mask & (ALL_PORTS_COAL_DONE | PORTS_0_3_COAL_DONE))
-		mask &= ~DONE_IRQ_0_3;
-	if (mask & (ALL_PORTS_COAL_DONE | PORTS_4_7_COAL_DONE))
-		mask &= ~DONE_IRQ_4_7;
-	writelfl(mask, hpriv->main_irq_mask_addr);
-}
-
-static void mv_set_main_irq_mask(struct ata_host *host,
-				 u32 disable_bits, u32 enable_bits)
-{
-	struct mv_host_priv *hpriv = host->private_data;
-	u32 old_mask, new_mask;
-
-	old_mask = hpriv->main_irq_mask;
-	new_mask = (old_mask & ~disable_bits) | enable_bits;
-	if (new_mask != old_mask) {
-		hpriv->main_irq_mask = new_mask;
-		mv_write_main_irq_mask(new_mask, hpriv);
-	}
-}
-
-static void mv_enable_port_irqs(struct ata_port *ap,
-				     unsigned int port_bits)
-{
-	unsigned int shift, hardport, port = ap->port_no;
-	u32 disable_bits, enable_bits;
-
-	MV_PORT_TO_SHIFT_AND_HARDPORT(port, shift, hardport);
-
-	disable_bits = (DONE_IRQ | ERR_IRQ) << shift;
-	enable_bits  = port_bits << shift;
-	mv_set_main_irq_mask(ap->host, disable_bits, enable_bits);
-}
-
-static void mv_clear_and_enable_port_irqs(struct ata_port *ap,
-					  void __iomem *port_mmio,
-					  unsigned int port_irqs)
-{
-	struct mv_host_priv *hpriv = ap->host->private_data;
-	int hardport = mv_hardport_from_port(ap->port_no);
-	void __iomem *hc_mmio = mv_hc_base_from_port(
-				mv_host_base(ap->host), ap->port_no);
-	u32 hc_irq_cause;
-
-	/* clear EDMA event indicators, if any */
-	writelfl(0, port_mmio + EDMA_ERR_IRQ_CAUSE);
-
-	/* clear pending irq events */
-	hc_irq_cause = ~((DEV_IRQ | DMA_IRQ) << hardport);
-	writelfl(hc_irq_cause, hc_mmio + HC_IRQ_CAUSE);
-
-	/* clear FIS IRQ Cause */
-	if (IS_GEN_IIE(hpriv))
-		writelfl(0, port_mmio + FIS_IRQ_CAUSE);
-
-	mv_enable_port_irqs(ap, port_irqs);
-}
-
-static void mv_set_irq_coalescing(struct ata_host *host,
-				  unsigned int count, unsigned int usecs)
-{
-	struct mv_host_priv *hpriv = host->private_data;
-	void __iomem *mmio = hpriv->base, *hc_mmio;
-	u32 coal_enable = 0;
-	unsigned long flags;
-	unsigned int clks, is_dual_hc = hpriv->n_ports > MV_PORTS_PER_HC;
-	const u32 coal_disable = PORTS_0_3_COAL_DONE | PORTS_4_7_COAL_DONE |
-							ALL_PORTS_COAL_DONE;
-
-	/* Disable IRQ coalescing if either threshold is zero */
-	if (!usecs || !count) {
-		clks = count = 0;
-	} else {
-		/* Respect maximum limits of the hardware */
-		clks = usecs * COAL_CLOCKS_PER_USEC;
-		if (clks > MAX_COAL_TIME_THRESHOLD)
-			clks = MAX_COAL_TIME_THRESHOLD;
-		if (count > MAX_COAL_IO_COUNT)
-			count = MAX_COAL_IO_COUNT;
-	}
-
-	spin_lock_irqsave(&host->lock, flags);
-	mv_set_main_irq_mask(host, coal_disable, 0);
-
-	if (is_dual_hc && !IS_GEN_I(hpriv)) {
-		/*
-		 * GEN_II/GEN_IIE with dual host controllers:
-		 * one set of global thresholds for the entire chip.
-		 */
-		writel(clks,  mmio + IRQ_COAL_TIME_THRESHOLD);
-		writel(count, mmio + IRQ_COAL_IO_THRESHOLD);
-		/* clear leftover coal IRQ bit */
-		writel(~ALL_PORTS_COAL_IRQ, mmio + IRQ_COAL_CAUSE);
-		if (count)
-			coal_enable = ALL_PORTS_COAL_DONE;
-		clks = count = 0; /* force clearing of regular regs below */
-	}
+	writel((pp->crpb_dma >> 16) >> 16, port_mmio + EDMA_RSP_Q_BASE_HI_OFS);
 
-	/*
-	 * All chips: independent thresholds for each HC on the chip.
-	 */
-	hc_mmio = mv_hc_base_from_port(mmio, 0);
-	writel(clks,  hc_mmio + HC_IRQ_COAL_TIME_THRESHOLD);
-	writel(count, hc_mmio + HC_IRQ_COAL_IO_THRESHOLD);
-	writel(~HC_COAL_IRQ, hc_mmio + HC_IRQ_CAUSE);
-	if (count)
-		coal_enable |= PORTS_0_3_COAL_DONE;
-	if (is_dual_hc) {
-		hc_mmio = mv_hc_base_from_port(mmio, MV_PORTS_PER_HC);
-		writel(clks,  hc_mmio + HC_IRQ_COAL_TIME_THRESHOLD);
-		writel(count, hc_mmio + HC_IRQ_COAL_IO_THRESHOLD);
-		writel(~HC_COAL_IRQ, hc_mmio + HC_IRQ_CAUSE);
-		if (count)
-			coal_enable |= PORTS_4_7_COAL_DONE;
-	}
+	if (hpriv->hp_flags & MV_HP_ERRATA_XX42A0)
+		writelfl((pp->crpb_dma & 0xffffffff) | index,
+			 port_mmio + EDMA_RSP_Q_IN_PTR_OFS);
+	else
+		writelfl(index, port_mmio + EDMA_RSP_Q_IN_PTR_OFS);
 
-	mv_set_main_irq_mask(host, 0, coal_enable);
-	spin_unlock_irqrestore(&host->lock, flags);
+	writelfl((pp->crpb_dma & EDMA_RSP_Q_BASE_LO_MASK) | index,
+		 port_mmio + EDMA_RSP_Q_OUT_PTR_OFS);
 }
 
 /**
- *      mv_start_edma - Enable eDMA engine
+ *      mv_start_dma - Enable eDMA engine
  *      @base: port base address
  *      @pp: port private data
  *
@@ -1129,94 +827,76 @@
  *      LOCKING:
  *      Inherited from caller.
  */
-static void mv_start_edma(struct ata_port *ap, void __iomem *port_mmio,
-			 struct mv_port_priv *pp, u8 protocol)
+static void mv_start_dma(void __iomem *base, struct mv_host_priv *hpriv,
+			 struct mv_port_priv *pp)
 {
-	int want_ncq = (protocol == ATA_PROT_NCQ);
-
-	if (pp->pp_flags & MV_PP_FLAG_EDMA_EN) {
-		int using_ncq = ((pp->pp_flags & MV_PP_FLAG_NCQ_EN) != 0);
-		if (want_ncq != using_ncq)
-			mv_stop_edma(ap);
-	}
 	if (!(pp->pp_flags & MV_PP_FLAG_EDMA_EN)) {
-		struct mv_host_priv *hpriv = ap->host->private_data;
+		/* clear EDMA event indicators, if any */
+		writelfl(0, base + EDMA_ERR_IRQ_CAUSE_OFS);
 
-		mv_edma_cfg(ap, want_ncq, 1);
+		mv_set_edma_ptrs(base, hpriv, pp);
 
-		mv_set_edma_ptrs(port_mmio, hpriv, pp);
-		mv_clear_and_enable_port_irqs(ap, port_mmio, DONE_IRQ|ERR_IRQ);
-
-		writelfl(EDMA_EN, port_mmio + EDMA_CMD);
+		writelfl(EDMA_EN, base + EDMA_CMD_OFS);
 		pp->pp_flags |= MV_PP_FLAG_EDMA_EN;
 	}
-}
-
-static void mv_wait_for_edma_empty_idle(struct ata_port *ap)
-{
-	void __iomem *port_mmio = mv_ap_base(ap);
-	const u32 empty_idle = (EDMA_STATUS_CACHE_EMPTY | EDMA_STATUS_IDLE);
-	const int per_loop = 5, timeout = (15 * 1000 / per_loop);
-	int i;
-
-	/*
-	 * Wait for the EDMA engine to finish transactions in progress.
-	 * No idea what a good "timeout" value might be, but measurements
-	 * indicate that it often requires hundreds of microseconds
-	 * with two drives in-use.  So we use the 15msec value above
-	 * as a rough guess at what even more drives might require.
-	 */
-	for (i = 0; i < timeout; ++i) {
-		u32 edma_stat = readl(port_mmio + EDMA_STATUS);
-		if ((edma_stat & empty_idle) == empty_idle)
-			break;
-		udelay(per_loop);
-	}
-	/* ata_port_printk(ap, KERN_INFO, "%s: %u+ usecs\n", __func__, i); */
+	WARN_ON(!(EDMA_EN & readl(base + EDMA_CMD_OFS)));
 }
 
 /**
- *      mv_stop_edma_engine - Disable eDMA engine
- *      @port_mmio: io base address
+ *      __mv_stop_dma - Disable eDMA engine
+ *      @ap: ATA channel to manipulate
+ *
+ *      Verify the local cache of the eDMA state is accurate with a
+ *      WARN_ON.
  *
  *      LOCKING:
  *      Inherited from caller.
  */
-static int mv_stop_edma_engine(void __iomem *port_mmio)
+static int __mv_stop_dma(struct ata_port *ap)
 {
-	int i;
+	void __iomem *port_mmio = mv_ap_base(ap);
+	struct mv_port_priv *pp	= ap->private_data;
+	u32 reg;
+	int i, err = 0;
 
-	/* Disable eDMA.  The disable bit auto clears. */
-	writelfl(EDMA_DS, port_mmio + EDMA_CMD);
+	if (pp->pp_flags & MV_PP_FLAG_EDMA_EN) {
+		/* Disable EDMA if active.   The disable bit auto clears.
+		 */
+		writelfl(EDMA_DS, port_mmio + EDMA_CMD_OFS);
+		pp->pp_flags &= ~MV_PP_FLAG_EDMA_EN;
+	} else {
+		WARN_ON(EDMA_EN & readl(port_mmio + EDMA_CMD_OFS));
+  	}
 
-	/* Wait for the chip to confirm eDMA is off. */
-	for (i = 10000; i > 0; i--) {
-		u32 reg = readl(port_mmio + EDMA_CMD);
+	/* now properly wait for the eDMA to stop */
+	for (i = 1000; i > 0; i--) {
+		reg = readl(port_mmio + EDMA_CMD_OFS);
 		if (!(reg & EDMA_EN))
-			return 0;
-		udelay(10);
-	}
-	return -EIO;
-}
+			break;
 
-static int mv_stop_edma(struct ata_port *ap)
-{
-	void __iomem *port_mmio = mv_ap_base(ap);
-	struct mv_port_priv *pp = ap->private_data;
-	int err = 0;
+		udelay(100);
+	}
 
-	if (!(pp->pp_flags & MV_PP_FLAG_EDMA_EN))
-		return 0;
-	pp->pp_flags &= ~MV_PP_FLAG_EDMA_EN;
-	mv_wait_for_edma_empty_idle(ap);
-	if (mv_stop_edma_engine(port_mmio)) {
+	if (reg & EDMA_EN) {
 		ata_port_printk(ap, KERN_ERR, "Unable to stop eDMA\n");
 		err = -EIO;
 	}
-	mv_edma_cfg(ap, 0, 0);
+
 	return err;
 }
 
+static int mv_stop_dma(struct ata_port *ap)
+{
+	unsigned long flags;
+	int rc;
+
+	spin_lock_irqsave(&ap->host->lock, flags);
+	rc = __mv_stop_dma(ap);
+	spin_unlock_irqrestore(&ap->host->lock, flags);
+
+	return rc;
+}
+
 #ifdef ATA_DEBUG
 static void mv_dump_mem(void __iomem *start, unsigned bytes)
 {
@@ -1224,7 +904,7 @@
 	for (b = 0; b < bytes; ) {
 		DPRINTK("%p: ", start + b);
 		for (w = 0; b < bytes && w < 4; w++) {
-			printk("%08x ", readl(start + b));
+			printk("%08x ",readl(start + b));
 			b += sizeof(u32);
 		}
 		printk("\n");
@@ -1240,8 +920,8 @@
 	for (b = 0; b < bytes; ) {
 		DPRINTK("%02x: ", b);
 		for (w = 0; b < bytes && w < 4; w++) {
-			(void) pci_read_config_dword(pdev, b, &dw);
-			printk("%08x ", dw);
+			(void) pci_read_config_dword(pdev,b,&dw);
+			printk("%08x ",dw);
 			b += sizeof(u32);
 		}
 		printk("\n");
@@ -1285,9 +965,9 @@
 	}
 	for (p = start_port; p < start_port + num_ports; p++) {
 		port_base = mv_port_base(mmio_base, p);
-		DPRINTK("EDMA regs (port %i):\n", p);
+		DPRINTK("EDMA regs (port %i):\n",p);
 		mv_dump_mem(port_base, 0x54);
-		DPRINTK("SATA regs (port %i):\n", p);
+		DPRINTK("SATA regs (port %i):\n",p);
 		mv_dump_mem(port_base+0x300, 0x60);
 	}
 #endif
@@ -1301,10 +981,10 @@
 	case SCR_STATUS:
 	case SCR_CONTROL:
 	case SCR_ERROR:
-		ofs = SATA_STATUS + (sc_reg_in * sizeof(u32));
+		ofs = SATA_STATUS_OFS + (sc_reg_in * sizeof(u32));
 		break;
 	case SCR_ACTIVE:
-		ofs = SATA_ACTIVE;   /* active is not with the others */
+		ofs = SATA_ACTIVE_OFS;   /* active is not with the others */
 		break;
 	default:
 		ofs = 0xffffffffU;
@@ -1313,333 +993,58 @@
 	return ofs;
 }
 
-static int mv_scr_read(struct ata_link *link, unsigned int sc_reg_in, u32 *val)
+static int mv_scr_read(struct ata_port *ap, unsigned int sc_reg_in, u32 *val)
 {
 	unsigned int ofs = mv_scr_offset(sc_reg_in);
 
 	if (ofs != 0xffffffffU) {
-		*val = readl(mv_ap_base(link->ap) + ofs);
+		*val = readl(mv_ap_base(ap) + ofs);
 		return 0;
 	} else
 		return -EINVAL;
 }
 
-static int mv_scr_write(struct ata_link *link, unsigned int sc_reg_in, u32 val)
+static int mv_scr_write(struct ata_port *ap, unsigned int sc_reg_in, u32 val)
 {
 	unsigned int ofs = mv_scr_offset(sc_reg_in);
 
 	if (ofs != 0xffffffffU) {
-		void __iomem *addr = mv_ap_base(link->ap) + ofs;
-		if (sc_reg_in == SCR_CONTROL) {
-			/*
-			 * Workaround for 88SX60x1 FEr SATA#26:
-			 *
-			 * COMRESETs have to take care not to accidently
-			 * put the drive to sleep when writing SCR_CONTROL.
-			 * Setting bits 12..15 prevents this problem.
-			 *
-			 * So if we see an outbound COMMRESET, set those bits.
-			 * Ditto for the followup write that clears the reset.
-			 *
-			 * The proprietary driver does this for
-			 * all chip versions, and so do we.
-			 */
-			if ((val & 0xf) == 1 || (readl(addr) & 0xf) == 1)
-				val |= 0xf000;
-		}
-		writelfl(val, addr);
+		writelfl(val, mv_ap_base(ap) + ofs);
 		return 0;
 	} else
 		return -EINVAL;
 }
 
-static void mv6_dev_config(struct ata_device *adev)
-{
-	/*
-	 * Deal with Gen-II ("mv6") hardware quirks/restrictions:
-	 *
-	 * Gen-II does not support NCQ over a port multiplier
-	 *  (no FIS-based switching).
-	 */
-	if (adev->flags & ATA_DFLAG_NCQ) {
-		if (sata_pmp_attached(adev->link->ap)) {
-			adev->flags &= ~ATA_DFLAG_NCQ;
-			ata_dev_printk(adev, KERN_INFO,
-				"NCQ disabled for command-based switching\n");
-		}
-	}
-}
-
-static int mv_qc_defer(struct ata_queued_cmd *qc)
-{
-	struct ata_link *link = qc->dev->link;
-	struct ata_port *ap = link->ap;
-	struct mv_port_priv *pp = ap->private_data;
-
-	/*
-	 * Don't allow new commands if we're in a delayed EH state
-	 * for NCQ and/or FIS-based switching.
-	 */
-	if (pp->pp_flags & MV_PP_FLAG_DELAYED_EH)
-		return ATA_DEFER_PORT;
-
-	/* PIO commands need exclusive link: no other commands [DMA or PIO]
-	 * can run concurrently.
-	 * set excl_link when we want to send a PIO command in DMA mode
-	 * or a non-NCQ command in NCQ mode.
-	 * When we receive a command from that link, and there are no
-	 * outstanding commands, mark a flag to clear excl_link and let
-	 * the command go through.
-	 */
-	if (unlikely(ap->excl_link)) {
-		if (link == ap->excl_link) {
-			if (ap->nr_active_links)
-				return ATA_DEFER_PORT;
-			qc->flags |= ATA_QCFLAG_CLEAR_EXCL;
-			return 0;
-		} else
-			return ATA_DEFER_PORT;
-	}
-
-	/*
-	 * If the port is completely idle, then allow the new qc.
-	 */
-	if (ap->nr_active_links == 0)
-		return 0;
-
-	/*
-	 * The port is operating in host queuing mode (EDMA) with NCQ
-	 * enabled, allow multiple NCQ commands.  EDMA also allows
-	 * queueing multiple DMA commands but libata core currently
-	 * doesn't allow it.
-	 */
-	if ((pp->pp_flags & MV_PP_FLAG_EDMA_EN) &&
-	    (pp->pp_flags & MV_PP_FLAG_NCQ_EN)) {
-		if (ata_is_ncq(qc->tf.protocol))
-			return 0;
-		else {
-			ap->excl_link = link;
-			return ATA_DEFER_PORT;
-		}
-	}
-
-	return ATA_DEFER_PORT;
-}
-
-static void mv_config_fbs(struct ata_port *ap, int want_ncq, int want_fbs)
-{
-	struct mv_port_priv *pp = ap->private_data;
-	void __iomem *port_mmio;
-
-	u32 fiscfg,   *old_fiscfg   = &pp->cached.fiscfg;
-	u32 ltmode,   *old_ltmode   = &pp->cached.ltmode;
-	u32 haltcond, *old_haltcond = &pp->cached.haltcond;
-
-	ltmode   = *old_ltmode & ~LTMODE_BIT8;
-	haltcond = *old_haltcond | EDMA_ERR_DEV;
-
-	if (want_fbs) {
-		fiscfg = *old_fiscfg | FISCFG_SINGLE_SYNC;
-		ltmode = *old_ltmode | LTMODE_BIT8;
-		if (want_ncq)
-			haltcond &= ~EDMA_ERR_DEV;
-		else
-			fiscfg |=  FISCFG_WAIT_DEV_ERR;
-	} else {
-		fiscfg = *old_fiscfg & ~(FISCFG_SINGLE_SYNC | FISCFG_WAIT_DEV_ERR);
-	}
-
-	port_mmio = mv_ap_base(ap);
-	mv_write_cached_reg(port_mmio + FISCFG, old_fiscfg, fiscfg);
-	mv_write_cached_reg(port_mmio + LTMODE, old_ltmode, ltmode);
-	mv_write_cached_reg(port_mmio + EDMA_HALTCOND, old_haltcond, haltcond);
-}
-
-static void mv_60x1_errata_sata25(struct ata_port *ap, int want_ncq)
-{
-	struct mv_host_priv *hpriv = ap->host->private_data;
-	u32 old, new;
-
-	/* workaround for 88SX60x1 FEr SATA#25 (part 1) */
-	old = readl(hpriv->base + GPIO_PORT_CTL);
-	if (want_ncq)
-		new = old | (1 << 22);
-	else
-		new = old & ~(1 << 22);
-	if (new != old)
-		writel(new, hpriv->base + GPIO_PORT_CTL);
-}
-
-/**
- *	mv_bmdma_enable - set a magic bit on GEN_IIE to allow bmdma
- *	@ap: Port being initialized
- *
- *	There are two DMA modes on these chips:  basic DMA, and EDMA.
- *
- *	Bit-0 of the "EDMA RESERVED" register enables/disables use
- *	of basic DMA on the GEN_IIE versions of the chips.
- *
- *	This bit survives EDMA resets, and must be set for basic DMA
- *	to function, and should be cleared when EDMA is active.
- */
-static void mv_bmdma_enable_iie(struct ata_port *ap, int enable_bmdma)
-{
-	struct mv_port_priv *pp = ap->private_data;
-	u32 new, *old = &pp->cached.unknown_rsvd;
-
-	if (enable_bmdma)
-		new = *old | 1;
-	else
-		new = *old & ~1;
-	mv_write_cached_reg(mv_ap_base(ap) + EDMA_UNKNOWN_RSVD, old, new);
-}
-
-/*
- * SOC chips have an issue whereby the HDD LEDs don't always blink
- * during I/O when NCQ is enabled. Enabling a special "LED blink" mode
- * of the SOC takes care of it, generating a steady blink rate when
- * any drive on the chip is active.
- *
- * Unfortunately, the blink mode is a global hardware setting for the SOC,
- * so we must use it whenever at least one port on the SOC has NCQ enabled.
- *
- * We turn "LED blink" off when NCQ is not in use anywhere, because the normal
- * LED operation works then, and provides better (more accurate) feedback.
- *
- * Note that this code assumes that an SOC never has more than one HC onboard.
- */
-static void mv_soc_led_blink_enable(struct ata_port *ap)
-{
-	struct ata_host *host = ap->host;
-	struct mv_host_priv *hpriv = host->private_data;
-	void __iomem *hc_mmio;
-	u32 led_ctrl;
-
-	if (hpriv->hp_flags & MV_HP_QUIRK_LED_BLINK_EN)
-		return;
-	hpriv->hp_flags |= MV_HP_QUIRK_LED_BLINK_EN;
-	hc_mmio = mv_hc_base_from_port(mv_host_base(host), ap->port_no);
-	led_ctrl = readl(hc_mmio + SOC_LED_CTRL);
-	writel(led_ctrl | SOC_LED_CTRL_BLINK, hc_mmio + SOC_LED_CTRL);
-}
-
-static void mv_soc_led_blink_disable(struct ata_port *ap)
-{
-	struct ata_host *host = ap->host;
-	struct mv_host_priv *hpriv = host->private_data;
-	void __iomem *hc_mmio;
-	u32 led_ctrl;
-	unsigned int port;
-
-	if (!(hpriv->hp_flags & MV_HP_QUIRK_LED_BLINK_EN))
-		return;
-
-	/* disable led-blink only if no ports are using NCQ */
-	for (port = 0; port < hpriv->n_ports; port++) {
-		struct ata_port *this_ap = host->ports[port];
-		struct mv_port_priv *pp = this_ap->private_data;
-
-		if (pp->pp_flags & MV_PP_FLAG_NCQ_EN)
-			return;
-	}
-
-	hpriv->hp_flags &= ~MV_HP_QUIRK_LED_BLINK_EN;
-	hc_mmio = mv_hc_base_from_port(mv_host_base(host), ap->port_no);
-	led_ctrl = readl(hc_mmio + SOC_LED_CTRL);
-	writel(led_ctrl & ~SOC_LED_CTRL_BLINK, hc_mmio + SOC_LED_CTRL);
-}
-
-static void mv_edma_cfg(struct ata_port *ap, int want_ncq, int want_edma)
+static void mv_edma_cfg(struct ata_port *ap, struct mv_host_priv *hpriv,
+			void __iomem *port_mmio)
 {
-	u32 cfg;
-	struct mv_port_priv *pp    = ap->private_data;
-	struct mv_host_priv *hpriv = ap->host->private_data;
-	void __iomem *port_mmio    = mv_ap_base(ap);
+	u32 cfg = readl(port_mmio + EDMA_CFG_OFS);
 
 	/* set up non-NCQ EDMA configuration */
-	cfg = EDMA_CFG_Q_DEPTH;		/* always 0x1f for *all* chips */
-	pp->pp_flags &=
-	  ~(MV_PP_FLAG_FBS_EN | MV_PP_FLAG_NCQ_EN | MV_PP_FLAG_FAKE_ATA_BUSY);
+	cfg &= ~(1 << 9);	/* disable eQue */
 
-	if (IS_GEN_I(hpriv))
+	if (IS_GEN_I(hpriv)) {
+		cfg &= ~0x1f;		/* clear queue depth */
 		cfg |= (1 << 8);	/* enab config burst size mask */
+	}
 
 	else if (IS_GEN_II(hpriv)) {
+		cfg &= ~0x1f;		/* clear queue depth */
 		cfg |= EDMA_CFG_RD_BRST_EXT | EDMA_CFG_WR_BUFF_LEN;
-		mv_60x1_errata_sata25(ap, want_ncq);
-
-	} else if (IS_GEN_IIE(hpriv)) {
-		int want_fbs = sata_pmp_attached(ap);
-		/*
-		 * Possible future enhancement:
-		 *
-		 * The chip can use FBS with non-NCQ, if we allow it,
-		 * But first we need to have the error handling in place
-		 * for this mode (datasheet section 7.3.15.4.2.3).
-		 * So disallow non-NCQ FBS for now.
-		 */
-		want_fbs &= want_ncq;
-
-		mv_config_fbs(ap, want_ncq, want_fbs);
-
-		if (want_fbs) {
-			pp->pp_flags |= MV_PP_FLAG_FBS_EN;
-			cfg |= EDMA_CFG_EDMA_FBS; /* FIS-based switching */
-		}
-
-		cfg |= (1 << 23);	/* do not mask PM field in rx'd FIS */
-		if (want_edma) {
-			cfg |= (1 << 22); /* enab 4-entry host queue cache */
-			if (!IS_SOC(hpriv))
-				cfg |= (1 << 18); /* enab early completion */
-		}
-		if (hpriv->hp_flags & MV_HP_CUT_THROUGH)
-			cfg |= (1 << 17); /* enab cut-thru (dis stor&forwrd) */
-		mv_bmdma_enable_iie(ap, !want_edma);
-
-		if (IS_SOC(hpriv)) {
-			if (want_ncq)
-				mv_soc_led_blink_enable(ap);
-			else
-				mv_soc_led_blink_disable(ap);
-		}
+		cfg &= ~(EDMA_CFG_NCQ | EDMA_CFG_NCQ_GO_ON_ERR); /* clear NCQ */
 	}
 
-	if (want_ncq) {
-		cfg |= EDMA_CFG_NCQ;
-		pp->pp_flags |=  MV_PP_FLAG_NCQ_EN;
+	else if (IS_GEN_IIE(hpriv)) {
+		cfg |= (1 << 23);	/* do not mask PM field in rx'd FIS */
+		cfg |= (1 << 22);	/* enab 4-entry host queue cache */
+		cfg &= ~(1 << 19);	/* dis 128-entry queue (for now?) */
+		cfg |= (1 << 18);	/* enab early completion */
+		cfg |= (1 << 17);	/* enab cut-through (dis stor&forwrd) */
+		cfg &= ~(1 << 16);	/* dis FIS-based switching (for now) */
+		cfg &= ~(EDMA_CFG_NCQ);	/* clear NCQ */
 	}
 
-	writelfl(cfg, port_mmio + EDMA_CFG);
-}
-
-static void mv_port_free_dma_mem(struct ata_port *ap)
-{
-	struct mv_host_priv *hpriv = ap->host->private_data;
-	struct mv_port_priv *pp = ap->private_data;
-	int tag;
-
-	if (pp->crqb) {
-		dma_pool_free(hpriv->crqb_pool, pp->crqb, pp->crqb_dma);
-		pp->crqb = NULL;
-	}
-	if (pp->crpb) {
-		dma_pool_free(hpriv->crpb_pool, pp->crpb, pp->crpb_dma);
-		pp->crpb = NULL;
-	}
-	/*
-	 * For GEN_I, there's no NCQ, so we have only a single sg_tbl.
-	 * For later hardware, we have one unique sg_tbl per NCQ tag.
-	 */
-	for (tag = 0; tag < MV_MAX_Q_DEPTH; ++tag) {
-		if (pp->sg_tbl[tag]) {
-			if (tag == 0 || !IS_GEN_I(hpriv))
-				dma_pool_free(hpriv->sg_tbl_pool,
-					      pp->sg_tbl[tag],
-					      pp->sg_tbl_dma[tag]);
-			pp->sg_tbl[tag] = NULL;
-		}
-	}
+	writelfl(cfg, port_mmio + EDMA_CFG_OFS);
 }
 
 /**
@@ -1657,53 +1062,62 @@
 	struct device *dev = ap->host->dev;
 	struct mv_host_priv *hpriv = ap->host->private_data;
 	struct mv_port_priv *pp;
+	void __iomem *port_mmio = mv_ap_base(ap);
+	void *mem;
+	dma_addr_t mem_dma;
 	unsigned long flags;
-	int tag;
+	int rc;
 
 	pp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);
 	if (!pp)
 		return -ENOMEM;
-	ap->private_data = pp;
 
-	pp->crqb = dma_pool_alloc(hpriv->crqb_pool, GFP_KERNEL, &pp->crqb_dma);
-	if (!pp->crqb)
+	mem = dmam_alloc_coherent(dev, MV_PORT_PRIV_DMA_SZ, &mem_dma,
+				  GFP_KERNEL);
+	if (!mem)
 		return -ENOMEM;
-	memset(pp->crqb, 0, MV_CRQB_Q_SZ);
+	memset(mem, 0, MV_PORT_PRIV_DMA_SZ);
 
-	pp->crpb = dma_pool_alloc(hpriv->crpb_pool, GFP_KERNEL, &pp->crpb_dma);
-	if (!pp->crpb)
-		goto out_port_free_dma_mem;
-	memset(pp->crpb, 0, MV_CRPB_Q_SZ);
-
-	/* 6041/6081 Rev. "C0" (and newer) are okay with async notify */
-	if (hpriv->hp_flags & MV_HP_ERRATA_60X1C0)
-		ap->flags |= ATA_FLAG_AN;
-	/*
-	 * For GEN_I, there's no NCQ, so we only allocate a single sg_tbl.
-	 * For later hardware, we need one unique sg_tbl per NCQ tag.
+	rc = ata_pad_alloc(ap, dev);
+	if (rc)
+		return rc;
+
+	/* First item in chunk of DMA memory:
+	 * 32-slot command request table (CRQB), 32 bytes each in size
 	 */
-	for (tag = 0; tag < MV_MAX_Q_DEPTH; ++tag) {
-		if (tag == 0 || !IS_GEN_I(hpriv)) {
-			pp->sg_tbl[tag] = dma_pool_alloc(hpriv->sg_tbl_pool,
-					      GFP_KERNEL, &pp->sg_tbl_dma[tag]);
-			if (!pp->sg_tbl[tag])
-				goto out_port_free_dma_mem;
-		} else {
-			pp->sg_tbl[tag]     = pp->sg_tbl[0];
-			pp->sg_tbl_dma[tag] = pp->sg_tbl_dma[0];
-		}
-	}
+	pp->crqb = mem;
+	pp->crqb_dma = mem_dma;
+	mem += MV_CRQB_Q_SZ;
+	mem_dma += MV_CRQB_Q_SZ;
 
-	spin_lock_irqsave(ap->lock, flags);
-	mv_save_cached_regs(ap);
-	mv_edma_cfg(ap, 0, 0);
-	spin_unlock_irqrestore(ap->lock, flags);
+	/* Second item:
+	 * 32-slot command response table (CRPB), 8 bytes each in size
+	 */
+	pp->crpb = mem;
+	pp->crpb_dma = mem_dma;
+	mem += MV_CRPB_Q_SZ;
+	mem_dma += MV_CRPB_Q_SZ;
 
-	return 0;
+	/* Third item:
+	 * Table of scatter-gather descriptors (ePRD), 16 bytes each
+	 */
+	pp->sg_tbl = mem;
+	pp->sg_tbl_dma = mem_dma;
+
+	spin_lock_irqsave(&ap->host->lock, flags);
+
+	mv_edma_cfg(ap, hpriv, port_mmio);
+
+	mv_set_edma_ptrs(port_mmio, hpriv, pp);
+
+	spin_unlock_irqrestore(&ap->host->lock, flags);
 
-out_port_free_dma_mem:
-	mv_port_free_dma_mem(ap);
-	return -ENOMEM;
+	/* Don't turn on EDMA here...do it before DMA commands only.  Else
+	 * we'll be unable to send non-data, PIO, etc due to restricted access
+	 * to shadow regs.
+	 */
+	ap->private_data = pp;
+	return 0;
 }
 
 /**
@@ -1717,13 +1131,7 @@
  */
 static void mv_port_stop(struct ata_port *ap)
 {
-	unsigned long flags;
-
-	spin_lock_irqsave(ap->lock, flags);
-	mv_stop_edma(ap);
-	mv_enable_port_irqs(ap, 0);
-	spin_unlock_irqrestore(ap->lock, flags);
-	mv_port_free_dma_mem(ap);
+	mv_stop_dma(ap);
 }
 
 /**
@@ -1739,11 +1147,10 @@
 {
 	struct mv_port_priv *pp = qc->ap->private_data;
 	struct scatterlist *sg;
-	struct mv_sg *mv_sg, *last_sg = NULL;
-	unsigned int si;
+	struct mv_sg *mv_sg;
 
-	mv_sg = pp->sg_tbl[qc->tag];
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
+	mv_sg = pp->sg_tbl;
+	ata_for_each_sg(sg, qc) {
 		dma_addr_t addr = sg_dma_address(sg);
 		u32 sg_len = sg_dma_len(sg);
 
@@ -1751,28 +1158,26 @@
 			u32 offset = addr & 0xffff;
 			u32 len = sg_len;
 
-			if (offset + len > 0x10000)
+			if ((offset + sg_len > 0x10000))
 				len = 0x10000 - offset;
 
 			mv_sg->addr = cpu_to_le32(addr & 0xffffffff);
 			mv_sg->addr_hi = cpu_to_le32((addr >> 16) >> 16);
 			mv_sg->flags_size = cpu_to_le32(len & 0xffff);
-			mv_sg->reserved = 0;
 
 			sg_len -= len;
 			addr += len;
 
-			last_sg = mv_sg;
+			if (!sg_len && ata_sg_is_last(sg, qc))
+				mv_sg->flags_size |= cpu_to_le32(EPRD_FLAG_END_OF_TBL);
+
 			mv_sg++;
 		}
-	}
 
-	if (likely(last_sg))
-		last_sg->flags_size |= cpu_to_le32(EPRD_FLAG_END_OF_TBL);
-	mb(); /* ensure data structure is visible to the chipset */
+	}
 }
 
-static void mv_crqb_pack_cmd(__le16 *cmdw, u8 data, u8 addr, unsigned last)
+static inline void mv_crqb_pack_cmd(__le16 *cmdw, u8 data, u8 addr, unsigned last)
 {
 	u16 tmp = data | (addr << CRQB_CMD_ADDR_SHIFT) | CRQB_CMD_CS |
 		(last ? CRQB_CMD_LAST : 0);
@@ -1780,199 +1185,6 @@
 }
 
 /**
- *	mv_sff_irq_clear - Clear hardware interrupt after DMA.
- *	@ap: Port associated with this ATA transaction.
- *
- *	We need this only for ATAPI bmdma transactions,
- *	as otherwise we experience spurious interrupts
- *	after libata-sff handles the bmdma interrupts.
- */
-static void mv_sff_irq_clear(struct ata_port *ap)
-{
-	mv_clear_and_enable_port_irqs(ap, mv_ap_base(ap), ERR_IRQ);
-}
-
-/**
- *	mv_check_atapi_dma - Filter ATAPI cmds which are unsuitable for DMA.
- *	@qc: queued command to check for chipset/DMA compatibility.
- *
- *	The bmdma engines cannot handle speculative data sizes
- *	(bytecount under/over flow).  So only allow DMA for
- *	data transfer commands with known data sizes.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static int mv_check_atapi_dma(struct ata_queued_cmd *qc)
-{
-	struct scsi_cmnd *scmd = qc->scsicmd;
-
-	if (scmd) {
-		switch (scmd->cmnd[0]) {
-		case READ_6:
-		case READ_10:
-		case READ_12:
-		case WRITE_6:
-		case WRITE_10:
-		case WRITE_12:
-		case GPCMD_READ_CD:
-		case GPCMD_SEND_DVD_STRUCTURE:
-		case GPCMD_SEND_CUE_SHEET:
-			return 0; /* DMA is safe */
-		}
-	}
-	return -EOPNOTSUPP; /* use PIO instead */
-}
-
-/**
- *	mv_bmdma_setup - Set up BMDMA transaction
- *	@qc: queued command to prepare DMA for.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static void mv_bmdma_setup(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	void __iomem *port_mmio = mv_ap_base(ap);
-	struct mv_port_priv *pp = ap->private_data;
-
-	mv_fill_sg(qc);
-
-	/* clear all DMA cmd bits */
-	writel(0, port_mmio + BMDMA_CMD);
-
-	/* load PRD table addr. */
-	writel((pp->sg_tbl_dma[qc->tag] >> 16) >> 16,
-		port_mmio + BMDMA_PRD_HIGH);
-	writelfl(pp->sg_tbl_dma[qc->tag],
-		port_mmio + BMDMA_PRD_LOW);
-
-	/* issue r/w command */
-	ap->ops->sff_exec_command(ap, &qc->tf);
-}
-
-/**
- *	mv_bmdma_start - Start a BMDMA transaction
- *	@qc: queued command to start DMA on.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static void mv_bmdma_start(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	void __iomem *port_mmio = mv_ap_base(ap);
-	unsigned int rw = (qc->tf.flags & ATA_TFLAG_WRITE);
-	u32 cmd = (rw ? 0 : ATA_DMA_WR) | ATA_DMA_START;
-
-	/* start host DMA transaction */
-	writelfl(cmd, port_mmio + BMDMA_CMD);
-}
-
-/**
- *	mv_bmdma_stop - Stop BMDMA transfer
- *	@qc: queued command to stop DMA on.
- *
- *	Clears the ATA_DMA_START flag in the bmdma control register
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static void mv_bmdma_stop_ap(struct ata_port *ap)
-{
-	void __iomem *port_mmio = mv_ap_base(ap);
-	u32 cmd;
-
-	/* clear start/stop bit */
-	cmd = readl(port_mmio + BMDMA_CMD);
-	if (cmd & ATA_DMA_START) {
-		cmd &= ~ATA_DMA_START;
-		writelfl(cmd, port_mmio + BMDMA_CMD);
-
-		/* one-PIO-cycle guaranteed wait, per spec, for HDMA1:0 transition */
-		ata_sff_dma_pause(ap);
-	}
-}
-
-static void mv_bmdma_stop(struct ata_queued_cmd *qc)
-{
-	mv_bmdma_stop_ap(qc->ap);
-}
-
-/**
- *	mv_bmdma_status - Read BMDMA status
- *	@ap: port for which to retrieve DMA status.
- *
- *	Read and return equivalent of the sff BMDMA status register.
- *
- *	LOCKING:
- *	Inherited from caller.
- */
-static u8 mv_bmdma_status(struct ata_port *ap)
-{
-	void __iomem *port_mmio = mv_ap_base(ap);
-	u32 reg, status;
-
-	/*
-	 * Other bits are valid only if ATA_DMA_ACTIVE==0,
-	 * and the ATA_DMA_INTR bit doesn't exist.
-	 */
-	reg = readl(port_mmio + BMDMA_STATUS);
-	if (reg & ATA_DMA_ACTIVE)
-		status = ATA_DMA_ACTIVE;
-	else if (reg & ATA_DMA_ERR)
-		status = (reg & ATA_DMA_ERR) | ATA_DMA_INTR;
-	else {
-		/*
-		 * Just because DMA_ACTIVE is 0 (DMA completed),
-		 * this does _not_ mean the device is "done".
-		 * So we should not yet be signalling ATA_DMA_INTR
-		 * in some cases.  Eg. DSM/TRIM, and perhaps others.
-		 */
-		mv_bmdma_stop_ap(ap);
-		if (ioread8(ap->ioaddr.altstatus_addr) & ATA_BUSY)
-			status = 0;
-		else
-			status = ATA_DMA_INTR;
-	}
-	return status;
-}
-
-static void mv_rw_multi_errata_sata24(struct ata_queued_cmd *qc)
-{
-	struct ata_taskfile *tf = &qc->tf;
-	/*
-	 * Workaround for 88SX60x1 FEr SATA#24.
-	 *
-	 * Chip may corrupt WRITEs if multi_count >= 4kB.
-	 * Note that READs are unaffected.
-	 *
-	 * It's not clear if this errata really means "4K bytes",
-	 * or if it always happens for multi_count > 7
-	 * regardless of device sector_size.
-	 *
-	 * So, for safety, any write with multi_count > 7
-	 * gets converted here into a regular PIO write instead:
-	 */
-	if ((tf->flags & ATA_TFLAG_WRITE) && is_multi_taskfile(tf)) {
-		if (qc->dev->multi_count > 7) {
-			switch (tf->command) {
-			case ATA_CMD_WRITE_MULTI:
-				tf->command = ATA_CMD_PIO_WRITE;
-				break;
-			case ATA_CMD_WRITE_MULTI_FUA_EXT:
-				tf->flags &= ~ATA_TFLAG_FUA; /* ugh */
-				/* fall through */
-			case ATA_CMD_WRITE_MULTI_EXT:
-				tf->command = ATA_CMD_PIO_WRITE_EXT;
-				break;
-			}
-		}
-	}
-}
-
-/**
  *      mv_qc_prep - Host specific command preparation.
  *      @qc: queued command to prepare
  *
@@ -1989,49 +1201,38 @@
 	struct ata_port *ap = qc->ap;
 	struct mv_port_priv *pp = ap->private_data;
 	__le16 *cw;
-	struct ata_taskfile *tf = &qc->tf;
+	struct ata_taskfile *tf;
 	u16 flags = 0;
 	unsigned in_index;
 
-	switch (tf->protocol) {
-	case ATA_PROT_DMA:
-		if (tf->command == ATA_CMD_DSM)
-			return;
-		/* fall-thru */
-	case ATA_PROT_NCQ:
-		break;	/* continue below */
-	case ATA_PROT_PIO:
-		mv_rw_multi_errata_sata24(qc);
-		return;
-	default:
+ 	if (qc->tf.protocol != ATA_PROT_DMA)
 		return;
-	}
 
 	/* Fill in command request block
 	 */
-	if (!(tf->flags & ATA_TFLAG_WRITE))
+	if (!(qc->tf.flags & ATA_TFLAG_WRITE))
 		flags |= CRQB_FLAG_READ;
 	WARN_ON(MV_MAX_Q_DEPTH <= qc->tag);
 	flags |= qc->tag << CRQB_TAG_SHIFT;
-	flags |= (qc->dev->link->pmp & 0xf) << CRQB_PMP_SHIFT;
+	flags |= qc->tag << CRQB_IOID_SHIFT;	/* 50xx appears to ignore this*/
 
 	/* get current queue index from software */
-	in_index = pp->req_idx;
+	in_index = pp->req_idx & MV_MAX_Q_DEPTH_MASK;
 
 	pp->crqb[in_index].sg_addr =
-		cpu_to_le32(pp->sg_tbl_dma[qc->tag] & 0xffffffff);
+		cpu_to_le32(pp->sg_tbl_dma & 0xffffffff);
 	pp->crqb[in_index].sg_addr_hi =
-		cpu_to_le32((pp->sg_tbl_dma[qc->tag] >> 16) >> 16);
+		cpu_to_le32((pp->sg_tbl_dma >> 16) >> 16);
 	pp->crqb[in_index].ctrl_flags = cpu_to_le16(flags);
 
 	cw = &pp->crqb[in_index].ata_cmd[0];
+	tf = &qc->tf;
 
 	/* Sadly, the CRQB cannot accomodate all registers--there are
 	 * only 11 bytes...so we must pick and choose required
 	 * registers based on the command.  So, we drop feature and
 	 * hob_feature for [RW] DMA commands, but they are needed for
-	 * NCQ.  NCQ will drop hob_nsect, which is not needed there
-	 * (nsect is used only for the tag; feat/hob_feat hold true nsect).
+	 * NCQ.  NCQ will drop hob_nsect.
 	 */
 	switch (tf->command) {
 	case ATA_CMD_READ:
@@ -2041,11 +1242,13 @@
 	case ATA_CMD_WRITE_FUA_EXT:
 		mv_crqb_pack_cmd(cw++, tf->hob_nsect, ATA_REG_NSECT, 0);
 		break;
+#ifdef LIBATA_NCQ		/* FIXME: remove this line when NCQ added */
 	case ATA_CMD_FPDMA_READ:
 	case ATA_CMD_FPDMA_WRITE:
 		mv_crqb_pack_cmd(cw++, tf->hob_feature, ATA_REG_FEATURE, 0);
 		mv_crqb_pack_cmd(cw++, tf->feature, ATA_REG_FEATURE, 0);
 		break;
+#endif				/* FIXME: remove this line when NCQ added */
 	default:
 		/* The only other commands EDMA supports in non-queued and
 		 * non-NCQ mode are: [RW] STREAM DMA and W DMA FUA EXT, none
@@ -2090,33 +1293,32 @@
 	struct ata_port *ap = qc->ap;
 	struct mv_port_priv *pp = ap->private_data;
 	struct mv_crqb_iie *crqb;
-	struct ata_taskfile *tf = &qc->tf;
+	struct ata_taskfile *tf;
 	unsigned in_index;
 	u32 flags = 0;
 
-	if ((tf->protocol != ATA_PROT_DMA) &&
-	    (tf->protocol != ATA_PROT_NCQ))
+ 	if (qc->tf.protocol != ATA_PROT_DMA)
 		return;
-	if (tf->command == ATA_CMD_DSM)
-		return;  /* use bmdma for this */
 
-	/* Fill in Gen IIE command request block */
-	if (!(tf->flags & ATA_TFLAG_WRITE))
+	/* Fill in Gen IIE command request block
+	 */
+	if (!(qc->tf.flags & ATA_TFLAG_WRITE))
 		flags |= CRQB_FLAG_READ;
 
 	WARN_ON(MV_MAX_Q_DEPTH <= qc->tag);
 	flags |= qc->tag << CRQB_TAG_SHIFT;
-	flags |= qc->tag << CRQB_HOSTQ_SHIFT;
-	flags |= (qc->dev->link->pmp & 0xf) << CRQB_PMP_SHIFT;
+	flags |= qc->tag << CRQB_IOID_SHIFT;	/* "I/O Id" is -really-
+						   what we use as our tag */
 
 	/* get current queue index from software */
-	in_index = pp->req_idx;
+	in_index = pp->req_idx & MV_MAX_Q_DEPTH_MASK;
 
 	crqb = (struct mv_crqb_iie *) &pp->crqb[in_index];
-	crqb->addr = cpu_to_le32(pp->sg_tbl_dma[qc->tag] & 0xffffffff);
-	crqb->addr_hi = cpu_to_le32((pp->sg_tbl_dma[qc->tag] >> 16) >> 16);
+	crqb->addr = cpu_to_le32(pp->sg_tbl_dma & 0xffffffff);
+	crqb->addr_hi = cpu_to_le32((pp->sg_tbl_dma >> 16) >> 16);
 	crqb->flags = cpu_to_le32(flags);
 
+	tf = &qc->tf;
 	crqb->ata_cmd[0] = cpu_to_le32(
 			(tf->command << 16) |
 			(tf->feature << 24)
@@ -2144,557 +1346,141 @@
 }
 
 /**
- *	mv_sff_check_status - fetch device status, if valid
- *	@ap: ATA port to fetch status from
- *
- *	When using command issue via mv_qc_issue_fis(),
- *	the initial ATA_BUSY state does not show up in the
- *	ATA status (shadow) register.  This can confuse libata!
+ *      mv_qc_issue - Initiate a command to the host
+ *      @qc: queued command to start
  *
- *	So we have a hook here to fake ATA_BUSY for that situation,
- *	until the first time a BUSY, DRQ, or ERR bit is seen.
+ *      This routine simply redirects to the general purpose routine
+ *      if command is not DMA.  Else, it sanity checks our local
+ *      caches of the request producer/consumer indices then enables
+ *      DMA and bumps the request producer index.
  *
- *	The rest of the time, it simply returns the ATA status register.
+ *      LOCKING:
+ *      Inherited from caller.
  */
-static u8 mv_sff_check_status(struct ata_port *ap)
+static unsigned int mv_qc_issue(struct ata_queued_cmd *qc)
 {
-	u8 stat = ioread8(ap->ioaddr.status_addr);
+	struct ata_port *ap = qc->ap;
+	void __iomem *port_mmio = mv_ap_base(ap);
 	struct mv_port_priv *pp = ap->private_data;
+	struct mv_host_priv *hpriv = ap->host->private_data;
+	u32 in_index;
 
-	if (pp->pp_flags & MV_PP_FLAG_FAKE_ATA_BUSY) {
-		if (stat & (ATA_BUSY | ATA_DRQ | ATA_ERR))
-			pp->pp_flags &= ~MV_PP_FLAG_FAKE_ATA_BUSY;
-		else
-			stat = ATA_BUSY;
+	if (qc->tf.protocol != ATA_PROT_DMA) {
+		/* We're about to send a non-EDMA capable command to the
+		 * port.  Turn off EDMA so there won't be problems accessing
+		 * shadow block, etc registers.
+		 */
+		__mv_stop_dma(ap);
+		return ata_qc_issue_prot(qc);
 	}
-	return stat;
-}
 
-/**
- *	mv_send_fis - Send a FIS, using the "Vendor-Unique FIS" register
- *	@fis: fis to be sent
- *	@nwords: number of 32-bit words in the fis
- */
-static unsigned int mv_send_fis(struct ata_port *ap, u32 *fis, int nwords)
-{
-	void __iomem *port_mmio = mv_ap_base(ap);
-	u32 ifctl, old_ifctl, ifstat;
-	int i, timeout = 200, final_word = nwords - 1;
+	mv_start_dma(port_mmio, hpriv, pp);
 
-	/* Initiate FIS transmission mode */
-	old_ifctl = readl(port_mmio + SATA_IFCTL);
-	ifctl = 0x100 | (old_ifctl & 0xf);
-	writelfl(ifctl, port_mmio + SATA_IFCTL);
-
-	/* Send all words of the FIS except for the final word */
-	for (i = 0; i < final_word; ++i)
-		writel(fis[i], port_mmio + VENDOR_UNIQUE_FIS);
-
-	/* Flag end-of-transmission, and then send the final word */
-	writelfl(ifctl | 0x200, port_mmio + SATA_IFCTL);
-	writelfl(fis[final_word], port_mmio + VENDOR_UNIQUE_FIS);
+	in_index = pp->req_idx & MV_MAX_Q_DEPTH_MASK;
 
-	/*
-	 * Wait for FIS transmission to complete.
-	 * This typically takes just a single iteration.
-	 */
-	do {
-		ifstat = readl(port_mmio + SATA_IFSTAT);
-	} while (!(ifstat & 0x1000) && --timeout);
+	/* until we do queuing, the queue should be empty at this point */
+	WARN_ON(in_index != ((readl(port_mmio + EDMA_REQ_Q_OUT_PTR_OFS)
+		>> EDMA_REQ_Q_PTR_SHIFT) & MV_MAX_Q_DEPTH_MASK));
 
-	/* Restore original port configuration */
-	writelfl(old_ifctl, port_mmio + SATA_IFCTL);
+	pp->req_idx++;
 
-	/* See if it worked */
-	if ((ifstat & 0x3000) != 0x1000) {
-		ata_port_printk(ap, KERN_WARNING,
-				"%s transmission error, ifstat=%08x\n",
-				__func__, ifstat);
-		return AC_ERR_OTHER;
-	}
-	return 0;
-}
+	in_index = (pp->req_idx & MV_MAX_Q_DEPTH_MASK) << EDMA_REQ_Q_PTR_SHIFT;
 
-/**
- *	mv_qc_issue_fis - Issue a command directly as a FIS
- *	@qc: queued command to start
- *
- *	Note that the ATA shadow registers are not updated
- *	after command issue, so the device will appear "READY"
- *	if polled, even while it is BUSY processing the command.
- *
- *	So we use a status hook to fake ATA_BUSY until the drive changes state.
- *
- *	Note: we don't get updated shadow regs on *completion*
- *	of non-data commands. So avoid sending them via this function,
- *	as they will appear to have completed immediately.
- *
- *	GEN_IIE has special registers that we could get the result tf from,
- *	but earlier chipsets do not.  For now, we ignore those registers.
- */
-static unsigned int mv_qc_issue_fis(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct mv_port_priv *pp = ap->private_data;
-	struct ata_link *link = qc->dev->link;
-	u32 fis[5];
-	int err = 0;
-
-	ata_tf_to_fis(&qc->tf, link->pmp, 1, (void *)fis);
-	err = mv_send_fis(ap, fis, sizeof(fis) / sizeof(fis[0]));
-	if (err)
-		return err;
-
-	switch (qc->tf.protocol) {
-	case ATAPI_PROT_PIO:
-		pp->pp_flags |= MV_PP_FLAG_FAKE_ATA_BUSY;
-		/* fall through */
-	case ATAPI_PROT_NODATA:
-		ap->hsm_task_state = HSM_ST_FIRST;
-		break;
-	case ATA_PROT_PIO:
-		pp->pp_flags |= MV_PP_FLAG_FAKE_ATA_BUSY;
-		if (qc->tf.flags & ATA_TFLAG_WRITE)
-			ap->hsm_task_state = HSM_ST_FIRST;
-		else
-			ap->hsm_task_state = HSM_ST;
-		break;
-	default:
-		ap->hsm_task_state = HSM_ST_LAST;
-		break;
-	}
+	/* and write the request in pointer to kick the EDMA to life */
+	writelfl((pp->crqb_dma & EDMA_REQ_Q_BASE_LO_MASK) | in_index,
+		 port_mmio + EDMA_REQ_Q_IN_PTR_OFS);
 
-	if (qc->tf.flags & ATA_TFLAG_POLLING)
-		ata_pio_queue_task(ap, qc, 0);
 	return 0;
 }
 
 /**
- *      mv_qc_issue - Initiate a command to the host
- *      @qc: queued command to start
- *
- *      This routine simply redirects to the general purpose routine
- *      if command is not DMA.  Else, it sanity checks our local
- *      caches of the request producer/consumer indices then enables
- *      DMA and bumps the request producer index.
- *
- *      LOCKING:
- *      Inherited from caller.
- */
-static unsigned int mv_qc_issue(struct ata_queued_cmd *qc)
-{
-	static int limit_warnings = 10;
-	struct ata_port *ap = qc->ap;
-	void __iomem *port_mmio = mv_ap_base(ap);
-	struct mv_port_priv *pp = ap->private_data;
-	u32 in_index;
-	unsigned int port_irqs;
-
-	pp->pp_flags &= ~MV_PP_FLAG_FAKE_ATA_BUSY; /* paranoia */
-
-	switch (qc->tf.protocol) {
-	case ATA_PROT_DMA:
-		if (qc->tf.command == ATA_CMD_DSM) {
-			if (!ap->ops->bmdma_setup)  /* no bmdma on GEN_I */
-				return AC_ERR_OTHER;
-			break;  /* use bmdma for this */
-		}
-		/* fall thru */
-	case ATA_PROT_NCQ:
-		mv_start_edma(ap, port_mmio, pp, qc->tf.protocol);
-		pp->req_idx = (pp->req_idx + 1) & MV_MAX_Q_DEPTH_MASK;
-		in_index = pp->req_idx << EDMA_REQ_Q_PTR_SHIFT;
-
-		/* Write the request in pointer to kick the EDMA to life */
-		writelfl((pp->crqb_dma & EDMA_REQ_Q_BASE_LO_MASK) | in_index,
-					port_mmio + EDMA_REQ_Q_IN_PTR);
-		return 0;
-
-	case ATA_PROT_PIO:
-		/*
-		 * Errata SATA#16, SATA#24: warn if multiple DRQs expected.
-		 *
-		 * Someday, we might implement special polling workarounds
-		 * for these, but it all seems rather unnecessary since we
-		 * normally use only DMA for commands which transfer more
-		 * than a single block of data.
-		 *
-		 * Much of the time, this could just work regardless.
-		 * So for now, just log the incident, and allow the attempt.
-		 */
-		if (limit_warnings > 0 && (qc->nbytes / qc->sect_size) > 1) {
-			--limit_warnings;
-			ata_link_printk(qc->dev->link, KERN_WARNING, DRV_NAME
-					": attempting PIO w/multiple DRQ: "
-					"this may fail due to h/w errata\n");
-		}
-		/* drop through */
-	case ATA_PROT_NODATA:
-	case ATAPI_PROT_PIO:
-	case ATAPI_PROT_NODATA:
-		if (ap->flags & ATA_FLAG_PIO_POLLING)
-			qc->tf.flags |= ATA_TFLAG_POLLING;
-		break;
-	}
-
-	if (qc->tf.flags & ATA_TFLAG_POLLING)
-		port_irqs = ERR_IRQ;	/* mask device interrupt when polling */
-	else
-		port_irqs = ERR_IRQ | DONE_IRQ;	/* unmask all interrupts */
-
-	/*
-	 * We're about to send a non-EDMA capable command to the
-	 * port.  Turn off EDMA so there won't be problems accessing
-	 * shadow block, etc registers.
-	 */
-	mv_stop_edma(ap);
-	mv_clear_and_enable_port_irqs(ap, mv_ap_base(ap), port_irqs);
-	mv_pmp_select(ap, qc->dev->link->pmp);
-
-	if (qc->tf.command == ATA_CMD_READ_LOG_EXT) {
-		struct mv_host_priv *hpriv = ap->host->private_data;
-		/*
-		 * Workaround for 88SX60x1 FEr SATA#25 (part 2).
-		 *
-		 * After any NCQ error, the READ_LOG_EXT command
-		 * from libata-eh *must* use mv_qc_issue_fis().
-		 * Otherwise it might fail, due to chip errata.
-		 *
-		 * Rather than special-case it, we'll just *always*
-		 * use this method here for READ_LOG_EXT, making for
-		 * easier testing.
-		 */
-		if (IS_GEN_II(hpriv))
-			return mv_qc_issue_fis(qc);
-	}
-	return ata_sff_qc_issue(qc);
-}
-
-static struct ata_queued_cmd *mv_get_active_qc(struct ata_port *ap)
-{
-	struct mv_port_priv *pp = ap->private_data;
-	struct ata_queued_cmd *qc;
-
-	if (pp->pp_flags & MV_PP_FLAG_NCQ_EN)
-		return NULL;
-	qc = ata_qc_from_tag(ap, ap->link.active_tag);
-	if (qc) {
-		if (qc->tf.flags & ATA_TFLAG_POLLING)
-			qc = NULL;
-		else if (!(qc->flags & ATA_QCFLAG_ACTIVE))
-			qc = NULL;
-	}
-	return qc;
-}
-
-static void mv_pmp_error_handler(struct ata_port *ap)
-{
-	unsigned int pmp, pmp_map;
-	struct mv_port_priv *pp = ap->private_data;
-
-	if (pp->pp_flags & MV_PP_FLAG_DELAYED_EH) {
-		/*
-		 * Perform NCQ error analysis on failed PMPs
-		 * before we freeze the port entirely.
-		 *
-		 * The failed PMPs are marked earlier by mv_pmp_eh_prep().
-		 */
-		pmp_map = pp->delayed_eh_pmp_map;
-		pp->pp_flags &= ~MV_PP_FLAG_DELAYED_EH;
-		for (pmp = 0; pmp_map != 0; pmp++) {
-			unsigned int this_pmp = (1 << pmp);
-			if (pmp_map & this_pmp) {
-				struct ata_link *link = &ap->pmp_link[pmp];
-				pmp_map &= ~this_pmp;
-				ata_eh_analyze_ncq_error(link);
-			}
-		}
-		ata_port_freeze(ap);
-	}
-	sata_pmp_error_handler(ap);
-}
-
-static unsigned int mv_get_err_pmp_map(struct ata_port *ap)
-{
-	void __iomem *port_mmio = mv_ap_base(ap);
-
-	return readl(port_mmio + SATA_TESTCTL) >> 16;
-}
-
-static void mv_pmp_eh_prep(struct ata_port *ap, unsigned int pmp_map)
-{
-	struct ata_eh_info *ehi;
-	unsigned int pmp;
-
-	/*
-	 * Initialize EH info for PMPs which saw device errors
-	 */
-	ehi = &ap->link.eh_info;
-	for (pmp = 0; pmp_map != 0; pmp++) {
-		unsigned int this_pmp = (1 << pmp);
-		if (pmp_map & this_pmp) {
-			struct ata_link *link = &ap->pmp_link[pmp];
-
-			pmp_map &= ~this_pmp;
-			ehi = &link->eh_info;
-			ata_ehi_clear_desc(ehi);
-			ata_ehi_push_desc(ehi, "dev err");
-			ehi->err_mask |= AC_ERR_DEV;
-			ehi->action |= ATA_EH_RESET;
-			ata_link_abort(link);
-		}
-	}
-}
-
-static int mv_req_q_empty(struct ata_port *ap)
-{
-	void __iomem *port_mmio = mv_ap_base(ap);
-	u32 in_ptr, out_ptr;
-
-	in_ptr  = (readl(port_mmio + EDMA_REQ_Q_IN_PTR)
-			>> EDMA_REQ_Q_PTR_SHIFT) & MV_MAX_Q_DEPTH_MASK;
-	out_ptr = (readl(port_mmio + EDMA_REQ_Q_OUT_PTR)
-			>> EDMA_REQ_Q_PTR_SHIFT) & MV_MAX_Q_DEPTH_MASK;
-	return (in_ptr == out_ptr);	/* 1 == queue_is_empty */
-}
-
-static int mv_handle_fbs_ncq_dev_err(struct ata_port *ap)
-{
-	struct mv_port_priv *pp = ap->private_data;
-	int failed_links;
-	unsigned int old_map, new_map;
-
-	/*
-	 * Device error during FBS+NCQ operation:
-	 *
-	 * Set a port flag to prevent further I/O being enqueued.
-	 * Leave the EDMA running to drain outstanding commands from this port.
-	 * Perform the post-mortem/EH only when all responses are complete.
-	 * Follow recovery sequence from 6042/7042 datasheet (7.3.15.4.2.2).
-	 */
-	if (!(pp->pp_flags & MV_PP_FLAG_DELAYED_EH)) {
-		pp->pp_flags |= MV_PP_FLAG_DELAYED_EH;
-		pp->delayed_eh_pmp_map = 0;
-	}
-	old_map = pp->delayed_eh_pmp_map;
-	new_map = old_map | mv_get_err_pmp_map(ap);
-
-	if (old_map != new_map) {
-		pp->delayed_eh_pmp_map = new_map;
-		mv_pmp_eh_prep(ap, new_map & ~old_map);
-	}
-	failed_links = hweight16(new_map);
-
-	ata_port_printk(ap, KERN_INFO, "%s: pmp_map=%04x qc_map=%04x "
-			"failed_links=%d nr_active_links=%d\n",
-			__func__, pp->delayed_eh_pmp_map,
-			ap->qc_active, failed_links,
-			ap->nr_active_links);
-
-	if (ap->nr_active_links <= failed_links && mv_req_q_empty(ap)) {
-		mv_process_crpb_entries(ap, pp);
-		mv_stop_edma(ap);
-		mv_eh_freeze(ap);
-		ata_port_printk(ap, KERN_INFO, "%s: done\n", __func__);
-		return 1;	/* handled */
-	}
-	ata_port_printk(ap, KERN_INFO, "%s: waiting\n", __func__);
-	return 1;	/* handled */
-}
-
-static int mv_handle_fbs_non_ncq_dev_err(struct ata_port *ap)
-{
-	/*
-	 * Possible future enhancement:
-	 *
-	 * FBS+non-NCQ operation is not yet implemented.
-	 * See related notes in mv_edma_cfg().
-	 *
-	 * Device error during FBS+non-NCQ operation:
-	 *
-	 * We need to snapshot the shadow registers for each failed command.
-	 * Follow recovery sequence from 6042/7042 datasheet (7.3.15.4.2.3).
-	 */
-	return 0;	/* not handled */
-}
-
-static int mv_handle_dev_err(struct ata_port *ap, u32 edma_err_cause)
-{
-	struct mv_port_priv *pp = ap->private_data;
-
-	if (!(pp->pp_flags & MV_PP_FLAG_EDMA_EN))
-		return 0;	/* EDMA was not active: not handled */
-	if (!(pp->pp_flags & MV_PP_FLAG_FBS_EN))
-		return 0;	/* FBS was not active: not handled */
-
-	if (!(edma_err_cause & EDMA_ERR_DEV))
-		return 0;	/* non DEV error: not handled */
-	edma_err_cause &= ~EDMA_ERR_IRQ_TRANSIENT;
-	if (edma_err_cause & ~(EDMA_ERR_DEV | EDMA_ERR_SELF_DIS))
-		return 0;	/* other problems: not handled */
-
-	if (pp->pp_flags & MV_PP_FLAG_NCQ_EN) {
-		/*
-		 * EDMA should NOT have self-disabled for this case.
-		 * If it did, then something is wrong elsewhere,
-		 * and we cannot handle it here.
-		 */
-		if (edma_err_cause & EDMA_ERR_SELF_DIS) {
-			ata_port_printk(ap, KERN_WARNING,
-				"%s: err_cause=0x%x pp_flags=0x%x\n",
-				__func__, edma_err_cause, pp->pp_flags);
-			return 0; /* not handled */
-		}
-		return mv_handle_fbs_ncq_dev_err(ap);
-	} else {
-		/*
-		 * EDMA should have self-disabled for this case.
-		 * If it did not, then something is wrong elsewhere,
-		 * and we cannot handle it here.
-		 */
-		if (!(edma_err_cause & EDMA_ERR_SELF_DIS)) {
-			ata_port_printk(ap, KERN_WARNING,
-				"%s: err_cause=0x%x pp_flags=0x%x\n",
-				__func__, edma_err_cause, pp->pp_flags);
-			return 0; /* not handled */
-		}
-		return mv_handle_fbs_non_ncq_dev_err(ap);
-	}
-	return 0;	/* not handled */
-}
-
-static void mv_unexpected_intr(struct ata_port *ap, int edma_was_enabled)
-{
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	char *when = "idle";
-
-	ata_ehi_clear_desc(ehi);
-	if (ap->flags & ATA_FLAG_DISABLED) {
-		when = "disabled";
-	} else if (edma_was_enabled) {
-		when = "EDMA enabled";
-	} else {
-		struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->link.active_tag);
-		if (qc && (qc->tf.flags & ATA_TFLAG_POLLING))
-			when = "polling";
-	}
-	ata_ehi_push_desc(ehi, "unexpected device interrupt while %s", when);
-	ehi->err_mask |= AC_ERR_OTHER;
-	ehi->action   |= ATA_EH_RESET;
-	ata_port_freeze(ap);
-}
-
-/**
  *      mv_err_intr - Handle error interrupts on the port
  *      @ap: ATA channel to manipulate
+ *      @reset_allowed: bool: 0 == don't trigger from reset here
  *
- *      Most cases require a full reset of the chip's state machine,
- *      which also performs a COMRESET.
- *      Also, if the port disabled DMA, update our cached copy to match.
+ *      In most cases, just clear the interrupt and move on.  However,
+ *      some cases require an eDMA reset, which is done right before
+ *      the COMRESET in mv_phy_reset().  The SERR case requires a
+ *      clear of pending errors in the SATA SERROR register.  Finally,
+ *      if the port disabled DMA, update our cached copy to match.
  *
  *      LOCKING:
  *      Inherited from caller.
  */
-static void mv_err_intr(struct ata_port *ap)
+static void mv_err_intr(struct ata_port *ap, struct ata_queued_cmd *qc)
 {
 	void __iomem *port_mmio = mv_ap_base(ap);
 	u32 edma_err_cause, eh_freeze_mask, serr = 0;
-	u32 fis_cause = 0;
 	struct mv_port_priv *pp = ap->private_data;
 	struct mv_host_priv *hpriv = ap->host->private_data;
+	unsigned int edma_enabled = (pp->pp_flags & MV_PP_FLAG_EDMA_EN);
 	unsigned int action = 0, err_mask = 0;
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	struct ata_queued_cmd *qc;
-	int abort = 0;
+	struct ata_eh_info *ehi = &ap->eh_info;
 
-	/*
-	 * Read and clear the SError and err_cause bits.
-	 * For GenIIe, if EDMA_ERR_TRANS_IRQ_7 is set, we also must read/clear
-	 * the FIS_IRQ_CAUSE register before clearing edma_err_cause.
-	 */
-	sata_scr_read(&ap->link, SCR_ERROR, &serr);
-	sata_scr_write_flush(&ap->link, SCR_ERROR, serr);
+	ata_ehi_clear_desc(ehi);
 
-	edma_err_cause = readl(port_mmio + EDMA_ERR_IRQ_CAUSE);
-	if (IS_GEN_IIE(hpriv) && (edma_err_cause & EDMA_ERR_TRANS_IRQ_7)) {
-		fis_cause = readl(port_mmio + FIS_IRQ_CAUSE);
-		writelfl(~fis_cause, port_mmio + FIS_IRQ_CAUSE);
-	}
-	writelfl(~edma_err_cause, port_mmio + EDMA_ERR_IRQ_CAUSE);
-
-	if (edma_err_cause & EDMA_ERR_DEV) {
-		/*
-		 * Device errors during FIS-based switching operation
-		 * require special handling.
+	if (!edma_enabled) {
+		/* just a guess: do we need to do this? should we
+		 * expand this, and do it in all cases?
 		 */
-		if (mv_handle_dev_err(ap, edma_err_cause))
-			return;
+		sata_scr_read(ap, SCR_ERROR, &serr);
+		sata_scr_write_flush(ap, SCR_ERROR, serr);
 	}
 
-	qc = mv_get_active_qc(ap);
-	ata_ehi_clear_desc(ehi);
-	ata_ehi_push_desc(ehi, "edma_err_cause=%08x pp_flags=%08x",
-			  edma_err_cause, pp->pp_flags);
+	edma_err_cause = readl(port_mmio + EDMA_ERR_IRQ_CAUSE_OFS);
+
+	ata_ehi_push_desc(ehi, "edma_err 0x%08x", edma_err_cause);
 
-	if (IS_GEN_IIE(hpriv) && (edma_err_cause & EDMA_ERR_TRANS_IRQ_7)) {
-		ata_ehi_push_desc(ehi, "fis_cause=%08x", fis_cause);
-		if (fis_cause & FIS_IRQ_CAUSE_AN) {
-			u32 ec = edma_err_cause &
-			       ~(EDMA_ERR_TRANS_IRQ_7 | EDMA_ERR_IRQ_TRANSIENT);
-			sata_async_notification(ap);
-			if (!ec)
-				return; /* Just an AN; no need for the nukes */
-			ata_ehi_push_desc(ehi, "SDB notify");
-		}
-	}
 	/*
-	 * All generations share these EDMA error cause bits:
+	 * all generations share these EDMA error cause bits
 	 */
-	if (edma_err_cause & EDMA_ERR_DEV) {
+
+	if (edma_err_cause & EDMA_ERR_DEV)
 		err_mask |= AC_ERR_DEV;
-		action |= ATA_EH_RESET;
-		ata_ehi_push_desc(ehi, "dev error");
-	}
 	if (edma_err_cause & (EDMA_ERR_D_PAR | EDMA_ERR_PRD_PAR |
 			EDMA_ERR_CRQB_PAR | EDMA_ERR_CRPB_PAR |
 			EDMA_ERR_INTRL_PAR)) {
 		err_mask |= AC_ERR_ATA_BUS;
-		action |= ATA_EH_RESET;
+		action |= ATA_EH_HARDRESET;
 		ata_ehi_push_desc(ehi, "parity error");
 	}
 	if (edma_err_cause & (EDMA_ERR_DEV_DCON | EDMA_ERR_DEV_CON)) {
 		ata_ehi_hotplugged(ehi);
 		ata_ehi_push_desc(ehi, edma_err_cause & EDMA_ERR_DEV_DCON ?
 			"dev disconnect" : "dev connect");
-		action |= ATA_EH_RESET;
 	}
 
-	/*
-	 * Gen-I has a different SELF_DIS bit,
-	 * different FREEZE bits, and no SERR bit:
-	 */
 	if (IS_GEN_I(hpriv)) {
 		eh_freeze_mask = EDMA_EH_FREEZE_5;
+
 		if (edma_err_cause & EDMA_ERR_SELF_DIS_5) {
+			struct mv_port_priv *pp	= ap->private_data;
 			pp->pp_flags &= ~MV_PP_FLAG_EDMA_EN;
 			ata_ehi_push_desc(ehi, "EDMA self-disable");
 		}
 	} else {
 		eh_freeze_mask = EDMA_EH_FREEZE;
+
 		if (edma_err_cause & EDMA_ERR_SELF_DIS) {
+			struct mv_port_priv *pp	= ap->private_data;
 			pp->pp_flags &= ~MV_PP_FLAG_EDMA_EN;
 			ata_ehi_push_desc(ehi, "EDMA self-disable");
 		}
+
 		if (edma_err_cause & EDMA_ERR_SERR) {
-			ata_ehi_push_desc(ehi, "SError=%08x", serr);
-			err_mask |= AC_ERR_ATA_BUS;
-			action |= ATA_EH_RESET;
+			sata_scr_read(ap, SCR_ERROR, &serr);
+			sata_scr_write_flush(ap, SCR_ERROR, serr);
+			err_mask = AC_ERR_ATA_BUS;
+			action |= ATA_EH_HARDRESET;
 		}
 	}
 
+	/* Clear EDMA now that SERR cleanup done */
+	writelfl(0, port_mmio + EDMA_ERR_IRQ_CAUSE_OFS);
+
 	if (!err_mask) {
 		err_mask = AC_ERR_OTHER;
-		action |= ATA_EH_RESET;
+		action |= ATA_EH_HARDRESET;
 	}
 
 	ehi->serror |= serr;
@@ -2705,222 +1491,191 @@
 	else
 		ehi->err_mask |= err_mask;
 
-	if (err_mask == AC_ERR_DEV) {
-		/*
-		 * Cannot do ata_port_freeze() here,
-		 * because it would kill PIO access,
-		 * which is needed for further diagnosis.
-		 */
-		mv_eh_freeze(ap);
-		abort = 1;
-	} else if (edma_err_cause & eh_freeze_mask) {
-		/*
-		 * Note to self: ata_port_freeze() calls ata_port_abort()
-		 */
+	if (edma_err_cause & eh_freeze_mask)
 		ata_port_freeze(ap);
-	} else {
-		abort = 1;
-	}
-
-	if (abort) {
-		if (qc)
-			ata_link_abort(qc->dev->link);
-		else
-			ata_port_abort(ap);
-	}
+	else
+		ata_port_abort(ap);
 }
 
-static void mv_process_crpb_response(struct ata_port *ap,
-		struct mv_crpb *response, unsigned int tag, int ncq_enabled)
+static void mv_intr_pio(struct ata_port *ap)
 {
-	struct ata_queued_cmd *qc = ata_qc_from_tag(ap, tag);
+	struct ata_queued_cmd *qc;
+	u8 ata_status;
 
-	if (qc) {
-		u8 ata_status;
-		u16 edma_status = le16_to_cpu(response->flags);
-		/*
-		 * edma_status from a response queue entry:
-		 *   LSB is from EDMA_ERR_IRQ_CAUSE (non-NCQ only).
-		 *   MSB is saved ATA status from command completion.
-		 */
-		if (!ncq_enabled) {
-			u8 err_cause = edma_status & 0xff & ~EDMA_ERR_DEV;
-			if (err_cause) {
-				/*
-				 * Error will be seen/handled by mv_err_intr().
-				 * So do nothing at all here.
-				 */
-				return;
-			}
-		}
-		ata_status = edma_status >> CRPB_FLAG_STATUS_SHIFT;
-		if (!ac_err_mask(ata_status))
-			ata_qc_complete(qc);
-		/* else: leave it for mv_err_intr() */
-	} else {
-		ata_port_printk(ap, KERN_ERR, "%s: no qc for tag=%d\n",
-				__func__, tag);
-	}
+	/* ignore spurious intr if drive still BUSY */
+	ata_status = readb(ap->ioaddr.status_addr);
+	if (unlikely(ata_status & ATA_BUSY))
+		return;
+
+	/* get active ATA command */
+	qc = ata_qc_from_tag(ap, ap->active_tag);
+	if (unlikely(!qc))			/* no active tag */
+		return;
+	if (qc->tf.flags & ATA_TFLAG_POLLING)	/* polling; we don't own qc */
+		return;
+
+	/* and finally, complete the ATA command */
+	qc->err_mask |= ac_err_mask(ata_status);
+	ata_qc_complete(qc);
 }
 
-static void mv_process_crpb_entries(struct ata_port *ap, struct mv_port_priv *pp)
+static void mv_intr_edma(struct ata_port *ap)
 {
 	void __iomem *port_mmio = mv_ap_base(ap);
 	struct mv_host_priv *hpriv = ap->host->private_data;
-	u32 in_index;
+	struct mv_port_priv *pp = ap->private_data;
+	struct ata_queued_cmd *qc;
+	u32 out_index, in_index;
 	bool work_done = false;
-	int ncq_enabled = (pp->pp_flags & MV_PP_FLAG_NCQ_EN);
 
-	/* Get the hardware queue position index */
-	in_index = (readl(port_mmio + EDMA_RSP_Q_IN_PTR)
+	/* get h/w response queue pointer */
+	in_index = (readl(port_mmio + EDMA_RSP_Q_IN_PTR_OFS)
 			>> EDMA_RSP_Q_PTR_SHIFT) & MV_MAX_Q_DEPTH_MASK;
 
-	/* Process new responses from since the last time we looked */
-	while (in_index != pp->resp_idx) {
+	while (1) {
+		u16 status;
 		unsigned int tag;
-		struct mv_crpb *response = &pp->crpb[pp->resp_idx];
 
-		pp->resp_idx = (pp->resp_idx + 1) & MV_MAX_Q_DEPTH_MASK;
+		/* get s/w response queue last-read pointer, and compare */
+		out_index = pp->resp_idx & MV_MAX_Q_DEPTH_MASK;
+		if (in_index == out_index)
+			break;
 
-		if (IS_GEN_I(hpriv)) {
-			/* 50xx: no NCQ, only one command active at a time */
-			tag = ap->link.active_tag;
-		} else {
-			/* Gen II/IIE: get command tag from CRPB entry */
-			tag = le16_to_cpu(response->id) & 0x1f;
+		/* 50xx: get active ATA command */
+		if (IS_GEN_I(hpriv))
+			tag = ap->active_tag;
+
+		/* Gen II/IIE: get active ATA command via tag, to enable
+		 * support for queueing.  this works transparently for
+		 * queued and non-queued modes.
+		 */
+		else if (IS_GEN_II(hpriv))
+			tag = (le16_to_cpu(pp->crpb[out_index].id)
+				>> CRPB_IOID_SHIFT_6) & 0x3f;
+
+		else /* IS_GEN_IIE */
+			tag = (le16_to_cpu(pp->crpb[out_index].id)
+				>> CRPB_IOID_SHIFT_7) & 0x3f;
+
+		qc = ata_qc_from_tag(ap, tag);
+
+		/* lower 8 bits of status are EDMA_ERR_IRQ_CAUSE_OFS
+		 * bits (WARNING: might not necessarily be associated
+		 * with this command), which -should- be clear
+		 * if all is well
+		 */
+		status = le16_to_cpu(pp->crpb[out_index].flags);
+		if (unlikely(status & 0xff)) {
+			mv_err_intr(ap, qc);
+			return;
+		}
+
+		/* and finally, complete the ATA command */
+		if (qc) {
+			qc->err_mask |=
+				ac_err_mask(status >> CRPB_FLAG_STATUS_SHIFT);
+			ata_qc_complete(qc);
 		}
-		mv_process_crpb_response(ap, response, tag, ncq_enabled);
+
+		/* advance software response queue pointer, to
+		 * indicate (after the loop completes) to hardware
+		 * that we have consumed a response queue entry.
+		 */
 		work_done = true;
+		pp->resp_idx++;
 	}
 
-	/* Update the software queue position index in hardware */
 	if (work_done)
 		writelfl((pp->crpb_dma & EDMA_RSP_Q_BASE_LO_MASK) |
-			 (pp->resp_idx << EDMA_RSP_Q_PTR_SHIFT),
-			 port_mmio + EDMA_RSP_Q_OUT_PTR);
-}
-
-static void mv_port_intr(struct ata_port *ap, u32 port_cause)
-{
-	struct mv_port_priv *pp;
-	int edma_was_enabled;
-
-	if (!ap || (ap->flags & ATA_FLAG_DISABLED)) {
-		mv_unexpected_intr(ap, 0);
-		return;
-	}
-	/*
-	 * Grab a snapshot of the EDMA_EN flag setting,
-	 * so that we have a consistent view for this port,
-	 * even if something we call of our routines changes it.
-	 */
-	pp = ap->private_data;
-	edma_was_enabled = (pp->pp_flags & MV_PP_FLAG_EDMA_EN);
-	/*
-	 * Process completed CRPB response(s) before other events.
-	 */
-	if (edma_was_enabled && (port_cause & DONE_IRQ)) {
-		mv_process_crpb_entries(ap, pp);
-		if (pp->pp_flags & MV_PP_FLAG_DELAYED_EH)
-			mv_handle_fbs_ncq_dev_err(ap);
-	}
-	/*
-	 * Handle chip-reported errors, or continue on to handle PIO.
-	 */
-	if (unlikely(port_cause & ERR_IRQ)) {
-		mv_err_intr(ap);
-	} else if (!edma_was_enabled) {
-		struct ata_queued_cmd *qc = mv_get_active_qc(ap);
-		if (qc)
-			ata_sff_host_intr(ap, qc);
-		else
-			mv_unexpected_intr(ap, edma_was_enabled);
-	}
+			 (out_index << EDMA_RSP_Q_PTR_SHIFT),
+			 port_mmio + EDMA_RSP_Q_OUT_PTR_OFS);
 }
 
 /**
  *      mv_host_intr - Handle all interrupts on the given host controller
  *      @host: host specific structure
- *      @main_irq_cause: Main interrupt cause register for the chip.
+ *      @relevant: port error bits relevant to this host controller
+ *      @hc: which host controller we're to look at
+ *
+ *      Read then write clear the HC interrupt status then walk each
+ *      port connected to the HC and see if it needs servicing.  Port
+ *      success ints are reported in the HC interrupt status reg, the
+ *      port error ints are reported in the higher level main
+ *      interrupt status register and thus are passed in via the
+ *      'relevant' argument.
  *
  *      LOCKING:
  *      Inherited from caller.
  */
-static int mv_host_intr(struct ata_host *host, u32 main_irq_cause)
+static void mv_host_intr(struct ata_host *host, u32 relevant, unsigned int hc)
 {
-	struct mv_host_priv *hpriv = host->private_data;
-	void __iomem *mmio = hpriv->base, *hc_mmio;
-	unsigned int handled = 0, port;
+	void __iomem *mmio = host->iomap[MV_PRIMARY_BAR];
+	void __iomem *hc_mmio = mv_hc_base(mmio, hc);
+	u32 hc_irq_cause;
+	int port, port0;
+
+	if (hc == 0)
+		port0 = 0;
+	else
+		port0 = MV_PORTS_PER_HC;
 
-	/* If asserted, clear the "all ports" IRQ coalescing bit */
-	if (main_irq_cause & ALL_PORTS_COAL_DONE)
-		writel(~ALL_PORTS_COAL_IRQ, mmio + IRQ_COAL_CAUSE);
+	/* we'll need the HC success int register in most cases */
+	hc_irq_cause = readl(hc_mmio + HC_IRQ_CAUSE_OFS);
+	if (!hc_irq_cause)
+		return;
+
+	writelfl(~hc_irq_cause, hc_mmio + HC_IRQ_CAUSE_OFS);
 
-	for (port = 0; port < hpriv->n_ports; port++) {
+	VPRINTK("ENTER, hc%u relevant=0x%08x HC IRQ cause=0x%08x\n",
+		hc,relevant,hc_irq_cause);
+
+	for (port = port0; port < port0 + MV_PORTS_PER_HC; port++) {
 		struct ata_port *ap = host->ports[port];
-		unsigned int p, shift, hardport, port_cause;
+		struct mv_port_priv *pp = ap->private_data;
+		int have_err_bits, hard_port, shift;
 
-		MV_PORT_TO_SHIFT_AND_HARDPORT(port, shift, hardport);
-		/*
-		 * Each hc within the host has its own hc_irq_cause register,
-		 * where the interrupting ports bits get ack'd.
-		 */
-		if (hardport == 0) {	/* first port on this hc ? */
-			u32 hc_cause = (main_irq_cause >> shift) & HC0_IRQ_PEND;
-			u32 port_mask, ack_irqs;
-			/*
-			 * Skip this entire hc if nothing pending for any ports
-			 */
-			if (!hc_cause) {
-				port += MV_PORTS_PER_HC - 1;
+		if ((!ap) || (ap->flags & ATA_FLAG_DISABLED))
+			continue;
+
+		shift = port << 1;		/* (port * 2) */
+		if (port >= MV_PORTS_PER_HC) {
+			shift++;	/* skip bit 8 in the HC Main IRQ reg */
+		}
+		have_err_bits = ((PORT0_ERR << shift) & relevant);
+
+		if (unlikely(have_err_bits)) {
+			struct ata_queued_cmd *qc;
+
+			qc = ata_qc_from_tag(ap, ap->active_tag);
+			if (qc && (qc->tf.flags & ATA_TFLAG_POLLING))
 				continue;
-			}
-			/*
-			 * We don't need/want to read the hc_irq_cause register,
-			 * because doing so hurts performance, and
-			 * main_irq_cause already gives us everything we need.
-			 *
-			 * But we do have to *write* to the hc_irq_cause to ack
-			 * the ports that we are handling this time through.
-			 *
-			 * This requires that we create a bitmap for those
-			 * ports which interrupted us, and use that bitmap
-			 * to ack (only) those ports via hc_irq_cause.
-			 */
-			ack_irqs = 0;
-			if (hc_cause & PORTS_0_3_COAL_DONE)
-				ack_irqs = HC_COAL_IRQ;
-			for (p = 0; p < MV_PORTS_PER_HC; ++p) {
-				if ((port + p) >= hpriv->n_ports)
-					break;
-				port_mask = (DONE_IRQ | ERR_IRQ) << (p * 2);
-				if (hc_cause & port_mask)
-					ack_irqs |= (DMA_IRQ | DEV_IRQ) << p;
-			}
-			hc_mmio = mv_hc_base_from_port(mmio, port);
-			writelfl(~ack_irqs, hc_mmio + HC_IRQ_CAUSE);
-			handled = 1;
+
+			mv_err_intr(ap, qc);
+			continue;
+		}
+
+		hard_port = mv_hardport_from_port(port); /* range 0..3 */
+
+		if (pp->pp_flags & MV_PP_FLAG_EDMA_EN) {
+			if ((CRPB_DMA_DONE << hard_port) & hc_irq_cause)
+				mv_intr_edma(ap);
+		} else {
+			if ((DEV_IRQ << hard_port) & hc_irq_cause)
+				mv_intr_pio(ap);
 		}
-		/*
-		 * Handle interrupts signalled for this port:
-		 */
-		port_cause = (main_irq_cause >> shift) & (DONE_IRQ | ERR_IRQ);
-		if (port_cause)
-			mv_port_intr(ap, port_cause);
 	}
-	return handled;
+	VPRINTK("EXIT\n");
 }
 
-static int mv_pci_error(struct ata_host *host, void __iomem *mmio)
+static void mv_pci_error(struct ata_host *host, void __iomem *mmio)
 {
-	struct mv_host_priv *hpriv = host->private_data;
 	struct ata_port *ap;
 	struct ata_queued_cmd *qc;
 	struct ata_eh_info *ehi;
 	unsigned int i, err_mask, printed = 0;
 	u32 err_cause;
 
-	err_cause = readl(mmio + hpriv->irq_cause_offset);
+	err_cause = readl(mmio + PCI_IRQ_CAUSE_OFS);
 
 	dev_printk(KERN_ERR, host->dev, "PCI ERROR; PCI IRQ cause=0x%08x\n",
 		   err_cause);
@@ -2928,19 +1683,19 @@
 	DPRINTK("All regs @ PCI error\n");
 	mv_dump_all_regs(mmio, -1, to_pci_dev(host->dev));
 
-	writelfl(0, mmio + hpriv->irq_cause_offset);
+	writelfl(0, mmio + PCI_IRQ_CAUSE_OFS);
 
 	for (i = 0; i < host->n_ports; i++) {
 		ap = host->ports[i];
-		if (!ata_link_offline(&ap->link)) {
-			ehi = &ap->link.eh_info;
+		if (!ata_port_offline(ap)) {
+			ehi = &ap->eh_info;
 			ata_ehi_clear_desc(ehi);
 			if (!printed++)
 				ata_ehi_push_desc(ehi,
 					"PCI err cause 0x%08x", err_cause);
 			err_mask = AC_ERR_HOST_BUS;
-			ehi->action = ATA_EH_RESET;
-			qc = ata_qc_from_tag(ap, ap->link.active_tag);
+			ehi->action = ATA_EH_HARDRESET;
+			qc = ata_qc_from_tag(ap, ap->active_tag);
 			if (qc)
 				qc->err_mask |= err_mask;
 			else
@@ -2949,7 +1704,6 @@
 			ata_port_freeze(ap);
 		}
 	}
-	return 1;	/* handled */
 }
 
 /**
@@ -2969,39 +1723,49 @@
 static irqreturn_t mv_interrupt(int irq, void *dev_instance)
 {
 	struct ata_host *host = dev_instance;
-	struct mv_host_priv *hpriv = host->private_data;
-	unsigned int handled = 0;
-	int using_msi = hpriv->hp_flags & MV_HP_FLAG_MSI;
-	u32 main_irq_cause, pending_irqs;
-
-	spin_lock(&host->lock);
+	unsigned int hc, handled = 0, n_hcs;
+	void __iomem *mmio = host->iomap[MV_PRIMARY_BAR];
+	u32 irq_stat;
 
-	/* for MSI:  block new interrupts while in here */
-	if (using_msi)
-		mv_write_main_irq_mask(0, hpriv);
+	irq_stat = readl(mmio + HC_MAIN_IRQ_CAUSE_OFS);
 
-	main_irq_cause = readl(hpriv->main_irq_cause_addr);
-	pending_irqs   = main_irq_cause & hpriv->main_irq_mask;
-	/*
-	 * Deal with cases where we either have nothing pending, or have read
-	 * a bogus register value which can indicate HW removal or PCI fault.
+	/* check the cases where we either have nothing pending or have read
+	 * a bogus register value which can indicate HW removal or PCI fault
 	 */
-	if (pending_irqs && main_irq_cause != 0xffffffffU) {
-		if (unlikely((pending_irqs & PCI_ERR) && !IS_SOC(hpriv)))
-			handled = mv_pci_error(host, hpriv->base);
-		else
-			handled = mv_host_intr(host, pending_irqs);
+	if (!irq_stat || (0xffffffffU == irq_stat))
+		return IRQ_NONE;
+
+	n_hcs = mv_get_hc_count(host->ports[0]->flags);
+	spin_lock(&host->lock);
+
+	if (unlikely(irq_stat & PCI_ERR)) {
+		mv_pci_error(host, mmio);
+		handled = 1;
+		goto out_unlock;	/* skip all other HC irq handling */
 	}
 
-	/* for MSI: unmask; interrupt cause bits will retrigger now */
-	if (using_msi)
-		mv_write_main_irq_mask(hpriv->main_irq_mask, hpriv);
+	for (hc = 0; hc < n_hcs; hc++) {
+		u32 relevant = irq_stat & (HC0_IRQ_PEND << (hc * HC_SHIFT));
+		if (relevant) {
+			mv_host_intr(host, relevant, hc);
+			handled = 1;
+		}
+	}
 
+out_unlock:
 	spin_unlock(&host->lock);
 
 	return IRQ_RETVAL(handled);
 }
 
+static void __iomem *mv5_phy_base(void __iomem *mmio, unsigned int port)
+{
+	void __iomem *hc_mmio = mv_hc_base_from_port(mmio, port);
+	unsigned long ofs = (mv_hardport_from_port(port) + 1) * 0x100UL;
+
+	return hc_mmio + ofs;
+}
+
 static unsigned int mv5_scr_offset(unsigned int sc_reg_in)
 {
 	unsigned int ofs;
@@ -3019,11 +1783,10 @@
 	return ofs;
 }
 
-static int mv5_scr_read(struct ata_link *link, unsigned int sc_reg_in, u32 *val)
+static int mv5_scr_read(struct ata_port *ap, unsigned int sc_reg_in, u32 *val)
 {
-	struct mv_host_priv *hpriv = link->ap->host->private_data;
-	void __iomem *mmio = hpriv->base;
-	void __iomem *addr = mv5_phy_base(mmio, link->ap->port_no);
+	void __iomem *mmio = ap->host->iomap[MV_PRIMARY_BAR];
+	void __iomem *addr = mv5_phy_base(mmio, ap->port_no);
 	unsigned int ofs = mv5_scr_offset(sc_reg_in);
 
 	if (ofs != 0xffffffffU) {
@@ -3033,11 +1796,10 @@
 		return -EINVAL;
 }
 
-static int mv5_scr_write(struct ata_link *link, unsigned int sc_reg_in, u32 val)
+static int mv5_scr_write(struct ata_port *ap, unsigned int sc_reg_in, u32 val)
 {
-	struct mv_host_priv *hpriv = link->ap->host->private_data;
-	void __iomem *mmio = hpriv->base;
-	void __iomem *addr = mv5_phy_base(mmio, link->ap->port_no);
+	void __iomem *mmio = ap->host->iomap[MV_PRIMARY_BAR];
+	void __iomem *addr = mv5_phy_base(mmio, ap->port_no);
 	unsigned int ofs = mv5_scr_offset(sc_reg_in);
 
 	if (ofs != 0xffffffffU) {
@@ -3047,9 +1809,8 @@
 		return -EINVAL;
 }
 
-static void mv5_reset_bus(struct ata_host *host, void __iomem *mmio)
+static void mv5_reset_bus(struct pci_dev *pdev, void __iomem *mmio)
 {
-	struct pci_dev *pdev = to_pci_dev(host->dev);
 	int early_5080;
 
 	early_5080 = (pdev->device == 0x5080) && (pdev->revision == 0);
@@ -3060,12 +1821,12 @@
 		writel(tmp, mmio + MV_PCI_EXP_ROM_BAR_CTL);
 	}
 
-	mv_reset_pci_bus(host, mmio);
+	mv_reset_pci_bus(pdev, mmio);
 }
 
 static void mv5_reset_flash(struct mv_host_priv *hpriv, void __iomem *mmio)
 {
-	writel(0x0fcfffff, mmio + FLASH_CTL);
+	writel(0x0fcfffff, mmio + MV_FLASH_CTL);
 }
 
 static void mv5_read_preamp(struct mv_host_priv *hpriv, int idx,
@@ -3084,7 +1845,7 @@
 {
 	u32 tmp;
 
-	writel(0, mmio + GPIO_PORT_CTL);
+	writel(0, mmio + MV_GPIO_PORT_CTL);
 
 	/* FIXME: handle MV_HP_ERRATA_50XXB2 errata */
 
@@ -3102,9 +1863,9 @@
 	int fix_apm_sq = (hpriv->hp_flags & MV_HP_ERRATA_50XXB0);
 
 	if (fix_apm_sq) {
-		tmp = readl(phy_mmio + MV5_LTMODE);
+		tmp = readl(phy_mmio + MV5_LT_MODE);
 		tmp |= (1 << 19);
-		writel(tmp, phy_mmio + MV5_LTMODE);
+		writel(tmp, phy_mmio + MV5_LT_MODE);
 
 		tmp = readl(phy_mmio + MV5_PHY_CTL);
 		tmp &= ~0x3;
@@ -3127,10 +1888,12 @@
 {
 	void __iomem *port_mmio = mv_port_base(mmio, port);
 
-	mv_reset_channel(hpriv, mmio, port);
+	writelfl(EDMA_DS, port_mmio + EDMA_CMD_OFS);
+
+	mv_channel_reset(hpriv, mmio, port);
 
 	ZERO(0x028);	/* command */
-	writel(0x11f, port_mmio + EDMA_CFG);
+	writel(0x11f, port_mmio + EDMA_CFG_OFS);
 	ZERO(0x004);	/* timer */
 	ZERO(0x008);	/* irq err cause */
 	ZERO(0x00c);	/* irq err mask */
@@ -3182,9 +1945,8 @@
 
 #undef ZERO
 #define ZERO(reg) writel(0, mmio + (reg))
-static void mv_reset_pci_bus(struct ata_host *host, void __iomem *mmio)
+static void mv_reset_pci_bus(struct pci_dev *pdev, void __iomem *mmio)
 {
-	struct mv_host_priv *hpriv = host->private_data;
 	u32 tmp;
 
 	tmp = readl(mmio + MV_PCI_MODE);
@@ -3194,9 +1956,10 @@
 	ZERO(MV_PCI_DISC_TIMER);
 	ZERO(MV_PCI_MSI_TRIGGER);
 	writel(0x000100ff, mmio + MV_PCI_XBAR_TMOUT);
+	ZERO(HC_MAIN_IRQ_MASK_OFS);
 	ZERO(MV_PCI_SERR_MASK);
-	ZERO(hpriv->irq_cause_offset);
-	ZERO(hpriv->irq_mask_offset);
+	ZERO(PCI_IRQ_CAUSE_OFS);
+	ZERO(PCI_IRQ_MASK_OFS);
 	ZERO(MV_PCI_ERR_LOW_ADDRESS);
 	ZERO(MV_PCI_ERR_HIGH_ADDRESS);
 	ZERO(MV_PCI_ERR_ATTRIBUTE);
@@ -3210,10 +1973,10 @@
 
 	mv5_reset_flash(hpriv, mmio);
 
-	tmp = readl(mmio + GPIO_PORT_CTL);
+	tmp = readl(mmio + MV_GPIO_PORT_CTL);
 	tmp &= 0x3;
 	tmp |= (1 << 5) | (1 << 6);
-	writel(tmp, mmio + GPIO_PORT_CTL);
+	writel(tmp, mmio + MV_GPIO_PORT_CTL);
 }
 
 /**
@@ -3228,7 +1991,7 @@
 static int mv6_reset_hc(struct mv_host_priv *hpriv, void __iomem *mmio,
 			unsigned int n_hc)
 {
-	void __iomem *reg = mmio + PCI_MAIN_CMD_STS;
+	void __iomem *reg = mmio + PCI_MAIN_CMD_STS_OFS;
 	int i, rc = 0;
 	u32 t;
 
@@ -3241,8 +2004,9 @@
 	for (i = 0; i < 1000; i++) {
 		udelay(1);
 		t = readl(reg);
-		if (PCI_MASTER_EMPTY & t)
+		if (PCI_MASTER_EMPTY & t) {
 			break;
+		}
 	}
 	if (!(PCI_MASTER_EMPTY & t)) {
 		printk(KERN_ERR DRV_NAME ": PCI master won't flush\n");
@@ -3286,7 +2050,7 @@
 	void __iomem *port_mmio;
 	u32 tmp;
 
-	tmp = readl(mmio + RESET_CFG);
+	tmp = readl(mmio + MV_RESET_CFG);
 	if ((tmp & (1 << 0)) == 0) {
 		hpriv->signal[idx].amps = 0x7 << 8;
 		hpriv->signal[idx].pre = 0x1 << 5;
@@ -3302,7 +2066,7 @@
 
 static void mv6_enable_leds(struct mv_host_priv *hpriv, void __iomem *mmio)
 {
-	writel(0x00000060, mmio + GPIO_PORT_CTL);
+	writel(0x00000060, mmio + MV_GPIO_PORT_CTL);
 }
 
 static void mv6_phy_errata(struct mv_host_priv *hpriv, void __iomem *mmio,
@@ -3315,7 +2079,7 @@
 		hp_flags & (MV_HP_ERRATA_60X1B2 | MV_HP_ERRATA_60X1C0);
 	int fix_phy_mode4 =
 		hp_flags & (MV_HP_ERRATA_60X1B2 | MV_HP_ERRATA_60X1C0);
-	u32 m2, m3;
+	u32 m2, tmp;
 
 	if (fix_phy_mode2) {
 		m2 = readl(port_mmio + PHY_MODE2);
@@ -3332,37 +2096,27 @@
 		udelay(200);
 	}
 
-	/*
-	 * Gen-II/IIe PHY_MODE3 errata RM#2:
-	 * Achieves better receiver noise performance than the h/w default:
-	 */
-	m3 = readl(port_mmio + PHY_MODE3);
-	m3 = (m3 & 0x1f) | (0x5555601 << 5);
-
-	/* Guideline 88F5182 (GL# SATA-S11) */
-	if (IS_SOC(hpriv))
-		m3 &= ~0x1c;
+	/* who knows what this magic does */
+	tmp = readl(port_mmio + PHY_MODE3);
+	tmp &= ~0x7F800000;
+	tmp |= 0x2A800000;
+	writel(tmp, port_mmio + PHY_MODE3);
 
 	if (fix_phy_mode4) {
-		u32 m4 = readl(port_mmio + PHY_MODE4);
-		/*
-		 * Enforce reserved-bit restrictions on GenIIe devices only.
-		 * For earlier chipsets, force only the internal config field
-		 *  (workaround for errata FEr SATA#10 part 1).
-		 */
-		if (IS_GEN_IIE(hpriv))
-			m4 = (m4 & ~PHY_MODE4_RSVD_ZEROS) | PHY_MODE4_RSVD_ONES;
-		else
-			m4 = (m4 & ~PHY_MODE4_CFG_MASK) | PHY_MODE4_CFG_VALUE;
-		writel(m4, port_mmio + PHY_MODE4);
-	}
-	/*
-	 * Workaround for 60x1-B2 errata SATA#13:
-	 * Any write to PHY_MODE4 (above) may corrupt PHY_MODE3,
-	 * so we must always rewrite PHY_MODE3 after PHY_MODE4.
-	 * Or ensure we use writelfl() when writing PHY_MODE4.
-	 */
-	writel(m3, port_mmio + PHY_MODE3);
+		u32 m4;
+
+		m4 = readl(port_mmio + PHY_MODE4);
+
+		if (hp_flags & MV_HP_ERRATA_60X1B2)
+			tmp = readl(port_mmio + 0x310);
+
+		m4 = (m4 & ~(1 << 1)) | (1 << 0);
+
+		writel(m4, port_mmio + PHY_MODE4);
+
+		if (hp_flags & MV_HP_ERRATA_60X1B2)
+			writel(tmp, port_mmio + 0x310);
+	}
 
 	/* Revert values of pre-emphasis and signal amps to the saved ones */
 	m2 = readl(port_mmio + PHY_MODE2);
@@ -3381,271 +2135,262 @@
 	writel(m2, port_mmio + PHY_MODE2);
 }
 
-/* TODO: use the generic LED interface to configure the SATA Presence */
-/* & Acitivy LEDs on the board */
-static void mv_soc_enable_leds(struct mv_host_priv *hpriv,
-				      void __iomem *mmio)
+static void mv_channel_reset(struct mv_host_priv *hpriv, void __iomem *mmio,
+			     unsigned int port_no)
 {
-	return;
-}
+	void __iomem *port_mmio = mv_port_base(mmio, port_no);
 
-static void mv_soc_read_preamp(struct mv_host_priv *hpriv, int idx,
-			   void __iomem *mmio)
-{
-	void __iomem *port_mmio;
-	u32 tmp;
+	writelfl(ATA_RST, port_mmio + EDMA_CMD_OFS);
 
-	port_mmio = mv_port_base(mmio, idx);
-	tmp = readl(port_mmio + PHY_MODE2);
+	if (IS_GEN_II(hpriv)) {
+		u32 ifctl = readl(port_mmio + SATA_INTERFACE_CTL);
+		ifctl |= (1 << 7);		/* enable gen2i speed */
+		ifctl = (ifctl & 0xfff) | 0x9b1000; /* from chip spec */
+		writelfl(ifctl, port_mmio + SATA_INTERFACE_CTL);
+	}
 
-	hpriv->signal[idx].amps = tmp & 0x700;	/* bits 10:8 */
-	hpriv->signal[idx].pre = tmp & 0xe0;	/* bits 7:5 */
+	udelay(25);		/* allow reset propagation */
+
+	/* Spec never mentions clearing the bit.  Marvell's driver does
+	 * clear the bit, however.
+	 */
+	writelfl(0, port_mmio + EDMA_CMD_OFS);
+
+	hpriv->ops->phy_errata(hpriv, mmio, port_no);
+
+	if (IS_GEN_I(hpriv))
+		mdelay(1);
 }
 
-#undef ZERO
-#define ZERO(reg) writel(0, port_mmio + (reg))
-static void mv_soc_reset_hc_port(struct mv_host_priv *hpriv,
-					void __iomem *mmio, unsigned int port)
+/**
+ *      mv_phy_reset - Perform eDMA reset followed by COMRESET
+ *      @ap: ATA channel to manipulate
+ *
+ *      Part of this is taken from __sata_phy_reset and modified to
+ *      not sleep since this routine gets called from interrupt level.
+ *
+ *      LOCKING:
+ *      Inherited from caller.  This is coded to safe to call at
+ *      interrupt level, i.e. it does not sleep.
+ */
+static void mv_phy_reset(struct ata_port *ap, unsigned int *class,
+			 unsigned long deadline)
 {
-	void __iomem *port_mmio = mv_port_base(mmio, port);
+	struct mv_port_priv *pp	= ap->private_data;
+	struct mv_host_priv *hpriv = ap->host->private_data;
+	void __iomem *port_mmio = mv_ap_base(ap);
+	int retry = 5;
+	u32 sstatus;
 
-	mv_reset_channel(hpriv, mmio, port);
+	VPRINTK("ENTER, port %u, mmio 0x%p\n", ap->port_no, port_mmio);
 
-	ZERO(0x028);		/* command */
-	writel(0x101f, port_mmio + EDMA_CFG);
-	ZERO(0x004);		/* timer */
-	ZERO(0x008);		/* irq err cause */
-	ZERO(0x00c);		/* irq err mask */
-	ZERO(0x010);		/* rq bah */
-	ZERO(0x014);		/* rq inp */
-	ZERO(0x018);		/* rq outp */
-	ZERO(0x01c);		/* respq bah */
-	ZERO(0x024);		/* respq outp */
-	ZERO(0x020);		/* respq inp */
-	ZERO(0x02c);		/* test control */
-	writel(0xbc, port_mmio + EDMA_IORDY_TMOUT);
-}
+#ifdef DEBUG
+	{
+		u32 sstatus, serror, scontrol;
+
+		mv_scr_read(ap, SCR_STATUS, &sstatus);
+		mv_scr_read(ap, SCR_ERROR, &serror);
+		mv_scr_read(ap, SCR_CONTROL, &scontrol);
+		DPRINTK("S-regs after ATA_RST: SStat 0x%08x SErr 0x%08x "
+			"SCtrl 0x%08x\n", status, serror, scontrol);
+	}
+#endif
 
-#undef ZERO
+	/* Issue COMRESET via SControl */
+comreset_retry:
+	sata_scr_write_flush(ap, SCR_CONTROL, 0x301);
+	msleep(1);
 
-#define ZERO(reg) writel(0, hc_mmio + (reg))
-static void mv_soc_reset_one_hc(struct mv_host_priv *hpriv,
-				       void __iomem *mmio)
-{
-	void __iomem *hc_mmio = mv_hc_base(mmio, 0);
+	sata_scr_write_flush(ap, SCR_CONTROL, 0x300);
+	msleep(20);
 
-	ZERO(0x00c);
-	ZERO(0x010);
-	ZERO(0x014);
+	do {
+		sata_scr_read(ap, SCR_STATUS, &sstatus);
+		if (((sstatus & 0x3) == 3) || ((sstatus & 0x3) == 0))
+			break;
 
-}
+		msleep(1);
+	} while (time_before(jiffies, deadline));
 
-#undef ZERO
+	/* work around errata */
+	if (IS_GEN_II(hpriv) &&
+	    (sstatus != 0x0) && (sstatus != 0x113) && (sstatus != 0x123) &&
+	    (retry-- > 0))
+		goto comreset_retry;
+
+#ifdef DEBUG
+	{
+		u32 sstatus, serror, scontrol;
+
+		mv_scr_read(ap, SCR_STATUS, &sstatus);
+		mv_scr_read(ap, SCR_ERROR, &serror);
+		mv_scr_read(ap, SCR_CONTROL, &scontrol);
+		DPRINTK("S-regs after PHY wake: SStat 0x%08x SErr 0x%08x "
+			"SCtrl 0x%08x\n", sstatus, serror, scontrol);
+	}
+#endif
 
-static int mv_soc_reset_hc(struct mv_host_priv *hpriv,
-				  void __iomem *mmio, unsigned int n_hc)
-{
-	unsigned int port;
+	if (ata_port_offline(ap)) {
+		*class = ATA_DEV_NONE;
+		return;
+	}
 
-	for (port = 0; port < hpriv->n_ports; port++)
-		mv_soc_reset_hc_port(hpriv, mmio, port);
+	/* even after SStatus reflects that device is ready,
+	 * it seems to take a while for link to be fully
+	 * established (and thus Status no longer 0x80/0x7F),
+	 * so we poll a bit for that, here.
+	 */
+	retry = 20;
+	while (1) {
+		u8 drv_stat = ata_check_status(ap);
+		if ((drv_stat != 0x80) && (drv_stat != 0x7f))
+			break;
+		msleep(500);
+		if (retry-- <= 0)
+			break;
+		if (time_after(jiffies, deadline))
+			break;
+	}
 
-	mv_soc_reset_one_hc(hpriv, mmio);
+	/* FIXME: if we passed the deadline, the following
+	 * code probably produces an invalid result
+	 */
 
-	return 0;
-}
+	/* finally, read device signature from TF registers */
+	*class = ata_dev_try_classify(ap, 0, NULL);
 
-static void mv_soc_reset_flash(struct mv_host_priv *hpriv,
-				      void __iomem *mmio)
-{
-	return;
-}
+	writelfl(0, port_mmio + EDMA_ERR_IRQ_CAUSE_OFS);
 
-static void mv_soc_reset_bus(struct ata_host *host, void __iomem *mmio)
-{
-	return;
+	WARN_ON(pp->pp_flags & MV_PP_FLAG_EDMA_EN);
+
+	VPRINTK("EXIT\n");
 }
 
-static void mv_soc_65n_phy_errata(struct mv_host_priv *hpriv,
-				  void __iomem *mmio, unsigned int port)
+static int mv_prereset(struct ata_port *ap, unsigned long deadline)
 {
-	void __iomem *port_mmio = mv_port_base(mmio, port);
-	u32	reg;
+	struct mv_port_priv *pp	= ap->private_data;
+	struct ata_eh_context *ehc = &ap->eh_context;
+	int rc;
 
-	reg = readl(port_mmio + PHY_MODE3);
-	reg &= ~(0x3 << 27);	/* SELMUPF (bits 28:27) to 1 */
-	reg |= (0x1 << 27);
-	reg &= ~(0x3 << 29);	/* SELMUPI (bits 30:29) to 1 */
-	reg |= (0x1 << 29);
-	writel(reg, port_mmio + PHY_MODE3);
-
-	reg = readl(port_mmio + PHY_MODE4);
-	reg &= ~0x1;	/* SATU_OD8 (bit 0) to 0, reserved bit 16 must be set */
-	reg |= (0x1 << 16);
-	writel(reg, port_mmio + PHY_MODE4);
-
-	reg = readl(port_mmio + PHY_MODE9_GEN2);
-	reg &= ~0xf;	/* TXAMP[3:0] (bits 3:0) to 8 */
-	reg |= 0x8;
-	reg &= ~(0x1 << 14);	/* TXAMP[4] (bit 14) to 0 */
-	writel(reg, port_mmio + PHY_MODE9_GEN2);
-
-	reg = readl(port_mmio + PHY_MODE9_GEN1);
-	reg &= ~0xf;	/* TXAMP[3:0] (bits 3:0) to 8 */
-	reg |= 0x8;
-	reg &= ~(0x1 << 14);	/* TXAMP[4] (bit 14) to 0 */
-	writel(reg, port_mmio + PHY_MODE9_GEN1);
-}
+	rc = mv_stop_dma(ap);
+	if (rc)
+		ehc->i.action |= ATA_EH_HARDRESET;
 
-/**
- *	soc_is_65 - check if the soc is 65 nano device
- *
- *	Detect the type of the SoC, this is done by reading the PHYCFG_OFS
- *	register, this register should contain non-zero value and it exists only
- *	in the 65 nano devices, when reading it from older devices we get 0.
- */
-static bool soc_is_65n(struct mv_host_priv *hpriv)
-{
-	void __iomem *port0_mmio = mv_port_base(hpriv->base, 0);
+	if (!(pp->pp_flags & MV_PP_FLAG_HAD_A_RESET)) {
+		pp->pp_flags |= MV_PP_FLAG_HAD_A_RESET;
+		ehc->i.action |= ATA_EH_HARDRESET;
+	}
 
-	if (readl(port0_mmio + PHYCFG_OFS))
-		return true;
-	return false;
-}
+	/* if we're about to do hardreset, nothing more to do */
+	if (ehc->i.action & ATA_EH_HARDRESET)
+		return 0;
 
-static void mv_setup_ifcfg(void __iomem *port_mmio, int want_gen2i)
-{
-	u32 ifcfg = readl(port_mmio + SATA_IFCFG);
+	if (ata_port_online(ap))
+		rc = ata_wait_ready(ap, deadline);
+	else
+		rc = -ENODEV;
 
-	ifcfg = (ifcfg & 0xf7f) | 0x9b1000;	/* from chip spec */
-	if (want_gen2i)
-		ifcfg |= (1 << 7);		/* enable gen2i speed */
-	writelfl(ifcfg, port_mmio + SATA_IFCFG);
+	return rc;
 }
 
-static void mv_reset_channel(struct mv_host_priv *hpriv, void __iomem *mmio,
-			     unsigned int port_no)
+static int mv_hardreset(struct ata_port *ap, unsigned int *class,
+			unsigned long deadline)
 {
-	void __iomem *port_mmio = mv_port_base(mmio, port_no);
+	struct mv_host_priv *hpriv = ap->host->private_data;
+	void __iomem *mmio = ap->host->iomap[MV_PRIMARY_BAR];
 
-	/*
-	 * The datasheet warns against setting EDMA_RESET when EDMA is active
-	 * (but doesn't say what the problem might be).  So we first try
-	 * to disable the EDMA engine before doing the EDMA_RESET operation.
-	 */
-	mv_stop_edma_engine(port_mmio);
-	writelfl(EDMA_RESET, port_mmio + EDMA_CMD);
+	mv_stop_dma(ap);
 
-	if (!IS_GEN_I(hpriv)) {
-		/* Enable 3.0gb/s link speed: this survives EDMA_RESET */
-		mv_setup_ifcfg(port_mmio, 1);
-	}
-	/*
-	 * Strobing EDMA_RESET here causes a hard reset of the SATA transport,
-	 * link, and physical layers.  It resets all SATA interface registers
-	 * (except for SATA_IFCFG), and issues a COMRESET to the dev.
-	 */
-	writelfl(EDMA_RESET, port_mmio + EDMA_CMD);
-	udelay(25);	/* allow reset propagation */
-	writelfl(0, port_mmio + EDMA_CMD);
+	mv_channel_reset(hpriv, mmio, ap->port_no);
 
-	hpriv->ops->phy_errata(hpriv, mmio, port_no);
+	mv_phy_reset(ap, class, deadline);
 
-	if (IS_GEN_I(hpriv))
-		mdelay(1);
+	return 0;
 }
 
-static void mv_pmp_select(struct ata_port *ap, int pmp)
+static void mv_postreset(struct ata_port *ap, unsigned int *classes)
 {
-	if (sata_pmp_supported(ap)) {
-		void __iomem *port_mmio = mv_ap_base(ap);
-		u32 reg = readl(port_mmio + SATA_IFCTL);
-		int old = reg & 0xf;
-
-		if (old != pmp) {
-			reg = (reg & ~0xf) | pmp;
-			writelfl(reg, port_mmio + SATA_IFCTL);
-		}
+	u32 serr;
+
+	/* print link status */
+	sata_print_link_status(ap);
+
+	/* clear SError */
+	sata_scr_read(ap, SCR_ERROR, &serr);
+	sata_scr_write_flush(ap, SCR_ERROR, serr);
+
+	/* bail out if no device is present */
+	if (classes[0] == ATA_DEV_NONE && classes[1] == ATA_DEV_NONE) {
+		DPRINTK("EXIT, no device\n");
+		return;
 	}
-}
 
-static int mv_pmp_hardreset(struct ata_link *link, unsigned int *class,
-				unsigned long deadline)
-{
-	mv_pmp_select(link->ap, sata_srst_pmp(link));
-	return sata_std_hardreset(link, class, deadline);
+	/* set up device control */
+	iowrite8(ap->ctl, ap->ioaddr.ctl_addr);
 }
 
-static int mv_softreset(struct ata_link *link, unsigned int *class,
-				unsigned long deadline)
+static void mv_error_handler(struct ata_port *ap)
 {
-	mv_pmp_select(link->ap, sata_srst_pmp(link));
-	return ata_sff_softreset(link, class, deadline);
+	ata_do_eh(ap, mv_prereset, ata_std_softreset,
+		  mv_hardreset, mv_postreset);
 }
 
-static int mv_hardreset(struct ata_link *link, unsigned int *class,
-			unsigned long deadline)
+static void mv_post_int_cmd(struct ata_queued_cmd *qc)
 {
-	struct ata_port *ap = link->ap;
-	struct mv_host_priv *hpriv = ap->host->private_data;
-	struct mv_port_priv *pp = ap->private_data;
-	void __iomem *mmio = hpriv->base;
-	int rc, attempts = 0, extra = 0;
-	u32 sstatus;
-	bool online;
-
-	mv_reset_channel(hpriv, mmio, ap->port_no);
-	pp->pp_flags &= ~MV_PP_FLAG_EDMA_EN;
-	pp->pp_flags &=
-	  ~(MV_PP_FLAG_FBS_EN | MV_PP_FLAG_NCQ_EN | MV_PP_FLAG_FAKE_ATA_BUSY);
-
-	/* Workaround for errata FEr SATA#10 (part 2) */
-	do {
-		const unsigned long *timing =
-				sata_ehc_deb_timing(&link->eh_context);
-
-		rc = sata_link_hardreset(link, timing, deadline + extra,
-					 &online, NULL);
-		rc = online ? -EAGAIN : rc;
-		if (rc)
-			return rc;
-		sata_scr_read(link, SCR_STATUS, &sstatus);
-		if (!IS_GEN_I(hpriv) && ++attempts >= 5 && sstatus == 0x121) {
-			/* Force 1.5gb/s link speed and try again */
-			mv_setup_ifcfg(mv_ap_base(ap), 0);
-			if (time_after(jiffies + HZ, deadline))
-				extra = HZ; /* only extend it once, max */
-		}
-	} while (sstatus != 0x0 && sstatus != 0x113 && sstatus != 0x123);
-	mv_save_cached_regs(ap);
-	mv_edma_cfg(ap, 0, 0);
-
-	return rc;
+	mv_stop_dma(qc->ap);
 }
 
 static void mv_eh_freeze(struct ata_port *ap)
 {
-	mv_stop_edma(ap);
-	mv_enable_port_irqs(ap, 0);
+	void __iomem *mmio = ap->host->iomap[MV_PRIMARY_BAR];
+	unsigned int hc = (ap->port_no > 3) ? 1 : 0;
+	u32 tmp, mask;
+	unsigned int shift;
+
+	/* FIXME: handle coalescing completion events properly */
+
+	shift = ap->port_no * 2;
+	if (hc > 0)
+		shift++;
+
+	mask = 0x3 << shift;
+
+	/* disable assertion of portN err, done events */
+	tmp = readl(mmio + HC_MAIN_IRQ_MASK_OFS);
+	writelfl(tmp & ~mask, mmio + HC_MAIN_IRQ_MASK_OFS);
 }
 
 static void mv_eh_thaw(struct ata_port *ap)
 {
-	struct mv_host_priv *hpriv = ap->host->private_data;
-	unsigned int port = ap->port_no;
-	unsigned int hardport = mv_hardport_from_port(port);
-	void __iomem *hc_mmio = mv_hc_base_from_port(hpriv->base, port);
+	void __iomem *mmio = ap->host->iomap[MV_PRIMARY_BAR];
+	unsigned int hc = (ap->port_no > 3) ? 1 : 0;
+	void __iomem *hc_mmio = mv_hc_base(mmio, hc);
 	void __iomem *port_mmio = mv_ap_base(ap);
-	u32 hc_irq_cause;
+	u32 tmp, mask, hc_irq_cause;
+	unsigned int shift, hc_port_no = ap->port_no;
+
+	/* FIXME: handle coalescing completion events properly */
+
+	shift = ap->port_no * 2;
+	if (hc > 0) {
+		shift++;
+		hc_port_no -= 4;
+	}
+
+	mask = 0x3 << shift;
 
 	/* clear EDMA errors on this port */
-	writel(0, port_mmio + EDMA_ERR_IRQ_CAUSE);
+	writel(0, port_mmio + EDMA_ERR_IRQ_CAUSE_OFS);
 
 	/* clear pending irq events */
-	hc_irq_cause = ~((DEV_IRQ | DMA_IRQ) << hardport);
-	writelfl(hc_irq_cause, hc_mmio + HC_IRQ_CAUSE);
-
-	mv_enable_port_irqs(ap, ERR_IRQ);
+	hc_irq_cause = readl(hc_mmio + HC_IRQ_CAUSE_OFS);
+	hc_irq_cause &= ~(1 << hc_port_no);	/* clear CRPB-done */
+	hc_irq_cause &= ~(1 << (hc_port_no + 8)); /* clear Device int */
+	writel(hc_irq_cause, hc_mmio + HC_IRQ_CAUSE_OFS);
+
+	/* enable assertion of portN err, done events */
+	tmp = readl(mmio + HC_MAIN_IRQ_MASK_OFS);
+	writelfl(tmp | mask, mmio + HC_MAIN_IRQ_MASK_OFS);
 }
 
 /**
@@ -3662,7 +2407,8 @@
  */
 static void mv_port_init(struct ata_ioports *port,  void __iomem *port_mmio)
 {
-	void __iomem *serr, *shd_base = port_mmio + SHD_BLK;
+	void __iomem *shd_base = port_mmio + SHD_BLK_OFS;
+	unsigned serr_ofs;
 
 	/* PIO related setup
 	 */
@@ -3677,63 +2423,23 @@
 	port->status_addr =
 		port->command_addr = shd_base + (sizeof(u32) * ATA_REG_STATUS);
 	/* special case: control/altstatus doesn't have ATA_REG_ address */
-	port->altstatus_addr = port->ctl_addr = shd_base + SHD_CTL_AST;
+	port->altstatus_addr = port->ctl_addr = shd_base + SHD_CTL_AST_OFS;
 
 	/* unused: */
 	port->cmd_addr = port->bmdma_addr = port->scr_addr = NULL;
 
 	/* Clear any currently outstanding port interrupt conditions */
-	serr = port_mmio + mv_scr_offset(SCR_ERROR);
-	writelfl(readl(serr), serr);
-	writelfl(0, port_mmio + EDMA_ERR_IRQ_CAUSE);
+	serr_ofs = mv_scr_offset(SCR_ERROR);
+	writelfl(readl(port_mmio + serr_ofs), port_mmio + serr_ofs);
+	writelfl(0, port_mmio + EDMA_ERR_IRQ_CAUSE_OFS);
 
-	/* unmask all non-transient EDMA error interrupts */
-	writelfl(~EDMA_ERR_IRQ_TRANSIENT, port_mmio + EDMA_ERR_IRQ_MASK);
+	/* unmask all EDMA error interrupts */
+	writelfl(~0, port_mmio + EDMA_ERR_IRQ_MASK_OFS);
 
 	VPRINTK("EDMA cfg=0x%08x EDMA IRQ err cause/mask=0x%08x/0x%08x\n",
-		readl(port_mmio + EDMA_CFG),
-		readl(port_mmio + EDMA_ERR_IRQ_CAUSE),
-		readl(port_mmio + EDMA_ERR_IRQ_MASK));
-}
-
-static unsigned int mv_in_pcix_mode(struct ata_host *host)
-{
-	struct mv_host_priv *hpriv = host->private_data;
-	void __iomem *mmio = hpriv->base;
-	u32 reg;
-
-	if (IS_SOC(hpriv) || !IS_PCIE(hpriv))
-		return 0;	/* not PCI-X capable */
-	reg = readl(mmio + MV_PCI_MODE);
-	if ((reg & MV_PCI_MODE_MASK) == 0)
-		return 0;	/* conventional PCI mode */
-	return 1;	/* chip is in PCI-X mode */
-}
-
-static int mv_pci_cut_through_okay(struct ata_host *host)
-{
-	struct mv_host_priv *hpriv = host->private_data;
-	void __iomem *mmio = hpriv->base;
-	u32 reg;
-
-	if (!mv_in_pcix_mode(host)) {
-		reg = readl(mmio + MV_PCI_COMMAND);
-		if (reg & MV_PCI_COMMAND_MRDTRIG)
-			return 0; /* not okay */
-	}
-	return 1; /* okay */
-}
-
-static void mv_60x1b2_errata_pci7(struct ata_host *host)
-{
-	struct mv_host_priv *hpriv = host->private_data;
-	void __iomem *mmio = hpriv->base;
-
-	/* workaround for 60x1-B2 errata PCI#7 */
-	if (mv_in_pcix_mode(host)) {
-		u32 reg = readl(mmio + MV_PCI_COMMAND);
-		writelfl(reg & ~MV_PCI_COMMAND_MWRCOM, mmio + MV_PCI_COMMAND);
-	}
+		readl(port_mmio + EDMA_CFG_OFS),
+		readl(port_mmio + EDMA_ERR_IRQ_CAUSE_OFS),
+		readl(port_mmio + EDMA_ERR_IRQ_MASK_OFS));
 }
 
 static int mv_chip_id(struct ata_host *host, unsigned int board_idx)
@@ -3742,7 +2448,7 @@
 	struct mv_host_priv *hpriv = host->private_data;
 	u32 hp_flags = hpriv->hp_flags;
 
-	switch (board_idx) {
+	switch(board_idx) {
 	case chip_5080:
 		hpriv->ops = &mv5xxx_ops;
 		hp_flags |= MV_HP_GEN_I;
@@ -3789,7 +2495,6 @@
 
 		switch (pdev->revision) {
 		case 0x7:
-			mv_60x1b2_errata_pci7(host);
 			hp_flags |= MV_HP_ERRATA_60X1B2;
 			break;
 		case 0x9:
@@ -3804,45 +2509,15 @@
 		break;
 
 	case chip_7042:
-		hp_flags |= MV_HP_PCIE | MV_HP_CUT_THROUGH;
-		if (pdev->vendor == PCI_VENDOR_ID_TTI &&
-		    (pdev->device == 0x2300 || pdev->device == 0x2310))
-		{
-			/*
-			 * Highpoint RocketRAID PCIe 23xx series cards:
-			 *
-			 * Unconfigured drives are treated as "Legacy"
-			 * by the BIOS, and it overwrites sector 8 with
-			 * a "Lgcy" metadata block prior to Linux boot.
-			 *
-			 * Configured drives (RAID or JBOD) leave sector 8
-			 * alone, but instead overwrite a high numbered
-			 * sector for the RAID metadata.  This sector can
-			 * be determined exactly, by truncating the physical
-			 * drive capacity to a nice even GB value.
-			 *
-			 * RAID metadata is at: (dev->n_sectors & ~0xfffff)
-			 *
-			 * Warn the user, lest they think we're just buggy.
-			 */
-			printk(KERN_WARNING DRV_NAME ": Highpoint RocketRAID"
-				" BIOS CORRUPTS DATA on all attached drives,"
-				" regardless of if/how they are configured."
-				" BEWARE!\n");
-			printk(KERN_WARNING DRV_NAME ": For data safety, do not"
-				" use sectors 8-9 on \"Legacy\" drives,"
-				" and avoid the final two gigabytes on"
-				" all RocketRAID BIOS initialized drives.\n");
-		}
-		/* drop through */
 	case chip_6042:
 		hpriv->ops = &mv6xxx_ops;
 		hp_flags |= MV_HP_GEN_IIE;
-		if (board_idx == chip_6042 && mv_pci_cut_through_okay(host))
-			hp_flags |= MV_HP_CUT_THROUGH;
 
 		switch (pdev->revision) {
-		case 0x2: /* Rev.B0: the first/only public release */
+		case 0x0:
+			hp_flags |= MV_HP_ERRATA_XX42A0;
+			break;
+		case 0x1:
 			hp_flags |= MV_HP_ERRATA_60X1C0;
 			break;
 		default:
@@ -3852,31 +2527,13 @@
 			break;
 		}
 		break;
-	case chip_soc:
-		if (soc_is_65n(hpriv))
-			hpriv->ops = &mv_soc_65n_ops;
-		else
-			hpriv->ops = &mv_soc_ops;
-		hp_flags |= MV_HP_FLAG_SOC | MV_HP_GEN_IIE |
-			MV_HP_ERRATA_60X1C0;
-		break;
 
 	default:
-		dev_printk(KERN_ERR, host->dev,
-			   "BUG: invalid board index %u\n", board_idx);
+		printk(KERN_ERR DRV_NAME ": BUG: invalid board index %u\n", board_idx);
 		return 1;
 	}
 
 	hpriv->hp_flags = hp_flags;
-	if (hp_flags & MV_HP_PCIE) {
-		hpriv->irq_cause_offset	= PCIE_IRQ_CAUSE;
-		hpriv->irq_mask_offset	= PCIE_IRQ_MASK;
-		hpriv->unmask_all_irqs	= PCIE_UNMASK_ALL_IRQS;
-	} else {
-		hpriv->irq_cause_offset	= PCI_IRQ_CAUSE;
-		hpriv->irq_mask_offset	= PCI_IRQ_MASK;
-		hpriv->unmask_all_irqs	= PCI_UNMASK_ALL_IRQS;
-	}
 
 	return 0;
 }
@@ -3895,54 +2552,46 @@
 static int mv_init_host(struct ata_host *host, unsigned int board_idx)
 {
 	int rc = 0, n_hc, port, hc;
+	struct pci_dev *pdev = to_pci_dev(host->dev);
+	void __iomem *mmio = host->iomap[MV_PRIMARY_BAR];
 	struct mv_host_priv *hpriv = host->private_data;
-	void __iomem *mmio = hpriv->base;
+
+	/* global interrupt mask */
+	writel(0, mmio + HC_MAIN_IRQ_MASK_OFS);
 
 	rc = mv_chip_id(host, board_idx);
 	if (rc)
 		goto done;
 
-	if (IS_SOC(hpriv)) {
-		hpriv->main_irq_cause_addr = mmio + SOC_HC_MAIN_IRQ_CAUSE;
-		hpriv->main_irq_mask_addr  = mmio + SOC_HC_MAIN_IRQ_MASK;
-	} else {
-		hpriv->main_irq_cause_addr = mmio + PCI_HC_MAIN_IRQ_CAUSE;
-		hpriv->main_irq_mask_addr  = mmio + PCI_HC_MAIN_IRQ_MASK;
-	}
-
-	/* initialize shadow irq mask with register's value */
-	hpriv->main_irq_mask = readl(hpriv->main_irq_mask_addr);
-
-	/* global interrupt mask: 0 == mask everything */
-	mv_set_main_irq_mask(host, ~0, 0);
-
 	n_hc = mv_get_hc_count(host->ports[0]->flags);
 
 	for (port = 0; port < host->n_ports; port++)
-		if (hpriv->ops->read_preamp)
-			hpriv->ops->read_preamp(hpriv, port, mmio);
+		hpriv->ops->read_preamp(hpriv, port, mmio);
 
 	rc = hpriv->ops->reset_hc(hpriv, mmio, n_hc);
 	if (rc)
 		goto done;
 
 	hpriv->ops->reset_flash(hpriv, mmio);
-	hpriv->ops->reset_bus(host, mmio);
+	hpriv->ops->reset_bus(pdev, mmio);
 	hpriv->ops->enable_leds(hpriv, mmio);
 
 	for (port = 0; port < host->n_ports; port++) {
-		struct ata_port *ap = host->ports[port];
-		void __iomem *port_mmio = mv_port_base(mmio, port);
+		if (IS_GEN_II(hpriv)) {
+			void __iomem *port_mmio = mv_port_base(mmio, port);
 
-		mv_port_init(&ap->ioaddr, port_mmio);
-
-#ifdef CONFIG_PCI
-		if (!IS_SOC(hpriv)) {
-			unsigned int offset = port_mmio - mmio;
-			ata_port_pbar_desc(ap, MV_PRIMARY_BAR, -1, "mmio");
-			ata_port_pbar_desc(ap, MV_PRIMARY_BAR, offset, "port");
+			u32 ifctl = readl(port_mmio + SATA_INTERFACE_CTL);
+			ifctl |= (1 << 7);		/* enable gen2i speed */
+			ifctl = (ifctl & 0xfff) | 0x9b1000; /* from chip spec */
+			writelfl(ifctl, port_mmio + SATA_INTERFACE_CTL);
 		}
-#endif
+
+		hpriv->ops->phy_errata(hpriv, mmio, port);
+	}
+
+	for (port = 0; port < host->n_ports; port++) {
+		void __iomem *port_mmio = mv_port_base(mmio, port);
+		mv_port_init(&host->ports[port]->ioaddr, port_mmio);
 	}
 
 	for (hc = 0; hc < n_hc; hc++) {
@@ -3950,219 +2599,32 @@
 
 		VPRINTK("HC%i: HC config=0x%08x HC IRQ cause "
 			"(before clear)=0x%08x\n", hc,
-			readl(hc_mmio + HC_CFG),
-			readl(hc_mmio + HC_IRQ_CAUSE));
+			readl(hc_mmio + HC_CFG_OFS),
+			readl(hc_mmio + HC_IRQ_CAUSE_OFS));
 
 		/* Clear any currently outstanding hc interrupt conditions */
-		writelfl(0, hc_mmio + HC_IRQ_CAUSE);
-	}
-
-	if (!IS_SOC(hpriv)) {
-		/* Clear any currently outstanding host interrupt conditions */
-		writelfl(0, mmio + hpriv->irq_cause_offset);
-
-		/* and unmask interrupt generation for host regs */
-		writelfl(hpriv->unmask_all_irqs, mmio + hpriv->irq_mask_offset);
-	}
-
-	/*
-	 * enable only global host interrupts for now.
-	 * The per-port interrupts get done later as ports are set up.
-	 */
-	mv_set_main_irq_mask(host, 0, PCI_ERR);
-	mv_set_irq_coalescing(host, irq_coalescing_io_count,
-				    irq_coalescing_usecs);
-done:
-	return rc;
-}
-
-static int mv_create_dma_pools(struct mv_host_priv *hpriv, struct device *dev)
-{
-	hpriv->crqb_pool   = dmam_pool_create("crqb_q", dev, MV_CRQB_Q_SZ,
-							     MV_CRQB_Q_SZ, 0);
-	if (!hpriv->crqb_pool)
-		return -ENOMEM;
-
-	hpriv->crpb_pool   = dmam_pool_create("crpb_q", dev, MV_CRPB_Q_SZ,
-							     MV_CRPB_Q_SZ, 0);
-	if (!hpriv->crpb_pool)
-		return -ENOMEM;
-
-	hpriv->sg_tbl_pool = dmam_pool_create("sg_tbl", dev, MV_SG_TBL_SZ,
-							     MV_SG_TBL_SZ, 0);
-	if (!hpriv->sg_tbl_pool)
-		return -ENOMEM;
-
-	return 0;
-}
-
-static void mv_conf_mbus_windows(struct mv_host_priv *hpriv,
-				 struct mbus_dram_target_info *dram)
-{
-	int i;
-
-	for (i = 0; i < 4; i++) {
-		writel(0, hpriv->base + WINDOW_CTRL(i));
-		writel(0, hpriv->base + WINDOW_BASE(i));
-	}
-
-	for (i = 0; i < dram->num_cs; i++) {
-		struct mbus_dram_window *cs = dram->cs + i;
-
-		writel(((cs->size - 1) & 0xffff0000) |
-			(cs->mbus_attr << 8) |
-			(dram->mbus_dram_target_id << 4) | 1,
-			hpriv->base + WINDOW_CTRL(i));
-		writel(cs->base, hpriv->base + WINDOW_BASE(i));
+		writelfl(0, hc_mmio + HC_IRQ_CAUSE_OFS);
 	}
-}
 
-/**
- *      mv_platform_probe - handle a positive probe of an soc Marvell
- *      host
- *      @pdev: platform device found
- *
- *      LOCKING:
- *      Inherited from caller.
- */
-static int mv_platform_probe(struct platform_device *pdev)
-{
-	static int printed_version;
-	const struct mv_sata_platform_data *mv_platform_data;
-	const struct ata_port_info *ppi[] =
-	    { &mv_port_info[chip_soc], NULL };
-	struct ata_host *host;
-	struct mv_host_priv *hpriv;
-	struct resource *res;
-	int n_ports, rc;
-
-	if (!printed_version++)
-		dev_printk(KERN_INFO, &pdev->dev, "version " DRV_VERSION "\n");
-
-	/*
-	 * Simple resource validation ..
-	 */
-	if (unlikely(pdev->num_resources != 2)) {
-		dev_err(&pdev->dev, "invalid number of resources\n");
-		return -EINVAL;
-	}
-
-	/*
-	 * Get the register base first
-	 */
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	if (res == NULL)
-		return -EINVAL;
-
-	/* allocate host */
-	mv_platform_data = pdev->dev.platform_data;
-	n_ports = mv_platform_data->n_ports;
-
-	host = ata_host_alloc_pinfo(&pdev->dev, ppi, n_ports);
-	hpriv = devm_kzalloc(&pdev->dev, sizeof(*hpriv), GFP_KERNEL);
-
-	if (!host || !hpriv)
-		return -ENOMEM;
-	host->private_data = hpriv;
-	hpriv->n_ports = n_ports;
+	/* Clear any currently outstanding host interrupt conditions */
+	writelfl(0, mmio + PCI_IRQ_CAUSE_OFS);
 
-	host->iomap = NULL;
-	hpriv->base = devm_ioremap(&pdev->dev, res->start,
-				   resource_size(res));
-	hpriv->base -= SATAHC0_REG_BASE;
+	/* and unmask interrupt generation for host regs */
+	writelfl(PCI_UNMASK_ALL_IRQS, mmio + PCI_IRQ_MASK_OFS);
 
-	/*
-	 * (Re-)program MBUS remapping windows if we are asked to.
-	 */
-	if (mv_platform_data->dram != NULL)
-		mv_conf_mbus_windows(hpriv, mv_platform_data->dram);
-
-	rc = mv_create_dma_pools(hpriv, &pdev->dev);
-	if (rc)
-		return rc;
-
-	/* initialize adapter */
-	rc = mv_init_host(host, chip_soc);
-	if (rc)
-		return rc;
-
-	dev_printk(KERN_INFO, &pdev->dev,
-		   "slots %u ports %d\n", (unsigned)MV_MAX_Q_DEPTH,
-		   host->n_ports);
-
-	return ata_host_activate(host, platform_get_irq(pdev, 0), mv_interrupt,
-				 IRQF_SHARED, &mv6_sht);
-}
-
-/*
- *
- *      mv_platform_remove    -       unplug a platform interface
- *      @pdev: platform device
- *
- *      A platform bus SATA device has been unplugged. Perform the needed
- *      cleanup. Also called on module unload for any active devices.
- */
-static int __devexit mv_platform_remove(struct platform_device *pdev)
-{
-	struct device *dev = &pdev->dev;
-	struct ata_host *host = dev_get_drvdata(dev);
-
-	ata_host_detach(host);
-	return 0;
-}
-
-static struct platform_driver mv_platform_driver = {
-	.probe			= mv_platform_probe,
-	.remove			= __devexit_p(mv_platform_remove),
-	.driver			= {
-				   .name = DRV_NAME,
-				   .owner = THIS_MODULE,
-				  },
-};
-
-
-#ifdef CONFIG_PCI
-static int mv_pci_init_one(struct pci_dev *pdev,
-			   const struct pci_device_id *ent);
-
-
-static struct pci_driver mv_pci_driver = {
-	.name			= DRV_NAME,
-	.id_table		= mv_pci_tbl,
-	.probe			= mv_pci_init_one,
-	.remove			= ata_pci_remove_one,
-};
-
-/* move to PCI layer or libata core? */
-static int pci_go_64(struct pci_dev *pdev)
-{
-	int rc;
+	if (IS_GEN_I(hpriv))
+		writelfl(~HC_MAIN_MASKED_IRQS_5, mmio + HC_MAIN_IRQ_MASK_OFS);
+	else
+		writelfl(~HC_MAIN_MASKED_IRQS, mmio + HC_MAIN_IRQ_MASK_OFS);
 
-	if (!pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {
-		rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
-		if (rc) {
-			rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
-			if (rc) {
-				dev_printk(KERN_ERR, &pdev->dev,
-					   "64-bit DMA enable failed\n");
-				return rc;
-			}
-		}
-	} else {
-		rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
-		if (rc) {
-			dev_printk(KERN_ERR, &pdev->dev,
-				   "32-bit DMA enable failed\n");
-			return rc;
-		}
-		rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
-		if (rc) {
-			dev_printk(KERN_ERR, &pdev->dev,
-				   "32-bit consistent DMA enable failed\n");
-			return rc;
-		}
-	}
+	VPRINTK("HC MAIN IRQ cause/mask=0x%08x/0x%08x "
+		"PCI int cause/mask=0x%08x/0x%08x\n",
+		readl(mmio + HC_MAIN_IRQ_CAUSE_OFS),
+		readl(mmio + HC_MAIN_IRQ_MASK_OFS),
+		readl(mmio + PCI_IRQ_CAUSE_OFS),
+		readl(mmio + PCI_IRQ_MASK_OFS));
 
+done:
 	return rc;
 }
 
@@ -4209,17 +2671,16 @@
 }
 
 /**
- *      mv_pci_init_one - handle a positive probe of a PCI Marvell host
+ *      mv_init_one - handle a positive probe of a Marvell host
  *      @pdev: PCI device found
  *      @ent: PCI device ID entry for the matched host
  *
  *      LOCKING:
  *      Inherited from caller.
  */
-static int mv_pci_init_one(struct pci_dev *pdev,
-			   const struct pci_device_id *ent)
+static int mv_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
 {
-	static int printed_version;
+	static int printed_version = 0;
 	unsigned int board_idx = (unsigned int)ent->driver_data;
 	const struct ata_port_info *ppi[] = { &mv_port_info[board_idx], NULL };
 	struct ata_host *host;
@@ -4237,7 +2698,6 @@
 	if (!host || !hpriv)
 		return -ENOMEM;
 	host->private_data = hpriv;
-	hpriv->n_ports = n_ports;
 
 	/* acquire resources */
 	rc = pcim_enable_device(pdev);
@@ -4250,24 +2710,19 @@
 	if (rc)
 		return rc;
 	host->iomap = pcim_iomap_table(pdev);
-	hpriv->base = host->iomap[MV_PRIMARY_BAR];
 
 	rc = pci_go_64(pdev);
 	if (rc)
 		return rc;
 
-	rc = mv_create_dma_pools(hpriv, &pdev->dev);
-	if (rc)
-		return rc;
-
 	/* initialize adapter */
 	rc = mv_init_host(host, board_idx);
 	if (rc)
 		return rc;
 
-	/* Enable message-switched interrupts, if requested */
-	if (msi && pci_enable_msi(pdev) == 0)
-		hpriv->hp_flags |= MV_HP_FLAG_MSI;
+	/* Enable interrupts */
+	if (msi && pci_enable_msi(pdev))
+		pci_intx(pdev, 1);
 
 	mv_dump_pci_cfg(pdev, 0x68);
 	mv_print_info(host);
@@ -4277,34 +2732,15 @@
 	return ata_host_activate(host, pdev->irq, mv_interrupt, IRQF_SHARED,
 				 IS_GEN_I(hpriv) ? &mv5_sht : &mv6_sht);
 }
-#endif
-
-static int mv_platform_probe(struct platform_device *pdev);
-static int __devexit mv_platform_remove(struct platform_device *pdev);
 
 static int __init mv_init(void)
 {
-	int rc = -ENODEV;
-#ifdef CONFIG_PCI
-	rc = pci_register_driver(&mv_pci_driver);
-	if (rc < 0)
-		return rc;
-#endif
-	rc = platform_driver_register(&mv_platform_driver);
-
-#ifdef CONFIG_PCI
-	if (rc < 0)
-		pci_unregister_driver(&mv_pci_driver);
-#endif
-	return rc;
+	return pci_register_driver(&mv_pci_driver);
 }
 
 static void __exit mv_exit(void)
 {
-#ifdef CONFIG_PCI
 	pci_unregister_driver(&mv_pci_driver);
-#endif
-	platform_driver_unregister(&mv_platform_driver);
 }
 
 MODULE_AUTHOR("Brett Russ");
@@ -4312,7 +2748,9 @@
 MODULE_LICENSE("GPL");
 MODULE_DEVICE_TABLE(pci, mv_pci_tbl);
 MODULE_VERSION(DRV_VERSION);
-MODULE_ALIAS("platform:" DRV_NAME);
+
+module_param(msi, int, 0444);
+MODULE_PARM_DESC(msi, "Enable use of PCI MSI (0=off, 1=on)");
 
 module_init(mv_init);
 module_exit(mv_exit);
diff -Nur linux-sh4/drivers/ata.org/sata_nv.c linux-sh4/drivers/ata/sata_nv.c
--- linux-sh4/drivers/ata.org/sata_nv.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/sata_nv.c	2012-01-15 06:30:15.000000000 -0800
@@ -57,9 +57,9 @@
 	NV_MMIO_BAR			= 5,
 
 	NV_PORTS			= 2,
-	NV_PIO_MASK			= ATA_PIO4,
-	NV_MWDMA_MASK			= ATA_MWDMA2,
-	NV_UDMA_MASK			= ATA_UDMA6,
+	NV_PIO_MASK			= 0x1f,
+	NV_MWDMA_MASK			= 0x07,
+	NV_UDMA_MASK			= 0x7f,
 	NV_PORT0_SCR_REG_OFFSET		= 0x00,
 	NV_PORT1_SCR_REG_OFFSET		= 0x40,
 
@@ -163,41 +163,12 @@
 	NV_ADMA_STAT_STOPPED		= (1 << 10),
 	NV_ADMA_STAT_DONE		= (1 << 12),
 	NV_ADMA_STAT_ERR		= NV_ADMA_STAT_CPBERR |
-					  NV_ADMA_STAT_TIMEOUT,
+	 				  NV_ADMA_STAT_TIMEOUT,
 
 	/* port flags */
 	NV_ADMA_PORT_REGISTER_MODE	= (1 << 0),
 	NV_ADMA_ATAPI_SETUP_COMPLETE	= (1 << 1),
 
-	/* MCP55 reg offset */
-	NV_CTL_MCP55			= 0x400,
-	NV_INT_STATUS_MCP55		= 0x440,
-	NV_INT_ENABLE_MCP55		= 0x444,
-	NV_NCQ_REG_MCP55		= 0x448,
-
-	/* MCP55 */
-	NV_INT_ALL_MCP55		= 0xffff,
-	NV_INT_PORT_SHIFT_MCP55		= 16,	/* each port occupies 16 bits */
-	NV_INT_MASK_MCP55		= NV_INT_ALL_MCP55 & 0xfffd,
-
-	/* SWNCQ ENABLE BITS*/
-	NV_CTL_PRI_SWNCQ		= 0x02,
-	NV_CTL_SEC_SWNCQ		= 0x04,
-
-	/* SW NCQ status bits*/
-	NV_SWNCQ_IRQ_DEV		= (1 << 0),
-	NV_SWNCQ_IRQ_PM			= (1 << 1),
-	NV_SWNCQ_IRQ_ADDED		= (1 << 2),
-	NV_SWNCQ_IRQ_REMOVED		= (1 << 3),
-
-	NV_SWNCQ_IRQ_BACKOUT		= (1 << 4),
-	NV_SWNCQ_IRQ_SDBFIS		= (1 << 5),
-	NV_SWNCQ_IRQ_DHREGFIS		= (1 << 6),
-	NV_SWNCQ_IRQ_DMASETUP		= (1 << 7),
-
-	NV_SWNCQ_IRQ_HOTPLUG		= NV_SWNCQ_IRQ_ADDED |
-					  NV_SWNCQ_IRQ_REMOVED,
-
 };
 
 /* ADMA Physical Region Descriptor - one SG segment */
@@ -228,7 +199,7 @@
 	u8			reserved1;     /* 1 */
 	u8			ctl_flags;     /* 2 */
 	/* len is length of taskfile in 64 bit words */
-	u8			len;		/* 3  */
+ 	u8			len;           /* 3  */
 	u8			tag;           /* 4 */
 	u8			next_cpb_idx;  /* 5 */
 	__le16			reserved2;     /* 6-7 */
@@ -244,10 +215,9 @@
 	dma_addr_t		cpb_dma;
 	struct nv_adma_prd	*aprd;
 	dma_addr_t		aprd_dma;
-	void __iomem		*ctl_block;
-	void __iomem		*gen_block;
-	void __iomem		*notifier_clear_block;
-	u64			adma_dma_mask;
+	void __iomem *		ctl_block;
+	void __iomem *		gen_block;
+	void __iomem *		notifier_clear_block;
 	u8			flags;
 	int			last_issue_ncq;
 };
@@ -256,45 +226,9 @@
 	unsigned long		type;
 };
 
-struct defer_queue {
-	u32		defer_bits;
-	unsigned int	head;
-	unsigned int	tail;
-	unsigned int	tag[ATA_MAX_QUEUE];
-};
-
-enum ncq_saw_flag_list {
-	ncq_saw_d2h	= (1U << 0),
-	ncq_saw_dmas	= (1U << 1),
-	ncq_saw_sdb	= (1U << 2),
-	ncq_saw_backout	= (1U << 3),
-};
-
-struct nv_swncq_port_priv {
-	struct ata_prd	*prd;	 /* our SG list */
-	dma_addr_t	prd_dma; /* and its DMA mapping */
-	void __iomem	*sactive_block;
-	void __iomem	*irq_block;
-	void __iomem	*tag_block;
-	u32		qc_active;
-
-	unsigned int	last_issue_tag;
-
-	/* fifo circular queue to store deferral command */
-	struct defer_queue defer_queue;
-
-	/* for NCQ interrupt analysis */
-	u32		dhfis_bits;
-	u32		dmafis_bits;
-	u32		sdbfis_bits;
+#define NV_ADMA_CHECK_INTR(GCTL, PORT) ((GCTL) & ( 1 << (19 + (12 * (PORT)))))
 
-	unsigned int	ncq_flags;
-};
-
-
-#define NV_ADMA_CHECK_INTR(GCTL, PORT) ((GCTL) & (1 << (19 + (12 * (PORT)))))
-
-static int nv_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
+static int nv_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
 #ifdef CONFIG_PM
 static int nv_pci_device_resume(struct pci_dev *pdev);
 #endif
@@ -302,15 +236,14 @@
 static irqreturn_t nv_generic_interrupt(int irq, void *dev_instance);
 static irqreturn_t nv_nf2_interrupt(int irq, void *dev_instance);
 static irqreturn_t nv_ck804_interrupt(int irq, void *dev_instance);
-static int nv_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val);
-static int nv_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val);
+static int nv_scr_read (struct ata_port *ap, unsigned int sc_reg, u32 *val);
+static int nv_scr_write (struct ata_port *ap, unsigned int sc_reg, u32 val);
 
-static int nv_hardreset(struct ata_link *link, unsigned int *class,
-			unsigned long deadline);
 static void nv_nf2_freeze(struct ata_port *ap);
 static void nv_nf2_thaw(struct ata_port *ap);
 static void nv_ck804_freeze(struct ata_port *ap);
 static void nv_ck804_thaw(struct ata_port *ap);
+static void nv_error_handler(struct ata_port *ap);
 static int nv_adma_slave_config(struct scsi_device *sdev);
 static int nv_adma_check_atapi_dma(struct ata_queued_cmd *qc);
 static void nv_adma_qc_prep(struct ata_queued_cmd *qc);
@@ -330,30 +263,13 @@
 static void nv_adma_post_internal_cmd(struct ata_queued_cmd *qc);
 static void nv_adma_tf_read(struct ata_port *ap, struct ata_taskfile *tf);
 
-static void nv_mcp55_thaw(struct ata_port *ap);
-static void nv_mcp55_freeze(struct ata_port *ap);
-static void nv_swncq_error_handler(struct ata_port *ap);
-static int nv_swncq_slave_config(struct scsi_device *sdev);
-static int nv_swncq_port_start(struct ata_port *ap);
-static void nv_swncq_qc_prep(struct ata_queued_cmd *qc);
-static void nv_swncq_fill_sg(struct ata_queued_cmd *qc);
-static unsigned int nv_swncq_qc_issue(struct ata_queued_cmd *qc);
-static void nv_swncq_irq_clear(struct ata_port *ap, u16 fis);
-static irqreturn_t nv_swncq_interrupt(int irq, void *dev_instance);
-#ifdef CONFIG_PM
-static int nv_swncq_port_suspend(struct ata_port *ap, pm_message_t mesg);
-static int nv_swncq_port_resume(struct ata_port *ap);
-#endif
-
 enum nv_host_type
 {
 	GENERIC,
 	NFORCE2,
 	NFORCE3 = NFORCE2,	/* NF2 == NF3 as far as sata_nv is concerned */
 	CK804,
-	ADMA,
-	MCP5x,
-	SWNCQ,
+	ADMA
 };
 
 static const struct pci_device_id nv_pci_tbl[] = {
@@ -364,10 +280,10 @@
 	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_CK804_SATA2), CK804 },
 	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP04_SATA), CK804 },
 	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP04_SATA2), CK804 },
-	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP51_SATA), MCP5x },
-	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP51_SATA2), MCP5x },
-	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP55_SATA), MCP5x },
-	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP55_SATA2), MCP5x },
+	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP51_SATA), GENERIC },
+	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP51_SATA2), GENERIC },
+	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP55_SATA), GENERIC },
+	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP55_SATA2), GENERIC },
 	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP61_SATA), GENERIC },
 	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP61_SATA2), GENERIC },
 	{ PCI_VDEVICE(NVIDIA, PCI_DEVICE_ID_NVIDIA_NFORCE_MCP61_SATA3), GENERIC },
@@ -387,119 +303,145 @@
 };
 
 static struct scsi_host_template nv_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 static struct scsi_host_template nv_adma_sht = {
-	ATA_NCQ_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.change_queue_depth	= ata_scsi_change_queue_depth,
 	.can_queue		= NV_ADMA_MAX_CPBS,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= NV_ADMA_SGTBL_TOTAL_LEN,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
 	.dma_boundary		= NV_ADMA_DMA_BOUNDARY,
 	.slave_configure	= nv_adma_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct scsi_host_template nv_swncq_sht = {
-	ATA_NCQ_SHT(DRV_NAME),
-	.can_queue		= ATA_MAX_QUEUE,
-	.sg_tablesize		= LIBATA_MAX_PRD,
-	.dma_boundary		= ATA_DMA_BOUNDARY,
-	.slave_configure	= nv_swncq_slave_config,
-};
-
-/*
- * NV SATA controllers have various different problems with hardreset
- * protocol depending on the specific controller and device.
- *
- * GENERIC:
- *
- *  bko11195 reports that link doesn't come online after hardreset on
- *  generic nv's and there have been several other similar reports on
- *  linux-ide.
- *
- *  bko12351#c23 reports that warmplug on MCP61 doesn't work with
- *  softreset.
- *
- * NF2/3:
- *
- *  bko3352 reports nf2/3 controllers can't determine device signature
- *  reliably after hardreset.  The following thread reports detection
- *  failure on cold boot with the standard debouncing timing.
- *
- *  http://thread.gmane.org/gmane.linux.ide/34098
- *
- *  bko12176 reports that hardreset fails to bring up the link during
- *  boot on nf2.
- *
- * CK804:
- *
- *  For initial probing after boot and hot plugging, hardreset mostly
- *  works fine on CK804 but curiously, reprobing on the initial port
- *  by rescanning or rmmod/insmod fails to acquire the initial D2H Reg
- *  FIS in somewhat undeterministic way.
- *
- * SWNCQ:
- *
- *  bko12351 reports that when SWNCQ is enabled, for hotplug to work,
- *  hardreset should be used and hardreset can't report proper
- *  signature, which suggests that mcp5x is closer to nf2 as long as
- *  reset quirkiness is concerned.
- *
- *  bko12703 reports that boot probing fails for intel SSD with
- *  hardreset.  Link fails to come online.  Softreset works fine.
- *
- * The failures are varied but the following patterns seem true for
- * all flavors.
- *
- * - Softreset during boot always works.
- *
- * - Hardreset during boot sometimes fails to bring up the link on
- *   certain comibnations and device signature acquisition is
- *   unreliable.
- *
- * - Hardreset is often necessary after hotplug.
- *
- * So, preferring softreset for boot probing and error handling (as
- * hardreset might bring down the link) but using hardreset for
- * post-boot probing should work around the above issues in most
- * cases.  Define nv_hardreset() which only kicks in for post-boot
- * probing and use it for all variants.
- */
-static struct ata_port_operations nv_generic_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.lost_interrupt		= ATA_OP_NULL,
+static const struct ata_port_operations nv_generic_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.exec_command		= ata_exec_command,
+	.check_status		= ata_check_status,
+	.dev_select		= ata_std_dev_select,
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= nv_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.data_xfer		= ata_data_xfer,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 	.scr_read		= nv_scr_read,
 	.scr_write		= nv_scr_write,
-	.hardreset		= nv_hardreset,
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations nv_nf2_ops = {
-	.inherits		= &nv_generic_ops,
+static const struct ata_port_operations nv_nf2_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.exec_command		= ata_exec_command,
+	.check_status		= ata_check_status,
+	.dev_select		= ata_std_dev_select,
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
 	.freeze			= nv_nf2_freeze,
 	.thaw			= nv_nf2_thaw,
+	.error_handler		= nv_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.data_xfer		= ata_data_xfer,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+	.scr_read		= nv_scr_read,
+	.scr_write		= nv_scr_write,
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations nv_ck804_ops = {
-	.inherits		= &nv_generic_ops,
+static const struct ata_port_operations nv_ck804_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.exec_command		= ata_exec_command,
+	.check_status		= ata_check_status,
+	.dev_select		= ata_std_dev_select,
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
 	.freeze			= nv_ck804_freeze,
 	.thaw			= nv_ck804_thaw,
+	.error_handler		= nv_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.data_xfer		= ata_data_xfer,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+	.scr_read		= nv_scr_read,
+	.scr_write		= nv_scr_write,
+	.port_start		= ata_port_start,
 	.host_stop		= nv_ck804_host_stop,
 };
 
-static struct ata_port_operations nv_adma_ops = {
-	.inherits		= &nv_ck804_ops,
-
+static const struct ata_port_operations nv_adma_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= nv_adma_tf_read,
 	.check_atapi_dma	= nv_adma_check_atapi_dma,
-	.sff_tf_read		= nv_adma_tf_read,
-	.qc_defer		= ata_std_qc_defer,
+	.exec_command		= ata_exec_command,
+	.check_status		= ata_check_status,
+	.dev_select		= ata_std_dev_select,
+	.bmdma_setup		= ata_bmdma_setup,
+	.bmdma_start		= ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
 	.qc_prep		= nv_adma_qc_prep,
 	.qc_issue		= nv_adma_qc_issue,
-	.sff_irq_clear		= nv_adma_irq_clear,
-
 	.freeze			= nv_adma_freeze,
 	.thaw			= nv_adma_thaw,
 	.error_handler		= nv_adma_error_handler,
 	.post_internal_cmd	= nv_adma_post_internal_cmd,
-
+	.data_xfer		= ata_data_xfer,
+	.irq_clear		= nv_adma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+	.scr_read		= nv_scr_read,
+	.scr_write		= nv_scr_write,
 	.port_start		= nv_adma_port_start,
 	.port_stop		= nv_adma_port_stop,
 #ifdef CONFIG_PM
@@ -509,88 +451,51 @@
 	.host_stop		= nv_adma_host_stop,
 };
 
-static struct ata_port_operations nv_swncq_ops = {
-	.inherits		= &nv_generic_ops,
-
-	.qc_defer		= ata_std_qc_defer,
-	.qc_prep		= nv_swncq_qc_prep,
-	.qc_issue		= nv_swncq_qc_issue,
-
-	.freeze			= nv_mcp55_freeze,
-	.thaw			= nv_mcp55_thaw,
-	.error_handler		= nv_swncq_error_handler,
-
-#ifdef CONFIG_PM
-	.port_suspend		= nv_swncq_port_suspend,
-	.port_resume		= nv_swncq_port_resume,
-#endif
-	.port_start		= nv_swncq_port_start,
-};
-
-struct nv_pi_priv {
-	irq_handler_t			irq_handler;
-	struct scsi_host_template	*sht;
-};
-
-#define NV_PI_PRIV(_irq_handler, _sht) \
-	&(struct nv_pi_priv){ .irq_handler = _irq_handler, .sht = _sht }
-
 static const struct ata_port_info nv_port_info[] = {
 	/* generic */
 	{
-		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY,
+		.sht		= &nv_sht,
+		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
+				  ATA_FLAG_HRST_TO_RESUME,
 		.pio_mask	= NV_PIO_MASK,
 		.mwdma_mask	= NV_MWDMA_MASK,
 		.udma_mask	= NV_UDMA_MASK,
 		.port_ops	= &nv_generic_ops,
-		.private_data	= NV_PI_PRIV(nv_generic_interrupt, &nv_sht),
+		.irq_handler	= nv_generic_interrupt,
 	},
 	/* nforce2/3 */
 	{
-		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY,
+		.sht		= &nv_sht,
+		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
+				  ATA_FLAG_HRST_TO_RESUME,
 		.pio_mask	= NV_PIO_MASK,
 		.mwdma_mask	= NV_MWDMA_MASK,
 		.udma_mask	= NV_UDMA_MASK,
 		.port_ops	= &nv_nf2_ops,
-		.private_data	= NV_PI_PRIV(nv_nf2_interrupt, &nv_sht),
+		.irq_handler	= nv_nf2_interrupt,
 	},
 	/* ck804 */
 	{
-		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY,
+		.sht		= &nv_sht,
+		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
+				  ATA_FLAG_HRST_TO_RESUME,
 		.pio_mask	= NV_PIO_MASK,
 		.mwdma_mask	= NV_MWDMA_MASK,
 		.udma_mask	= NV_UDMA_MASK,
 		.port_ops	= &nv_ck804_ops,
-		.private_data	= NV_PI_PRIV(nv_ck804_interrupt, &nv_sht),
+		.irq_handler	= nv_ck804_interrupt,
 	},
 	/* ADMA */
 	{
+		.sht		= &nv_adma_sht,
 		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
+				  ATA_FLAG_HRST_TO_RESUME |
 				  ATA_FLAG_MMIO | ATA_FLAG_NCQ,
 		.pio_mask	= NV_PIO_MASK,
 		.mwdma_mask	= NV_MWDMA_MASK,
 		.udma_mask	= NV_UDMA_MASK,
 		.port_ops	= &nv_adma_ops,
-		.private_data	= NV_PI_PRIV(nv_adma_interrupt, &nv_adma_sht),
-	},
-	/* MCP5x */
-	{
-		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY,
-		.pio_mask	= NV_PIO_MASK,
-		.mwdma_mask	= NV_MWDMA_MASK,
-		.udma_mask	= NV_UDMA_MASK,
-		.port_ops	= &nv_generic_ops,
-		.private_data	= NV_PI_PRIV(nv_generic_interrupt, &nv_sht),
-	},
-	/* SWNCQ */
-	{
-		.flags	        = ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
-				  ATA_FLAG_NCQ,
-		.pio_mask	= NV_PIO_MASK,
-		.mwdma_mask	= NV_MWDMA_MASK,
-		.udma_mask	= NV_UDMA_MASK,
-		.port_ops	= &nv_swncq_ops,
-		.private_data	= NV_PI_PRIV(nv_swncq_interrupt, &nv_swncq_sht),
+		.irq_handler	= nv_adma_interrupt,
 	},
 };
 
@@ -600,9 +505,7 @@
 MODULE_DEVICE_TABLE(pci, nv_pci_tbl);
 MODULE_VERSION(DRV_VERSION);
 
-static int adma_enabled;
-static int swncq_enabled = 1;
-static int msi_enabled;
+static int adma_enabled = 1;
 
 static void nv_adma_register_mode(struct ata_port *ap)
 {
@@ -615,12 +518,12 @@
 		return;
 
 	status = readw(mmio + NV_ADMA_STAT);
-	while (!(status & NV_ADMA_STAT_IDLE) && count < 20) {
+	while(!(status & NV_ADMA_STAT_IDLE) && count < 20) {
 		ndelay(50);
 		status = readw(mmio + NV_ADMA_STAT);
 		count++;
 	}
-	if (count == 20)
+	if(count == 20)
 		ata_port_printk(ap, KERN_WARNING,
 			"timeout waiting for ADMA IDLE, stat=0x%hx\n",
 			status);
@@ -630,12 +533,12 @@
 
 	count = 0;
 	status = readw(mmio + NV_ADMA_STAT);
-	while (!(status & NV_ADMA_STAT_LEGACY) && count < 20) {
+	while(!(status & NV_ADMA_STAT_LEGACY) && count < 20) {
 		ndelay(50);
 		status = readw(mmio + NV_ADMA_STAT);
 		count++;
 	}
-	if (count == 20)
+	if(count == 20)
 		ata_port_printk(ap, KERN_WARNING,
 			 "timeout waiting for ADMA LEGACY, stat=0x%hx\n",
 			 status);
@@ -659,13 +562,13 @@
 	writew(tmp | NV_ADMA_CTL_GO, mmio + NV_ADMA_CTL);
 
 	status = readw(mmio + NV_ADMA_STAT);
-	while (((status & NV_ADMA_STAT_LEGACY) ||
+	while(((status & NV_ADMA_STAT_LEGACY) ||
 	      !(status & NV_ADMA_STAT_IDLE)) && count < 20) {
 		ndelay(50);
 		status = readw(mmio + NV_ADMA_STAT);
 		count++;
 	}
-	if (count == 20)
+	if(count == 20)
 		ata_port_printk(ap, KERN_WARNING,
 			"timeout waiting for ADMA LEGACY clear and IDLE, stat=0x%hx\n",
 			status);
@@ -677,10 +580,9 @@
 {
 	struct ata_port *ap = ata_shost_to_port(sdev->host);
 	struct nv_adma_port_priv *pp = ap->private_data;
-	struct nv_adma_port_priv *port0, *port1;
-	struct scsi_device *sdev0, *sdev1;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	unsigned long segment_boundary, flags;
+	u64 bounce_limit;
+	unsigned long segment_boundary;
 	unsigned short sg_tablesize;
 	int rc;
 	int adma_enable;
@@ -692,9 +594,7 @@
 		/* Not a proper libata device, ignore */
 		return rc;
 
-	spin_lock_irqsave(ap->lock, flags);
-
-	if (ap->link.device[sdev->id].class == ATA_DEV_ATAPI) {
+	if (ap->device[sdev->id].class == ATA_DEV_ATAPI) {
 		/*
 		 * NVIDIA reports that ADMA mode does not support ATAPI commands.
 		 * Therefore ATAPI commands are sent through the legacy interface.
@@ -702,6 +602,7 @@
 		 * Restrict DMA parameters as required by the legacy interface
 		 * when an ATAPI device is connected.
 		 */
+		bounce_limit = ATA_DMA_MASK;
 		segment_boundary = ATA_DMA_BOUNDARY;
 		/* Subtract 1 since an extra entry may be needed for padding, see
 		   libata-scsi.c */
@@ -711,7 +612,9 @@
 		   on the port. */
 		adma_enable = 0;
 		nv_adma_register_mode(ap);
-	} else {
+	}
+	else {
+		bounce_limit = *ap->dev->dma_mask;
 		segment_boundary = NV_ADMA_DMA_BOUNDARY;
 		sg_tablesize = NV_ADMA_SGTBL_TOTAL_LEN;
 		adma_enable = 1;
@@ -719,67 +622,31 @@
 
 	pci_read_config_dword(pdev, NV_MCP_SATA_CFG_20, &current_reg);
 
-	if (ap->port_no == 1)
+	if(ap->port_no == 1)
 		config_mask = NV_MCP_SATA_CFG_20_PORT1_EN |
 			      NV_MCP_SATA_CFG_20_PORT1_PWB_EN;
 	else
 		config_mask = NV_MCP_SATA_CFG_20_PORT0_EN |
 			      NV_MCP_SATA_CFG_20_PORT0_PWB_EN;
 
-	if (adma_enable) {
+	if(adma_enable) {
 		new_reg = current_reg | config_mask;
 		pp->flags &= ~NV_ADMA_ATAPI_SETUP_COMPLETE;
-	} else {
+	}
+	else {
 		new_reg = current_reg & ~config_mask;
 		pp->flags |= NV_ADMA_ATAPI_SETUP_COMPLETE;
 	}
 
-	if (current_reg != new_reg)
+	if(current_reg != new_reg)
 		pci_write_config_dword(pdev, NV_MCP_SATA_CFG_20, new_reg);
 
-	port0 = ap->host->ports[0]->private_data;
-	port1 = ap->host->ports[1]->private_data;
-	sdev0 = ap->host->ports[0]->link.device[0].sdev;
-	sdev1 = ap->host->ports[1]->link.device[0].sdev;
-	if ((port0->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) ||
-	    (port1->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)) {
-		/** We have to set the DMA mask to 32-bit if either port is in
-		    ATAPI mode, since they are on the same PCI device which is
-		    used for DMA mapping. If we set the mask we also need to set
-		    the bounce limit on both ports to ensure that the block
-		    layer doesn't feed addresses that cause DMA mapping to
-		    choke. If either SCSI device is not allocated yet, it's OK
-		    since that port will discover its correct setting when it
-		    does get allocated.
-		    Note: Setting 32-bit mask should not fail. */
-		if (sdev0)
-			blk_queue_bounce_limit(sdev0->request_queue,
-					       ATA_DMA_MASK);
-		if (sdev1)
-			blk_queue_bounce_limit(sdev1->request_queue,
-					       ATA_DMA_MASK);
-
-		pci_set_dma_mask(pdev, ATA_DMA_MASK);
-	} else {
-		/** This shouldn't fail as it was set to this value before */
-		pci_set_dma_mask(pdev, pp->adma_dma_mask);
-		if (sdev0)
-			blk_queue_bounce_limit(sdev0->request_queue,
-					       pp->adma_dma_mask);
-		if (sdev1)
-			blk_queue_bounce_limit(sdev1->request_queue,
-					       pp->adma_dma_mask);
-	}
-
+	blk_queue_bounce_limit(sdev->request_queue, bounce_limit);
 	blk_queue_segment_boundary(sdev->request_queue, segment_boundary);
 	blk_queue_max_hw_segments(sdev->request_queue, sg_tablesize);
 	ata_port_printk(ap, KERN_INFO,
-		"DMA mask 0x%llX, segment boundary 0x%lX, hw segs %hu\n",
-		(unsigned long long)*ap->host->dev->dma_mask,
-		segment_boundary, sg_tablesize);
-
-	spin_unlock_irqrestore(ap->lock, flags);
-
+		"bounce limit 0x%llX, segment boundary 0x%lX, hw segs %hu\n",
+		(unsigned long long)bounce_limit, segment_boundary, sg_tablesize);
 	return rc;
 }
 
@@ -791,23 +658,21 @@
 
 static void nv_adma_tf_read(struct ata_port *ap, struct ata_taskfile *tf)
 {
-	/* Other than when internal or pass-through commands are executed,
-	   the only time this function will be called in ADMA mode will be
-	   if a command fails. In the failure case we don't care about going
-	   into register mode with ADMA commands pending, as the commands will
-	   all shortly be aborted anyway. We assume that NCQ commands are not
-	   issued via passthrough, which is the only way that switching into
-	   ADMA mode could abort outstanding commands. */
+	/* Since commands where a result TF is requested are not
+	   executed in ADMA mode, the only time this function will be called
+	   in ADMA mode will be if a command fails. In this case we
+	   don't care about going into register mode with ADMA commands
+	   pending, as the commands will all shortly be aborted anyway. */
 	nv_adma_register_mode(ap);
 
-	ata_sff_tf_read(ap, tf);
+	ata_tf_read(ap, tf);
 }
 
 static unsigned int nv_adma_tf_to_cpb(struct ata_taskfile *tf, __le16 *cpb)
 {
 	unsigned int idx = 0;
 
-	if (tf->flags & ATA_TFLAG_ISADDR) {
+	if(tf->flags & ATA_TFLAG_ISADDR) {
 		if (tf->flags & ATA_TFLAG_LBA48) {
 			cpb[idx++] = cpu_to_le16((ATA_REG_ERR   << 8) | tf->hob_feature | WNB);
 			cpb[idx++] = cpu_to_le16((ATA_REG_NSECT << 8) | tf->hob_nsect);
@@ -824,12 +689,12 @@
 		cpb[idx++] = cpu_to_le16((ATA_REG_LBAH   << 8) | tf->lbah);
 	}
 
-	if (tf->flags & ATA_TFLAG_DEVICE)
+	if(tf->flags & ATA_TFLAG_DEVICE)
 		cpb[idx++] = cpu_to_le16((ATA_REG_DEVICE << 8) | tf->device);
 
 	cpb[idx++] = cpu_to_le16((ATA_REG_CMD    << 8) | tf->command | CMDEND);
 
-	while (idx < 12)
+	while(idx < 12)
 		cpb[idx++] = cpu_to_le16(IGN);
 
 	return idx;
@@ -846,11 +711,11 @@
 		     flags & (NV_CPB_RESP_ATA_ERR |
 			      NV_CPB_RESP_CMD_ERR |
 			      NV_CPB_RESP_CPB_ERR)))) {
-		struct ata_eh_info *ehi = &ap->link.eh_info;
+		struct ata_eh_info *ehi = &ap->eh_info;
 		int freeze = 0;
 
 		ata_ehi_clear_desc(ehi);
-		__ata_ehi_push_desc(ehi, "CPB resp_flags 0x%x: ", flags);
+		__ata_ehi_push_desc(ehi, "CPB resp_flags 0x%x: ", flags );
 		if (flags & NV_CPB_RESP_ATA_ERR) {
 			ata_ehi_push_desc(ehi, "ATA error");
 			ehi->err_mask |= AC_ERR_DEV;
@@ -879,18 +744,17 @@
 		struct ata_queued_cmd *qc = ata_qc_from_tag(ap, cpb_num);
 		VPRINTK("CPB flags done, flags=0x%x\n", flags);
 		if (likely(qc)) {
-			DPRINTK("Completing qc from tag %d\n", cpb_num);
+			DPRINTK("Completing qc from tag %d\n",cpb_num);
 			ata_qc_complete(qc);
 		} else {
-			struct ata_eh_info *ehi = &ap->link.eh_info;
+			struct ata_eh_info *ehi = &ap->eh_info;
 			/* Notifier bits set without a command may indicate the drive
 			   is misbehaving. Raise host state machine violation on this
 			   condition. */
-			ata_port_printk(ap, KERN_ERR,
-					"notifier for tag %d with no cmd?\n",
-					cpb_num);
+			ata_port_printk(ap, KERN_ERR, "notifier for tag %d with no command?\n",
+				cpb_num);
 			ehi->err_mask |= AC_ERR_HSM;
-			ehi->action |= ATA_EH_RESET;
+			ehi->action |= ATA_EH_SOFTRESET;
 			ata_port_freeze(ap);
 			return 1;
 		}
@@ -900,7 +764,7 @@
 
 static int nv_host_intr(struct ata_port *ap, u8 irq_stat)
 {
-	struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->link.active_tag);
+	struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->active_tag);
 
 	/* freeze if hotplugged */
 	if (unlikely(irq_stat & (NV_INT_ADDED | NV_INT_REMOVED))) {
@@ -914,12 +778,12 @@
 
 	/* DEV interrupt w/ no active qc? */
 	if (unlikely(!qc || (qc->tf.flags & ATA_TFLAG_POLLING))) {
-		ata_sff_check_status(ap);
+		ata_check_status(ap);
 		return 1;
 	}
 
 	/* handle interrupt */
-	return ata_sff_host_intr(ap, qc);
+	return ata_host_intr(ap, qc);
 }
 
 static irqreturn_t nv_adma_interrupt(int irq, void *dev_instance)
@@ -953,7 +817,7 @@
 			if (pp->flags & NV_ADMA_PORT_REGISTER_MODE) {
 				u8 irq_stat = readb(host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_CK804)
 					>> (NV_INT_PORT_SHIFT * i);
-				if (ata_tag_valid(ap->link.active_tag))
+				if(ata_tag_valid(ap->active_tag))
 					/** NV_INT_DEV indication seems unreliable at times
 					    at least in ADMA mode. Force it on always when a
 					    command is active, to prevent losing interrupts. */
@@ -967,7 +831,7 @@
 
 			gen_ctl = readl(pp->gen_block + NV_ADMA_GEN_CTL);
 
-			if (!NV_ADMA_CHECK_INTR(gen_ctl, ap->port_no) && !notifier &&
+			if( !NV_ADMA_CHECK_INTR(gen_ctl, ap->port_no) && !notifier &&
 			    !notifier_error)
 				/* Nothing to do */
 				continue;
@@ -988,10 +852,10 @@
 					       NV_ADMA_STAT_HOTUNPLUG |
 					       NV_ADMA_STAT_TIMEOUT |
 					       NV_ADMA_STAT_SERROR))) {
-				struct ata_eh_info *ehi = &ap->link.eh_info;
+				struct ata_eh_info *ehi = &ap->eh_info;
 
 				ata_ehi_clear_desc(ehi);
-				__ata_ehi_push_desc(ehi, "ADMA status 0x%08x: ", status);
+				__ata_ehi_push_desc(ehi, "ADMA status 0x%08x: ", status );
 				if (status & NV_ADMA_STAT_TIMEOUT) {
 					ehi->err_mask |= AC_ERR_SYSTEM;
 					ata_ehi_push_desc(ehi, "timeout");
@@ -1011,33 +875,27 @@
 			}
 
 			if (status & (NV_ADMA_STAT_DONE |
-				      NV_ADMA_STAT_CPBERR |
-				      NV_ADMA_STAT_CMD_COMPLETE)) {
-				u32 check_commands = notifier_clears[i];
+				      NV_ADMA_STAT_CPBERR)) {
+				u32 check_commands;
 				int pos, error = 0;
 
-				if (status & NV_ADMA_STAT_CPBERR) {
-					/* Check all active commands */
-					if (ata_tag_valid(ap->link.active_tag))
-						check_commands = 1 <<
-							ap->link.active_tag;
-					else
-						check_commands = ap->
-							link.sactive;
-				}
+				if(ata_tag_valid(ap->active_tag))
+					check_commands = 1 << ap->active_tag;
+				else
+					check_commands = ap->sactive;
 
 				/** Check CPBs for completed commands */
 				while ((pos = ffs(check_commands)) && !error) {
 					pos--;
 					error = nv_adma_check_cpb(ap, pos,
-						notifier_error & (1 << pos));
-					check_commands &= ~(1 << pos);
+						notifier_error & (1 << pos) );
+					check_commands &= ~(1 << pos );
 				}
 			}
 		}
 	}
 
-	if (notifier_clears[0] || notifier_clears[1]) {
+	if(notifier_clears[0] || notifier_clears[1]) {
 		/* Note: Both notifier clear registers must be written
 		   if either is set, even if one is zero, according to NVIDIA. */
 		struct nv_adma_port_priv *pp = host->ports[0]->private_data;
@@ -1063,14 +921,14 @@
 		return;
 
 	/* clear any outstanding CK804 notifications */
-	writeb(NV_INT_ALL << (ap->port_no * NV_INT_PORT_SHIFT),
+	writeb( NV_INT_ALL << (ap->port_no * NV_INT_PORT_SHIFT),
 		ap->host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_CK804);
 
 	/* Disable interrupt */
 	tmp = readw(mmio + NV_ADMA_CTL);
-	writew(tmp & ~(NV_ADMA_CTL_AIEN | NV_ADMA_CTL_HOTPLUG_IEN),
+	writew( tmp & ~(NV_ADMA_CTL_AIEN | NV_ADMA_CTL_HOTPLUG_IEN),
 		mmio + NV_ADMA_CTL);
-	readw(mmio + NV_ADMA_CTL);	/* flush posted write */
+	readw( mmio + NV_ADMA_CTL );	/* flush posted write */
 }
 
 static void nv_adma_thaw(struct ata_port *ap)
@@ -1086,9 +944,9 @@
 
 	/* Enable interrupt */
 	tmp = readw(mmio + NV_ADMA_CTL);
-	writew(tmp | (NV_ADMA_CTL_AIEN | NV_ADMA_CTL_HOTPLUG_IEN),
+	writew( tmp | (NV_ADMA_CTL_AIEN | NV_ADMA_CTL_HOTPLUG_IEN),
 		mmio + NV_ADMA_CTL);
-	readw(mmio + NV_ADMA_CTL);	/* flush posted write */
+	readw( mmio + NV_ADMA_CTL );	/* flush posted write */
 }
 
 static void nv_adma_irq_clear(struct ata_port *ap)
@@ -1098,12 +956,12 @@
 	u32 notifier_clears[2];
 
 	if (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) {
-		ata_sff_irq_clear(ap);
+		ata_bmdma_irq_clear(ap);
 		return;
 	}
 
 	/* clear any outstanding CK804 notifications */
-	writeb(NV_INT_ALL << (ap->port_no * NV_INT_PORT_SHIFT),
+	writeb( NV_INT_ALL << (ap->port_no * NV_INT_PORT_SHIFT),
 		ap->host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_CK804);
 
 	/* clear ADMA status */
@@ -1128,8 +986,8 @@
 {
 	struct nv_adma_port_priv *pp = qc->ap->private_data;
 
-	if (pp->flags & NV_ADMA_PORT_REGISTER_MODE)
-		ata_sff_post_internal_cmd(qc);
+	if(pp->flags & NV_ADMA_PORT_REGISTER_MODE)
+		ata_bmdma_post_internal_cmd(qc);
 }
 
 static int nv_adma_port_start(struct ata_port *ap)
@@ -1140,20 +998,10 @@
 	void *mem;
 	dma_addr_t mem_dma;
 	void __iomem *mmio;
-	struct pci_dev *pdev = to_pci_dev(dev);
 	u16 tmp;
 
 	VPRINTK("ENTER\n");
 
-	/* Ensure DMA mask is set to 32-bit before allocating legacy PRD and
-	   pad buffers */
-	rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
-	if (rc)
-		return rc;
-	rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
-	if (rc)
-		return rc;
-
 	rc = ata_port_start(ap);
 	if (rc)
 		return rc;
@@ -1169,15 +1017,6 @@
 	pp->notifier_clear_block = pp->gen_block +
 	       NV_ADMA_NOTIFIER_CLEAR + (4 * ap->port_no);
 
-	/* Now that the legacy PRD and padding buffer are allocated we can
-	   safely raise the DMA mask to allocate the CPB/APRD table.
-	   These are allowed to fail since we store the value that ends up
-	   being used to set as the bounce limit in slave_config later if
-	   needed. */
-	pci_set_dma_mask(pdev, DMA_BIT_MASK(64));
-	pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
-	pp->adma_dma_mask = *dev->dma_mask;
-
 	mem = dmam_alloc_coherent(dev, NV_ADMA_PORT_PRIV_DMA_SZ,
 				  &mem_dma, GFP_KERNEL);
 	if (!mem)
@@ -1193,7 +1032,7 @@
 	pp->cpb_dma = mem_dma;
 
 	writel(mem_dma & 0xFFFFFFFF, 	mmio + NV_ADMA_CPB_BASE_LOW);
-	writel((mem_dma >> 16) >> 16,	mmio + NV_ADMA_CPB_BASE_HIGH);
+	writel((mem_dma >> 16 ) >> 16,	mmio + NV_ADMA_CPB_BASE_HIGH);
 
 	mem     += NV_ADMA_MAX_CPBS * NV_ADMA_CPB_SZ;
 	mem_dma += NV_ADMA_MAX_CPBS * NV_ADMA_CPB_SZ;
@@ -1217,15 +1056,15 @@
 
 	/* clear GO for register mode, enable interrupt */
 	tmp = readw(mmio + NV_ADMA_CTL);
-	writew((tmp & ~NV_ADMA_CTL_GO) | NV_ADMA_CTL_AIEN |
-		NV_ADMA_CTL_HOTPLUG_IEN, mmio + NV_ADMA_CTL);
+	writew( (tmp & ~NV_ADMA_CTL_GO) | NV_ADMA_CTL_AIEN |
+		 NV_ADMA_CTL_HOTPLUG_IEN, mmio + NV_ADMA_CTL);
 
 	tmp = readw(mmio + NV_ADMA_CTL);
 	writew(tmp | NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);
-	readw(mmio + NV_ADMA_CTL);	/* flush posted write */
+	readw( mmio + NV_ADMA_CTL );	/* flush posted write */
 	udelay(1);
 	writew(tmp & ~NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);
-	readw(mmio + NV_ADMA_CTL);	/* flush posted write */
+	readw( mmio + NV_ADMA_CTL );	/* flush posted write */
 
 	return 0;
 }
@@ -1265,7 +1104,7 @@
 
 	/* set CPB block location */
 	writel(pp->cpb_dma & 0xFFFFFFFF, 	mmio + NV_ADMA_CPB_BASE_LOW);
-	writel((pp->cpb_dma >> 16) >> 16,	mmio + NV_ADMA_CPB_BASE_HIGH);
+	writel((pp->cpb_dma >> 16 ) >> 16,	mmio + NV_ADMA_CPB_BASE_HIGH);
 
 	/* clear any outstanding interrupt conditions */
 	writew(0xffff, mmio + NV_ADMA_STAT);
@@ -1278,15 +1117,15 @@
 
 	/* clear GO for register mode, enable interrupt */
 	tmp = readw(mmio + NV_ADMA_CTL);
-	writew((tmp & ~NV_ADMA_CTL_GO) | NV_ADMA_CTL_AIEN |
-		NV_ADMA_CTL_HOTPLUG_IEN, mmio + NV_ADMA_CTL);
+	writew( (tmp & ~NV_ADMA_CTL_GO) | NV_ADMA_CTL_AIEN |
+		 NV_ADMA_CTL_HOTPLUG_IEN, mmio + NV_ADMA_CTL);
 
 	tmp = readw(mmio + NV_ADMA_CTL);
 	writew(tmp | NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);
-	readw(mmio + NV_ADMA_CTL);	/* flush posted write */
+	readw( mmio + NV_ADMA_CTL );	/* flush posted write */
 	udelay(1);
 	writew(tmp & ~NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);
-	readw(mmio + NV_ADMA_CTL);	/* flush posted write */
+	readw( mmio + NV_ADMA_CTL );	/* flush posted write */
 
 	return 0;
 }
@@ -1361,18 +1200,20 @@
 static void nv_adma_fill_sg(struct ata_queued_cmd *qc, struct nv_adma_cpb *cpb)
 {
 	struct nv_adma_port_priv *pp = qc->ap->private_data;
+	unsigned int idx;
 	struct nv_adma_prd *aprd;
 	struct scatterlist *sg;
-	unsigned int si;
 
 	VPRINTK("ENTER\n");
 
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		aprd = (si < 5) ? &cpb->aprd[si] :
-			       &pp->aprd[NV_ADMA_SGTBL_LEN * qc->tag + (si-5)];
-		nv_adma_fill_aprd(qc, sg, si, aprd);
+	idx = 0;
+
+	ata_for_each_sg(sg, qc) {
+		aprd = (idx < 5) ? &cpb->aprd[idx] : &pp->aprd[NV_ADMA_SGTBL_LEN * qc->tag + (idx-5)];
+		nv_adma_fill_aprd(qc, sg, idx, aprd);
+		idx++;
 	}
-	if (si > 5)
+	if (idx > 5)
 		cpb->next_aprd = cpu_to_le64(((u64)(pp->aprd_dma + NV_ADMA_SGTBL_SZ * qc->tag)));
 	else
 		cpb->next_aprd = cpu_to_le64(0);
@@ -1383,12 +1224,14 @@
 	struct nv_adma_port_priv *pp = qc->ap->private_data;
 
 	/* ADMA engine can only be used for non-ATAPI DMA commands,
-	   or interrupt-driven no-data commands. */
-	if ((pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) ||
-	   (qc->tf.flags & ATA_TFLAG_POLLING))
+	   or interrupt-driven no-data commands, where a result taskfile
+	   is not required. */
+	if((pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) ||
+	   (qc->tf.flags & ATA_TFLAG_POLLING) ||
+	   (qc->flags & ATA_QCFLAG_RESULT_TF))
 		return 1;
 
-	if ((qc->flags & ATA_QCFLAG_DMAMAP) ||
+	if((qc->flags & ATA_QCFLAG_DMAMAP) ||
 	   (qc->tf.protocol == ATA_PROT_NODATA))
 		return 0;
 
@@ -1403,10 +1246,8 @@
 		       NV_CPB_CTL_IEN;
 
 	if (nv_adma_use_reg_mode(qc)) {
-		BUG_ON(!(pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) &&
-			(qc->flags & ATA_QCFLAG_DMAMAP));
 		nv_adma_register_mode(qc->ap);
-		ata_sff_qc_prep(qc);
+		ata_qc_prep(qc);
 		return;
 	}
 
@@ -1427,14 +1268,14 @@
 
 	nv_adma_tf_to_cpb(&qc->tf, cpb->tf);
 
-	if (qc->flags & ATA_QCFLAG_DMAMAP) {
+	if(qc->flags & ATA_QCFLAG_DMAMAP) {
 		nv_adma_fill_sg(qc, cpb);
 		ctl_flags |= NV_CPB_CTL_APRD_VALID;
 	} else
 		memset(&cpb->aprd[0], 0, sizeof(struct nv_adma_prd) * 5);
 
-	/* Be paranoid and don't let the device see NV_CPB_CTL_CPB_VALID
-	   until we are finished filling in all of the contents */
+	/* Be paranoid and don't let the device see NV_CPB_CTL_CPB_VALID until we are
+	   finished filling in all of the contents */
 	wmb();
 	cpb->ctl_flags = ctl_flags;
 	wmb();
@@ -1449,23 +1290,11 @@
 
 	VPRINTK("ENTER\n");
 
-	/* We can't handle result taskfile with NCQ commands, since
-	   retrieving the taskfile switches us out of ADMA mode and would abort
-	   existing commands. */
-	if (unlikely(qc->tf.protocol == ATA_PROT_NCQ &&
-		     (qc->flags & ATA_QCFLAG_RESULT_TF))) {
-		ata_dev_printk(qc->dev, KERN_ERR,
-			"NCQ w/ RESULT_TF not allowed\n");
-		return AC_ERR_SYSTEM;
-	}
-
 	if (nv_adma_use_reg_mode(qc)) {
 		/* use ATA register mode */
 		VPRINTK("using ATA register mode: 0x%lx\n", qc->flags);
-		BUG_ON(!(pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) &&
-			(qc->flags & ATA_QCFLAG_DMAMAP));
 		nv_adma_register_mode(qc->ap);
-		return ata_sff_qc_issue(qc);
+		return ata_qc_issue_prot(qc);
 	} else
 		nv_adma_mode(qc->ap);
 
@@ -1473,16 +1302,16 @@
 	   and (number of cpbs to append -1) in top 8 bits */
 	wmb();
 
-	if (curr_ncq != pp->last_issue_ncq) {
-		/* Seems to need some delay before switching between NCQ and
-		   non-NCQ commands, else we get command timeouts and such. */
+	if(curr_ncq != pp->last_issue_ncq) {
+	   	/* Seems to need some delay before switching between NCQ and non-NCQ
+		   commands, else we get command timeouts and such. */
 		udelay(20);
 		pp->last_issue_ncq = curr_ncq;
 	}
 
 	writew(qc->tag, mmio + NV_ADMA_APPEND);
 
-	DPRINTK("Issued tag %u\n", qc->tag);
+	DPRINTK("Issued tag %u\n",qc->tag);
 
 	return 0;
 }
@@ -1504,13 +1333,13 @@
 		    !(ap->flags & ATA_FLAG_DISABLED)) {
 			struct ata_queued_cmd *qc;
 
-			qc = ata_qc_from_tag(ap, ap->link.active_tag);
+			qc = ata_qc_from_tag(ap, ap->active_tag);
 			if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)))
-				handled += ata_sff_host_intr(ap, qc);
+				handled += ata_host_intr(ap, qc);
 			else
 				// No request pending?  Clear interrupt status
 				// anyway, in case there's one pending.
-				ap->ops->sff_check_status(ap);
+				ap->ops->check_status(ap);
 		}
 
 	}
@@ -1564,56 +1393,24 @@
 	return ret;
 }
 
-static int nv_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)
+static int nv_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
 
-	*val = ioread32(link->ap->ioaddr.scr_addr + (sc_reg * 4));
+	*val = ioread32(ap->ioaddr.scr_addr + (sc_reg * 4));
 	return 0;
 }
 
-static int nv_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)
+static int nv_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
 
-	iowrite32(val, link->ap->ioaddr.scr_addr + (sc_reg * 4));
+	iowrite32(val, ap->ioaddr.scr_addr + (sc_reg * 4));
 	return 0;
 }
 
-static int nv_hardreset(struct ata_link *link, unsigned int *class,
-			unsigned long deadline)
-{
-	struct ata_eh_context *ehc = &link->eh_context;
-
-	/* Do hardreset iff it's post-boot probing, please read the
-	 * comment above port ops for details.
-	 */
-	if (!(link->ap->pflags & ATA_PFLAG_LOADING) &&
-	    !ata_dev_enabled(link->device))
-		sata_link_hardreset(link, sata_deb_timing_hotplug, deadline,
-				    NULL, NULL);
-	else {
-		const unsigned long *timing = sata_ehc_deb_timing(ehc);
-		int rc;
-
-		if (!(ehc->i.flags & ATA_EHI_QUIET))
-			ata_link_printk(link, KERN_INFO, "nv: skipping "
-					"hardreset on occupied port\n");
-
-		/* make sure the link is online */
-		rc = sata_link_resume(link, timing, deadline);
-		/* whine about phy resume failure but proceed */
-		if (rc && rc != -EOPNOTSUPP)
-			ata_link_printk(link, KERN_WARNING, "failed to resume "
-					"link (errno=%d)\n", rc);
-	}
-
-	/* device signature acquisition is unreliable */
-	return -EAGAIN;
-}
-
 static void nv_nf2_freeze(struct ata_port *ap)
 {
 	void __iomem *scr_addr = ap->host->ports[0]->ioaddr.scr_addr;
@@ -1662,41 +1459,33 @@
 	writeb(mask, mmio_base + NV_INT_ENABLE_CK804);
 }
 
-static void nv_mcp55_freeze(struct ata_port *ap)
+static int nv_hardreset(struct ata_port *ap, unsigned int *class,
+			unsigned long deadline)
 {
-	void __iomem *mmio_base = ap->host->iomap[NV_MMIO_BAR];
-	int shift = ap->port_no * NV_INT_PORT_SHIFT_MCP55;
-	u32 mask;
+	unsigned int dummy;
 
-	writel(NV_INT_ALL_MCP55 << shift, mmio_base + NV_INT_STATUS_MCP55);
-
-	mask = readl(mmio_base + NV_INT_ENABLE_MCP55);
-	mask &= ~(NV_INT_ALL_MCP55 << shift);
-	writel(mask, mmio_base + NV_INT_ENABLE_MCP55);
+	/* SATA hardreset fails to retrieve proper device signature on
+	 * some controllers.  Don't classify on hardreset.  For more
+	 * info, see http://bugme.osdl.org/show_bug.cgi?id=3352
+	 */
+	return sata_std_hardreset(ap, &dummy, deadline);
 }
 
-static void nv_mcp55_thaw(struct ata_port *ap)
+static void nv_error_handler(struct ata_port *ap)
 {
-	void __iomem *mmio_base = ap->host->iomap[NV_MMIO_BAR];
-	int shift = ap->port_no * NV_INT_PORT_SHIFT_MCP55;
-	u32 mask;
-
-	writel(NV_INT_ALL_MCP55 << shift, mmio_base + NV_INT_STATUS_MCP55);
-
-	mask = readl(mmio_base + NV_INT_ENABLE_MCP55);
-	mask |= (NV_INT_MASK_MCP55 << shift);
-	writel(mask, mmio_base + NV_INT_ENABLE_MCP55);
+	ata_bmdma_drive_eh(ap, ata_std_prereset, ata_std_softreset,
+			   nv_hardreset, ata_std_postreset);
 }
 
 static void nv_adma_error_handler(struct ata_port *ap)
 {
 	struct nv_adma_port_priv *pp = ap->private_data;
-	if (!(pp->flags & NV_ADMA_PORT_REGISTER_MODE)) {
+	if(!(pp->flags & NV_ADMA_PORT_REGISTER_MODE)) {
 		void __iomem *mmio = pp->ctl_block;
 		int i;
 		u16 tmp;
 
-		if (ata_tag_valid(ap->link.active_tag) || ap->link.sactive) {
+		if(ata_tag_valid(ap->active_tag) || ap->sactive) {
 			u32 notifier = readl(mmio + NV_ADMA_NOTIFIER);
 			u32 notifier_error = readl(mmio + NV_ADMA_NOTIFIER_ERROR);
 			u32 gen_ctl = readl(pp->gen_block + NV_ADMA_GEN_CTL);
@@ -1704,17 +1493,16 @@
 			u8 cpb_count = readb(mmio + NV_ADMA_CPB_COUNT);
 			u8 next_cpb_idx = readb(mmio + NV_ADMA_NEXT_CPB_IDX);
 
-			ata_port_printk(ap, KERN_ERR,
-				"EH in ADMA mode, notifier 0x%X "
+			ata_port_printk(ap, KERN_ERR, "EH in ADMA mode, notifier 0x%X "
 				"notifier_error 0x%X gen_ctl 0x%X status 0x%X "
 				"next cpb count 0x%X next cpb idx 0x%x\n",
 				notifier, notifier_error, gen_ctl, status,
 				cpb_count, next_cpb_idx);
 
-			for (i = 0; i < NV_ADMA_MAX_CPBS; i++) {
+			for( i=0;i<NV_ADMA_MAX_CPBS;i++) {
 				struct nv_adma_cpb *cpb = &pp->cpb[i];
-				if ((ata_tag_valid(ap->link.active_tag) && i == ap->link.active_tag) ||
-				    ap->link.sactive & (1 << i))
+				if( (ata_tag_valid(ap->active_tag) && i == ap->active_tag) ||
+				    ap->sactive & (1 << i) )
 					ata_port_printk(ap, KERN_ERR,
 						"CPB %d: ctl_flags 0x%x, resp_flags 0x%x\n",
 						i, cpb->ctl_flags, cpb->resp_flags);
@@ -1724,9 +1512,8 @@
 		/* Push us back into port register mode for error handling. */
 		nv_adma_register_mode(ap);
 
-		/* Mark all of the CPBs as invalid to prevent them from
-		   being executed */
-		for (i = 0; i < NV_ADMA_MAX_CPBS; i++)
+		/* Mark all of the CPBs as invalid to prevent them from being executed */
+		for( i=0;i<NV_ADMA_MAX_CPBS;i++)
 			pp->cpb[i].ctl_flags &= ~NV_CPB_CTL_CPB_VALID;
 
 		/* clear CPB fetch count */
@@ -1735,672 +1522,20 @@
 		/* Reset channel */
 		tmp = readw(mmio + NV_ADMA_CTL);
 		writew(tmp | NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);
-		readw(mmio + NV_ADMA_CTL);	/* flush posted write */
+		readw( mmio + NV_ADMA_CTL );	/* flush posted write */
 		udelay(1);
 		writew(tmp & ~NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);
-		readw(mmio + NV_ADMA_CTL);	/* flush posted write */
-	}
-
-	ata_sff_error_handler(ap);
-}
-
-static void nv_swncq_qc_to_dq(struct ata_port *ap, struct ata_queued_cmd *qc)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-	struct defer_queue *dq = &pp->defer_queue;
-
-	/* queue is full */
-	WARN_ON(dq->tail - dq->head == ATA_MAX_QUEUE);
-	dq->defer_bits |= (1 << qc->tag);
-	dq->tag[dq->tail++ & (ATA_MAX_QUEUE - 1)] = qc->tag;
-}
-
-static struct ata_queued_cmd *nv_swncq_qc_from_dq(struct ata_port *ap)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-	struct defer_queue *dq = &pp->defer_queue;
-	unsigned int tag;
-
-	if (dq->head == dq->tail)	/* null queue */
-		return NULL;
-
-	tag = dq->tag[dq->head & (ATA_MAX_QUEUE - 1)];
-	dq->tag[dq->head++ & (ATA_MAX_QUEUE - 1)] = ATA_TAG_POISON;
-	WARN_ON(!(dq->defer_bits & (1 << tag)));
-	dq->defer_bits &= ~(1 << tag);
-
-	return ata_qc_from_tag(ap, tag);
-}
-
-static void nv_swncq_fis_reinit(struct ata_port *ap)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-
-	pp->dhfis_bits = 0;
-	pp->dmafis_bits = 0;
-	pp->sdbfis_bits = 0;
-	pp->ncq_flags = 0;
-}
-
-static void nv_swncq_pp_reinit(struct ata_port *ap)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-	struct defer_queue *dq = &pp->defer_queue;
-
-	dq->head = 0;
-	dq->tail = 0;
-	dq->defer_bits = 0;
-	pp->qc_active = 0;
-	pp->last_issue_tag = ATA_TAG_POISON;
-	nv_swncq_fis_reinit(ap);
-}
-
-static void nv_swncq_irq_clear(struct ata_port *ap, u16 fis)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-
-	writew(fis, pp->irq_block);
-}
-
-static void __ata_bmdma_stop(struct ata_port *ap)
-{
-	struct ata_queued_cmd qc;
-
-	qc.ap = ap;
-	ata_bmdma_stop(&qc);
-}
-
-static void nv_swncq_ncq_stop(struct ata_port *ap)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-	unsigned int i;
-	u32 sactive;
-	u32 done_mask;
-
-	ata_port_printk(ap, KERN_ERR,
-			"EH in SWNCQ mode,QC:qc_active 0x%X sactive 0x%X\n",
-			ap->qc_active, ap->link.sactive);
-	ata_port_printk(ap, KERN_ERR,
-		"SWNCQ:qc_active 0x%X defer_bits 0x%X last_issue_tag 0x%x\n  "
-		"dhfis 0x%X dmafis 0x%X sdbfis 0x%X\n",
-		pp->qc_active, pp->defer_queue.defer_bits, pp->last_issue_tag,
-		pp->dhfis_bits, pp->dmafis_bits, pp->sdbfis_bits);
-
-	ata_port_printk(ap, KERN_ERR, "ATA_REG 0x%X ERR_REG 0x%X\n",
-			ap->ops->sff_check_status(ap),
-			ioread8(ap->ioaddr.error_addr));
-
-	sactive = readl(pp->sactive_block);
-	done_mask = pp->qc_active ^ sactive;
-
-	ata_port_printk(ap, KERN_ERR, "tag : dhfis dmafis sdbfis sacitve\n");
-	for (i = 0; i < ATA_MAX_QUEUE; i++) {
-		u8 err = 0;
-		if (pp->qc_active & (1 << i))
-			err = 0;
-		else if (done_mask & (1 << i))
-			err = 1;
-		else
-			continue;
-
-		ata_port_printk(ap, KERN_ERR,
-				"tag 0x%x: %01x %01x %01x %01x %s\n", i,
-				(pp->dhfis_bits >> i) & 0x1,
-				(pp->dmafis_bits >> i) & 0x1,
-				(pp->sdbfis_bits >> i) & 0x1,
-				(sactive >> i) & 0x1,
-				(err ? "error! tag doesn't exit" : " "));
-	}
-
-	nv_swncq_pp_reinit(ap);
-	ap->ops->sff_irq_clear(ap);
-	__ata_bmdma_stop(ap);
-	nv_swncq_irq_clear(ap, 0xffff);
-}
-
-static void nv_swncq_error_handler(struct ata_port *ap)
-{
-	struct ata_eh_context *ehc = &ap->link.eh_context;
-
-	if (ap->link.sactive) {
-		nv_swncq_ncq_stop(ap);
-		ehc->i.action |= ATA_EH_RESET;
-	}
-
-	ata_sff_error_handler(ap);
-}
-
-#ifdef CONFIG_PM
-static int nv_swncq_port_suspend(struct ata_port *ap, pm_message_t mesg)
-{
-	void __iomem *mmio = ap->host->iomap[NV_MMIO_BAR];
-	u32 tmp;
-
-	/* clear irq */
-	writel(~0, mmio + NV_INT_STATUS_MCP55);
-
-	/* disable irq */
-	writel(0, mmio + NV_INT_ENABLE_MCP55);
-
-	/* disable swncq */
-	tmp = readl(mmio + NV_CTL_MCP55);
-	tmp &= ~(NV_CTL_PRI_SWNCQ | NV_CTL_SEC_SWNCQ);
-	writel(tmp, mmio + NV_CTL_MCP55);
-
-	return 0;
-}
-
-static int nv_swncq_port_resume(struct ata_port *ap)
-{
-	void __iomem *mmio = ap->host->iomap[NV_MMIO_BAR];
-	u32 tmp;
-
-	/* clear irq */
-	writel(~0, mmio + NV_INT_STATUS_MCP55);
-
-	/* enable irq */
-	writel(0x00fd00fd, mmio + NV_INT_ENABLE_MCP55);
-
-	/* enable swncq */
-	tmp = readl(mmio + NV_CTL_MCP55);
-	writel(tmp | NV_CTL_PRI_SWNCQ | NV_CTL_SEC_SWNCQ, mmio + NV_CTL_MCP55);
-
-	return 0;
-}
-#endif
-
-static void nv_swncq_host_init(struct ata_host *host)
-{
-	u32 tmp;
-	void __iomem *mmio = host->iomap[NV_MMIO_BAR];
-	struct pci_dev *pdev = to_pci_dev(host->dev);
-	u8 regval;
-
-	/* disable  ECO 398 */
-	pci_read_config_byte(pdev, 0x7f, &regval);
-	regval &= ~(1 << 7);
-	pci_write_config_byte(pdev, 0x7f, regval);
-
-	/* enable swncq */
-	tmp = readl(mmio + NV_CTL_MCP55);
-	VPRINTK("HOST_CTL:0x%X\n", tmp);
-	writel(tmp | NV_CTL_PRI_SWNCQ | NV_CTL_SEC_SWNCQ, mmio + NV_CTL_MCP55);
-
-	/* enable irq intr */
-	tmp = readl(mmio + NV_INT_ENABLE_MCP55);
-	VPRINTK("HOST_ENABLE:0x%X\n", tmp);
-	writel(tmp | 0x00fd00fd, mmio + NV_INT_ENABLE_MCP55);
-
-	/*  clear port irq */
-	writel(~0x0, mmio + NV_INT_STATUS_MCP55);
-}
-
-static int nv_swncq_slave_config(struct scsi_device *sdev)
-{
-	struct ata_port *ap = ata_shost_to_port(sdev->host);
-	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
-	struct ata_device *dev;
-	int rc;
-	u8 rev;
-	u8 check_maxtor = 0;
-	unsigned char model_num[ATA_ID_PROD_LEN + 1];
-
-	rc = ata_scsi_slave_config(sdev);
-	if (sdev->id >= ATA_MAX_DEVICES || sdev->channel || sdev->lun)
-		/* Not a proper libata device, ignore */
-		return rc;
-
-	dev = &ap->link.device[sdev->id];
-	if (!(ap->flags & ATA_FLAG_NCQ) || dev->class == ATA_DEV_ATAPI)
-		return rc;
-
-	/* if MCP51 and Maxtor, then disable ncq */
-	if (pdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP51_SATA ||
-		pdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP51_SATA2)
-		check_maxtor = 1;
-
-	/* if MCP55 and rev <= a2 and Maxtor, then disable ncq */
-	if (pdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP55_SATA ||
-		pdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP55_SATA2) {
-		pci_read_config_byte(pdev, 0x8, &rev);
-		if (rev <= 0xa2)
-			check_maxtor = 1;
+		readw( mmio + NV_ADMA_CTL );	/* flush posted write */
 	}
 
-	if (!check_maxtor)
-		return rc;
-
-	ata_id_c_string(dev->id, model_num, ATA_ID_PROD, sizeof(model_num));
-
-	if (strncmp(model_num, "Maxtor", 6) == 0) {
-		ata_scsi_change_queue_depth(sdev, 1);
-		ata_dev_printk(dev, KERN_NOTICE,
-			"Disabling SWNCQ mode (depth %x)\n", sdev->queue_depth);
-	}
-
-	return rc;
-}
-
-static int nv_swncq_port_start(struct ata_port *ap)
-{
-	struct device *dev = ap->host->dev;
-	void __iomem *mmio = ap->host->iomap[NV_MMIO_BAR];
-	struct nv_swncq_port_priv *pp;
-	int rc;
-
-	rc = ata_port_start(ap);
-	if (rc)
-		return rc;
-
-	pp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);
-	if (!pp)
-		return -ENOMEM;
-
-	pp->prd = dmam_alloc_coherent(dev, ATA_PRD_TBL_SZ * ATA_MAX_QUEUE,
-				      &pp->prd_dma, GFP_KERNEL);
-	if (!pp->prd)
-		return -ENOMEM;
-	memset(pp->prd, 0, ATA_PRD_TBL_SZ * ATA_MAX_QUEUE);
-
-	ap->private_data = pp;
-	pp->sactive_block = ap->ioaddr.scr_addr + 4 * SCR_ACTIVE;
-	pp->irq_block = mmio + NV_INT_STATUS_MCP55 + ap->port_no * 2;
-	pp->tag_block = mmio + NV_NCQ_REG_MCP55 + ap->port_no * 2;
-
-	return 0;
-}
-
-static void nv_swncq_qc_prep(struct ata_queued_cmd *qc)
-{
-	if (qc->tf.protocol != ATA_PROT_NCQ) {
-		ata_sff_qc_prep(qc);
-		return;
-	}
-
-	if (!(qc->flags & ATA_QCFLAG_DMAMAP))
-		return;
-
-	nv_swncq_fill_sg(qc);
-}
-
-static void nv_swncq_fill_sg(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	struct scatterlist *sg;
-	struct nv_swncq_port_priv *pp = ap->private_data;
-	struct ata_prd *prd;
-	unsigned int si, idx;
-
-	prd = pp->prd + ATA_MAX_PRD * qc->tag;
-
-	idx = 0;
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		u32 addr, offset;
-		u32 sg_len, len;
-
-		addr = (u32)sg_dma_address(sg);
-		sg_len = sg_dma_len(sg);
-
-		while (sg_len) {
-			offset = addr & 0xffff;
-			len = sg_len;
-			if ((offset + sg_len) > 0x10000)
-				len = 0x10000 - offset;
-
-			prd[idx].addr = cpu_to_le32(addr);
-			prd[idx].flags_len = cpu_to_le32(len & 0xffff);
-
-			idx++;
-			sg_len -= len;
-			addr += len;
-		}
-	}
-
-	prd[idx - 1].flags_len |= cpu_to_le32(ATA_PRD_EOT);
-}
-
-static unsigned int nv_swncq_issue_atacmd(struct ata_port *ap,
-					  struct ata_queued_cmd *qc)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-
-	if (qc == NULL)
-		return 0;
-
-	DPRINTK("Enter\n");
-
-	writel((1 << qc->tag), pp->sactive_block);
-	pp->last_issue_tag = qc->tag;
-	pp->dhfis_bits &= ~(1 << qc->tag);
-	pp->dmafis_bits &= ~(1 << qc->tag);
-	pp->qc_active |= (0x1 << qc->tag);
-
-	ap->ops->sff_tf_load(ap, &qc->tf);	 /* load tf registers */
-	ap->ops->sff_exec_command(ap, &qc->tf);
-
-	DPRINTK("Issued tag %u\n", qc->tag);
-
-	return 0;
+	ata_bmdma_drive_eh(ap, ata_std_prereset, ata_std_softreset,
+			   nv_hardreset, ata_std_postreset);
 }
 
-static unsigned int nv_swncq_qc_issue(struct ata_queued_cmd *qc)
+static int nv_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
-	struct ata_port *ap = qc->ap;
-	struct nv_swncq_port_priv *pp = ap->private_data;
-
-	if (qc->tf.protocol != ATA_PROT_NCQ)
-		return ata_sff_qc_issue(qc);
-
-	DPRINTK("Enter\n");
-
-	if (!pp->qc_active)
-		nv_swncq_issue_atacmd(ap, qc);
-	else
-		nv_swncq_qc_to_dq(ap, qc);	/* add qc to defer queue */
-
-	return 0;
-}
-
-static void nv_swncq_hotplug(struct ata_port *ap, u32 fis)
-{
-	u32 serror;
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-
-	ata_ehi_clear_desc(ehi);
-
-	/* AHCI needs SError cleared; otherwise, it might lock up */
-	sata_scr_read(&ap->link, SCR_ERROR, &serror);
-	sata_scr_write(&ap->link, SCR_ERROR, serror);
-
-	/* analyze @irq_stat */
-	if (fis & NV_SWNCQ_IRQ_ADDED)
-		ata_ehi_push_desc(ehi, "hot plug");
-	else if (fis & NV_SWNCQ_IRQ_REMOVED)
-		ata_ehi_push_desc(ehi, "hot unplug");
-
-	ata_ehi_hotplugged(ehi);
-
-	/* okay, let's hand over to EH */
-	ehi->serror |= serror;
-
-	ata_port_freeze(ap);
-}
-
-static int nv_swncq_sdbfis(struct ata_port *ap)
-{
-	struct ata_queued_cmd *qc;
-	struct nv_swncq_port_priv *pp = ap->private_data;
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	u32 sactive;
-	int nr_done = 0;
-	u32 done_mask;
-	int i;
-	u8 host_stat;
-	u8 lack_dhfis = 0;
-
-	host_stat = ap->ops->bmdma_status(ap);
-	if (unlikely(host_stat & ATA_DMA_ERR)) {
-		/* error when transfering data to/from memory */
-		ata_ehi_clear_desc(ehi);
-		ata_ehi_push_desc(ehi, "BMDMA stat 0x%x", host_stat);
-		ehi->err_mask |= AC_ERR_HOST_BUS;
-		ehi->action |= ATA_EH_RESET;
-		return -EINVAL;
-	}
-
-	ap->ops->sff_irq_clear(ap);
-	__ata_bmdma_stop(ap);
-
-	sactive = readl(pp->sactive_block);
-	done_mask = pp->qc_active ^ sactive;
-
-	if (unlikely(done_mask & sactive)) {
-		ata_ehi_clear_desc(ehi);
-		ata_ehi_push_desc(ehi, "illegal SWNCQ:qc_active transition"
-				  "(%08x->%08x)", pp->qc_active, sactive);
-		ehi->err_mask |= AC_ERR_HSM;
-		ehi->action |= ATA_EH_RESET;
-		return -EINVAL;
-	}
-	for (i = 0; i < ATA_MAX_QUEUE; i++) {
-		if (!(done_mask & (1 << i)))
-			continue;
-
-		qc = ata_qc_from_tag(ap, i);
-		if (qc) {
-			ata_qc_complete(qc);
-			pp->qc_active &= ~(1 << i);
-			pp->dhfis_bits &= ~(1 << i);
-			pp->dmafis_bits &= ~(1 << i);
-			pp->sdbfis_bits |= (1 << i);
-			nr_done++;
-		}
-	}
-
-	if (!ap->qc_active) {
-		DPRINTK("over\n");
-		nv_swncq_pp_reinit(ap);
-		return nr_done;
-	}
-
-	if (pp->qc_active & pp->dhfis_bits)
-		return nr_done;
-
-	if ((pp->ncq_flags & ncq_saw_backout) ||
-	    (pp->qc_active ^ pp->dhfis_bits))
-		/* if the controller cann't get a device to host register FIS,
-		 * The driver needs to reissue the new command.
-		 */
-		lack_dhfis = 1;
-
-	DPRINTK("id 0x%x QC: qc_active 0x%x,"
-		"SWNCQ:qc_active 0x%X defer_bits %X "
-		"dhfis 0x%X dmafis 0x%X last_issue_tag %x\n",
-		ap->print_id, ap->qc_active, pp->qc_active,
-		pp->defer_queue.defer_bits, pp->dhfis_bits,
-		pp->dmafis_bits, pp->last_issue_tag);
-
-	nv_swncq_fis_reinit(ap);
-
-	if (lack_dhfis) {
-		qc = ata_qc_from_tag(ap, pp->last_issue_tag);
-		nv_swncq_issue_atacmd(ap, qc);
-		return nr_done;
-	}
-
-	if (pp->defer_queue.defer_bits) {
-		/* send deferral queue command */
-		qc = nv_swncq_qc_from_dq(ap);
-		WARN_ON(qc == NULL);
-		nv_swncq_issue_atacmd(ap, qc);
-	}
-
-	return nr_done;
-}
-
-static inline u32 nv_swncq_tag(struct ata_port *ap)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-	u32 tag;
-
-	tag = readb(pp->tag_block) >> 2;
-	return (tag & 0x1f);
-}
-
-static int nv_swncq_dmafis(struct ata_port *ap)
-{
-	struct ata_queued_cmd *qc;
-	unsigned int rw;
-	u8 dmactl;
-	u32 tag;
-	struct nv_swncq_port_priv *pp = ap->private_data;
-
-	__ata_bmdma_stop(ap);
-	tag = nv_swncq_tag(ap);
-
-	DPRINTK("dma setup tag 0x%x\n", tag);
-	qc = ata_qc_from_tag(ap, tag);
-
-	if (unlikely(!qc))
-		return 0;
-
-	rw = qc->tf.flags & ATA_TFLAG_WRITE;
-
-	/* load PRD table addr. */
-	iowrite32(pp->prd_dma + ATA_PRD_TBL_SZ * qc->tag,
-		  ap->ioaddr.bmdma_addr + ATA_DMA_TABLE_OFS);
-
-	/* specify data direction, triple-check start bit is clear */
-	dmactl = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
-	dmactl &= ~ATA_DMA_WR;
-	if (!rw)
-		dmactl |= ATA_DMA_WR;
-
-	iowrite8(dmactl | ATA_DMA_START, ap->ioaddr.bmdma_addr + ATA_DMA_CMD);
-
-	return 1;
-}
-
-static void nv_swncq_host_interrupt(struct ata_port *ap, u16 fis)
-{
-	struct nv_swncq_port_priv *pp = ap->private_data;
-	struct ata_queued_cmd *qc;
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	u32 serror;
-	u8 ata_stat;
-	int rc = 0;
-
-	ata_stat = ap->ops->sff_check_status(ap);
-	nv_swncq_irq_clear(ap, fis);
-	if (!fis)
-		return;
-
-	if (ap->pflags & ATA_PFLAG_FROZEN)
-		return;
-
-	if (fis & NV_SWNCQ_IRQ_HOTPLUG) {
-		nv_swncq_hotplug(ap, fis);
-		return;
-	}
-
-	if (!pp->qc_active)
-		return;
-
-	if (ap->ops->scr_read(&ap->link, SCR_ERROR, &serror))
-		return;
-	ap->ops->scr_write(&ap->link, SCR_ERROR, serror);
-
-	if (ata_stat & ATA_ERR) {
-		ata_ehi_clear_desc(ehi);
-		ata_ehi_push_desc(ehi, "Ata error. fis:0x%X", fis);
-		ehi->err_mask |= AC_ERR_DEV;
-		ehi->serror |= serror;
-		ehi->action |= ATA_EH_RESET;
-		ata_port_freeze(ap);
-		return;
-	}
-
-	if (fis & NV_SWNCQ_IRQ_BACKOUT) {
-		/* If the IRQ is backout, driver must issue
-		 * the new command again some time later.
-		 */
-		pp->ncq_flags |= ncq_saw_backout;
-	}
-
-	if (fis & NV_SWNCQ_IRQ_SDBFIS) {
-		pp->ncq_flags |= ncq_saw_sdb;
-		DPRINTK("id 0x%x SWNCQ: qc_active 0x%X "
-			"dhfis 0x%X dmafis 0x%X sactive 0x%X\n",
-			ap->print_id, pp->qc_active, pp->dhfis_bits,
-			pp->dmafis_bits, readl(pp->sactive_block));
-		rc = nv_swncq_sdbfis(ap);
-		if (rc < 0)
-			goto irq_error;
-	}
-
-	if (fis & NV_SWNCQ_IRQ_DHREGFIS) {
-		/* The interrupt indicates the new command
-		 * was transmitted correctly to the drive.
-		 */
-		pp->dhfis_bits |= (0x1 << pp->last_issue_tag);
-		pp->ncq_flags |= ncq_saw_d2h;
-		if (pp->ncq_flags & (ncq_saw_sdb | ncq_saw_backout)) {
-			ata_ehi_push_desc(ehi, "illegal fis transaction");
-			ehi->err_mask |= AC_ERR_HSM;
-			ehi->action |= ATA_EH_RESET;
-			goto irq_error;
-		}
-
-		if (!(fis & NV_SWNCQ_IRQ_DMASETUP) &&
-		    !(pp->ncq_flags & ncq_saw_dmas)) {
-			ata_stat = ap->ops->sff_check_status(ap);
-			if (ata_stat & ATA_BUSY)
-				goto irq_exit;
-
-			if (pp->defer_queue.defer_bits) {
-				DPRINTK("send next command\n");
-				qc = nv_swncq_qc_from_dq(ap);
-				nv_swncq_issue_atacmd(ap, qc);
-			}
-		}
-	}
-
-	if (fis & NV_SWNCQ_IRQ_DMASETUP) {
-		/* program the dma controller with appropriate PRD buffers
-		 * and start the DMA transfer for requested command.
-		 */
-		pp->dmafis_bits |= (0x1 << nv_swncq_tag(ap));
-		pp->ncq_flags |= ncq_saw_dmas;
-		rc = nv_swncq_dmafis(ap);
-	}
-
-irq_exit:
-	return;
-irq_error:
-	ata_ehi_push_desc(ehi, "fis:0x%x", fis);
-	ata_port_freeze(ap);
-	return;
-}
-
-static irqreturn_t nv_swncq_interrupt(int irq, void *dev_instance)
-{
-	struct ata_host *host = dev_instance;
-	unsigned int i;
-	unsigned int handled = 0;
-	unsigned long flags;
-	u32 irq_stat;
-
-	spin_lock_irqsave(&host->lock, flags);
-
-	irq_stat = readl(host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_MCP55);
-
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-
-		if (ap && !(ap->flags & ATA_FLAG_DISABLED)) {
-			if (ap->link.sactive) {
-				nv_swncq_host_interrupt(ap, (u16)irq_stat);
-				handled = 1;
-			} else {
-				if (irq_stat)	/* reserve Hotplug */
-					nv_swncq_irq_clear(ap, 0xfff0);
-
-				handled += nv_host_intr(ap, (u8)irq_stat);
-			}
-		}
-		irq_stat >>= NV_INT_PORT_SHIFT_MCP55;
-	}
-
-	spin_unlock_irqrestore(&host->lock, flags);
-
-	return IRQ_RETVAL(handled);
-}
-
-static int nv_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
-{
-	static int printed_version;
+	static int printed_version = 0;
 	const struct ata_port_info *ppi[] = { NULL, NULL };
-	struct nv_pi_priv *ipriv;
 	struct ata_host *host;
 	struct nv_host_priv *hpriv;
 	int rc;
@@ -2411,7 +1546,7 @@
         // Make sure this is a SATA controller by counting the number of bars
         // (NVIDIA SATA controllers will always have six bars).  Otherwise,
         // it's an IDE controller and we ignore it.
-	for (bar = 0; bar < 6; bar++)
+	for (bar=0; bar<6; bar++)
 		if (pci_resource_start(pdev, bar) == 0)
 			return -ENODEV;
 
@@ -2423,17 +1558,13 @@
 		return rc;
 
 	/* determine type and allocate host */
-	if (type == CK804 && adma_enabled) {
+	if (type >= CK804 && adma_enabled) {
 		dev_printk(KERN_NOTICE, &pdev->dev, "Using ADMA mode\n");
 		type = ADMA;
-	} else if (type == MCP5x && swncq_enabled) {
-		dev_printk(KERN_NOTICE, &pdev->dev, "Using SWNCQ mode\n");
-		type = SWNCQ;
 	}
 
 	ppi[0] = &nv_port_info[type];
-	ipriv = ppi[0]->private_data;
-	rc = ata_pci_sff_prepare_host(pdev, ppi, &host);
+	rc = ata_pci_prepare_sff_host(pdev, ppi, &host);
 	if (rc)
 		return rc;
 
@@ -2443,6 +1574,12 @@
 	hpriv->type = type;
 	host->private_data = hpriv;
 
+	/* set 64bit dma masks, may fail */
+	if (type == ADMA) {
+		if (pci_set_dma_mask(pdev, DMA_64BIT_MASK) == 0)
+			pci_set_consistent_dma_mask(pdev, DMA_64BIT_MASK);
+	}
+
 	/* request and iomap NV_MMIO_BAR */
 	rc = pcim_iomap_regions(pdev, 1 << NV_MMIO_BAR, DRV_NAME);
 	if (rc)
@@ -2467,16 +1604,11 @@
 		rc = nv_adma_host_init(host);
 		if (rc)
 			return rc;
-	} else if (type == SWNCQ)
-		nv_swncq_host_init(host);
-
-	if (msi_enabled) {
-		dev_printk(KERN_NOTICE, &pdev->dev, "Using MSI\n");
-		pci_enable_msi(pdev);
 	}
 
 	pci_set_master(pdev);
-	return ata_pci_sff_activate_host(host, ipriv->irq_handler, ipriv->sht);
+	return ata_host_activate(host, pdev->irq, ppi[0]->irq_handler,
+				 IRQF_SHARED, ppi[0]->sht);
 }
 
 #ifdef CONFIG_PM
@@ -2487,37 +1619,37 @@
 	int rc;
 
 	rc = ata_pci_device_do_resume(pdev);
-	if (rc)
+	if(rc)
 		return rc;
 
 	if (pdev->dev.power.power_state.event == PM_EVENT_SUSPEND) {
-		if (hpriv->type >= CK804) {
+		if(hpriv->type >= CK804) {
 			u8 regval;
 
 			pci_read_config_byte(pdev, NV_MCP_SATA_CFG_20, &regval);
 			regval |= NV_MCP_SATA_CFG_20_SATA_SPACE_EN;
 			pci_write_config_byte(pdev, NV_MCP_SATA_CFG_20, regval);
 		}
-		if (hpriv->type == ADMA) {
+		if(hpriv->type == ADMA) {
 			u32 tmp32;
 			struct nv_adma_port_priv *pp;
 			/* enable/disable ADMA on the ports appropriately */
 			pci_read_config_dword(pdev, NV_MCP_SATA_CFG_20, &tmp32);
 
 			pp = host->ports[0]->private_data;
-			if (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)
+			if(pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)
 				tmp32 &= ~(NV_MCP_SATA_CFG_20_PORT0_EN |
-					   NV_MCP_SATA_CFG_20_PORT0_PWB_EN);
+				 	   NV_MCP_SATA_CFG_20_PORT0_PWB_EN);
 			else
 				tmp32 |=  (NV_MCP_SATA_CFG_20_PORT0_EN |
-					   NV_MCP_SATA_CFG_20_PORT0_PWB_EN);
+				 	   NV_MCP_SATA_CFG_20_PORT0_PWB_EN);
 			pp = host->ports[1]->private_data;
-			if (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)
+			if(pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)
 				tmp32 &= ~(NV_MCP_SATA_CFG_20_PORT1_EN |
-					   NV_MCP_SATA_CFG_20_PORT1_PWB_EN);
+				 	   NV_MCP_SATA_CFG_20_PORT1_PWB_EN);
 			else
 				tmp32 |=  (NV_MCP_SATA_CFG_20_PORT1_EN |
-					   NV_MCP_SATA_CFG_20_PORT1_PWB_EN);
+				 	   NV_MCP_SATA_CFG_20_PORT1_PWB_EN);
 
 			pci_write_config_dword(pdev, NV_MCP_SATA_CFG_20, tmp32);
 		}
@@ -2570,9 +1702,4 @@
 module_init(nv_init);
 module_exit(nv_exit);
 module_param_named(adma, adma_enabled, bool, 0444);
-MODULE_PARM_DESC(adma, "Enable use of ADMA (Default: false)");
-module_param_named(swncq, swncq_enabled, bool, 0444);
-MODULE_PARM_DESC(swncq, "Enable use of SWNCQ (Default: true)");
-module_param_named(msi, msi_enabled, bool, 0444);
-MODULE_PARM_DESC(msi, "Enable use of MSI (Default: false)");
-
+MODULE_PARM_DESC(adma, "Enable use of ADMA (Default: true)");
diff -Nur linux-sh4/drivers/ata.org/sata_promise.c linux-sh4/drivers/ata/sata_promise.c
--- linux-sh4/drivers/ata.org/sata_promise.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_promise.c	2012-01-15 06:30:15.000000000 -0800
@@ -2,7 +2,6 @@
  *  sata_promise.c - Promise SATA
  *
  *  Maintained by:  Jeff Garzik <jgarzik@pobox.com>
- *		    Mikael Pettersson <mikpe@it.uu.se>
  *  		    Please ALWAYS copy linux-ide@vger.kernel.org
  *		    on emails.
  *
@@ -46,23 +45,14 @@
 #include "sata_promise.h"
 
 #define DRV_NAME	"sata_promise"
-#define DRV_VERSION	"2.12"
+#define DRV_VERSION	"2.10"
 
 enum {
 	PDC_MAX_PORTS		= 4,
 	PDC_MMIO_BAR		= 3,
 	PDC_MAX_PRD		= LIBATA_MAX_PRD - 1, /* -1 for ASIC PRD bug workaround */
 
-	/* host register offsets (from host->iomap[PDC_MMIO_BAR]) */
-	PDC_INT_SEQMASK		= 0x40,	/* Mask of asserted SEQ INTs */
-	PDC_FLASH_CTL		= 0x44, /* Flash control register */
-	PDC_PCI_CTL		= 0x48, /* PCI control/status reg */
-	PDC_SATA_PLUG_CSR	= 0x6C, /* SATA Plug control/status reg */
-	PDC2_SATA_PLUG_CSR	= 0x60, /* SATAII Plug control/status reg */
-	PDC_TBG_MODE		= 0x41C, /* TBG mode (not SATAII) */
-	PDC_SLEW_CTL		= 0x470, /* slew rate control reg (not SATAII) */
-
-	/* per-port ATA register offsets (from ap->ioaddr.cmd_addr) */
+	/* register offsets */
 	PDC_FEATURE		= 0x04, /* Feature/Error reg (per port) */
 	PDC_SECTOR_COUNT	= 0x08, /* Sector count reg (per port) */
 	PDC_SECTOR_NUMBER	= 0x0C, /* Sector number reg (per port) */
@@ -72,21 +62,14 @@
 	PDC_COMMAND		= 0x1C, /* Command/status reg (per port) */
 	PDC_ALTSTATUS		= 0x38, /* Alternate-status/device-control reg (per port) */
 	PDC_PKT_SUBMIT		= 0x40, /* Command packet pointer addr */
+	PDC_INT_SEQMASK		= 0x40,	/* Mask of asserted SEQ INTs */
+	PDC_FLASH_CTL		= 0x44, /* Flash control register */
 	PDC_GLOBAL_CTL		= 0x48, /* Global control/status (per port) */
 	PDC_CTLSTAT		= 0x60,	/* IDE control and status (per port) */
-
-	/* per-port SATA register offsets (from ap->ioaddr.scr_addr) */
-	PDC_SATA_ERROR		= 0x04,
-	PDC_PHYMODE4		= 0x14,
-	PDC_LINK_LAYER_ERRORS	= 0x6C,
-	PDC_FPDMA_CTLSTAT	= 0xD8,
-	PDC_INTERNAL_DEBUG_1	= 0xF8,	/* also used for PATA */
-	PDC_INTERNAL_DEBUG_2	= 0xFC,	/* also used for PATA */
-
-	/* PDC_FPDMA_CTLSTAT bit definitions */
-	PDC_FPDMA_CTLSTAT_RESET			= 1 << 3,
-	PDC_FPDMA_CTLSTAT_DMASETUP_INT_FLAG	= 1 << 10,
-	PDC_FPDMA_CTLSTAT_SETDB_INT_FLAG	= 1 << 11,
+	PDC_SATA_PLUG_CSR	= 0x6C, /* SATA Plug control/status reg */
+	PDC2_SATA_PLUG_CSR	= 0x60, /* SATAII Plug control/status reg */
+	PDC_TBG_MODE		= 0x41C, /* TBG mode (not SATAII) */
+	PDC_SLEW_CTL		= 0x470, /* slew rate control reg (not SATAII) */
 
 	/* PDC_GLOBAL_CTL bit definitions */
 	PDC_PH_ERR		= (1 <<  8), /* PCI error while loading packet */
@@ -101,12 +84,10 @@
 	PDC_PCI_SYS_ERR		= (1 << 22), /* PCI system error */
 	PDC1_PCI_PARITY_ERR	= (1 << 23), /* PCI parity error (from SATA150 driver) */
 	PDC1_ERR_MASK		= PDC1_PCI_PARITY_ERR,
-	PDC2_ERR_MASK		= PDC2_HTO_ERR | PDC2_ATA_HBA_ERR |
-				  PDC2_ATA_DMA_CNT_ERR,
-	PDC_ERR_MASK		= PDC_PH_ERR | PDC_SH_ERR | PDC_DH_ERR |
-				  PDC_OVERRUN_ERR | PDC_UNDERRUN_ERR |
-				  PDC_DRIVE_ERR | PDC_PCI_SYS_ERR |
-				  PDC1_ERR_MASK | PDC2_ERR_MASK,
+	PDC2_ERR_MASK		= PDC2_HTO_ERR | PDC2_ATA_HBA_ERR | PDC2_ATA_DMA_CNT_ERR,
+	PDC_ERR_MASK		= (PDC_PH_ERR | PDC_SH_ERR | PDC_DH_ERR | PDC_OVERRUN_ERR
+				   | PDC_UNDERRUN_ERR | PDC_DRIVE_ERR | PDC_PCI_SYS_ERR
+				   | PDC1_ERR_MASK | PDC2_ERR_MASK),
 
 	board_2037x		= 0,	/* FastTrak S150 TX2plus */
 	board_2037x_pata	= 1,	/* FastTrak S150 TX2plus PATA port */
@@ -148,9 +129,9 @@
 	dma_addr_t		pkt_dma;
 };
 
-static int pdc_sata_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val);
-static int pdc_sata_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val);
-static int pdc_ata_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
+static int pdc_sata_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val);
+static int pdc_sata_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val);
+static int pdc_ata_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
 static int pdc_common_port_start(struct ata_port *ap);
 static int pdc_sata_port_start(struct ata_port *ap);
 static void pdc_qc_prep(struct ata_queued_cmd *qc);
@@ -159,137 +140,176 @@
 static int pdc_check_atapi_dma(struct ata_queued_cmd *qc);
 static int pdc_old_sata_check_atapi_dma(struct ata_queued_cmd *qc);
 static void pdc_irq_clear(struct ata_port *ap);
-static unsigned int pdc_qc_issue(struct ata_queued_cmd *qc);
+static unsigned int pdc_qc_issue_prot(struct ata_queued_cmd *qc);
 static void pdc_freeze(struct ata_port *ap);
-static void pdc_sata_freeze(struct ata_port *ap);
 static void pdc_thaw(struct ata_port *ap);
-static void pdc_sata_thaw(struct ata_port *ap);
-static int pdc_pata_softreset(struct ata_link *link, unsigned int *class,
-			      unsigned long deadline);
-static int pdc_sata_hardreset(struct ata_link *link, unsigned int *class,
-			      unsigned long deadline);
-static void pdc_error_handler(struct ata_port *ap);
+static void pdc_pata_error_handler(struct ata_port *ap);
+static void pdc_sata_error_handler(struct ata_port *ap);
 static void pdc_post_internal_cmd(struct ata_queued_cmd *qc);
 static int pdc_pata_cable_detect(struct ata_port *ap);
 static int pdc_sata_cable_detect(struct ata_port *ap);
 
 static struct scsi_host_template pdc_ata_sht = {
-	ATA_BASE_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= PDC_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
 	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static const struct ata_port_operations pdc_common_ops = {
-	.inherits		= &ata_sff_port_ops,
-
-	.sff_tf_load		= pdc_tf_load_mmio,
-	.sff_exec_command	= pdc_exec_command_mmio,
+static const struct ata_port_operations pdc_sata_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= pdc_tf_load_mmio,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= pdc_exec_command_mmio,
+	.dev_select		= ata_std_dev_select,
 	.check_atapi_dma	= pdc_check_atapi_dma,
-	.qc_prep		= pdc_qc_prep,
-	.qc_issue		= pdc_qc_issue,
-
-	.sff_irq_clear		= pdc_irq_clear,
-	.lost_interrupt		= ATA_OP_NULL,
 
+	.qc_prep		= pdc_qc_prep,
+	.qc_issue		= pdc_qc_issue_prot,
+	.freeze			= pdc_freeze,
+	.thaw			= pdc_thaw,
+	.error_handler		= pdc_sata_error_handler,
 	.post_internal_cmd	= pdc_post_internal_cmd,
-	.error_handler		= pdc_error_handler,
-};
-
-static struct ata_port_operations pdc_sata_ops = {
-	.inherits		= &pdc_common_ops,
 	.cable_detect		= pdc_sata_cable_detect,
-	.freeze			= pdc_sata_freeze,
-	.thaw			= pdc_sata_thaw,
+	.data_xfer		= ata_data_xfer,
+	.irq_clear		= pdc_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
 	.scr_read		= pdc_sata_scr_read,
 	.scr_write		= pdc_sata_scr_write,
 	.port_start		= pdc_sata_port_start,
-	.hardreset		= pdc_sata_hardreset,
 };
 
-/* First-generation chips need a more restrictive ->check_atapi_dma op,
-   and ->freeze/thaw that ignore the hotplug controls. */
-static struct ata_port_operations pdc_old_sata_ops = {
-	.inherits		= &pdc_sata_ops,
+/* First-generation chips need a more restrictive ->check_atapi_dma op */
+static const struct ata_port_operations pdc_old_sata_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= pdc_tf_load_mmio,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= pdc_exec_command_mmio,
+	.dev_select		= ata_std_dev_select,
+	.check_atapi_dma	= pdc_old_sata_check_atapi_dma,
+
+	.qc_prep		= pdc_qc_prep,
+	.qc_issue		= pdc_qc_issue_prot,
 	.freeze			= pdc_freeze,
 	.thaw			= pdc_thaw,
-	.check_atapi_dma	= pdc_old_sata_check_atapi_dma,
+	.error_handler		= pdc_sata_error_handler,
+	.post_internal_cmd	= pdc_post_internal_cmd,
+	.cable_detect		= pdc_sata_cable_detect,
+	.data_xfer		= ata_data_xfer,
+	.irq_clear		= pdc_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.scr_read		= pdc_sata_scr_read,
+	.scr_write		= pdc_sata_scr_write,
+	.port_start		= pdc_sata_port_start,
 };
 
-static struct ata_port_operations pdc_pata_ops = {
-	.inherits		= &pdc_common_ops,
-	.cable_detect		= pdc_pata_cable_detect,
+static const struct ata_port_operations pdc_pata_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= pdc_tf_load_mmio,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= pdc_exec_command_mmio,
+	.dev_select		= ata_std_dev_select,
+	.check_atapi_dma	= pdc_check_atapi_dma,
+
+	.qc_prep		= pdc_qc_prep,
+	.qc_issue		= pdc_qc_issue_prot,
 	.freeze			= pdc_freeze,
 	.thaw			= pdc_thaw,
+	.error_handler		= pdc_pata_error_handler,
+	.post_internal_cmd	= pdc_post_internal_cmd,
+	.cable_detect		= pdc_pata_cable_detect,
+	.data_xfer		= ata_data_xfer,
+	.irq_clear		= pdc_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
 	.port_start		= pdc_common_port_start,
-	.softreset		= pdc_pata_softreset,
 };
 
 static const struct ata_port_info pdc_port_info[] = {
-	[board_2037x] =
+	/* board_2037x */
 	{
 		.flags		= PDC_COMMON_FLAGS | ATA_FLAG_SATA |
 				  PDC_FLAG_SATA_PATA,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &pdc_old_sata_ops,
 	},
 
-	[board_2037x_pata] =
+	/* board_2037x_pata */
 	{
 		.flags		= PDC_COMMON_FLAGS | ATA_FLAG_SLAVE_POSS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &pdc_pata_ops,
 	},
 
-	[board_20319] =
+	/* board_20319 */
 	{
 		.flags		= PDC_COMMON_FLAGS | ATA_FLAG_SATA |
 				  PDC_FLAG_4_PORTS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &pdc_old_sata_ops,
 	},
 
-	[board_20619] =
+	/* board_20619 */
 	{
 		.flags		= PDC_COMMON_FLAGS | ATA_FLAG_SLAVE_POSS |
 				  PDC_FLAG_4_PORTS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &pdc_pata_ops,
 	},
 
-	[board_2057x] =
+	/* board_2057x */
 	{
 		.flags		= PDC_COMMON_FLAGS | ATA_FLAG_SATA |
 				  PDC_FLAG_GEN_II | PDC_FLAG_SATA_PATA,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &pdc_sata_ops,
 	},
 
-	[board_2057x_pata] =
+	/* board_2057x_pata */
 	{
 		.flags		= PDC_COMMON_FLAGS | ATA_FLAG_SLAVE_POSS |
 				  PDC_FLAG_GEN_II,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &pdc_pata_ops,
 	},
 
-	[board_40518] =
+	/* board_40518 */
 	{
 		.flags		= PDC_COMMON_FLAGS | ATA_FLAG_SATA |
 				  PDC_FLAG_GEN_II | PDC_FLAG_4_PORTS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &pdc_sata_ops,
 	},
@@ -359,114 +379,45 @@
 
 	/* fix up PHYMODE4 align timing */
 	if (ap->flags & PDC_FLAG_GEN_II) {
-		void __iomem *sata_mmio = ap->ioaddr.scr_addr;
+		void __iomem *mmio = ap->ioaddr.scr_addr;
 		unsigned int tmp;
 
-		tmp = readl(sata_mmio + PDC_PHYMODE4);
+		tmp = readl(mmio + 0x014);
 		tmp = (tmp & ~3) | 1;	/* set bits 1:0 = 0:1 */
-		writel(tmp, sata_mmio + PDC_PHYMODE4);
+		writel(tmp, mmio + 0x014);
 	}
 
 	return 0;
 }
 
-static void pdc_fpdma_clear_interrupt_flag(struct ata_port *ap)
-{
-	void __iomem *sata_mmio = ap->ioaddr.scr_addr;
-	u32 tmp;
-
-	tmp = readl(sata_mmio + PDC_FPDMA_CTLSTAT);
-	tmp |= PDC_FPDMA_CTLSTAT_DMASETUP_INT_FLAG;
-	tmp |= PDC_FPDMA_CTLSTAT_SETDB_INT_FLAG;
-
-	/* It's not allowed to write to the entire FPDMA_CTLSTAT register
-	   when NCQ is running. So do a byte-sized write to bits 10 and 11. */
-	writeb(tmp >> 8, sata_mmio + PDC_FPDMA_CTLSTAT + 1);
-	readb(sata_mmio + PDC_FPDMA_CTLSTAT + 1); /* flush */
-}
-
-static void pdc_fpdma_reset(struct ata_port *ap)
-{
-	void __iomem *sata_mmio = ap->ioaddr.scr_addr;
-	u8 tmp;
-
-	tmp = (u8)readl(sata_mmio + PDC_FPDMA_CTLSTAT);
-	tmp &= 0x7F;
-	tmp |= PDC_FPDMA_CTLSTAT_RESET;
-	writeb(tmp, sata_mmio + PDC_FPDMA_CTLSTAT);
-	readl(sata_mmio + PDC_FPDMA_CTLSTAT); /* flush */
-	udelay(100);
-	tmp &= ~PDC_FPDMA_CTLSTAT_RESET;
-	writeb(tmp, sata_mmio + PDC_FPDMA_CTLSTAT);
-	readl(sata_mmio + PDC_FPDMA_CTLSTAT); /* flush */
-
-	pdc_fpdma_clear_interrupt_flag(ap);
-}
-
-static void pdc_not_at_command_packet_phase(struct ata_port *ap)
-{
-	void __iomem *sata_mmio = ap->ioaddr.scr_addr;
-	unsigned int i;
-	u32 tmp;
-
-	/* check not at ASIC packet command phase */
-	for (i = 0; i < 100; ++i) {
-		writel(0, sata_mmio + PDC_INTERNAL_DEBUG_1);
-		tmp = readl(sata_mmio + PDC_INTERNAL_DEBUG_2);
-		if ((tmp & 0xF) != 1)
-			break;
-		udelay(100);
-	}
-}
-
-static void pdc_clear_internal_debug_record_error_register(struct ata_port *ap)
-{
-	void __iomem *sata_mmio = ap->ioaddr.scr_addr;
-
-	writel(0xffffffff, sata_mmio + PDC_SATA_ERROR);
-	writel(0xffff0000, sata_mmio + PDC_LINK_LAYER_ERRORS);
-}
-
 static void pdc_reset_port(struct ata_port *ap)
 {
-	void __iomem *ata_ctlstat_mmio = ap->ioaddr.cmd_addr + PDC_CTLSTAT;
+	void __iomem *mmio = ap->ioaddr.cmd_addr + PDC_CTLSTAT;
 	unsigned int i;
 	u32 tmp;
 
-	if (ap->flags & PDC_FLAG_GEN_II)
-		pdc_not_at_command_packet_phase(ap);
-
-	tmp = readl(ata_ctlstat_mmio);
-	tmp |= PDC_RESET;
-	writel(tmp, ata_ctlstat_mmio);
-
 	for (i = 11; i > 0; i--) {
-		tmp = readl(ata_ctlstat_mmio);
+		tmp = readl(mmio);
 		if (tmp & PDC_RESET)
 			break;
 
 		udelay(100);
 
 		tmp |= PDC_RESET;
-		writel(tmp, ata_ctlstat_mmio);
+		writel(tmp, mmio);
 	}
 
 	tmp &= ~PDC_RESET;
-	writel(tmp, ata_ctlstat_mmio);
-	readl(ata_ctlstat_mmio);	/* flush */
-
-	if (sata_scr_valid(&ap->link) && (ap->flags & PDC_FLAG_GEN_II)) {
-		pdc_fpdma_reset(ap);
-		pdc_clear_internal_debug_record_error_register(ap);
-	}
+	writel(tmp, mmio);
+	readl(mmio);	/* flush */
 }
 
 static int pdc_pata_cable_detect(struct ata_port *ap)
 {
 	u8 tmp;
-	void __iomem *ata_mmio = ap->ioaddr.cmd_addr;
+	void __iomem *mmio = ap->ioaddr.cmd_addr + PDC_CTLSTAT + 0x03;
 
-	tmp = readb(ata_mmio + PDC_CTLSTAT + 3);
+	tmp = readb(mmio);
 	if (tmp & 0x01)
 		return ATA_CBL_PATA40;
 	return ATA_CBL_PATA80;
@@ -477,21 +428,19 @@
 	return ATA_CBL_SATA;
 }
 
-static int pdc_sata_scr_read(struct ata_link *link,
-			     unsigned int sc_reg, u32 *val)
+static int pdc_sata_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	*val = readl(link->ap->ioaddr.scr_addr + (sc_reg * 4));
+	*val = readl(ap->ioaddr.scr_addr + (sc_reg * 4));
 	return 0;
 }
 
-static int pdc_sata_scr_write(struct ata_link *link,
-			      unsigned int sc_reg, u32 val)
+static int pdc_sata_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	writel(val, link->ap->ioaddr.scr_addr + (sc_reg * 4));
+	writel(val, ap->ioaddr.scr_addr + (sc_reg * 4));
 	return 0;
 }
 
@@ -503,20 +452,20 @@
 	u8 *cdb = qc->cdb;
 	struct pdc_port_priv *pp = ap->private_data;
 	u8 *buf = pp->pkt;
-	__le32 *buf32 = (__le32 *) buf;
-	unsigned int dev_sel, feature;
+	u32 *buf32 = (u32 *) buf;
+	unsigned int dev_sel, feature, nbytes;
 
 	/* set control bits (byte 0), zero delay seq id (byte 3),
 	 * and seq id (byte 2)
 	 */
 	switch (qc->tf.protocol) {
-	case ATAPI_PROT_DMA:
+	case ATA_PROT_ATAPI_DMA:
 		if (!(qc->tf.flags & ATA_TFLAG_WRITE))
 			buf32[0] = cpu_to_le32(PDC_PKT_READ);
 		else
 			buf32[0] = 0;
 		break;
-	case ATAPI_PROT_NODATA:
+	case ATA_PROT_ATAPI_NODATA:
 		buf32[0] = cpu_to_le32(PDC_PKT_NODATA);
 		break;
 	default:
@@ -527,37 +476,45 @@
 	buf32[2] = 0;				/* no next-packet */
 
 	/* select drive */
-	if (sata_scr_valid(&ap->link))
+	if (sata_scr_valid(ap)) {
 		dev_sel = PDC_DEVICE_SATA;
-	else
-		dev_sel = qc->tf.device;
-
+	} else {
+		dev_sel = ATA_DEVICE_OBS;
+		if (qc->dev->devno != 0)
+			dev_sel |= ATA_DEV1;
+	}
 	buf[12] = (1 << 5) | ATA_REG_DEVICE;
 	buf[13] = dev_sel;
 	buf[14] = (1 << 5) | ATA_REG_DEVICE | PDC_PKT_CLEAR_BSY;
 	buf[15] = dev_sel; /* once more, waiting for BSY to clear */
 
 	buf[16] = (1 << 5) | ATA_REG_NSECT;
-	buf[17] = qc->tf.nsect;
+	buf[17] = 0x00;
 	buf[18] = (1 << 5) | ATA_REG_LBAL;
-	buf[19] = qc->tf.lbal;
+	buf[19] = 0x00;
 
 	/* set feature and byte counter registers */
-	if (qc->tf.protocol != ATAPI_PROT_DMA)
+	if (qc->tf.protocol != ATA_PROT_ATAPI_DMA) {
 		feature = PDC_FEATURE_ATAPI_PIO;
-	else
+		/* set byte counter register to real transfer byte count */
+		nbytes = qc->nbytes;
+		if (nbytes > 0xffff)
+			nbytes = 0xffff;
+	} else {
 		feature = PDC_FEATURE_ATAPI_DMA;
-
+		/* set byte counter register to 0 */
+		nbytes = 0;
+	}
 	buf[20] = (1 << 5) | ATA_REG_FEATURE;
 	buf[21] = feature;
 	buf[22] = (1 << 5) | ATA_REG_BYTEL;
-	buf[23] = qc->tf.lbam;
+	buf[23] = nbytes & 0xFF;
 	buf[24] = (1 << 5) | ATA_REG_BYTEH;
-	buf[25] = qc->tf.lbah;
+	buf[25] = (nbytes >> 8) & 0xFF;
 
 	/* send ATAPI packet command 0xA0 */
 	buf[26] = (1 << 5) | ATA_REG_CMD;
-	buf[27] = qc->tf.command;
+	buf[27] = ATA_CMD_PACKET;
 
 	/* select drive and check DRQ */
 	buf[28] = (1 << 5) | ATA_REG_DEVICE | PDC_PKT_WAIT_DRDY;
@@ -587,17 +544,19 @@
 {
 	struct ata_port *ap = qc->ap;
 	struct scatterlist *sg;
+	unsigned int idx;
 	const u32 SG_COUNT_ASIC_BUG = 41*4;
-	unsigned int si, idx;
-	u32 len;
 
 	if (!(qc->flags & ATA_QCFLAG_DMAMAP))
 		return;
 
+	WARN_ON(qc->__sg == NULL);
+	WARN_ON(qc->n_elem == 0 && qc->pad_len == 0);
+
 	idx = 0;
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
+	ata_for_each_sg(sg, qc) {
 		u32 addr, offset;
-		u32 sg_len;
+		u32 sg_len, len;
 
 		/* determine if physical DMA addr spans 64K boundary.
 		 * Note h/w doesn't support 64-bit, so we unconditionally
@@ -622,27 +581,29 @@
 		}
 	}
 
-	len = le32_to_cpu(ap->prd[idx - 1].flags_len);
+	if (idx) {
+		u32 len = le32_to_cpu(ap->prd[idx - 1].flags_len);
 
-	if (len > SG_COUNT_ASIC_BUG) {
-		u32 addr;
+		if (len > SG_COUNT_ASIC_BUG) {
+			u32 addr;
 
-		VPRINTK("Splitting last PRD.\n");
+			VPRINTK("Splitting last PRD.\n");
 
-		addr = le32_to_cpu(ap->prd[idx - 1].addr);
-		ap->prd[idx - 1].flags_len = cpu_to_le32(len - SG_COUNT_ASIC_BUG);
-		VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", idx - 1, addr, SG_COUNT_ASIC_BUG);
+			addr = le32_to_cpu(ap->prd[idx - 1].addr);
+			ap->prd[idx - 1].flags_len = cpu_to_le32(len - SG_COUNT_ASIC_BUG);
+			VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", idx - 1, addr, SG_COUNT_ASIC_BUG);
 
-		addr = addr + len - SG_COUNT_ASIC_BUG;
-		len = SG_COUNT_ASIC_BUG;
-		ap->prd[idx].addr = cpu_to_le32(addr);
-		ap->prd[idx].flags_len = cpu_to_le32(len);
-		VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", idx, addr, len);
+			addr = addr + len - SG_COUNT_ASIC_BUG;
+			len = SG_COUNT_ASIC_BUG;
+			ap->prd[idx].addr = cpu_to_le32(addr);
+			ap->prd[idx].flags_len = cpu_to_le32(len);
+			VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", idx, addr, len);
 
-		idx++;
-	}
+			idx++;
+		}
 
-	ap->prd[idx - 1].flags_len |= cpu_to_le32(ATA_PRD_EOT);
+		ap->prd[idx - 1].flags_len |= cpu_to_le32(ATA_PRD_EOT);
+	}
 }
 
 static void pdc_qc_prep(struct ata_queued_cmd *qc)
@@ -655,189 +616,81 @@
 	switch (qc->tf.protocol) {
 	case ATA_PROT_DMA:
 		pdc_fill_sg(qc);
-		/*FALLTHROUGH*/
+		/* fall through */
+
 	case ATA_PROT_NODATA:
 		i = pdc_pkt_header(&qc->tf, qc->ap->prd_dma,
 				   qc->dev->devno, pp->pkt);
+
 		if (qc->tf.flags & ATA_TFLAG_LBA48)
 			i = pdc_prep_lba48(&qc->tf, pp->pkt, i);
 		else
 			i = pdc_prep_lba28(&qc->tf, pp->pkt, i);
+
 		pdc_pkt_footer(&qc->tf, pp->pkt, i);
 		break;
-	case ATAPI_PROT_PIO:
+
+	case ATA_PROT_ATAPI:
 		pdc_fill_sg(qc);
 		break;
-	case ATAPI_PROT_DMA:
+
+	case ATA_PROT_ATAPI_DMA:
 		pdc_fill_sg(qc);
 		/*FALLTHROUGH*/
-	case ATAPI_PROT_NODATA:
+	case ATA_PROT_ATAPI_NODATA:
 		pdc_atapi_pkt(qc);
 		break;
+
 	default:
 		break;
 	}
 }
 
-static int pdc_is_sataii_tx4(unsigned long flags)
-{
-	const unsigned long mask = PDC_FLAG_GEN_II | PDC_FLAG_4_PORTS;
-	return (flags & mask) == mask;
-}
-
-static unsigned int pdc_port_no_to_ata_no(unsigned int port_no,
-					  int is_sataii_tx4)
-{
-	static const unsigned char sataii_tx4_port_remap[4] = { 3, 1, 0, 2};
-	return is_sataii_tx4 ? sataii_tx4_port_remap[port_no] : port_no;
-}
-
-static unsigned int pdc_sata_nr_ports(const struct ata_port *ap)
-{
-	return (ap->flags & PDC_FLAG_4_PORTS) ? 4 : 2;
-}
-
-static unsigned int pdc_sata_ata_port_to_ata_no(const struct ata_port *ap)
-{
-	const struct ata_host *host = ap->host;
-	unsigned int nr_ports = pdc_sata_nr_ports(ap);
-	unsigned int i;
-
-	for (i = 0; i < nr_ports && host->ports[i] != ap; ++i)
-		;
-	BUG_ON(i >= nr_ports);
-	return pdc_port_no_to_ata_no(i, pdc_is_sataii_tx4(ap->flags));
-}
-
 static void pdc_freeze(struct ata_port *ap)
 {
-	void __iomem *ata_mmio = ap->ioaddr.cmd_addr;
+	void __iomem *mmio = ap->ioaddr.cmd_addr;
 	u32 tmp;
 
-	tmp = readl(ata_mmio + PDC_CTLSTAT);
+	tmp = readl(mmio + PDC_CTLSTAT);
 	tmp |= PDC_IRQ_DISABLE;
 	tmp &= ~PDC_DMA_ENABLE;
-	writel(tmp, ata_mmio + PDC_CTLSTAT);
-	readl(ata_mmio + PDC_CTLSTAT); /* flush */
-}
-
-static void pdc_sata_freeze(struct ata_port *ap)
-{
-	struct ata_host *host = ap->host;
-	void __iomem *host_mmio = host->iomap[PDC_MMIO_BAR];
-	unsigned int hotplug_offset = PDC2_SATA_PLUG_CSR;
-	unsigned int ata_no = pdc_sata_ata_port_to_ata_no(ap);
-	u32 hotplug_status;
-
-	/* Disable hotplug events on this port.
-	 *
-	 * Locking:
-	 * 1) hotplug register accesses must be serialised via host->lock
-	 * 2) ap->lock == &ap->host->lock
-	 * 3) ->freeze() and ->thaw() are called with ap->lock held
-	 */
-	hotplug_status = readl(host_mmio + hotplug_offset);
-	hotplug_status |= 0x11 << (ata_no + 16);
-	writel(hotplug_status, host_mmio + hotplug_offset);
-	readl(host_mmio + hotplug_offset); /* flush */
-
-	pdc_freeze(ap);
+	writel(tmp, mmio + PDC_CTLSTAT);
+	readl(mmio + PDC_CTLSTAT); /* flush */
 }
 
 static void pdc_thaw(struct ata_port *ap)
 {
-	void __iomem *ata_mmio = ap->ioaddr.cmd_addr;
+	void __iomem *mmio = ap->ioaddr.cmd_addr;
 	u32 tmp;
 
 	/* clear IRQ */
-	readl(ata_mmio + PDC_COMMAND);
+	readl(mmio + PDC_INT_SEQMASK);
 
 	/* turn IRQ back on */
-	tmp = readl(ata_mmio + PDC_CTLSTAT);
+	tmp = readl(mmio + PDC_CTLSTAT);
 	tmp &= ~PDC_IRQ_DISABLE;
-	writel(tmp, ata_mmio + PDC_CTLSTAT);
-	readl(ata_mmio + PDC_CTLSTAT); /* flush */
-}
-
-static void pdc_sata_thaw(struct ata_port *ap)
-{
-	struct ata_host *host = ap->host;
-	void __iomem *host_mmio = host->iomap[PDC_MMIO_BAR];
-	unsigned int hotplug_offset = PDC2_SATA_PLUG_CSR;
-	unsigned int ata_no = pdc_sata_ata_port_to_ata_no(ap);
-	u32 hotplug_status;
-
-	pdc_thaw(ap);
-
-	/* Enable hotplug events on this port.
-	 * Locking: see pdc_sata_freeze().
-	 */
-	hotplug_status = readl(host_mmio + hotplug_offset);
-	hotplug_status |= 0x11 << ata_no;
-	hotplug_status &= ~(0x11 << (ata_no + 16));
-	writel(hotplug_status, host_mmio + hotplug_offset);
-	readl(host_mmio + hotplug_offset); /* flush */
-}
-
-static int pdc_pata_softreset(struct ata_link *link, unsigned int *class,
-			      unsigned long deadline)
-{
-	pdc_reset_port(link->ap);
-	return ata_sff_softreset(link, class, deadline);
+	writel(tmp, mmio + PDC_CTLSTAT);
+	readl(mmio + PDC_CTLSTAT); /* flush */
 }
 
-static unsigned int pdc_ata_port_to_ata_no(const struct ata_port *ap)
+static void pdc_common_error_handler(struct ata_port *ap, ata_reset_fn_t hardreset)
 {
-	void __iomem *ata_mmio = ap->ioaddr.cmd_addr;
-	void __iomem *host_mmio = ap->host->iomap[PDC_MMIO_BAR];
+	if (!(ap->pflags & ATA_PFLAG_FROZEN))
+		pdc_reset_port(ap);
 
-	/* ata_mmio == host_mmio + 0x200 + ata_no * 0x80 */
-	return (ata_mmio - host_mmio - 0x200) / 0x80;
+	/* perform recovery */
+	ata_do_eh(ap, ata_std_prereset, ata_std_softreset, hardreset,
+		  ata_std_postreset);
 }
 
-static void pdc_hard_reset_port(struct ata_port *ap)
+static void pdc_pata_error_handler(struct ata_port *ap)
 {
-	void __iomem *host_mmio = ap->host->iomap[PDC_MMIO_BAR];
-	void __iomem *pcictl_b1_mmio = host_mmio + PDC_PCI_CTL + 1;
-	unsigned int ata_no = pdc_ata_port_to_ata_no(ap);
-	u8 tmp;
-
-	spin_lock(&ap->host->lock);
-
-	tmp = readb(pcictl_b1_mmio);
-	tmp &= ~(0x10 << ata_no);
-	writeb(tmp, pcictl_b1_mmio);
-	readb(pcictl_b1_mmio); /* flush */
-	udelay(100);
-	tmp |= (0x10 << ata_no);
-	writeb(tmp, pcictl_b1_mmio);
-	readb(pcictl_b1_mmio); /* flush */
-
-	spin_unlock(&ap->host->lock);
-}
-
-static int pdc_sata_hardreset(struct ata_link *link, unsigned int *class,
-			      unsigned long deadline)
-{
-	if (link->ap->flags & PDC_FLAG_GEN_II)
-		pdc_not_at_command_packet_phase(link->ap);
-	/* hotplug IRQs should have been masked by pdc_sata_freeze() */
-	pdc_hard_reset_port(link->ap);
-	pdc_reset_port(link->ap);
-
-	/* sata_promise can't reliably acquire the first D2H Reg FIS
-	 * after hardreset.  Do non-waiting hardreset and request
-	 * follow-up SRST.
-	 */
-	return sata_std_hardreset(link, class, deadline);
+	pdc_common_error_handler(ap, NULL);
 }
 
-static void pdc_error_handler(struct ata_port *ap)
+static void pdc_sata_error_handler(struct ata_port *ap)
 {
-	if (!(ap->pflags & ATA_PFLAG_FROZEN))
-		pdc_reset_port(ap);
-
-	ata_std_error_handler(ap);
+	pdc_common_error_handler(ap, sata_std_hardreset);
 }
 
 static void pdc_post_internal_cmd(struct ata_queued_cmd *qc)
@@ -852,7 +705,7 @@
 static void pdc_error_intr(struct ata_port *ap, struct ata_queued_cmd *qc,
 			   u32 port_status, u32 err_mask)
 {
-	struct ata_eh_info *ehi = &ap->link.eh_info;
+	struct ata_eh_info *ehi = &ap->eh_info;
 	unsigned int ac_err_mask = 0;
 
 	ata_ehi_clear_desc(ehi);
@@ -869,10 +722,10 @@
 			   | PDC_PCI_SYS_ERR | PDC1_PCI_PARITY_ERR))
 		ac_err_mask |= AC_ERR_HOST_BUS;
 
-	if (sata_scr_valid(&ap->link)) {
+	if (sata_scr_valid(ap)) {
 		u32 serror;
 
-		pdc_sata_scr_read(&ap->link, SCR_ERROR, &serror);
+		pdc_sata_scr_read(ap, SCR_ERROR, &serror);
 		ehi->serror |= serror;
 	}
 
@@ -883,11 +736,11 @@
 	ata_port_abort(ap);
 }
 
-static unsigned int pdc_host_intr(struct ata_port *ap,
-				  struct ata_queued_cmd *qc)
+static inline unsigned int pdc_host_intr(struct ata_port *ap,
+					 struct ata_queued_cmd *qc)
 {
 	unsigned int handled = 0;
-	void __iomem *ata_mmio = ap->ioaddr.cmd_addr;
+	void __iomem *port_mmio = ap->ioaddr.cmd_addr;
 	u32 port_status, err_mask;
 
 	err_mask = PDC_ERR_MASK;
@@ -895,7 +748,7 @@
 		err_mask &= ~PDC1_ERR_MASK;
 	else
 		err_mask &= ~PDC2_ERR_MASK;
-	port_status = readl(ata_mmio + PDC_GLOBAL_CTL);
+	port_status = readl(port_mmio + PDC_GLOBAL_CTL);
 	if (unlikely(port_status & err_mask)) {
 		pdc_error_intr(ap, qc, port_status, err_mask);
 		return 1;
@@ -904,12 +757,13 @@
 	switch (qc->tf.protocol) {
 	case ATA_PROT_DMA:
 	case ATA_PROT_NODATA:
-	case ATAPI_PROT_DMA:
-	case ATAPI_PROT_NODATA:
+	case ATA_PROT_ATAPI_DMA:
+	case ATA_PROT_ATAPI_NODATA:
 		qc->err_mask |= ac_err_mask(ata_wait_idle(ap));
 		ata_qc_complete(qc);
 		handled = 1;
 		break;
+
 	default:
 		ap->stats.idle_irq++;
 		break;
@@ -920,19 +774,32 @@
 
 static void pdc_irq_clear(struct ata_port *ap)
 {
-	void __iomem *ata_mmio = ap->ioaddr.cmd_addr;
+	struct ata_host *host = ap->host;
+	void __iomem *mmio = host->iomap[PDC_MMIO_BAR];
+
+	readl(mmio + PDC_INT_SEQMASK);
+}
+
+static inline int pdc_is_sataii_tx4(unsigned long flags)
+{
+	const unsigned long mask = PDC_FLAG_GEN_II | PDC_FLAG_4_PORTS;
+	return (flags & mask) == mask;
+}
 
-	readl(ata_mmio + PDC_COMMAND);
+static inline unsigned int pdc_port_no_to_ata_no(unsigned int port_no, int is_sataii_tx4)
+{
+	static const unsigned char sataii_tx4_port_remap[4] = { 3, 1, 0, 2};
+	return is_sataii_tx4 ? sataii_tx4_port_remap[port_no] : port_no;
 }
 
-static irqreturn_t pdc_interrupt(int irq, void *dev_instance)
+static irqreturn_t pdc_interrupt (int irq, void *dev_instance)
 {
 	struct ata_host *host = dev_instance;
 	struct ata_port *ap;
 	u32 mask = 0;
 	unsigned int i, tmp;
 	unsigned int handled = 0;
-	void __iomem *host_mmio;
+	void __iomem *mmio_base;
 	unsigned int hotplug_offset, ata_no;
 	u32 hotplug_status;
 	int is_sataii_tx4;
@@ -944,35 +811,35 @@
 		return IRQ_NONE;
 	}
 
-	host_mmio = host->iomap[PDC_MMIO_BAR];
-
-	spin_lock(&host->lock);
+	mmio_base = host->iomap[PDC_MMIO_BAR];
 
 	/* read and clear hotplug flags for all ports */
-	if (host->ports[0]->flags & PDC_FLAG_GEN_II) {
+	if (host->ports[0]->flags & PDC_FLAG_GEN_II)
 		hotplug_offset = PDC2_SATA_PLUG_CSR;
-		hotplug_status = readl(host_mmio + hotplug_offset);
-		if (hotplug_status & 0xff)
-			writel(hotplug_status | 0xff, host_mmio + hotplug_offset);
-		hotplug_status &= 0xff;	/* clear uninteresting bits */
-	} else
-		hotplug_status = 0;
+	else
+		hotplug_offset = PDC_SATA_PLUG_CSR;
+	hotplug_status = readl(mmio_base + hotplug_offset);
+	if (hotplug_status & 0xff)
+		writel(hotplug_status | 0xff, mmio_base + hotplug_offset);
+	hotplug_status &= 0xff;	/* clear uninteresting bits */
 
 	/* reading should also clear interrupts */
-	mask = readl(host_mmio + PDC_INT_SEQMASK);
+	mask = readl(mmio_base + PDC_INT_SEQMASK);
 
 	if (mask == 0xffffffff && hotplug_status == 0) {
 		VPRINTK("QUICK EXIT 2\n");
-		goto done_irq;
+		return IRQ_NONE;
 	}
 
-	mask &= 0xffff;		/* only 16 SEQIDs possible */
+	spin_lock(&host->lock);
+
+	mask &= 0xffff;		/* only 16 tags possible */
 	if (mask == 0 && hotplug_status == 0) {
 		VPRINTK("QUICK EXIT 3\n");
 		goto done_irq;
 	}
 
-	writel(mask, host_mmio + PDC_INT_SEQMASK);
+	writel(mask, mmio_base + PDC_INT_SEQMASK);
 
 	is_sataii_tx4 = pdc_is_sataii_tx4(host->ports[0]->flags);
 
@@ -985,7 +852,7 @@
 		tmp = hotplug_status & (0x11 << ata_no);
 		if (tmp && ap &&
 		    !(ap->flags & ATA_FLAG_DISABLED)) {
-			struct ata_eh_info *ehi = &ap->link.eh_info;
+			struct ata_eh_info *ehi = &ap->eh_info;
 			ata_ehi_clear_desc(ehi);
 			ata_ehi_hotplugged(ehi);
 			ata_ehi_push_desc(ehi, "hotplug_status %#x", tmp);
@@ -1000,7 +867,7 @@
 		    !(ap->flags & ATA_FLAG_DISABLED)) {
 			struct ata_queued_cmd *qc;
 
-			qc = ata_qc_from_tag(ap, ap->link.active_tag);
+			qc = ata_qc_from_tag(ap, ap->active_tag);
 			if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)))
 				handled += pdc_host_intr(ap, qc);
 		}
@@ -1013,30 +880,29 @@
 	return IRQ_RETVAL(handled);
 }
 
-static void pdc_packet_start(struct ata_queued_cmd *qc)
+static inline void pdc_packet_start(struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	struct pdc_port_priv *pp = ap->private_data;
-	void __iomem *host_mmio = ap->host->iomap[PDC_MMIO_BAR];
-	void __iomem *ata_mmio = ap->ioaddr.cmd_addr;
+	void __iomem *mmio = ap->host->iomap[PDC_MMIO_BAR];
 	unsigned int port_no = ap->port_no;
 	u8 seq = (u8) (port_no + 1);
 
 	VPRINTK("ENTER, ap %p\n", ap);
 
-	writel(0x00000001, host_mmio + (seq * 4));
-	readl(host_mmio + (seq * 4));	/* flush */
+	writel(0x00000001, mmio + (seq * 4));
+	readl(mmio + (seq * 4));	/* flush */
 
 	pp->pkt[2] = seq;
 	wmb();			/* flush PRD, pkt writes */
-	writel(pp->pkt_dma, ata_mmio + PDC_PKT_SUBMIT);
-	readl(ata_mmio + PDC_PKT_SUBMIT); /* flush */
+	writel(pp->pkt_dma, ap->ioaddr.cmd_addr + PDC_PKT_SUBMIT);
+	readl(ap->ioaddr.cmd_addr + PDC_PKT_SUBMIT); /* flush */
 }
 
-static unsigned int pdc_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int pdc_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	switch (qc->tf.protocol) {
-	case ATAPI_PROT_NODATA:
+	case ATA_PROT_ATAPI_NODATA:
 		if (qc->dev->flags & ATA_DFLAG_CDB_INTR)
 			break;
 		/*FALLTHROUGH*/
@@ -1044,27 +910,30 @@
 		if (qc->tf.flags & ATA_TFLAG_POLLING)
 			break;
 		/*FALLTHROUGH*/
-	case ATAPI_PROT_DMA:
+	case ATA_PROT_ATAPI_DMA:
 	case ATA_PROT_DMA:
 		pdc_packet_start(qc);
 		return 0;
+
 	default:
 		break;
 	}
-	return ata_sff_qc_issue(qc);
+
+	return ata_qc_issue_prot(qc);
 }
 
 static void pdc_tf_load_mmio(struct ata_port *ap, const struct ata_taskfile *tf)
 {
-	WARN_ON(tf->protocol == ATA_PROT_DMA || tf->protocol == ATAPI_PROT_DMA);
-	ata_sff_tf_load(ap, tf);
+	WARN_ON (tf->protocol == ATA_PROT_DMA ||
+		 tf->protocol == ATA_PROT_ATAPI_DMA);
+	ata_tf_load(ap, tf);
 }
 
-static void pdc_exec_command_mmio(struct ata_port *ap,
-				  const struct ata_taskfile *tf)
+static void pdc_exec_command_mmio(struct ata_port *ap, const struct ata_taskfile *tf)
 {
-	WARN_ON(tf->protocol == ATA_PROT_DMA || tf->protocol == ATAPI_PROT_DMA);
-	ata_sff_exec_command(ap, tf);
+	WARN_ON (tf->protocol == ATA_PROT_DMA ||
+		 tf->protocol == ATA_PROT_ATAPI_DMA);
+	ata_exec_command(ap, tf);
 }
 
 static int pdc_check_atapi_dma(struct ata_queued_cmd *qc)
@@ -1086,11 +955,8 @@
 	}
 	/* -45150 (FFFF4FA2) to -1 (FFFFFFFF) shall use PIO mode */
 	if (scsicmd[0] == WRITE_10) {
-		unsigned int lba =
-			(scsicmd[2] << 24) |
-			(scsicmd[3] << 16) |
-			(scsicmd[4] << 8) |
-			scsicmd[5];
+		unsigned int lba;
+		lba = (scsicmd[2] << 24) | (scsicmd[3] << 16) | (scsicmd[4] << 8) | scsicmd[5];
 		if (lba >= 0xFFFF4FA2)
 			pio = 1;
 	}
@@ -1124,7 +990,7 @@
 
 static void pdc_host_init(struct ata_host *host)
 {
-	void __iomem *host_mmio = host->iomap[PDC_MMIO_BAR];
+	void __iomem *mmio = host->iomap[PDC_MMIO_BAR];
 	int is_gen2 = host->ports[0]->flags & PDC_FLAG_GEN_II;
 	int hotplug_offset;
 	u32 tmp;
@@ -1141,50 +1007,47 @@
 	 */
 
 	/* enable BMR_BURST, maybe change FIFO_SHD to 8 dwords */
-	tmp = readl(host_mmio + PDC_FLASH_CTL);
+	tmp = readl(mmio + PDC_FLASH_CTL);
 	tmp |= 0x02000;	/* bit 13 (enable bmr burst) */
 	if (!is_gen2)
 		tmp |= 0x10000;	/* bit 16 (fifo threshold at 8 dw) */
-	writel(tmp, host_mmio + PDC_FLASH_CTL);
+	writel(tmp, mmio + PDC_FLASH_CTL);
 
 	/* clear plug/unplug flags for all ports */
-	tmp = readl(host_mmio + hotplug_offset);
-	writel(tmp | 0xff, host_mmio + hotplug_offset);
+	tmp = readl(mmio + hotplug_offset);
+	writel(tmp | 0xff, mmio + hotplug_offset);
 
-	tmp = readl(host_mmio + hotplug_offset);
-	if (is_gen2)	/* unmask plug/unplug ints */
-		writel(tmp & ~0xff0000, host_mmio + hotplug_offset);
-	else		/* mask plug/unplug ints */
-		writel(tmp | 0xff0000, host_mmio + hotplug_offset);
+	/* unmask plug/unplug ints */
+	tmp = readl(mmio + hotplug_offset);
+	writel(tmp & ~0xff0000, mmio + hotplug_offset);
 
 	/* don't initialise TBG or SLEW on 2nd generation chips */
 	if (is_gen2)
 		return;
 
 	/* reduce TBG clock to 133 Mhz. */
-	tmp = readl(host_mmio + PDC_TBG_MODE);
+	tmp = readl(mmio + PDC_TBG_MODE);
 	tmp &= ~0x30000; /* clear bit 17, 16*/
 	tmp |= 0x10000;  /* set bit 17:16 = 0:1 */
-	writel(tmp, host_mmio + PDC_TBG_MODE);
+	writel(tmp, mmio + PDC_TBG_MODE);
 
-	readl(host_mmio + PDC_TBG_MODE);	/* flush */
+	readl(mmio + PDC_TBG_MODE);	/* flush */
 	msleep(10);
 
 	/* adjust slew rate control register. */
-	tmp = readl(host_mmio + PDC_SLEW_CTL);
+	tmp = readl(mmio + PDC_SLEW_CTL);
 	tmp &= 0xFFFFF03F; /* clear bit 11 ~ 6 */
 	tmp  |= 0x00000900; /* set bit 11-9 = 100b , bit 8-6 = 100 */
-	writel(tmp, host_mmio + PDC_SLEW_CTL);
+	writel(tmp, mmio + PDC_SLEW_CTL);
 }
 
-static int pdc_ata_init_one(struct pci_dev *pdev,
-			    const struct pci_device_id *ent)
+static int pdc_ata_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
 	const struct ata_port_info *pi = &pdc_port_info[ent->driver_data];
 	const struct ata_port_info *ppi[PDC_MAX_PORTS];
 	struct ata_host *host;
-	void __iomem *host_mmio;
+	void __iomem *base;
 	int n_ports, i, rc;
 	int is_sataii_tx4;
 
@@ -1201,7 +1064,7 @@
 		pcim_pin_device(pdev);
 	if (rc)
 		return rc;
-	host_mmio = pcim_iomap_table(pdev)[PDC_MMIO_BAR];
+	base = pcim_iomap_table(pdev)[PDC_MMIO_BAR];
 
 	/* determine port configuration and setup host */
 	n_ports = 2;
@@ -1211,7 +1074,7 @@
 		ppi[i] = pi;
 
 	if (pi->flags & PDC_FLAG_SATA_PATA) {
-		u8 tmp = readb(host_mmio + PDC_FLASH_CTL + 1);
+		u8 tmp = readb(base + PDC_FLASH_CTL+1);
 		if (!(tmp & 0x80))
 			ppi[n_ports++] = pi + 1;
 	}
@@ -1225,15 +1088,10 @@
 
 	is_sataii_tx4 = pdc_is_sataii_tx4(pi->flags);
 	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
 		unsigned int ata_no = pdc_port_no_to_ata_no(i, is_sataii_tx4);
-		unsigned int ata_offset = 0x200 + ata_no * 0x80;
-		unsigned int scr_offset = 0x400 + ata_no * 0x100;
-
-		pdc_ata_setup_port(ap, host_mmio + ata_offset, host_mmio + scr_offset);
-
-		ata_port_pbar_desc(ap, PDC_MMIO_BAR, -1, "mmio");
-		ata_port_pbar_desc(ap, PDC_MMIO_BAR, ata_offset, "ata");
+		pdc_ata_setup_port(host->ports[i],
+				   base + 0x200 + ata_no * 0x80,
+				   base + 0x400 + ata_no * 0x100);
 	}
 
 	/* initialize adapter */
diff -Nur linux-sh4/drivers/ata.org/sata_promise.h linux-sh4/drivers/ata/sata_promise.h
--- linux-sh4/drivers/ata.org/sata_promise.h	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_promise.h	2012-01-15 06:30:15.000000000 -0800
@@ -46,7 +46,7 @@
 					  unsigned int devno, u8 *buf)
 {
 	u8 dev_reg;
-	__le32 *buf32 = (__le32 *) buf;
+	u32 *buf32 = (u32 *) buf;
 
 	/* set control bits (byte 0), zero delay seq id (byte 3),
 	 * and seq id (byte 2)
diff -Nur linux-sh4/drivers/ata.org/sata_qstor.c linux-sh4/drivers/ata/sata_qstor.c
--- linux-sh4/drivers/ata.org/sata_qstor.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_qstor.c	2012-01-15 06:30:15.000000000 -0800
@@ -103,7 +103,7 @@
 	QS_DMA_BOUNDARY		= ~0UL
 };
 
-typedef enum { qs_state_mmio, qs_state_pkt } qs_state_t;
+typedef enum { qs_state_idle, qs_state_pkt, qs_state_mmio } qs_state_t;
 
 struct qs_port_priv {
 	u8			*pkt;
@@ -111,57 +111,71 @@
 	qs_state_t		state;
 };
 
-static int qs_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val);
-static int qs_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val);
-static int qs_ata_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
+static int qs_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val);
+static int qs_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val);
+static int qs_ata_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
 static int qs_port_start(struct ata_port *ap);
 static void qs_host_stop(struct ata_host *host);
+static void qs_phy_reset(struct ata_port *ap);
 static void qs_qc_prep(struct ata_queued_cmd *qc);
 static unsigned int qs_qc_issue(struct ata_queued_cmd *qc);
 static int qs_check_atapi_dma(struct ata_queued_cmd *qc);
 static void qs_bmdma_stop(struct ata_queued_cmd *qc);
 static u8 qs_bmdma_status(struct ata_port *ap);
-static void qs_freeze(struct ata_port *ap);
-static void qs_thaw(struct ata_port *ap);
-static int qs_prereset(struct ata_link *link, unsigned long deadline);
-static void qs_error_handler(struct ata_port *ap);
+static void qs_irq_clear(struct ata_port *ap);
+static void qs_eng_timeout(struct ata_port *ap);
 
 static struct scsi_host_template qs_ata_sht = {
-	ATA_BASE_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= QS_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	//FIXME .use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.use_clustering		= ENABLE_CLUSTERING,
+	.proc_name		= DRV_NAME,
 	.dma_boundary		= QS_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations qs_ata_ops = {
-	.inherits		= &ata_sff_port_ops,
-
+static const struct ata_port_operations qs_ata_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
 	.check_atapi_dma	= qs_check_atapi_dma,
-	.bmdma_stop		= qs_bmdma_stop,
-	.bmdma_status		= qs_bmdma_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+	.phy_reset		= qs_phy_reset,
 	.qc_prep		= qs_qc_prep,
 	.qc_issue		= qs_qc_issue,
-
-	.freeze			= qs_freeze,
-	.thaw			= qs_thaw,
-	.prereset		= qs_prereset,
-	.softreset		= ATA_OP_NULL,
-	.error_handler		= qs_error_handler,
-	.post_internal_cmd	= ATA_OP_NULL,
-	.lost_interrupt		= ATA_OP_NULL,
-
+	.data_xfer		= ata_data_xfer,
+	.eng_timeout		= qs_eng_timeout,
+	.irq_clear		= qs_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 	.scr_read		= qs_scr_read,
 	.scr_write		= qs_scr_write,
-
 	.port_start		= qs_port_start,
 	.host_stop		= qs_host_stop,
+	.bmdma_stop		= qs_bmdma_stop,
+	.bmdma_status		= qs_bmdma_status,
 };
 
 static const struct ata_port_info qs_port_info[] = {
 	/* board_2068_idx */
 	{
 		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
+				  ATA_FLAG_SATA_RESET |
+				  //FIXME ATA_FLAG_SRST |
 				  ATA_FLAG_MMIO | ATA_FLAG_PIO_POLLING,
-		.pio_mask	= ATA_PIO4_ONLY,
+		.pio_mask	= 0x10, /* pio4 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &qs_ata_ops,
 	},
@@ -200,12 +214,15 @@
 	return 0;
 }
 
+static void qs_irq_clear(struct ata_port *ap)
+{
+	/* nothing */
+}
+
 static inline void qs_enter_reg_mode(struct ata_port *ap)
 {
 	u8 __iomem *chan = qs_mmio_base(ap->host) + (ap->port_no * 0x4000);
-	struct qs_port_priv *pp = ap->private_data;
 
-	pp->state = qs_state_mmio;
 	writeb(QS_CTR0_REG, chan + QS_CCT_CTR0);
 	readb(chan + QS_CCT_CTR0);        /* flush */
 }
@@ -219,49 +236,38 @@
 	qs_enter_reg_mode(ap);
 }
 
-static void qs_freeze(struct ata_port *ap)
-{
-	u8 __iomem *mmio_base = qs_mmio_base(ap->host);
-
-	writeb(0, mmio_base + QS_HCT_CTRL); /* disable host interrupts */
-	qs_enter_reg_mode(ap);
-}
-
-static void qs_thaw(struct ata_port *ap)
+static void qs_phy_reset(struct ata_port *ap)
 {
-	u8 __iomem *mmio_base = qs_mmio_base(ap->host);
+	struct qs_port_priv *pp = ap->private_data;
 
-	qs_enter_reg_mode(ap);
-	writeb(1, mmio_base + QS_HCT_CTRL); /* enable host interrupts */
+	pp->state = qs_state_idle;
+	qs_reset_channel_logic(ap);
+	sata_phy_reset(ap);
 }
 
-static int qs_prereset(struct ata_link *link, unsigned long deadline)
+static void qs_eng_timeout(struct ata_port *ap)
 {
-	struct ata_port *ap = link->ap;
+	struct qs_port_priv *pp = ap->private_data;
 
+	if (pp->state != qs_state_idle) /* healthy paranoia */
+		pp->state = qs_state_mmio;
 	qs_reset_channel_logic(ap);
-	return ata_sff_prereset(link, deadline);
+	ata_eng_timeout(ap);
 }
 
-static int qs_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)
+static int qs_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	*val = readl(link->ap->ioaddr.scr_addr + (sc_reg * 8));
+	*val = readl(ap->ioaddr.scr_addr + (sc_reg * 8));
 	return 0;
 }
 
-static void qs_error_handler(struct ata_port *ap)
-{
-	qs_enter_reg_mode(ap);
-	ata_std_error_handler(ap);
-}
-
-static int qs_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)
+static int qs_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	writel(val, link->ap->ioaddr.scr_addr + (sc_reg * 8));
+	writel(val, ap->ioaddr.scr_addr + (sc_reg * 8));
 	return 0;
 }
 
@@ -270,10 +276,14 @@
 	struct scatterlist *sg;
 	struct ata_port *ap = qc->ap;
 	struct qs_port_priv *pp = ap->private_data;
+	unsigned int nelem;
 	u8 *prd = pp->pkt + QS_CPB_BYTES;
-	unsigned int si;
 
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
+	WARN_ON(qc->__sg == NULL);
+	WARN_ON(qc->n_elem == 0 && qc->pad_len == 0);
+
+	nelem = 0;
+	ata_for_each_sg(sg, qc) {
 		u64 addr;
 		u32 len;
 
@@ -285,11 +295,12 @@
 		*(__le32 *)prd = cpu_to_le32(len);
 		prd += sizeof(u64);
 
-		VPRINTK("PRD[%u] = (0x%llX, 0x%X)\n", si,
+		VPRINTK("PRD[%u] = (0x%llX, 0x%X)\n", nelem,
 					(unsigned long long)addr, len);
+		nelem++;
 	}
 
-	return si;
+	return nelem;
 }
 
 static void qs_qc_prep(struct ata_queued_cmd *qc)
@@ -304,7 +315,7 @@
 
 	qs_enter_reg_mode(qc->ap);
 	if (qc->tf.protocol != ATA_PROT_DMA) {
-		ata_sff_qc_prep(qc);
+		ata_qc_prep(qc);
 		return;
 	}
 
@@ -350,11 +361,12 @@
 
 	switch (qc->tf.protocol) {
 	case ATA_PROT_DMA:
+
 		pp->state = qs_state_pkt;
 		qs_packet_start(qc);
 		return 0;
 
-	case ATAPI_PROT_DMA:
+	case ATA_PROT_ATAPI_DMA:
 		BUG();
 		break;
 
@@ -363,27 +375,7 @@
 	}
 
 	pp->state = qs_state_mmio;
-	return ata_sff_qc_issue(qc);
-}
-
-static void qs_do_or_die(struct ata_queued_cmd *qc, u8 status)
-{
-	qc->err_mask |= ac_err_mask(status);
-
-	if (!qc->err_mask) {
-		ata_qc_complete(qc);
-	} else {
-		struct ata_port    *ap  = qc->ap;
-		struct ata_eh_info *ehi = &ap->link.eh_info;
-
-		ata_ehi_clear_desc(ehi);
-		ata_ehi_push_desc(ehi, "status 0x%02X", status);
-
-		if (qc->err_mask == AC_ERR_DEV)
-			ata_port_abort(ap);
-		else
-			ata_port_freeze(ap);
-	}
+	return ata_qc_issue_prot(qc);
 }
 
 static inline unsigned int qs_intr_pkt(struct ata_host *host)
@@ -412,13 +404,15 @@
 				struct qs_port_priv *pp = ap->private_data;
 				if (!pp || pp->state != qs_state_pkt)
 					continue;
-				qc = ata_qc_from_tag(ap, ap->link.active_tag);
+				qc = ata_qc_from_tag(ap, ap->active_tag);
 				if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING))) {
 					switch (sHST) {
 					case 0: /* successful CPB */
 					case 3: /* device error */
+						pp->state = qs_state_idle;
 						qs_enter_reg_mode(qc->ap);
-						qs_do_or_die(qc, sDST);
+						qc->err_mask |= ac_err_mask(sDST);
+						ata_qc_complete(qc);
 						break;
 					default:
 						break;
@@ -440,27 +434,25 @@
 		if (ap &&
 		    !(ap->flags & ATA_FLAG_DISABLED)) {
 			struct ata_queued_cmd *qc;
-			struct qs_port_priv *pp;
-			qc = ata_qc_from_tag(ap, ap->link.active_tag);
-			if (!qc || !(qc->flags & ATA_QCFLAG_ACTIVE)) {
-				/*
-				 * The qstor hardware generates spurious
-				 * interrupts from time to time when switching
-				 * in and out of packet mode.
-				 * There's no obvious way to know if we're
-				 * here now due to that, so just ack the irq
-				 * and pretend we knew it was ours.. (ugh).
-				 * This does not affect packet mode.
-				 */
-				ata_sff_check_status(ap);
-				handled = 1;
-				continue;
-			}
-			pp = ap->private_data;
+			struct qs_port_priv *pp = ap->private_data;
 			if (!pp || pp->state != qs_state_mmio)
 				continue;
-			if (!(qc->tf.flags & ATA_TFLAG_POLLING))
-				handled |= ata_sff_host_intr(ap, qc);
+			qc = ata_qc_from_tag(ap, ap->active_tag);
+			if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING))) {
+
+				/* check main status, clearing INTRQ */
+				u8 status = ata_check_status(ap);
+				if ((status & ATA_BUSY))
+					continue;
+				DPRINTK("ata%u: protocol %d (dev_stat 0x%X)\n",
+					ap->print_id, qc->tf.protocol, status);
+
+				/* complete taskfile transaction */
+				pp->state = qs_state_idle;
+				qc->err_mask |= ac_err_mask(status);
+				ata_qc_complete(qc);
+				handled = 1;
+			}
 		}
 	}
 	return handled;
@@ -470,13 +462,12 @@
 {
 	struct ata_host *host = dev_instance;
 	unsigned int handled = 0;
-	unsigned long flags;
 
 	VPRINTK("ENTER\n");
 
-	spin_lock_irqsave(&host->lock, flags);
+	spin_lock(&host->lock);
 	handled  = qs_intr_pkt(host) | qs_intr_mmio(host);
-	spin_unlock_irqrestore(&host->lock, flags);
+	spin_unlock(&host->lock);
 
 	VPRINTK("EXIT\n");
 
@@ -513,6 +504,7 @@
 	rc = ata_port_start(ap);
 	if (rc)
 		return rc;
+	qs_enter_reg_mode(ap);
 	pp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);
 	if (!pp)
 		return -ENOMEM;
@@ -523,7 +515,6 @@
 	memset(pp->pkt, 0, QS_PKT_BYTES);
 	ap->private_data = pp;
 
-	qs_enter_reg_mode(ap);
 	addr = (u64)pp->pkt_dma;
 	writel((u32) addr,        chan + QS_CCF_CPBA);
 	writel((u32)(addr >> 32), chan + QS_CCF_CPBA + 4);
@@ -584,10 +575,10 @@
 	int rc, have_64bit_bus = (bus_info & QS_HPHY_64BIT);
 
 	if (have_64bit_bus &&
-	    !pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {
-		rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
+	    !pci_set_dma_mask(pdev, DMA_64BIT_MASK)) {
+		rc = pci_set_consistent_dma_mask(pdev, DMA_64BIT_MASK);
 		if (rc) {
-			rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+			rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 			if (rc) {
 				dev_printk(KERN_ERR, &pdev->dev,
 					   "64-bit DMA enable failed\n");
@@ -595,13 +586,13 @@
 			}
 		}
 	} else {
-		rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
+		rc = pci_set_dma_mask(pdev, DMA_32BIT_MASK);
 		if (rc) {
 			dev_printk(KERN_ERR, &pdev->dev,
 				"32-bit DMA enable failed\n");
 			return rc;
 		}
-		rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+		rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 		if (rc) {
 			dev_printk(KERN_ERR, &pdev->dev,
 				"32-bit consistent DMA enable failed\n");
@@ -646,14 +637,9 @@
 		return rc;
 
 	for (port_no = 0; port_no < host->n_ports; ++port_no) {
-		struct ata_port *ap = host->ports[port_no];
-		unsigned int offset = port_no * 0x4000;
-		void __iomem *chan = host->iomap[QS_MMIO_BAR] + offset;
-
-		qs_ata_setup_port(&ap->ioaddr, chan);
-
-		ata_port_pbar_desc(ap, QS_MMIO_BAR, -1, "mmio");
-		ata_port_pbar_desc(ap, QS_MMIO_BAR, offset, "port");
+		void __iomem *chan =
+			host->iomap[QS_MMIO_BAR] + (port_no * 0x4000);
+		qs_ata_setup_port(&host->ports[port_no]->ioaddr, chan);
 	}
 
 	/* initialize adapter */
diff -Nur linux-sh4/drivers/ata.org/sata_sil24.c linux-sh4/drivers/ata/sata_sil24.c
--- linux-sh4/drivers/ata.org/sata_sil24.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_sil24.c	2012-01-15 06:30:15.000000000 -0800
@@ -30,7 +30,7 @@
 #include <linux/libata.h>
 
 #define DRV_NAME	"sata_sil24"
-#define DRV_VERSION	"1.1"
+#define DRV_VERSION	"1.0"
 
 /*
  * Port request block (PRB) 32 bytes
@@ -51,26 +51,18 @@
 	__le32	flags;
 };
 
+/*
+ * Port multiplier
+ */
+struct sil24_port_multiplier {
+	__le32	diag;
+	__le32	sactive;
+};
 
 enum {
 	SIL24_HOST_BAR		= 0,
 	SIL24_PORT_BAR		= 2,
 
-	/* sil24 fetches in chunks of 64bytes.  The first block
-	 * contains the PRB and two SGEs.  From the second block, it's
-	 * consisted of four SGEs and called SGT.  Calculate the
-	 * number of SGTs that fit into one page.
-	 */
-	SIL24_PRB_SZ		= sizeof(struct sil24_prb)
-				  + 2 * sizeof(struct sil24_sge),
-	SIL24_MAX_SGT		= (PAGE_SIZE - SIL24_PRB_SZ)
-				  / (4 * sizeof(struct sil24_sge)),
-
-	/* This will give us one unused SGEs for ATA.  This extra SGE
-	 * will be used to store CDB for ATAPI devices.
-	 */
-	SIL24_MAX_SGE		= 4 * SIL24_MAX_SGT + 1,
-
 	/*
 	 * Global controller registers (128 bytes @ BAR0)
 	 */
@@ -176,7 +168,7 @@
 
 	DEF_PORT_IRQ		= PORT_IRQ_COMPLETE | PORT_IRQ_ERROR |
 				  PORT_IRQ_PHYRDY_CHG | PORT_IRQ_DEV_XCHG |
-				  PORT_IRQ_UNK_FIS | PORT_IRQ_SDB_NOTIFY,
+				  PORT_IRQ_UNK_FIS,
 
 	/* bits[27:16] are unmasked (raw) */
 	PORT_IRQ_RAW_SHIFT	= 16,
@@ -245,8 +237,8 @@
 	/* host flags */
 	SIL24_COMMON_FLAGS	= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
 				  ATA_FLAG_MMIO | ATA_FLAG_PIO_DMA |
-				  ATA_FLAG_NCQ | ATA_FLAG_ACPI_SATA |
-				  ATA_FLAG_AN | ATA_FLAG_PMP,
+				  ATA_FLAG_NCQ | ATA_FLAG_SKIP_D2H_BSY |
+				  ATA_FLAG_ACPI_SATA,
 	SIL24_FLAG_PCIX_IRQ_WOC	= (1 << 24), /* IRQ loss errata on PCI-X */
 
 	IRQ_STAT_4PORTS		= 0xf,
@@ -254,13 +246,13 @@
 
 struct sil24_ata_block {
 	struct sil24_prb prb;
-	struct sil24_sge sge[SIL24_MAX_SGE];
+	struct sil24_sge sge[LIBATA_MAX_PRD];
 };
 
 struct sil24_atapi_block {
 	struct sil24_prb prb;
 	u8 cdb[16];
-	struct sil24_sge sge[SIL24_MAX_SGE];
+	struct sil24_sge sge[LIBATA_MAX_PRD - 1];
 };
 
 union sil24_cmd_block {
@@ -272,51 +264,51 @@
 	unsigned int err_mask, action;
 	const char *desc;
 } sil24_cerr_db[] = {
-	[0]			= { AC_ERR_DEV, 0,
+	[0]			= { AC_ERR_DEV, ATA_EH_REVALIDATE,
 				    "device error" },
-	[PORT_CERR_DEV]		= { AC_ERR_DEV, 0,
+	[PORT_CERR_DEV]		= { AC_ERR_DEV, ATA_EH_REVALIDATE,
 				    "device error via D2H FIS" },
-	[PORT_CERR_SDB]		= { AC_ERR_DEV, 0,
+	[PORT_CERR_SDB]		= { AC_ERR_DEV, ATA_EH_REVALIDATE,
 				    "device error via SDB FIS" },
-	[PORT_CERR_DATA]	= { AC_ERR_ATA_BUS, ATA_EH_RESET,
+	[PORT_CERR_DATA]	= { AC_ERR_ATA_BUS, ATA_EH_SOFTRESET,
 				    "error in data FIS" },
-	[PORT_CERR_SEND]	= { AC_ERR_ATA_BUS, ATA_EH_RESET,
+	[PORT_CERR_SEND]	= { AC_ERR_ATA_BUS, ATA_EH_SOFTRESET,
 				    "failed to transmit command FIS" },
-	[PORT_CERR_INCONSISTENT] = { AC_ERR_HSM, ATA_EH_RESET,
+	[PORT_CERR_INCONSISTENT] = { AC_ERR_HSM, ATA_EH_SOFTRESET,
 				     "protocol mismatch" },
-	[PORT_CERR_DIRECTION]	= { AC_ERR_HSM, ATA_EH_RESET,
+	[PORT_CERR_DIRECTION]	= { AC_ERR_HSM, ATA_EH_SOFTRESET,
 				    "data directon mismatch" },
-	[PORT_CERR_UNDERRUN]	= { AC_ERR_HSM, ATA_EH_RESET,
+	[PORT_CERR_UNDERRUN]	= { AC_ERR_HSM, ATA_EH_SOFTRESET,
 				    "ran out of SGEs while writing" },
-	[PORT_CERR_OVERRUN]	= { AC_ERR_HSM, ATA_EH_RESET,
+	[PORT_CERR_OVERRUN]	= { AC_ERR_HSM, ATA_EH_SOFTRESET,
 				    "ran out of SGEs while reading" },
-	[PORT_CERR_PKT_PROT]	= { AC_ERR_HSM, ATA_EH_RESET,
+	[PORT_CERR_PKT_PROT]	= { AC_ERR_HSM, ATA_EH_SOFTRESET,
 				    "invalid data directon for ATAPI CDB" },
-	[PORT_CERR_SGT_BOUNDARY] = { AC_ERR_SYSTEM, ATA_EH_RESET,
-				     "SGT not on qword boundary" },
-	[PORT_CERR_SGT_TGTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_SGT_BOUNDARY] = { AC_ERR_SYSTEM, ATA_EH_SOFTRESET,
+				     "SGT no on qword boundary" },
+	[PORT_CERR_SGT_TGTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI target abort while fetching SGT" },
-	[PORT_CERR_SGT_MSTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_SGT_MSTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI master abort while fetching SGT" },
-	[PORT_CERR_SGT_PCIPERR]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_SGT_PCIPERR]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI parity error while fetching SGT" },
-	[PORT_CERR_CMD_BOUNDARY] = { AC_ERR_SYSTEM, ATA_EH_RESET,
+	[PORT_CERR_CMD_BOUNDARY] = { AC_ERR_SYSTEM, ATA_EH_SOFTRESET,
 				     "PRB not on qword boundary" },
-	[PORT_CERR_CMD_TGTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_CMD_TGTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI target abort while fetching PRB" },
-	[PORT_CERR_CMD_MSTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_CMD_MSTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI master abort while fetching PRB" },
-	[PORT_CERR_CMD_PCIPERR]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_CMD_PCIPERR]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI parity error while fetching PRB" },
-	[PORT_CERR_XFR_UNDEF]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_XFR_UNDEF]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "undefined error while transferring data" },
-	[PORT_CERR_XFR_TGTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_XFR_TGTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI target abort while transferring data" },
-	[PORT_CERR_XFR_MSTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_XFR_MSTABRT]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI master abort while transferring data" },
-	[PORT_CERR_XFR_PCIPERR]	= { AC_ERR_HOST_BUS, ATA_EH_RESET,
+	[PORT_CERR_XFR_PCIPERR]	= { AC_ERR_HOST_BUS, ATA_EH_SOFTRESET,
 				    "PCI parity error while transferring data" },
-	[PORT_CERR_SENDSERVICE]	= { AC_ERR_HSM, ATA_EH_RESET,
+	[PORT_CERR_SENDSERVICE]	= { AC_ERR_HSM, ATA_EH_SOFTRESET,
 				    "FIS received while sending service FIS" },
 };
 
@@ -329,33 +321,25 @@
 struct sil24_port_priv {
 	union sil24_cmd_block *cmd_block;	/* 32 cmd blocks */
 	dma_addr_t cmd_block_dma;		/* DMA base addr for them */
-	int do_port_rst;
+	struct ata_taskfile tf;			/* Cached taskfile registers */
 };
 
 static void sil24_dev_config(struct ata_device *dev);
-static int sil24_scr_read(struct ata_link *link, unsigned sc_reg, u32 *val);
-static int sil24_scr_write(struct ata_link *link, unsigned sc_reg, u32 val);
-static int sil24_qc_defer(struct ata_queued_cmd *qc);
+static u8 sil24_check_status(struct ata_port *ap);
+static int sil24_scr_read(struct ata_port *ap, unsigned sc_reg, u32 *val);
+static int sil24_scr_write(struct ata_port *ap, unsigned sc_reg, u32 val);
+static void sil24_tf_read(struct ata_port *ap, struct ata_taskfile *tf);
 static void sil24_qc_prep(struct ata_queued_cmd *qc);
 static unsigned int sil24_qc_issue(struct ata_queued_cmd *qc);
-static bool sil24_qc_fill_rtf(struct ata_queued_cmd *qc);
-static void sil24_pmp_attach(struct ata_port *ap);
-static void sil24_pmp_detach(struct ata_port *ap);
+static void sil24_irq_clear(struct ata_port *ap);
 static void sil24_freeze(struct ata_port *ap);
 static void sil24_thaw(struct ata_port *ap);
-static int sil24_softreset(struct ata_link *link, unsigned int *class,
-			   unsigned long deadline);
-static int sil24_hardreset(struct ata_link *link, unsigned int *class,
-			   unsigned long deadline);
-static int sil24_pmp_hardreset(struct ata_link *link, unsigned int *class,
-			       unsigned long deadline);
 static void sil24_error_handler(struct ata_port *ap);
 static void sil24_post_internal_cmd(struct ata_queued_cmd *qc);
 static int sil24_port_start(struct ata_port *ap);
 static int sil24_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
 #ifdef CONFIG_PM
 static int sil24_pci_device_resume(struct pci_dev *pdev);
-static int sil24_port_resume(struct ata_port *ap);
 #endif
 
 static const struct pci_device_id sil24_pci_tbl[] = {
@@ -363,7 +347,6 @@
 	{ PCI_VDEVICE(INTEL, 0x3124), BID_SIL3124 },
 	{ PCI_VDEVICE(CMD, 0x3132), BID_SIL3132 },
 	{ PCI_VDEVICE(CMD, 0x0242), BID_SIL3132 },
-	{ PCI_VDEVICE(CMD, 0x0244), BID_SIL3132 },
 	{ PCI_VDEVICE(CMD, 0x3131), BID_SIL3131 },
 	{ PCI_VDEVICE(CMD, 0x3531), BID_SIL3131 },
 
@@ -382,39 +365,51 @@
 };
 
 static struct scsi_host_template sil24_sht = {
-	ATA_NCQ_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.change_queue_depth	= ata_scsi_change_queue_depth,
 	.can_queue		= SIL24_MAX_CMDS,
-	.sg_tablesize		= SIL24_MAX_SGE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
 	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations sil24_ops = {
-	.inherits		= &sata_pmp_port_ops,
+static const struct ata_port_operations sil24_ops = {
+	.port_disable		= ata_port_disable,
+
+	.dev_config		= sil24_dev_config,
+
+	.check_status		= sil24_check_status,
+	.check_altstatus	= sil24_check_status,
+	.dev_select		= ata_noop_dev_select,
+
+	.tf_read		= sil24_tf_read,
 
-	.qc_defer		= sil24_qc_defer,
 	.qc_prep		= sil24_qc_prep,
 	.qc_issue		= sil24_qc_issue,
-	.qc_fill_rtf		= sil24_qc_fill_rtf,
+
+	.irq_clear		= sil24_irq_clear,
+	.irq_on			= ata_dummy_irq_on,
+	.irq_ack		= ata_dummy_irq_ack,
+
+	.scr_read		= sil24_scr_read,
+	.scr_write		= sil24_scr_write,
 
 	.freeze			= sil24_freeze,
 	.thaw			= sil24_thaw,
-	.softreset		= sil24_softreset,
-	.hardreset		= sil24_hardreset,
-	.pmp_softreset		= sil24_softreset,
-	.pmp_hardreset		= sil24_pmp_hardreset,
 	.error_handler		= sil24_error_handler,
 	.post_internal_cmd	= sil24_post_internal_cmd,
-	.dev_config		= sil24_dev_config,
-
-	.scr_read		= sil24_scr_read,
-	.scr_write		= sil24_scr_write,
-	.pmp_attach		= sil24_pmp_attach,
-	.pmp_detach		= sil24_pmp_detach,
 
 	.port_start		= sil24_port_start,
-#ifdef CONFIG_PM
-	.port_resume		= sil24_port_resume,
-#endif
 };
 
 /*
@@ -429,25 +424,25 @@
 	{
 		.flags		= SIL24_COMMON_FLAGS | SIL24_NPORTS2FLAG(4) |
 				  SIL24_FLAG_PCIX_IRQ_WOC,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask	= ATA_UDMA5,
+		.pio_mask	= 0x1f,			/* pio0-4 */
+		.mwdma_mask	= 0x07,			/* mwdma0-2 */
+		.udma_mask	= ATA_UDMA5,		/* udma0-5 */
 		.port_ops	= &sil24_ops,
 	},
 	/* sil_3132 */
 	{
 		.flags		= SIL24_COMMON_FLAGS | SIL24_NPORTS2FLAG(2),
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask	= ATA_UDMA5,
+		.pio_mask	= 0x1f,			/* pio0-4 */
+		.mwdma_mask	= 0x07,			/* mwdma0-2 */
+		.udma_mask	= ATA_UDMA5,		/* udma0-5 */
 		.port_ops	= &sil24_ops,
 	},
 	/* sil_3131/sil_3531 */
 	{
 		.flags		= SIL24_COMMON_FLAGS | SIL24_NPORTS2FLAG(1),
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask	= ATA_UDMA5,
+		.pio_mask	= 0x1f,			/* pio0-4 */
+		.mwdma_mask	= 0x07,			/* mwdma0-2 */
+		.udma_mask	= ATA_UDMA5,		/* udma0-5 */
 		.port_ops	= &sil24_ops,
 	},
 };
@@ -459,19 +454,9 @@
 	return tag;
 }
 
-static unsigned long sil24_port_offset(struct ata_port *ap)
-{
-	return ap->port_no * PORT_REGS_SIZE;
-}
-
-static void __iomem *sil24_port_base(struct ata_port *ap)
-{
-	return ap->host->iomap[SIL24_PORT_BAR] + sil24_port_offset(ap);
-}
-
 static void sil24_dev_config(struct ata_device *dev)
 {
-	void __iomem *port = sil24_port_base(dev->link->ap);
+	void __iomem *port = dev->ap->ioaddr.cmd_addr;
 
 	if (dev->cdb_len == 16)
 		writel(PORT_CS_CDB16, port + PORT_CTRL_STAT);
@@ -481,7 +466,7 @@
 
 static void sil24_read_tf(struct ata_port *ap, int tag, struct ata_taskfile *tf)
 {
-	void __iomem *port = sil24_port_base(ap);
+	void __iomem *port = ap->ioaddr.cmd_addr;
 	struct sil24_prb __iomem *prb;
 	u8 fis[6 * 4];
 
@@ -490,6 +475,12 @@
 	ata_tf_from_fis(fis, tf);
 }
 
+static u8 sil24_check_status(struct ata_port *ap)
+{
+	struct sil24_port_priv *pp = ap->private_data;
+	return pp->tf.command;
+}
+
 static int sil24_scr_map[] = {
 	[SCR_CONTROL]	= 0,
 	[SCR_STATUS]	= 1,
@@ -497,9 +488,9 @@
 	[SCR_ACTIVE]	= 3,
 };
 
-static int sil24_scr_read(struct ata_link *link, unsigned sc_reg, u32 *val)
+static int sil24_scr_read(struct ata_port *ap, unsigned sc_reg, u32 *val)
 {
-	void __iomem *scr_addr = sil24_port_base(link->ap) + PORT_SCONTROL;
+	void __iomem *scr_addr = ap->ioaddr.scr_addr;
 
 	if (sc_reg < ARRAY_SIZE(sil24_scr_map)) {
 		void __iomem *addr;
@@ -510,9 +501,9 @@
 	return -EINVAL;
 }
 
-static int sil24_scr_write(struct ata_link *link, unsigned sc_reg, u32 val)
+static int sil24_scr_write(struct ata_port *ap, unsigned sc_reg, u32 val)
 {
-	void __iomem *scr_addr = sil24_port_base(link->ap) + PORT_SCONTROL;
+	void __iomem *scr_addr = ap->ioaddr.scr_addr;
 
 	if (sc_reg < ARRAY_SIZE(sil24_scr_map)) {
 		void __iomem *addr;
@@ -523,78 +514,25 @@
 	return -EINVAL;
 }
 
-static void sil24_config_port(struct ata_port *ap)
+static void sil24_tf_read(struct ata_port *ap, struct ata_taskfile *tf)
 {
-	void __iomem *port = sil24_port_base(ap);
-
-	/* configure IRQ WoC */
-	if (ap->flags & SIL24_FLAG_PCIX_IRQ_WOC)
-		writel(PORT_CS_IRQ_WOC, port + PORT_CTRL_STAT);
-	else
-		writel(PORT_CS_IRQ_WOC, port + PORT_CTRL_CLR);
-
-	/* zero error counters. */
-	writel(0x8000, port + PORT_DECODE_ERR_THRESH);
-	writel(0x8000, port + PORT_CRC_ERR_THRESH);
-	writel(0x8000, port + PORT_HSHK_ERR_THRESH);
-	writel(0x0000, port + PORT_DECODE_ERR_CNT);
-	writel(0x0000, port + PORT_CRC_ERR_CNT);
-	writel(0x0000, port + PORT_HSHK_ERR_CNT);
-
-	/* always use 64bit activation */
-	writel(PORT_CS_32BIT_ACTV, port + PORT_CTRL_CLR);
-
-	/* clear port multiplier enable and resume bits */
-	writel(PORT_CS_PMP_EN | PORT_CS_PMP_RESUME, port + PORT_CTRL_CLR);
-}
-
-static void sil24_config_pmp(struct ata_port *ap, int attached)
-{
-	void __iomem *port = sil24_port_base(ap);
-
-	if (attached)
-		writel(PORT_CS_PMP_EN, port + PORT_CTRL_STAT);
-	else
-		writel(PORT_CS_PMP_EN, port + PORT_CTRL_CLR);
-}
-
-static void sil24_clear_pmp(struct ata_port *ap)
-{
-	void __iomem *port = sil24_port_base(ap);
-	int i;
-
-	writel(PORT_CS_PMP_RESUME, port + PORT_CTRL_CLR);
-
-	for (i = 0; i < SATA_PMP_MAX_PORTS; i++) {
-		void __iomem *pmp_base = port + PORT_PMP + i * PORT_PMP_SIZE;
-
-		writel(0, pmp_base + PORT_PMP_STATUS);
-		writel(0, pmp_base + PORT_PMP_QACTIVE);
-	}
+	struct sil24_port_priv *pp = ap->private_data;
+	*tf = pp->tf;
 }
 
 static int sil24_init_port(struct ata_port *ap)
 {
-	void __iomem *port = sil24_port_base(ap);
-	struct sil24_port_priv *pp = ap->private_data;
+	void __iomem *port = ap->ioaddr.cmd_addr;
 	u32 tmp;
 
-	/* clear PMP error status */
-	if (sata_pmp_attached(ap))
-		sil24_clear_pmp(ap);
-
 	writel(PORT_CS_INIT, port + PORT_CTRL_STAT);
 	ata_wait_register(port + PORT_CTRL_STAT,
 			  PORT_CS_INIT, PORT_CS_INIT, 10, 100);
 	tmp = ata_wait_register(port + PORT_CTRL_STAT,
 				PORT_CS_RDY, 0, 10, 100);
 
-	if ((tmp & (PORT_CS_INIT | PORT_CS_RDY)) != PORT_CS_RDY) {
-		pp->do_port_rst = 1;
-		ap->link.eh_context.i.action |= ATA_EH_RESET;
+	if ((tmp & (PORT_CS_INIT | PORT_CS_RDY)) != PORT_CS_RDY)
 		return -EIO;
-	}
-
 	return 0;
 }
 
@@ -603,7 +541,7 @@
 				 int is_cmd, u32 ctrl,
 				 unsigned long timeout_msec)
 {
-	void __iomem *port = sil24_port_base(ap);
+	void __iomem *port = ap->ioaddr.cmd_addr;
 	struct sil24_port_priv *pp = ap->private_data;
 	struct sil24_prb *prb = &pp->cmd_block[0].ata.prb;
 	dma_addr_t paddr = pp->cmd_block_dma;
@@ -645,11 +583,9 @@
 	return rc;
 }
 
-static int sil24_softreset(struct ata_link *link, unsigned int *class,
-			   unsigned long deadline)
+static int sil24_do_softreset(struct ata_port *ap, unsigned int *class,
+			      int pmp, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
-	int pmp = sata_srst_pmp(link);
 	unsigned long timeout_msec = 0;
 	struct ata_taskfile tf;
 	const char *reason;
@@ -657,9 +593,15 @@
 
 	DPRINTK("ENTER\n");
 
+	if (ata_port_offline(ap)) {
+		DPRINTK("PHY reports no device\n");
+		*class = ATA_DEV_NONE;
+		goto out;
+	}
+
 	/* put the port into known state */
 	if (sil24_init_port(ap)) {
-		reason = "port not ready";
+		reason ="port not ready";
 		goto err;
 	}
 
@@ -667,7 +609,7 @@
 	if (time_after(deadline, jiffies))
 		timeout_msec = jiffies_to_msecs(deadline - jiffies);
 
-	ata_tf_init(link->device, &tf);	/* doesn't really matter */
+	ata_tf_init(ap->device, &tf);	/* doesn't really matter */
 	rc = sil24_exec_polled_cmd(ap, pmp, &tf, 0, PRB_CTRL_SRST,
 				   timeout_msec);
 	if (rc == -EBUSY) {
@@ -681,70 +623,54 @@
 	sil24_read_tf(ap, 0, &tf);
 	*class = ata_dev_classify(&tf);
 
+	if (*class == ATA_DEV_UNKNOWN)
+		*class = ATA_DEV_NONE;
+
+ out:
 	DPRINTK("EXIT, class=%u\n", *class);
 	return 0;
 
  err:
-	ata_link_printk(link, KERN_ERR, "softreset failed (%s)\n", reason);
+	ata_port_printk(ap, KERN_ERR, "softreset failed (%s)\n", reason);
 	return -EIO;
 }
 
-static int sil24_hardreset(struct ata_link *link, unsigned int *class,
+static int sil24_softreset(struct ata_port *ap, unsigned int *class,
 			   unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
-	void __iomem *port = sil24_port_base(ap);
-	struct sil24_port_priv *pp = ap->private_data;
-	int did_port_rst = 0;
+	return sil24_do_softreset(ap, class, 0, deadline);
+}
+
+static int sil24_hardreset(struct ata_port *ap, unsigned int *class,
+			   unsigned long deadline)
+{
+	void __iomem *port = ap->ioaddr.cmd_addr;
 	const char *reason;
 	int tout_msec, rc;
 	u32 tmp;
 
- retry:
-	/* Sometimes, DEV_RST is not enough to recover the controller.
-	 * This happens often after PM DMA CS errata.
-	 */
-	if (pp->do_port_rst) {
-		ata_port_printk(ap, KERN_WARNING, "controller in dubious "
-				"state, performing PORT_RST\n");
-
-		writel(PORT_CS_PORT_RST, port + PORT_CTRL_STAT);
-		msleep(10);
-		writel(PORT_CS_PORT_RST, port + PORT_CTRL_CLR);
-		ata_wait_register(port + PORT_CTRL_STAT, PORT_CS_RDY, 0,
-				  10, 5000);
-
-		/* restore port configuration */
-		sil24_config_port(ap);
-		sil24_config_pmp(ap, ap->nr_pmp_links);
-
-		pp->do_port_rst = 0;
-		did_port_rst = 1;
-	}
-
 	/* sil24 does the right thing(tm) without any protection */
-	sata_set_spd(link);
+	sata_set_spd(ap);
 
 	tout_msec = 100;
-	if (ata_link_online(link))
+	if (ata_port_online(ap))
 		tout_msec = 5000;
 
 	writel(PORT_CS_DEV_RST, port + PORT_CTRL_STAT);
 	tmp = ata_wait_register(port + PORT_CTRL_STAT,
-				PORT_CS_DEV_RST, PORT_CS_DEV_RST, 10,
-				tout_msec);
+				PORT_CS_DEV_RST, PORT_CS_DEV_RST, 10, tout_msec);
 
 	/* SStatus oscillates between zero and valid status after
 	 * DEV_RST, debounce it.
 	 */
-	rc = sata_link_debounce(link, sata_deb_timing_long, deadline);
+	rc = sata_phy_debounce(ap, sata_deb_timing_long, deadline);
 	if (rc) {
 		reason = "PHY debouncing failed";
 		goto err;
 	}
 
 	if (tmp & PORT_CS_DEV_RST) {
-		if (ata_link_offline(link))
+		if (ata_port_offline(ap))
 			return 0;
 		reason = "link not ready";
 		goto err;
@@ -759,12 +685,7 @@
 	return -EAGAIN;
 
  err:
-	if (!did_port_rst) {
-		pp->do_port_rst = 1;
-		goto retry;
-	}
-
-	ata_link_printk(link, KERN_ERR, "hardreset failed (%s)\n", reason);
+	ata_port_printk(ap, KERN_ERR, "hardreset failed (%s)\n", reason);
 	return -EIO;
 }
 
@@ -772,64 +693,16 @@
 				 struct sil24_sge *sge)
 {
 	struct scatterlist *sg;
-	struct sil24_sge *last_sge = NULL;
-	unsigned int si;
 
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
+	ata_for_each_sg(sg, qc) {
 		sge->addr = cpu_to_le64(sg_dma_address(sg));
 		sge->cnt = cpu_to_le32(sg_dma_len(sg));
-		sge->flags = 0;
-
-		last_sge = sge;
+		if (ata_sg_is_last(sg, qc))
+			sge->flags = cpu_to_le32(SGE_TRM);
+		else
+			sge->flags = 0;
 		sge++;
 	}
-
-	last_sge->flags = cpu_to_le32(SGE_TRM);
-}
-
-static int sil24_qc_defer(struct ata_queued_cmd *qc)
-{
-	struct ata_link *link = qc->dev->link;
-	struct ata_port *ap = link->ap;
-	u8 prot = qc->tf.protocol;
-
-	/*
-	 * There is a bug in the chip:
-	 * Port LRAM Causes the PRB/SGT Data to be Corrupted
-	 * If the host issues a read request for LRAM and SActive registers
-	 * while active commands are available in the port, PRB/SGT data in
-	 * the LRAM can become corrupted. This issue applies only when
-	 * reading from, but not writing to, the LRAM.
-	 *
-	 * Therefore, reading LRAM when there is no particular error [and
-	 * other commands may be outstanding] is prohibited.
-	 *
-	 * To avoid this bug there are two situations where a command must run
-	 * exclusive of any other commands on the port:
-	 *
-	 * - ATAPI commands which check the sense data
-	 * - Passthrough ATA commands which always have ATA_QCFLAG_RESULT_TF
-	 *   set.
-	 *
- 	 */
-	int is_excl = (ata_is_atapi(prot) ||
-		       (qc->flags & ATA_QCFLAG_RESULT_TF));
-
-	if (unlikely(ap->excl_link)) {
-		if (link == ap->excl_link) {
-			if (ap->nr_active_links)
-				return ATA_DEFER_PORT;
-			qc->flags |= ATA_QCFLAG_CLEAR_EXCL;
-		} else
-			return ATA_DEFER_PORT;
-	} else if (unlikely(is_excl)) {
-		ap->excl_link = link;
-		if (ap->nr_active_links)
-			return ATA_DEFER_PORT;
-		qc->flags |= ATA_QCFLAG_CLEAR_EXCL;
-	}
-
-	return ata_std_qc_defer(qc);
 }
 
 static void sil24_qc_prep(struct ata_queued_cmd *qc)
@@ -843,36 +716,39 @@
 
 	cb = &pp->cmd_block[sil24_tag(qc->tag)];
 
-	if (!ata_is_atapi(qc->tf.protocol)) {
+	switch (qc->tf.protocol) {
+	case ATA_PROT_PIO:
+	case ATA_PROT_DMA:
+	case ATA_PROT_NCQ:
+	case ATA_PROT_NODATA:
 		prb = &cb->ata.prb;
 		sge = cb->ata.sge;
-		if (ata_is_data(qc->tf.protocol)) {
-			u16 prot = 0;
-			ctrl = PRB_CTRL_PROTOCOL;
-			if (ata_is_ncq(qc->tf.protocol))
-				prot |= PRB_PROT_NCQ;
-			if (qc->tf.flags & ATA_TFLAG_WRITE)
-				prot |= PRB_PROT_WRITE;
-			else
-				prot |= PRB_PROT_READ;
-			prb->prot = cpu_to_le16(prot);
-		}
-	} else {
+		break;
+
+	case ATA_PROT_ATAPI:
+	case ATA_PROT_ATAPI_DMA:
+	case ATA_PROT_ATAPI_NODATA:
 		prb = &cb->atapi.prb;
 		sge = cb->atapi.sge;
 		memset(cb->atapi.cdb, 0, 32);
 		memcpy(cb->atapi.cdb, qc->cdb, qc->dev->cdb_len);
 
-		if (ata_is_data(qc->tf.protocol)) {
+		if (qc->tf.protocol != ATA_PROT_ATAPI_NODATA) {
 			if (qc->tf.flags & ATA_TFLAG_WRITE)
 				ctrl = PRB_CTRL_PACKET_WRITE;
 			else
 				ctrl = PRB_CTRL_PACKET_READ;
 		}
+		break;
+
+	default:
+		prb = NULL;	/* shut up, gcc */
+		sge = NULL;
+		BUG();
 	}
 
 	prb->ctrl = cpu_to_le16(ctrl);
-	ata_tf_to_fis(&qc->tf, qc->dev->link->pmp, 1, prb->fis);
+	ata_tf_to_fis(&qc->tf, 0, 1, prb->fis);
 
 	if (qc->flags & ATA_QCFLAG_DMAMAP)
 		sil24_fill_sg(qc, sge);
@@ -882,7 +758,7 @@
 {
 	struct ata_port *ap = qc->ap;
 	struct sil24_port_priv *pp = ap->private_data;
-	void __iomem *port = sil24_port_base(ap);
+	void __iomem *port = ap->ioaddr.cmd_addr;
 	unsigned int tag = sil24_tag(qc->tag);
 	dma_addr_t paddr;
 	void __iomem *activate;
@@ -896,53 +772,14 @@
 	return 0;
 }
 
-static bool sil24_qc_fill_rtf(struct ata_queued_cmd *qc)
+static void sil24_irq_clear(struct ata_port *ap)
 {
-	sil24_read_tf(qc->ap, qc->tag, &qc->result_tf);
-	return true;
-}
-
-static void sil24_pmp_attach(struct ata_port *ap)
-{
-	u32 *gscr = ap->link.device->gscr;
-
-	sil24_config_pmp(ap, 1);
-	sil24_init_port(ap);
-
-	if (sata_pmp_gscr_vendor(gscr) == 0x11ab &&
-	    sata_pmp_gscr_devid(gscr) == 0x4140) {
-		ata_port_printk(ap, KERN_INFO,
-			"disabling NCQ support due to sil24-mv4140 quirk\n");
-		ap->flags &= ~ATA_FLAG_NCQ;
-	}
-}
-
-static void sil24_pmp_detach(struct ata_port *ap)
-{
-	sil24_init_port(ap);
-	sil24_config_pmp(ap, 0);
-
-	ap->flags |= ATA_FLAG_NCQ;
-}
-
-static int sil24_pmp_hardreset(struct ata_link *link, unsigned int *class,
-			       unsigned long deadline)
-{
-	int rc;
-
-	rc = sil24_init_port(link->ap);
-	if (rc) {
-		ata_link_printk(link, KERN_ERR,
-				"hardreset failed (port not ready)\n");
-		return rc;
-	}
-
-	return sata_std_hardreset(link, class, deadline);
+	/* unused */
 }
 
 static void sil24_freeze(struct ata_port *ap)
 {
-	void __iomem *port = sil24_port_base(ap);
+	void __iomem *port = ap->ioaddr.cmd_addr;
 
 	/* Port-wide IRQ mask in HOST_CTRL doesn't really work, clear
 	 * PORT_IRQ_ENABLE instead.
@@ -952,7 +789,7 @@
 
 static void sil24_thaw(struct ata_port *ap)
 {
-	void __iomem *port = sil24_port_base(ap);
+	void __iomem *port = ap->ioaddr.cmd_addr;
 	u32 tmp;
 
 	/* clear IRQ */
@@ -965,12 +802,10 @@
 
 static void sil24_error_intr(struct ata_port *ap)
 {
-	void __iomem *port = sil24_port_base(ap);
+	void __iomem *port = ap->ioaddr.cmd_addr;
 	struct sil24_port_priv *pp = ap->private_data;
-	struct ata_queued_cmd *qc = NULL;
-	struct ata_link *link;
-	struct ata_eh_info *ehi;
-	int abort = 0, freeze = 0;
+	struct ata_eh_info *ehi = &ap->eh_info;
+	int freeze = 0;
 	u32 irq_stat;
 
 	/* on error, we need to clear IRQ explicitly */
@@ -978,17 +813,10 @@
 	writel(irq_stat, port + PORT_IRQ_STAT);
 
 	/* first, analyze and record host port events */
-	link = &ap->link;
-	ehi = &link->eh_info;
 	ata_ehi_clear_desc(ehi);
 
 	ata_ehi_push_desc(ehi, "irq_stat 0x%08x", irq_stat);
 
-	if (irq_stat & PORT_IRQ_SDB_NOTIFY) {
-		ata_ehi_push_desc(ehi, "SDB notify");
-		sata_async_notification(ap);
-	}
-
 	if (irq_stat & (PORT_IRQ_PHYRDY_CHG | PORT_IRQ_DEV_XCHG)) {
 		ata_ehi_hotplugged(ehi);
 		ata_ehi_push_desc(ehi, "%s",
@@ -999,7 +827,7 @@
 
 	if (irq_stat & PORT_IRQ_UNK_FIS) {
 		ehi->err_mask |= AC_ERR_HSM;
-		ehi->action |= ATA_EH_RESET;
+		ehi->action |= ATA_EH_SOFTRESET;
 		ata_ehi_push_desc(ehi, "unknown FIS");
 		freeze = 1;
 	}
@@ -1008,44 +836,8 @@
 	if (irq_stat & PORT_IRQ_ERROR) {
 		struct sil24_cerr_info *ci = NULL;
 		unsigned int err_mask = 0, action = 0;
-		u32 context, cerr;
-		int pmp;
-
-		abort = 1;
-
-		/* DMA Context Switch Failure in Port Multiplier Mode
-		 * errata.  If we have active commands to 3 or more
-		 * devices, any error condition on active devices can
-		 * corrupt DMA context switching.
-		 */
-		if (ap->nr_active_links >= 3) {
-			ehi->err_mask |= AC_ERR_OTHER;
-			ehi->action |= ATA_EH_RESET;
-			ata_ehi_push_desc(ehi, "PMP DMA CS errata");
-			pp->do_port_rst = 1;
-			freeze = 1;
-		}
-
-		/* find out the offending link and qc */
-		if (sata_pmp_attached(ap)) {
-			context = readl(port + PORT_CONTEXT);
-			pmp = (context >> 5) & 0xf;
-
-			if (pmp < ap->nr_pmp_links) {
-				link = &ap->pmp_link[pmp];
-				ehi = &link->eh_info;
-				qc = ata_qc_from_tag(ap, link->active_tag);
-
-				ata_ehi_clear_desc(ehi);
-				ata_ehi_push_desc(ehi, "irq_stat 0x%08x",
-						  irq_stat);
-			} else {
-				err_mask |= AC_ERR_HSM;
-				action |= ATA_EH_RESET;
-				freeze = 1;
-			}
-		} else
-			qc = ata_qc_from_tag(ap, link->active_tag);
+		struct ata_queued_cmd *qc;
+		u32 cerr;
 
 		/* analyze CMD_ERR */
 		cerr = readl(port + PORT_CMD_ERR);
@@ -1055,44 +847,44 @@
 		if (ci && ci->desc) {
 			err_mask |= ci->err_mask;
 			action |= ci->action;
-			if (action & ATA_EH_RESET)
-				freeze = 1;
 			ata_ehi_push_desc(ehi, "%s", ci->desc);
 		} else {
 			err_mask |= AC_ERR_OTHER;
-			action |= ATA_EH_RESET;
-			freeze = 1;
+			action |= ATA_EH_SOFTRESET;
 			ata_ehi_push_desc(ehi, "unknown command error %d",
 					  cerr);
 		}
 
 		/* record error info */
-		if (qc)
+		qc = ata_qc_from_tag(ap, ap->active_tag);
+		if (qc) {
+			sil24_read_tf(ap, qc->tag, &pp->tf);
 			qc->err_mask |= err_mask;
-		else
+		} else
 			ehi->err_mask |= err_mask;
 
 		ehi->action |= action;
-
-		/* if PMP, resume */
-		if (sata_pmp_attached(ap))
-			writel(PORT_CS_PMP_RESUME, port + PORT_CTRL_STAT);
 	}
 
 	/* freeze or abort */
 	if (freeze)
 		ata_port_freeze(ap);
-	else if (abort) {
-		if (qc)
-			ata_link_abort(qc->dev->link);
-		else
-			ata_port_abort(ap);
-	}
+	else
+		ata_port_abort(ap);
+}
+
+static void sil24_finish_qc(struct ata_queued_cmd *qc)
+{
+	struct ata_port *ap = qc->ap;
+	struct sil24_port_priv *pp = ap->private_data;
+
+	if (qc->flags & ATA_QCFLAG_RESULT_TF)
+		sil24_read_tf(ap, qc->tag, &pp->tf);
 }
 
 static inline void sil24_host_intr(struct ata_port *ap)
 {
-	void __iomem *port = sil24_port_base(ap);
+	void __iomem *port = ap->ioaddr.cmd_addr;
 	u32 slot_stat, qc_active;
 	int rc;
 
@@ -1114,13 +906,13 @@
 	}
 
 	qc_active = slot_stat & ~HOST_SSTAT_ATTN;
-	rc = ata_qc_complete_multiple(ap, qc_active);
+	rc = ata_qc_complete_multiple(ap, qc_active, sil24_finish_qc);
 	if (rc > 0)
 		return;
 	if (rc < 0) {
-		struct ata_eh_info *ehi = &ap->link.eh_info;
+		struct ata_eh_info *ehi = &ap->eh_info;
 		ehi->err_mask |= AC_ERR_HSM;
-		ehi->action |= ATA_EH_RESET;
+		ehi->action |= ATA_EH_SOFTRESET;
 		ata_port_freeze(ap);
 		return;
 	}
@@ -1129,7 +921,7 @@
 	if (!(ap->flags & SIL24_FLAG_PCIX_IRQ_WOC) && ata_ratelimit())
 		ata_port_printk(ap, KERN_INFO, "spurious interrupt "
 			"(slot_stat 0x%x active_tag %d sactive 0x%x)\n",
-			slot_stat, ap->link.active_tag, ap->link.sactive);
+			slot_stat, ap->active_tag, ap->sactive);
 }
 
 static irqreturn_t sil24_interrupt(int irq, void *dev_instance)
@@ -1171,14 +963,16 @@
 
 static void sil24_error_handler(struct ata_port *ap)
 {
-	struct sil24_port_priv *pp = ap->private_data;
+	struct ata_eh_context *ehc = &ap->eh_context;
 
-	if (sil24_init_port(ap))
+	if (sil24_init_port(ap)) {
 		ata_eh_freeze_port(ap);
+		ehc->i.action |= ATA_EH_HARDRESET;
+	}
 
-	sata_pmp_error_handler(ap);
-
-	pp->do_port_rst = 0;
+	/* perform recovery */
+	ata_do_eh(ap, ata_std_prereset, sil24_softreset, sil24_hardreset,
+		  ata_std_postreset);
 }
 
 static void sil24_post_internal_cmd(struct ata_queued_cmd *qc)
@@ -1186,8 +980,8 @@
 	struct ata_port *ap = qc->ap;
 
 	/* make DMA engine forget about the failed command */
-	if ((qc->flags & ATA_QCFLAG_FAILED) && sil24_init_port(ap))
-		ata_eh_freeze_port(ap);
+	if (qc->flags & ATA_QCFLAG_FAILED)
+		sil24_init_port(ap);
 }
 
 static int sil24_port_start(struct ata_port *ap)
@@ -1197,30 +991,35 @@
 	union sil24_cmd_block *cb;
 	size_t cb_size = sizeof(*cb) * SIL24_MAX_CMDS;
 	dma_addr_t cb_dma;
+	int rc;
 
 	pp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);
 	if (!pp)
 		return -ENOMEM;
 
+	pp->tf.command = ATA_DRDY;
+
 	cb = dmam_alloc_coherent(dev, cb_size, &cb_dma, GFP_KERNEL);
 	if (!cb)
 		return -ENOMEM;
 	memset(cb, 0, cb_size);
 
+	rc = ata_pad_alloc(ap, dev);
+	if (rc)
+		return rc;
+
 	pp->cmd_block = cb;
 	pp->cmd_block_dma = cb_dma;
 
 	ap->private_data = pp;
 
-	ata_port_pbar_desc(ap, SIL24_HOST_BAR, -1, "host");
-	ata_port_pbar_desc(ap, SIL24_PORT_BAR, sil24_port_offset(ap), "port");
-
 	return 0;
 }
 
 static void sil24_init_controller(struct ata_host *host)
 {
 	void __iomem *host_base = host->iomap[SIL24_HOST_BAR];
+	void __iomem *port_base = host->iomap[SIL24_PORT_BAR];
 	u32 tmp;
 	int i;
 
@@ -1232,9 +1031,7 @@
 
 	/* init ports */
 	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		void __iomem *port = sil24_port_base(ap);
-
+		void __iomem *port = port_base + i * PORT_REGS_SIZE;
 
 		/* Initial PHY setting */
 		writel(0x20c, port + PORT_PHY_CFG);
@@ -1248,11 +1045,29 @@
 						PORT_CS_PORT_RST, 10, 100);
 			if (tmp & PORT_CS_PORT_RST)
 				dev_printk(KERN_ERR, host->dev,
-					   "failed to clear port RST\n");
+				           "failed to clear port RST\n");
 		}
 
-		/* configure port */
-		sil24_config_port(ap);
+		/* Configure IRQ WoC */
+		if (host->ports[0]->flags & SIL24_FLAG_PCIX_IRQ_WOC)
+			writel(PORT_CS_IRQ_WOC, port + PORT_CTRL_STAT);
+		else
+			writel(PORT_CS_IRQ_WOC, port + PORT_CTRL_CLR);
+
+		/* Zero error counters. */
+		writel(0x8000, port + PORT_DECODE_ERR_THRESH);
+		writel(0x8000, port + PORT_CRC_ERR_THRESH);
+		writel(0x8000, port + PORT_HSHK_ERR_THRESH);
+		writel(0x0000, port + PORT_DECODE_ERR_CNT);
+		writel(0x0000, port + PORT_CRC_ERR_CNT);
+		writel(0x0000, port + PORT_HSHK_ERR_CNT);
+
+		/* Always use 64bit activation */
+		writel(PORT_CS_32BIT_ACTV, port + PORT_CTRL_CLR);
+
+		/* Clear port multiplier enable and resume bits */
+		writel(PORT_CS_PMP_EN | PORT_CS_PMP_RESUME,
+		       port + PORT_CTRL_CLR);
 	}
 
 	/* Turn on interrupts */
@@ -1261,19 +1076,14 @@
 
 static int sil24_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
 {
-	extern int __MARKER__sil24_cmd_block_is_sized_wrongly;
-	static int printed_version;
+	static int printed_version = 0;
 	struct ata_port_info pi = sil24_port_info[ent->driver_data];
 	const struct ata_port_info *ppi[] = { &pi, NULL };
 	void __iomem * const *iomap;
 	struct ata_host *host;
-	int rc;
+	int i, rc;
 	u32 tmp;
 
-	/* cause link error if sil24_cmd_block is sized wrongly */
-	if (sizeof(union sil24_cmd_block) != PAGE_SIZE)
-		__MARKER__sil24_cmd_block_is_sized_wrongly = 1;
-
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
 
@@ -1307,11 +1117,20 @@
 		return -ENOMEM;
 	host->iomap = iomap;
 
+	for (i = 0; i < host->n_ports; i++) {
+		void __iomem *port = iomap[SIL24_PORT_BAR] + i * PORT_REGS_SIZE;
+
+		host->ports[i]->ioaddr.cmd_addr = port;
+		host->ports[i]->ioaddr.scr_addr = port + PORT_SCONTROL;
+
+		ata_std_ports(&host->ports[i]->ioaddr);
+	}
+
 	/* configure and activate the device */
-	if (!pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {
-		rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
+	if (!pci_set_dma_mask(pdev, DMA_64BIT_MASK)) {
+		rc = pci_set_consistent_dma_mask(pdev, DMA_64BIT_MASK);
 		if (rc) {
-			rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+			rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 			if (rc) {
 				dev_printk(KERN_ERR, &pdev->dev,
 					   "64-bit DMA enable failed\n");
@@ -1319,13 +1138,13 @@
 			}
 		}
 	} else {
-		rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
+		rc = pci_set_dma_mask(pdev, DMA_32BIT_MASK);
 		if (rc) {
 			dev_printk(KERN_ERR, &pdev->dev,
 				   "32-bit DMA enable failed\n");
 			return rc;
 		}
-		rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+		rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 		if (rc) {
 			dev_printk(KERN_ERR, &pdev->dev,
 				   "32-bit consistent DMA enable failed\n");
@@ -1333,11 +1152,6 @@
 		}
 	}
 
-	/* Set max read request size to 4096.  This slightly increases
-	 * write throughput for pci-e variants.
-	 */
-	pcie_set_readrq(pdev, 4096);
-
 	sil24_init_controller(host);
 
 	pci_set_master(pdev);
@@ -1365,12 +1179,6 @@
 
 	return 0;
 }
-
-static int sil24_port_resume(struct ata_port *ap)
-{
-	sil24_config_pmp(ap, ap->nr_pmp_links);
-	return 0;
-}
 #endif
 
 static int __init sil24_init(void)
diff -Nur linux-sh4/drivers/ata.org/sata_sil.c linux-sh4/drivers/ata/sata_sil.c
--- linux-sh4/drivers/ata.org/sata_sil.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_sil.c	2012-01-15 06:30:15.000000000 -0800
@@ -44,12 +44,9 @@
 #include <linux/device.h>
 #include <scsi/scsi_host.h>
 #include <linux/libata.h>
-#include <linux/dmi.h>
 
 #define DRV_NAME	"sata_sil"
-#define DRV_VERSION	"2.4"
-
-#define SIL_DMA_BOUNDARY	0x7fffffffUL
+#define DRV_VERSION	"2.3"
 
 enum {
 	SIL_MMIO_BAR		= 5,
@@ -62,7 +59,7 @@
 	SIL_FLAG_MOD15WRITE	= (1 << 30),
 
 	SIL_DFL_PORT_FLAGS	= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
-				  ATA_FLAG_MMIO,
+				  ATA_FLAG_MMIO | ATA_FLAG_HRST_TO_RESUME,
 
 	/*
 	 * Controller IDs
@@ -113,18 +110,14 @@
 	SIL_QUIRK_UDMA5MAX	= (1 << 1),
 };
 
-static int sil_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
+static int sil_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
 #ifdef CONFIG_PM
 static int sil_pci_device_resume(struct pci_dev *pdev);
 #endif
 static void sil_dev_config(struct ata_device *dev);
-static int sil_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val);
-static int sil_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val);
-static int sil_set_mode(struct ata_link *link, struct ata_device **r_failed);
-static void sil_qc_prep(struct ata_queued_cmd *qc);
-static void sil_bmdma_setup(struct ata_queued_cmd *qc);
-static void sil_bmdma_start(struct ata_queued_cmd *qc);
-static void sil_bmdma_stop(struct ata_queued_cmd *qc);
+static int sil_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val);
+static int sil_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val);
+static int sil_set_mode (struct ata_port *ap, struct ata_device **r_failed);
 static void sil_freeze(struct ata_port *ap);
 static void sil_thaw(struct ata_port *ap);
 
@@ -144,7 +137,7 @@
 
 /* TODO firmware versions should be added - eric */
 static const struct sil_drivelist {
-	const char *product;
+	const char * product;
 	unsigned int quirk;
 } sil_blacklist [] = {
 	{ "ST320012AS",		SIL_QUIRK_MOD15WRITE },
@@ -174,34 +167,57 @@
 };
 
 static struct scsi_host_template sil_sht = {
-	ATA_BASE_SHT(DRV_NAME),
-	/** These controllers support Large Block Transfer which allows
-	    transfer chunks up to 2GB and which cross 64KB boundaries,
-	    therefore the DMA limits are more relaxed than standard ATA SFF. */
-	.dma_boundary		= SIL_DMA_BOUNDARY,
-	.sg_tablesize		= ATA_MAX_PRD
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations sil_ops = {
-	.inherits		= &ata_bmdma32_port_ops,
+static const struct ata_port_operations sil_ops = {
+	.port_disable		= ata_port_disable,
 	.dev_config		= sil_dev_config,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
 	.set_mode		= sil_set_mode,
-	.bmdma_setup            = sil_bmdma_setup,
-	.bmdma_start            = sil_bmdma_start,
-	.bmdma_stop		= sil_bmdma_stop,
-	.qc_prep		= sil_qc_prep,
+	.bmdma_setup            = ata_bmdma_setup,
+	.bmdma_start            = ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
 	.freeze			= sil_freeze,
 	.thaw			= sil_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 	.scr_read		= sil_scr_read,
 	.scr_write		= sil_scr_write,
+	.port_start		= ata_port_start,
 };
 
 static const struct ata_port_info sil_port_info[] = {
 	/* sil_3112 */
 	{
 		.flags		= SIL_DFL_PORT_FLAGS | SIL_FLAG_MOD15WRITE,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,			/* pio0-4 */
+		.mwdma_mask	= 0x07,			/* mwdma0-2 */
 		.udma_mask	= ATA_UDMA5,
 		.port_ops	= &sil_ops,
 	},
@@ -209,24 +225,24 @@
 	{
 		.flags		= SIL_DFL_PORT_FLAGS | SIL_FLAG_MOD15WRITE |
 				  SIL_FLAG_NO_SATA_IRQ,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,			/* pio0-4 */
+		.mwdma_mask	= 0x07,			/* mwdma0-2 */
 		.udma_mask	= ATA_UDMA5,
 		.port_ops	= &sil_ops,
 	},
 	/* sil_3512 */
 	{
 		.flags		= SIL_DFL_PORT_FLAGS | SIL_FLAG_RERR_ON_DMA_ACT,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,			/* pio0-4 */
+		.mwdma_mask	= 0x07,			/* mwdma0-2 */
 		.udma_mask	= ATA_UDMA5,
 		.port_ops	= &sil_ops,
 	},
 	/* sil_3114 */
 	{
 		.flags		= SIL_DFL_PORT_FLAGS | SIL_FLAG_RERR_ON_DMA_ACT,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,			/* pio0-4 */
+		.mwdma_mask	= 0x07,			/* mwdma0-2 */
 		.udma_mask	= ATA_UDMA5,
 		.port_ops	= &sil_ops,
 	},
@@ -260,88 +276,11 @@
 MODULE_DEVICE_TABLE(pci, sil_pci_tbl);
 MODULE_VERSION(DRV_VERSION);
 
-static int slow_down;
+static int slow_down = 0;
 module_param(slow_down, int, 0444);
 MODULE_PARM_DESC(slow_down, "Sledgehammer used to work around random problems, by limiting commands to 15 sectors (0=off, 1=on)");
 
 
-static void sil_bmdma_stop(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	void __iomem *mmio_base = ap->host->iomap[SIL_MMIO_BAR];
-	void __iomem *bmdma2 = mmio_base + sil_port[ap->port_no].bmdma2;
-
-	/* clear start/stop bit - can safely always write 0 */
-	iowrite8(0, bmdma2);
-
-	/* one-PIO-cycle guaranteed wait, per spec, for HDMA1:0 transition */
-	ata_sff_dma_pause(ap);
-}
-
-static void sil_bmdma_setup(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-	void __iomem *bmdma = ap->ioaddr.bmdma_addr;
-
-	/* load PRD table addr. */
-	iowrite32(ap->prd_dma, bmdma + ATA_DMA_TABLE_OFS);
-
-	/* issue r/w command */
-	ap->ops->sff_exec_command(ap, &qc->tf);
-}
-
-static void sil_bmdma_start(struct ata_queued_cmd *qc)
-{
-	unsigned int rw = (qc->tf.flags & ATA_TFLAG_WRITE);
-	struct ata_port *ap = qc->ap;
-	void __iomem *mmio_base = ap->host->iomap[SIL_MMIO_BAR];
-	void __iomem *bmdma2 = mmio_base + sil_port[ap->port_no].bmdma2;
-	u8 dmactl = ATA_DMA_START;
-
-	/* set transfer direction, start host DMA transaction
-	   Note: For Large Block Transfer to work, the DMA must be started
-	   using the bmdma2 register. */
-	if (!rw)
-		dmactl |= ATA_DMA_WR;
-	iowrite8(dmactl, bmdma2);
-}
-
-/* The way God intended PCI IDE scatter/gather lists to look and behave... */
-static void sil_fill_sg(struct ata_queued_cmd *qc)
-{
-	struct scatterlist *sg;
-	struct ata_port *ap = qc->ap;
-	struct ata_prd *prd, *last_prd = NULL;
-	unsigned int si;
-
-	prd = &ap->prd[0];
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
-		/* Note h/w doesn't support 64-bit, so we unconditionally
-		 * truncate dma_addr_t to u32.
-		 */
-		u32 addr = (u32) sg_dma_address(sg);
-		u32 sg_len = sg_dma_len(sg);
-
-		prd->addr = cpu_to_le32(addr);
-		prd->flags_len = cpu_to_le32(sg_len);
-		VPRINTK("PRD[%u] = (0x%X, 0x%X)\n", si, addr, sg_len);
-
-		last_prd = prd;
-		prd++;
-	}
-
-	if (likely(last_prd))
-		last_prd->flags_len |= cpu_to_le32(ATA_PRD_EOT);
-}
-
-static void sil_qc_prep(struct ata_queued_cmd *qc)
-{
-	if (!(qc->flags & ATA_QCFLAG_DMAMAP))
-		return;
-
-	sil_fill_sg(qc);
-}
-
 static unsigned char sil_get_device_cache_line(struct pci_dev *pdev)
 {
 	u8 cache_line = 0;
@@ -351,33 +290,35 @@
 
 /**
  *	sil_set_mode		-	wrap set_mode functions
- *	@link: link to set up
+ *	@ap: port to set up
  *	@r_failed: returned device when we fail
  *
  *	Wrap the libata method for device setup as after the setup we need
  *	to inspect the results and do some configuration work
  */
 
-static int sil_set_mode(struct ata_link *link, struct ata_device **r_failed)
+static int sil_set_mode (struct ata_port *ap, struct ata_device **r_failed)
 {
-	struct ata_port *ap = link->ap;
-	void __iomem *mmio_base = ap->host->iomap[SIL_MMIO_BAR];
-	void __iomem *addr = mmio_base + sil_port[ap->port_no].xfer_mode;
+	struct ata_host *host = ap->host;
 	struct ata_device *dev;
-	u32 tmp, dev_mode[2] = { };
+	void __iomem *mmio_base = host->iomap[SIL_MMIO_BAR];
+	void __iomem *addr = mmio_base + sil_port[ap->port_no].xfer_mode;
+	u32 tmp, dev_mode[2];
+	unsigned int i;
 	int rc;
 
-	rc = ata_do_set_mode(link, r_failed);
+	rc = ata_do_set_mode(ap, r_failed);
 	if (rc)
 		return rc;
 
-	ata_for_each_dev(dev, link, ALL) {
+	for (i = 0; i < 2; i++) {
+		dev = &ap->device[i];
 		if (!ata_dev_enabled(dev))
-			dev_mode[dev->devno] = 0;	/* PIO0/1/2 */
+			dev_mode[i] = 0;	/* PIO0/1/2 */
 		else if (dev->flags & ATA_DFLAG_PIO)
-			dev_mode[dev->devno] = 1;	/* PIO3/4 */
+			dev_mode[i] = 1;	/* PIO3/4 */
 		else
-			dev_mode[dev->devno] = 3;	/* UDMA */
+			dev_mode[i] = 3;	/* UDMA */
 		/* value 2 indicates MDMA */
 	}
 
@@ -390,8 +331,7 @@
 	return 0;
 }
 
-static inline void __iomem *sil_scr_addr(struct ata_port *ap,
-					 unsigned int sc_reg)
+static inline void __iomem *sil_scr_addr(struct ata_port *ap, unsigned int sc_reg)
 {
 	void __iomem *offset = ap->ioaddr.scr_addr;
 
@@ -410,9 +350,9 @@
 	return NULL;
 }
 
-static int sil_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)
+static int sil_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
-	void __iomem *mmio = sil_scr_addr(link->ap, sc_reg);
+	void __iomem *mmio = sil_scr_addr(ap, sc_reg);
 
 	if (mmio) {
 		*val = readl(mmio);
@@ -421,9 +361,9 @@
 	return -EINVAL;
 }
 
-static int sil_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)
+static int sil_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
-	void __iomem *mmio = sil_scr_addr(link->ap, sc_reg);
+	void __iomem *mmio = sil_scr_addr(ap, sc_reg);
 
 	if (mmio) {
 		writel(val, mmio);
@@ -434,8 +374,8 @@
 
 static void sil_host_intr(struct ata_port *ap, u32 bmdma2)
 {
-	struct ata_eh_info *ehi = &ap->link.eh_info;
-	struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->link.active_tag);
+	struct ata_eh_info *ehi = &ap->eh_info;
+	struct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->active_tag);
 	u8 status;
 
 	if (unlikely(bmdma2 & SIL_DMA_SATA_IRQ)) {
@@ -445,24 +385,28 @@
 		 * controllers continue to assert IRQ as long as
 		 * SError bits are pending.  Clear SError immediately.
 		 */
-		sil_scr_read(&ap->link, SCR_ERROR, &serror);
-		sil_scr_write(&ap->link, SCR_ERROR, serror);
+		sil_scr_read(ap, SCR_ERROR, &serror);
+		sil_scr_write(ap, SCR_ERROR, serror);
 
-		/* Sometimes spurious interrupts occur, double check
-		 * it's PHYRDY CHG.
+		/* Trigger hotplug and accumulate SError only if the
+		 * port isn't already frozen.  Otherwise, PHY events
+		 * during hardreset makes controllers with broken SIEN
+		 * repeat probing needlessly.
 		 */
-		if (serror & SERR_PHYRDY_CHG) {
-			ap->link.eh_info.serror |= serror;
-			goto freeze;
+		if (!(ap->pflags & ATA_PFLAG_FROZEN)) {
+			ata_ehi_hotplugged(&ap->eh_info);
+			ap->eh_info.serror |= serror;
 		}
 
-		if (!(bmdma2 & SIL_DMA_COMPLETE))
-			return;
+		goto freeze;
 	}
 
-	if (unlikely(!qc || (qc->tf.flags & ATA_TFLAG_POLLING))) {
+	if (unlikely(!qc))
+		goto freeze;
+
+	if (unlikely(qc->tf.flags & ATA_TFLAG_POLLING)) {
 		/* this sometimes happens, just clear IRQ */
-		ap->ops->sff_check_status(ap);
+		ata_chk_status(ap);
 		return;
 	}
 
@@ -474,14 +418,15 @@
 		 */
 
 		/* Check the ATA_DFLAG_CDB_INTR flag is enough here.
-		 * The flag was turned on only for atapi devices.  No
-		 * need to check ata_is_atapi(qc->tf.protocol) again.
+		 * The flag was turned on only for atapi devices.
+		 * No need to check is_atapi_taskfile(&qc->tf) again.
 		 */
 		if (!(qc->dev->flags & ATA_DFLAG_CDB_INTR))
 			goto err_hsm;
 		break;
 	case HSM_ST_LAST:
-		if (ata_is_dma(qc->tf.protocol)) {
+		if (qc->tf.protocol == ATA_PROT_DMA ||
+		    qc->tf.protocol == ATA_PROT_ATAPI_DMA) {
 			/* clear DMA-Start bit */
 			ap->ops->bmdma_stop(qc);
 
@@ -498,17 +443,18 @@
 	}
 
 	/* check main status, clearing INTRQ */
-	status = ap->ops->sff_check_status(ap);
+	status = ata_chk_status(ap);
 	if (unlikely(status & ATA_BUSY))
 		goto err_hsm;
 
 	/* ack bmdma irq events */
-	ata_sff_irq_clear(ap);
+	ata_bmdma_irq_clear(ap);
 
 	/* kick HSM in the ass */
-	ata_sff_hsm_move(ap, qc, status, 0);
+	ata_hsm_move(ap, qc, status, 0);
 
-	if (unlikely(qc->err_mask) && ata_is_dma(qc->tf.protocol))
+	if (unlikely(qc->err_mask) && (qc->tf.protocol == ATA_PROT_DMA ||
+				       qc->tf.protocol == ATA_PROT_ATAPI_DMA))
 		ata_ehi_push_desc(ehi, "BMDMA2 stat 0x%x", bmdma2);
 
 	return;
@@ -532,7 +478,7 @@
 		struct ata_port *ap = host->ports[i];
 		u32 bmdma2 = readl(mmio_base + sil_port[ap->port_no].bmdma2);
 
-		if (unlikely(ap->flags & ATA_FLAG_DISABLED))
+		if (unlikely(!ap || ap->flags & ATA_FLAG_DISABLED))
 			continue;
 
 		/* turn off SATA_IRQ if not supported */
@@ -565,19 +511,6 @@
 	tmp |= SIL_MASK_IDE0_INT << ap->port_no;
 	writel(tmp, mmio_base + SIL_SYSCFG);
 	readl(mmio_base + SIL_SYSCFG);	/* flush */
-
-	/* Ensure DMA_ENABLE is off.
-	 *
-	 * This is because the controller will not give us access to the
-	 * taskfile registers while a DMA is in progress
-	 */
-	iowrite8(ioread8(ap->ioaddr.bmdma_addr) & ~SIL_DMA_ENABLE,
-		 ap->ioaddr.bmdma_addr);
-
-	/* According to ata_bmdma_stop, an HDMA transition requires
-	 * on PIO cycle. But we can't read a taskfile register.
-	 */
-	ioread8(ap->ioaddr.bmdma_addr);
 }
 
 static void sil_thaw(struct ata_port *ap)
@@ -586,8 +519,8 @@
 	u32 tmp;
 
 	/* clear IRQ */
-	ap->ops->sff_check_status(ap);
-	ata_sff_irq_clear(ap);
+	ata_chk_status(ap);
+	ata_bmdma_irq_clear(ap);
 
 	/* turn on SATA IRQ if supported */
 	if (!(ap->flags & SIL_FLAG_NO_SATA_IRQ))
@@ -629,8 +562,8 @@
  */
 static void sil_dev_config(struct ata_device *dev)
 {
-	struct ata_port *ap = dev->link->ap;
-	int print_info = ap->link.eh_context.i.flags & ATA_EHI_PRINTINFO;
+	struct ata_port *ap = dev->ap;
+	int print_info = ap->eh_context.i.flags & ATA_EHI_PRINTINFO;
 	unsigned int n, quirks = 0;
 	unsigned char model_num[ATA_ID_PROD_LEN + 1];
 
@@ -709,38 +642,11 @@
 	}
 }
 
-static bool sil_broken_system_poweroff(struct pci_dev *pdev)
-{
-	static const struct dmi_system_id broken_systems[] = {
-		{
-			.ident = "HP Compaq nx6325",
-			.matches = {
-				DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
-				DMI_MATCH(DMI_PRODUCT_NAME, "HP Compaq nx6325"),
-			},
-			/* PCI slot number of the controller */
-			.driver_data = (void *)0x12UL,
-		},
-
-		{ }	/* terminate list */
-	};
-	const struct dmi_system_id *dmi = dmi_first_match(broken_systems);
-
-	if (dmi) {
-		unsigned long slot = (unsigned long)dmi->driver_data;
-		/* apply the quirk only to on-board controllers */
-		return slot == PCI_SLOT(pdev->devfn);
-	}
-
-	return false;
-}
-
-static int sil_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
+static int sil_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
 	int board_id = ent->driver_data;
-	struct ata_port_info pi = sil_port_info[board_id];
-	const struct ata_port_info *ppi[] = { &pi, NULL };
+	const struct ata_port_info *ppi[] = { &sil_port_info[board_id], NULL };
 	struct ata_host *host;
 	void __iomem *mmio_base;
 	int n_ports, rc;
@@ -754,13 +660,6 @@
 	if (board_id == sil_3114)
 		n_ports = 4;
 
-	if (sil_broken_system_poweroff(pdev)) {
-		pi.flags |= ATA_FLAG_NO_POWEROFF_SPINDOWN |
-					ATA_FLAG_NO_HIBERNATE_SPINDOWN;
-		dev_info(&pdev->dev, "quirky BIOS, skipping spindown "
-				"on poweroff and hibernation\n");
-	}
-
 	host = ata_host_alloc_pinfo(&pdev->dev, ppi, n_ports);
 	if (!host)
 		return -ENOMEM;
@@ -787,18 +686,14 @@
 	mmio_base = host->iomap[SIL_MMIO_BAR];
 
 	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		struct ata_ioports *ioaddr = &ap->ioaddr;
+		struct ata_ioports *ioaddr = &host->ports[i]->ioaddr;
 
 		ioaddr->cmd_addr = mmio_base + sil_port[i].tf;
 		ioaddr->altstatus_addr =
 		ioaddr->ctl_addr = mmio_base + sil_port[i].ctl;
 		ioaddr->bmdma_addr = mmio_base + sil_port[i].bmdma;
 		ioaddr->scr_addr = mmio_base + sil_port[i].scr;
-		ata_sff_std_ports(ioaddr);
-
-		ata_port_pbar_desc(ap, SIL_MMIO_BAR, -1, "mmio");
-		ata_port_pbar_desc(ap, SIL_MMIO_BAR, sil_port[i].tf, "tf");
+		ata_std_ports(ioaddr);
 	}
 
 	/* initialize and activate */
diff -Nur linux-sh4/drivers/ata.org/sata_sis.c linux-sh4/drivers/ata/sata_sis.c
--- linux-sh4/drivers/ata.org/sata_sis.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_sis.c	2012-01-15 06:30:15.000000000 -0800
@@ -63,17 +63,17 @@
 	GENCTL_IOMAPPED_SCR	= (1 << 26), /* if set, SCRs are in IO space */
 };
 
-static int sis_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
-static int sis_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val);
-static int sis_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val);
+static int sis_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
+static int sis_scr_read (struct ata_port *ap, unsigned int sc_reg, u32 *val);
+static int sis_scr_write (struct ata_port *ap, unsigned int sc_reg, u32 val);
 
 static const struct pci_device_id sis_pci_tbl[] = {
-	{ PCI_VDEVICE(SI, 0x0180), sis_180 },	/* SiS 964/180 */
-	{ PCI_VDEVICE(SI, 0x0181), sis_180 },	/* SiS 964/180 */
-	{ PCI_VDEVICE(SI, 0x0182), sis_180 },	/* SiS 965/965L */
-	{ PCI_VDEVICE(SI, 0x0183), sis_180 },	/* SiS 965/965L */
-	{ PCI_VDEVICE(SI, 0x1182), sis_180 },	/* SiS 966/680 */
-	{ PCI_VDEVICE(SI, 0x1183), sis_180 },	/* SiS 966/966L/968/680 */
+	{ PCI_VDEVICE(SI, 0x0180), sis_180 },		/* SiS 964/180 */
+	{ PCI_VDEVICE(SI, 0x0181), sis_180 },		/* SiS 964/180 */
+	{ PCI_VDEVICE(SI, 0x0182), sis_180 },		/* SiS 965/965L */
+	{ PCI_VDEVICE(SI, 0x0183), sis_180 },		/* SiS 965/965L */
+	{ PCI_VDEVICE(SI, 0x1182), sis_180 },		/* SiS 966/680 */
+	{ PCI_VDEVICE(SI, 0x1183), sis_180 },		/* SiS 966/966L/968/680 */
 
 	{ }	/* terminate list */
 };
@@ -86,19 +86,53 @@
 };
 
 static struct scsi_host_template sis_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-static struct ata_port_operations sis_ops = {
-	.inherits		= &ata_bmdma_port_ops,
+static const struct ata_port_operations sis_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+	.bmdma_setup            = ata_bmdma_setup,
+	.bmdma_start            = ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 	.scr_read		= sis_scr_read,
 	.scr_write		= sis_scr_write,
+	.port_start		= ata_port_start,
 };
 
 static const struct ata_port_info sis_port_info = {
 	.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY,
-	.pio_mask	= ATA_PIO4,
-	.mwdma_mask	= ATA_MWDMA2,
+	.pio_mask	= 0x1f,
+	.mwdma_mask	= 0x7,
 	.udma_mask	= ATA_UDMA6,
 	.port_ops	= &sis_ops,
 };
@@ -109,89 +143,119 @@
 MODULE_DEVICE_TABLE(pci, sis_pci_tbl);
 MODULE_VERSION(DRV_VERSION);
 
-static unsigned int get_scr_cfg_addr(struct ata_link *link, unsigned int sc_reg)
+static unsigned int get_scr_cfg_addr(struct ata_port *ap, unsigned int sc_reg)
 {
-	struct ata_port *ap = link->ap;
 	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
 	unsigned int addr = SIS_SCR_BASE + (4 * sc_reg);
 	u8 pmr;
 
 	if (ap->port_no)  {
 		switch (pdev->device) {
-		case 0x0180:
-		case 0x0181:
-			pci_read_config_byte(pdev, SIS_PMR, &pmr);
-			if ((pmr & SIS_PMR_COMBINED) == 0)
-				addr += SIS180_SATA1_OFS;
-			break;
-
-		case 0x0182:
-		case 0x0183:
-		case 0x1182:
-			addr += SIS182_SATA1_OFS;
-			break;
+			case 0x0180:
+			case 0x0181:
+				pci_read_config_byte(pdev, SIS_PMR, &pmr);
+				if ((pmr & SIS_PMR_COMBINED) == 0)
+					addr += SIS180_SATA1_OFS;
+				break;
+
+			case 0x0182:
+			case 0x0183:
+			case 0x1182:
+				addr += SIS182_SATA1_OFS;
+				break;
 		}
 	}
-	if (link->pmp)
-		addr += 0x10;
-
 	return addr;
 }
 
-static u32 sis_scr_cfg_read(struct ata_link *link,
-			    unsigned int sc_reg, u32 *val)
+static u32 sis_scr_cfg_read (struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
-	struct pci_dev *pdev = to_pci_dev(link->ap->host->dev);
-	unsigned int cfg_addr = get_scr_cfg_addr(link, sc_reg);
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	unsigned int cfg_addr = get_scr_cfg_addr(ap, sc_reg);
+	u32 val2 = 0;
+	u8 pmr;
 
 	if (sc_reg == SCR_ERROR) /* doesn't exist in PCI cfg space */
-		return -EINVAL;
+		return 0xffffffff;
+
+	pci_read_config_byte(pdev, SIS_PMR, &pmr);
 
 	pci_read_config_dword(pdev, cfg_addr, val);
+
+	if ((pdev->device == 0x0182) || (pdev->device == 0x0183) ||
+	    (pdev->device == 0x1182) || (pmr & SIS_PMR_COMBINED))
+		pci_read_config_dword(pdev, cfg_addr+0x10, &val2);
+
+	*val |= val2;
+	*val &= 0xfffffffb;	/* avoid problems with powerdowned ports */
+
 	return 0;
 }
 
-static int sis_scr_cfg_write(struct ata_link *link,
-			     unsigned int sc_reg, u32 val)
+static void sis_scr_cfg_write (struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
-	struct pci_dev *pdev = to_pci_dev(link->ap->host->dev);
-	unsigned int cfg_addr = get_scr_cfg_addr(link, sc_reg);
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	unsigned int cfg_addr = get_scr_cfg_addr(ap, sc_reg);
+	u8 pmr;
+
+	if (sc_reg == SCR_ERROR) /* doesn't exist in PCI cfg space */
+		return;
+
+	pci_read_config_byte(pdev, SIS_PMR, &pmr);
 
 	pci_write_config_dword(pdev, cfg_addr, val);
-	return 0;
+
+	if ((pdev->device == 0x0182) || (pdev->device == 0x0183) ||
+	    (pdev->device == 0x1182) || (pmr & SIS_PMR_COMBINED))
+		pci_write_config_dword(pdev, cfg_addr+0x10, val);
 }
 
-static int sis_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)
+static int sis_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
-	struct ata_port *ap = link->ap;
-	void __iomem *base = ap->ioaddr.scr_addr + link->pmp * 0x10;
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	u8 pmr;
 
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
 
 	if (ap->flags & SIS_FLAG_CFGSCR)
-		return sis_scr_cfg_read(link, sc_reg, val);
+		return sis_scr_cfg_read(ap, sc_reg, val);
+
+	pci_read_config_byte(pdev, SIS_PMR, &pmr);
+
+	*val = ioread32(ap->ioaddr.scr_addr + (sc_reg * 4));
+
+	if ((pdev->device == 0x0182) || (pdev->device == 0x0183) ||
+	    (pdev->device == 0x1182) || (pmr & SIS_PMR_COMBINED))
+		*val |= ioread32(ap->ioaddr.scr_addr + (sc_reg * 4) + 0x10);
+
+	*val &= 0xfffffffb;
 
-	*val = ioread32(base + sc_reg * 4);
 	return 0;
 }
 
-static int sis_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)
+static int sis_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
-	struct ata_port *ap = link->ap;
-	void __iomem *base = ap->ioaddr.scr_addr + link->pmp * 0x10;
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	u8 pmr;
 
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
 
-	if (ap->flags & SIS_FLAG_CFGSCR)
-		return sis_scr_cfg_write(link, sc_reg, val);
+	pci_read_config_byte(pdev, SIS_PMR, &pmr);
 
-	iowrite32(val, base + (sc_reg * 4));
+	if (ap->flags & SIS_FLAG_CFGSCR)
+		sis_scr_cfg_write(ap, sc_reg, val);
+	else {
+		iowrite32(val, ap->ioaddr.scr_addr + (sc_reg * 4));
+		if ((pdev->device == 0x0182) || (pdev->device == 0x0183) ||
+		    (pdev->device == 0x1182) || (pmr & SIS_PMR_COMBINED))
+			iowrite32(val, ap->ioaddr.scr_addr + (sc_reg * 4)+0x10);
+	}
 	return 0;
 }
 
-static int sis_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
+static int sis_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
 	struct ata_port_info pi = sis_port_info;
@@ -200,7 +264,7 @@
 	u32 genctl, val;
 	u8 pmr;
 	u8 port2_start = 0x20;
-	int i, rc;
+	int rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_INFO, &pdev->dev, "version " DRV_VERSION "\n");
@@ -247,53 +311,38 @@
 		} else {
 			dev_printk(KERN_INFO, &pdev->dev,
 				   "Detected SiS 180/181 chipset in combined mode\n");
-			port2_start = 0;
+			port2_start=0;
 			pi.flags |= ATA_FLAG_SLAVE_POSS;
 		}
 		break;
 
 	case 0x0182:
 	case 0x0183:
-		pci_read_config_dword(pdev, 0x6C, &val);
+		pci_read_config_dword ( pdev, 0x6C, &val);
 		if (val & (1L << 31)) {
-			dev_printk(KERN_INFO, &pdev->dev,
-				   "Detected SiS 182/965 chipset\n");
+			dev_printk(KERN_INFO, &pdev->dev, "Detected SiS 182/965 chipset\n");
 			pi.flags |= ATA_FLAG_SLAVE_POSS;
 		} else {
-			dev_printk(KERN_INFO, &pdev->dev,
-				   "Detected SiS 182/965L chipset\n");
+			dev_printk(KERN_INFO, &pdev->dev, "Detected SiS 182/965L chipset\n");
 		}
 		break;
 
 	case 0x1182:
-		dev_printk(KERN_INFO, &pdev->dev,
-			   "Detected SiS 1182/966/680 SATA controller\n");
+		dev_printk(KERN_INFO, &pdev->dev, "Detected SiS 1182/966/680 SATA controller\n");
 		pi.flags |= ATA_FLAG_SLAVE_POSS;
 		break;
 
 	case 0x1183:
-		dev_printk(KERN_INFO, &pdev->dev,
-			   "Detected SiS 1183/966/966L/968/680 controller in PATA mode\n");
+		dev_printk(KERN_INFO, &pdev->dev, "Detected SiS 1183/966/966L/968/680 controller in PATA mode\n");
 		ppi[0] = &sis_info133_for_sata;
 		ppi[1] = &sis_info133_for_sata;
 		break;
 	}
 
-	rc = ata_pci_sff_prepare_host(pdev, ppi, &host);
+	rc = ata_pci_prepare_sff_host(pdev, ppi, &host);
 	if (rc)
 		return rc;
 
-	for (i = 0; i < 2; i++) {
-		struct ata_port *ap = host->ports[i];
-
-		if (ap->flags & ATA_FLAG_SATA &&
-		    ap->flags & ATA_FLAG_SLAVE_POSS) {
-			rc = ata_slave_link_init(ap);
-			if (rc)
-				return rc;
-		}
-	}
-
 	if (!(pi.flags & SIS_FLAG_CFGSCR)) {
 		void __iomem *mmio;
 
@@ -308,8 +357,8 @@
 
 	pci_set_master(pdev);
 	pci_intx(pdev, 1);
-	return ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &sis_sht);
+	return ata_host_activate(host, pdev->irq, ata_interrupt, IRQF_SHARED,
+				 &sis_sht);
 }
 
 static int __init sis_init(void)
diff -Nur linux-sh4/drivers/ata.org/sata_stm.c linux-sh4/drivers/ata/sata_stm.c
--- linux-sh4/drivers/ata.org/sata_stm.c	2012-03-10 00:25:26.000000000 -0800
+++ linux-sh4/drivers/ata/sata_stm.c	2012-01-15 06:30:15.000000000 -0800
@@ -26,21 +26,17 @@
 #include <linux/blkdev.h>
 #include <linux/delay.h>
 #include <linux/interrupt.h>
-#include <linux/list.h>
 #include <linux/platform_device.h>
-#include <linux/pm_runtime.h>
 #include <scsi/scsi.h>
 #include <scsi/scsi_host.h>
-#include <scsi/scsi_device.h>
 #include <scsi/scsi_cmnd.h>
-#include <scsi/scsi_transport.h>
 #include <linux/libata.h>
 #include <linux/stm/platform.h>
 #include <linux/stm/device.h>
 #include <linux/stm/miphy.h>
 
 #define DRV_NAME			"sata-stm"
-#define DRV_VERSION			"0.8"
+#define DRV_VERSION			"0.6"
 
 /* Offsets of the component blocks */
 #define SATA_AHB2STBUS_BASE			0x00000000
@@ -212,7 +208,6 @@
 #define SATA_BISTFCTR				(SATA_AHBHOST_BASE + 0x000000ac)
 #define SATA_BISTSR				(SATA_AHBHOST_BASE + 0x000000b0)
 #define SATA_BISTDECR				(SATA_AHBHOST_BASE + 0x000000b4)
-#define SATA_OOBR				(SATA_AHBHOST_BASE + 0x000000bc)
 #define SATA_TESTR				(SATA_AHBHOST_BASE + 0x000000f4)
 #define SATA_VERSIONR				(SATA_AHBHOST_BASE + 0x000000f8)
 #define SATA_IDR				(SATA_AHBHOST_BASE + 0x000000fc)
@@ -237,9 +232,9 @@
 
 #define SATA_FIS_SIZE	(8*1024)
 
-static int stm_sata_scr_read(struct ata_link *link, unsigned int sc_reg,
+static int stm_sata_scr_read(struct ata_port *ap, unsigned int sc_reg,
 			     u32 *val);
-static int stm_sata_scr_write(struct ata_link *link, unsigned int sc_reg,
+static int stm_sata_scr_write(struct ata_port *ap, unsigned int sc_reg,
 			      u32 val);
 
 /* Layout of a DMAC Linked List Item (LLI)
@@ -255,14 +250,9 @@
 struct stm_host_priv
 {
 	unsigned long phy_init;		/* Initial value for PHYCR */
-	int oob_wa;			/* OOB-06(a) certification test WA */
 	int softsg;			/* If using softsg */
 	int shared_dma_host_irq;	/* If we the interrupt from the DMA
 					 * and HOSTC are or'ed together */
-	struct stm_device_state *device_state;
-	void (*host_restart)(int port); /* Full reset of host and phy */
-	int port_num;			/* Parameter to host_restart */
-	struct stm_miphy *miphy_dev;	/* MiPHY Dev Struct */
 };
 
 struct stm_port_priv
@@ -272,8 +262,6 @@
 	struct stm_lli *softsg_node;	/* Current softsg node */
 	struct stm_lli *softsg_end;	/* End of the softsg node */
 	char smallburst;		/* Small DMA burst size */
-	char pmp;			/* Current SControl.PMP */
-	struct ata_link *active_link;	/* Link for last request */
 };
 
 /* There is an undocumented restriction that DMA blocks must not span
@@ -425,19 +413,24 @@
        readl(mmio + DMAC_ChEnReg),
        readl(mmio + DMAC_DmaCfgReg));
 
+
+	/* Enable channel 0 */
+	wmb();
+	writel((1<<8) | (1<<0), mmio + DMAC_ChEnReg);
+
 	/* issue r/w command */
-	ap->ops->sff_exec_command(ap, &qc->tf);
+	ata_exec_command(ap, &qc->tf);
 }
 
 static void stm_bmdma_start(struct ata_queued_cmd *qc)
 {
-	struct ata_port *ap = qc->ap;
-	void __iomem *mmio = ap->ioaddr.cmd_addr;
-
-	DPRINTK("ENTER\n");
 
+#if 0
+	void __iomem *mmio = ap->ioaddr.cmd_addr;
+	struct ata_port *ap = qc->ap;
 	/* Enable channel 0 */
 	writel((1<<8) | (1<<0), mmio + DMAC_ChEnReg);
+#endif
 }
 
 static void stm_bmdma_stop(struct ata_queued_cmd *qc)
@@ -457,6 +450,9 @@
 
 	/* Disable DMA on the SATA host */
 	writel(0, mmio + SATA_DMACR);
+
+	/* one-PIO-cycle guaranteed wait, per spec, for HDMA1:0 transition */
+	ata_altstatus(ap);        /* dummy read */
 }
 
 static u8 stm_bmdma_status(struct ata_port *ap)
@@ -475,12 +471,15 @@
 	struct stm_host_priv *hpriv = ap->host->private_data;
         struct stm_port_priv *pp = ap->private_data;
 	unsigned int write = (qc->tf.flags & ATA_TFLAG_WRITE);
-	unsigned int si, idx;
+	unsigned int idx;
 	u32 sar, dar, ctl0;
 	u32 fis_offset;
 
 	DPRINTK("ENTER\n");
 
+	WARN_ON(qc->__sg == NULL);
+	WARN_ON(qc->n_elem == 0 && qc->pad_len == 0);
+
 	ctl0 = 	DMAC_CTL_DST_TR_WIDTH_32	|
 		DMAC_CTL_SRC_TR_WIDTH_32	|
 		DMAC_CTL_DINC_INC		|
@@ -488,7 +487,7 @@
 
 	if (write) {
 		/* memory (master1) to SATA host (master2) transfer */
-		ctl0 |= DMAC_CTL_DEST_MSIZE_4		|
+		ctl0 |= DMAC_CTL_DEST_MSIZE_1		|
 			DMAC_CTL_SRC_MSIZE_16		|
 			DMAC_CTL_TT_FC_M2P_DMAC		|
 			DMAC_CTL_DMS_2			|
@@ -512,7 +511,7 @@
 	idx = 0;
 	sar = dar = 0;
 	fis_offset = 0;
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
+	ata_for_each_sg(sg, qc) {
 		u32 addr;
 		u32 sg_len, len;
 
@@ -565,39 +564,18 @@
 
 }
 
-static void stm_pmp_select(struct ata_port *ap, int pmp)
-{
-        if (sata_pmp_supported(ap)) {
-		struct stm_port_priv *pp = ap->private_data;
-
-		if (pp->pmp != pmp) {
-			u32 scontrol;
-
-			stm_sata_scr_read(&ap->link, SCR_CONTROL, &scontrol);
-			pp->pmp = pmp;
-			stm_sata_scr_write(&ap->link, SCR_CONTROL,
-					   (scontrol & 0xff0));
-		}
-	}
-}
-
 static void stm_qc_prep(struct ata_queued_cmd *qc)
 {
-	struct stm_port_priv *pp = qc->ap->private_data;
-
-	stm_pmp_select(qc->ap, qc->dev->link->pmp & 0xf);
-	pp->active_link = qc->dev->link;
-
 	if (!(qc->flags & ATA_QCFLAG_DMAMAP))
 		return;
 
 	stm_fill_sg(qc);
 }
 
-static unsigned int stm_data_xfer(struct ata_device *adev, unsigned char *buf,
-				  unsigned int buflen, int rw)
+static void stm_data_xfer(struct ata_device *adev, unsigned char *buf,
+		           unsigned int buflen, int write_data)
 {
-	struct ata_port *ap = adev->link->ap;
+	struct ata_port *ap = adev->ap;
 	unsigned int i;
 	unsigned int words = buflen >> 1;
 	u16 *buf16 = (u16 *) buf;
@@ -608,7 +586,7 @@
 	writel(~SERROR_ERR_E, mmio_base + SATA_ERRMR);
 
 	/* Transfer multiple of 2 bytes */
-	if (rw == WRITE) {
+	if (write_data) {
 		for (i = 0; i < words; i++) {
 			writew(le16_to_cpu(buf16[i]), mmio);
 			ndelay(120);
@@ -625,215 +603,63 @@
 		u16 align_buf[1] = { 0 };
 		unsigned char *trailing_buf = buf + buflen - 1;
 
-		if (rw == WRITE) {
+		if (write_data) {
 			memcpy(align_buf, trailing_buf, 1);
 			writew(le16_to_cpu(align_buf[0]), mmio);
 		} else {
 			align_buf[0] = cpu_to_le16(readw(mmio));
 			memcpy(trailing_buf, align_buf, 1);
 		}
-		words++;
 	}
 
 	/* Clear any errors and re-enable error reporting */
 	writel(-1, mmio_base + SATA_SCR1);
 	writel(0xffffffff, mmio_base + SATA_ERRMR);
-
-	return words << 1;
 }
 
 static void stm_freeze(struct ata_port *ap)
 {
 	void __iomem *mmio = ap->ioaddr.cmd_addr;
 
-	DPRINTK("ENTER\n");
-
 	/* Disable interrupts */
 	writel(0, mmio + SATA_INTMR);
 	readl(mmio + SATA_INTMR);	/* flush */
-	ata_sff_freeze(ap);
 }
 
 static void stm_thaw(struct ata_port *ap)
 {
 	void __iomem *mmio = ap->ioaddr.cmd_addr;
 
-	DPRINTK("ENTER\n");
-
 	/* Reenable interrupts */
 	writel(SATA_INT_ERR, mmio + SATA_INTMR);
-	ata_sff_thaw(ap);
 }
 
-static int stm_prereset(struct ata_link *link, unsigned long deadline)
+static int stm_prereset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
-	u32 serror;
-	struct stm_host_priv *hpriv = ap->host->private_data;
-	struct stm_miphy *miphy_dev = hpriv->miphy_dev;
-	u8 miphy_int_status = stm_miphy_sata_status(miphy_dev);
-
-	DPRINTK("ENTER\n");
-	stm_sata_scr_read(&ap->link, SCR_ERROR, &serror);
-
-	/*
-	 * Defect RnDHV00030463 and STLinux Bugzilla 9770.
-	 * Try and detect an ESD event which is resolved by
-	 * a reset of both the host and the phy.
-	 */
-	if (hpriv->host_restart && ((serror & SERROR_ERR_C) ||
-		miphy_int_status)) {
-		hpriv->host_restart(hpriv->port_num);
-		stm_miphy_start(miphy_dev);
-	}
-
 	stm_phy_configure(ap);
-	return ata_sff_prereset(link, deadline);
-}
-
-
-/*
- * Workaround for drive detection problems (STLinux bugzilla 9873).
- * Need to keep the MiPHY deserializer reset while performing the
- * COMMRESET and wait till COMMWAIT is received from device.
- */
-static int stm_sata_do_comreset(void __iomem *mmio_base,
-	struct stm_host_priv *hpriv)
-{
-	/* Make sure that PHY is up */
-	int timeout, val, rval = 0;
-	struct stm_miphy *miphy_dev = hpriv->miphy_dev;
-
-	/* OOB-6a certification test workaround */
-	/* Refer to RnDHV00020989/RnDHV00032380 for more information */
-	if (hpriv->oob_wa) {
-		writel(readl(mmio_base + SATA_OOBR) | 0x80000000,
-			mmio_base + SATA_OOBR);
-
-		writel(readl(mmio_base + SATA_OOBR) & 0x82FFFFFF,
-			mmio_base + SATA_OOBR);
-	}
-
-	val = readl(mmio_base + SATA_SCR1);
-	/* clearing the SATA_SCR1 register */
-	writel(val, (mmio_base + SATA_SCR1));
-
-	/* Assert MiPHY deserializer reset */
-	stm_miphy_assert_deserializer(miphy_dev, 1);
-
-	/* Send COMMRESET */
-	writel(0x1, (mmio_base + SATA_SCR2));
-	msleep(1);
-	writel(0x0, (mmio_base + SATA_SCR2));
-
-	/* wait a while before checking status*/
-	msleep(150);
-	/* Wait Till COMWAKE Detected */
-	timeout = 100;
-	while (timeout-- &&
-		((readl(mmio_base + SATA_SCR1) & 0x40000) != 0x40000))
-		msleep(1);
-
-	/* Deassert MiPHY deserializer reset */
-	stm_miphy_assert_deserializer(miphy_dev, 0);
-	if (timeout <= 0) {
-		rval = -1;
-		goto err;
-	}
-
-	timeout = 100;
-	/* Waiting for PHYRDY to be detected by Host */
-	while (timeout-- && ((readl(mmio_base + SATA_SCR0) & 0x03) != 0x03))
-		msleep(1);
-
-	if (timeout <= 0)
-		rval = -1;
-
-err:
-	if (hpriv->oob_wa)
-		writel(readl(mmio_base + SATA_OOBR) & 0x7FFFFFFF,
-			mmio_base + SATA_OOBR);
-
-
-	return rval;
+	return ata_std_prereset(ap, deadline);
 }
 
-static int stm_sata_hardreset(struct ata_link *link, unsigned int *class,
-			unsigned long deadline)
+static void stm_postreset(struct ata_port *ap, unsigned int *classes)
 {
-	struct ata_port *ap = link->ap;
-	void __iomem *mmio_base = ap->ioaddr.cmd_addr;
-	struct stm_host_priv *hpriv = ap->host->private_data;
-	/* Debounce timing */
-	const unsigned long *timing = sata_ehc_deb_timing(&link->eh_context);
-	u32 rc;
-
-	/* Check if device is detected */
-	if (readl(mmio_base + SATA_SCR0) == 0x0)
-		return 0; /* No device detected */
-
-	stm_phy_configure(ap);
-
-	if (stm_sata_do_comreset(mmio_base, hpriv))
-		return 0; /* Link Offline */
-
-	/* resume with Debounce */
-	rc = sata_link_resume(link, timing, deadline);
-	if (rc) {
-		ata_link_printk(link, KERN_WARNING, "failed to resume "
-					"link after reset (errno=%d)\n", rc);
-		return rc;
-	}
-	if (ata_link_offline(link))
-		return 0;
-
-	return -EAGAIN;
-}
-
-static void stm_postreset(struct ata_link *link, unsigned int *classes)
-{
-	struct ata_port *ap = link->ap;
 	void __iomem *mmio = ap->ioaddr.cmd_addr;
 
-	DPRINTK("ENTER\n");
-
 	/* Enable notification of errors. These are reset by COMRESET. */
 	writel(0xffffffff, mmio + SATA_ERRMR);
 	writel(SATA_INT_ERR, mmio + SATA_INTMR);
 
-	ata_std_postreset(link, classes);
+	ata_std_postreset(ap, classes);
 }
 
-static int stm_pmp_hardreset(struct ata_link *link, unsigned int *class,
-			     unsigned long deadline)
+static void stm_error_handler(struct ata_port *ap)
 {
-	DPRINTK("ENTER\n");
-
-	stm_pmp_select(link->ap, sata_srst_pmp(link));
-	return sata_std_hardreset(link, class, deadline);
-}
-
-static int stm_softreset(struct ata_link *link, unsigned int *class,
-			 unsigned long deadline)
-{
-	DPRINTK("ENTER\n");
-
-	stm_pmp_select(link->ap, sata_srst_pmp(link));
-	return ata_sff_softreset(link, class, deadline);
+        ata_do_eh(ap, stm_prereset, ata_std_softreset,
+                  sata_std_hardreset, stm_postreset);
 }
 
-static void stm_dev_config(struct ata_device *adev)
+static void stm_post_internal_cmd(struct ata_queued_cmd *qc)
 {
-	struct ata_port *ap = adev->link->ap;
-	int print_info = ap->link.eh_context.i.flags & ATA_EHI_PRINTINFO;
-
-	if (adev->max_sectors > STM_MAX_SECTORS) {
-		if (print_info)
-			ata_dev_printk(adev, KERN_INFO,
-				       "restricting to %d max sectors\n",
-				       STM_MAX_SECTORS);
-		adev->max_sectors = STM_MAX_SECTORS;
-	}
+	stm_bmdma_stop(qc);
 }
 
 /* This needs munging to give per controller stats */
@@ -880,14 +706,14 @@
 {
 	unsigned int handled = 0;
 	void __iomem *mmio = ap->ioaddr.cmd_addr;
-	struct ata_eh_info *ehi = &ap->link.eh_info;
+	struct ata_eh_info *ehi = &ap->eh_info;
 	u32 sstatus, serror;
 
 	if (readl(mmio + SATA_INTPR) & (SATA_INT_ERR)) {
 
-		stm_sata_scr_read(&ap->link, SCR_STATUS, &sstatus);
-		stm_sata_scr_read(&ap->link, SCR_ERROR, &serror);
-		stm_sata_scr_write(&ap->link, SCR_ERROR, serror);
+		stm_sata_scr_read(ap, SCR_STATUS, &sstatus);
+		stm_sata_scr_read(ap, SCR_ERROR, &serror);
+		stm_sata_scr_write(ap, SCR_ERROR, serror);
 
 		if (print_error)
 			ata_port_printk(ap, KERN_ERR,
@@ -901,7 +727,7 @@
 		ehi->serror |= serror;
 
 		if (serror & (SERROR_DIAG_N | SERROR_DIAG_X)) {
-			ata_ehi_hotplugged(ehi);
+			ata_ehi_hotplugged(&ap->eh_info);
 			ata_ehi_push_desc(ehi, "Treating as hot-%splug",
 					  serror & SERROR_DIAG_X ? "" : "un");
 		}
@@ -911,17 +737,10 @@
 	} else
 		if (ap && (!(ap->flags & ATA_FLAG_DISABLED))) {
 			struct ata_queued_cmd *qc;
-			struct stm_port_priv *pp = ap->private_data;
 
-			qc = ata_qc_from_tag(ap, pp->active_link->active_tag);
-			/*
-			 * ata_qc_issue sets qc->dev->link.active_tag
-			 * rather than ap->link.active_tag.  This
-			 * means for PMP the host link doesn't have
-			 * the tag set.
-			 */
+			qc = ata_qc_from_tag(ap, ap->active_tag);
 			if (qc && (!(qc->tf.ctl & ATA_NIEN)))
-				handled += ata_sff_host_intr(ap, qc);
+				handled += ata_host_intr(ap, qc);
 		}
 
 	return handled;
@@ -932,16 +751,19 @@
 	struct ata_host *host = dev_instance;
 	unsigned int handled = 0;
 	unsigned int i;
+	unsigned long flags;
 	struct stm_host_priv *hpriv = host->private_data;
 
+DPRINTK("ENTER DMA\n");
+
 	BUG_ON(hpriv->shared_dma_host_irq);
 
-	spin_lock(&host->lock);
+	spin_lock_irqsave(&host->lock, flags);
 
 	for (i = 0; i < host->n_ports; i++)
 		handled += stm_sata_dma_irq(host->ports[i]);
 
-	spin_unlock(&host->lock);
+	spin_unlock_irqrestore(&host->lock, flags);
 
 	return IRQ_RETVAL(handled);
 }
@@ -951,11 +773,12 @@
 	struct ata_host *host = dev_instance;
 	unsigned int handled = 0;
 	unsigned int i;
+	unsigned long flags;
 	struct stm_host_priv *hpriv = host->private_data;
 
 DPRINTK("ENTER\n");
 
-	spin_lock(&host->lock);
+	spin_lock_irqsave(&host->lock, flags);
 
 	for (i = 0; i < host->n_ports; i++) {
 		if (hpriv->shared_dma_host_irq)
@@ -963,7 +786,7 @@
 		handled += stm_sata_host_irq(host->ports[i]);
 	}
 
-	spin_unlock(&host->lock);
+	spin_unlock_irqrestore(&host->lock, flags);
 
 	return IRQ_RETVAL(handled);
 }
@@ -973,9 +796,9 @@
 	/* TODO */
 }
 
-static int stm_sata_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)
+static int stm_sata_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
-	void __iomem *mmio = link->ap->ioaddr.cmd_addr;
+	void __iomem *mmio = ap->ioaddr.cmd_addr;
 
 	if (sc_reg > SCR_CONTROL) return -EINVAL;
 
@@ -983,20 +806,13 @@
 	return 0;
 }
 
-static int stm_sata_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)
+static int stm_sata_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
-	void __iomem *mmio = link->ap->ioaddr.cmd_addr;
+	void __iomem *mmio = ap->ioaddr.cmd_addr;
 
 DPRINTK("%d = %08x\n", sc_reg, val);
 	if (sc_reg > SCR_CONTROL) return -EINVAL;
 
-	if (sc_reg == SCR_CONTROL) {
-		struct stm_port_priv *pp = link->ap->private_data;
-
-		val &= ~(0xf << 16);
-		val |= pp->pmp << 16;
-	}
-
 	writel(val, mmio + SATA_SCR0 + (sc_reg * 4));
 	return 0;
 }
@@ -1006,6 +822,7 @@
 	struct device *dev = ap->host->dev;
 	struct stm_host_priv *hpriv = ap->host->private_data;
 	struct stm_port_priv *pp;
+	int rc;
 
 	pp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);
 	if (pp == NULL)
@@ -1023,6 +840,10 @@
 
 	pp->smallburst = 0;
 
+	rc = ata_pad_alloc(ap, dev);
+	if (rc)
+		return rc;
+
 	ap->private_data = pp;
 
 	return 0;
@@ -1031,6 +852,7 @@
 static ssize_t stm_show_serror(struct device *dev,
 			       struct device_attribute *attr, char *buf)
 {
+	//struct Scsi_Host *host = class_to_shost(class_dev);
 	ssize_t len;
 
 	len = snprintf(buf, PAGE_SIZE, "%ld\n", error_count);
@@ -1041,16 +863,25 @@
 				struct device_attribute *attr,
 				const char *buf, size_t count)
 {
+	// struct Scsi_Host *host = class_to_shost(class_dev);
+
 	error_count = simple_strtoul(buf, NULL, 10);
 	return count;
 }
 
-static DEVICE_ATTR(serror, S_IRUGO | S_IWUGO,
-		   stm_show_serror, stm_store_serror);
+static struct device_attribute stm_host_stats_attr = {
+	.attr = {
+		.name =		"serror",
+		.mode =		S_IRUGO | S_IWUGO,
+	},
+	.show = stm_show_serror,
+	.store = stm_store_serror,
+};
 
 static ssize_t stm_show_printerror(struct device *dev,
 				   struct device_attribute *attr, char *buf)
 {
+	//struct Scsi_Host *host = class_to_shost(class_dev);
 	ssize_t len;
 
 	len = snprintf(buf, PAGE_SIZE, "%d\n", print_error);
@@ -1061,121 +892,101 @@
 				    struct device_attribute *attr,
 				    const char *buf, size_t count)
 {
+	// struct Scsi_Host *host = class_to_shost(class_dev);
+
 	print_error = simple_strtoul(buf, NULL, 10);
 	return count;
 }
 
-static DEVICE_ATTR(printerror, S_IRUGO | S_IWUGO,
-		   stm_show_printerror, stm_store_printerror);
+static struct device_attribute stm_host_printerror_attr = {
+	.attr = {
+		.name =		"printerror",
+		.mode =		S_IRUGO | S_IWUGO,
+	},
+	.show = stm_show_printerror,
+	.store = stm_store_printerror,
+};
 
 /* Host attributes initializer */
 static struct device_attribute *stm_host_attrs[] = {
-	&dev_attr_serror,
-	&dev_attr_printerror,
+	&stm_host_stats_attr,
+	&stm_host_printerror_attr,
 	NULL,
 };
 
 static struct scsi_host_template stm_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
 	.max_sectors		= STM_MAX_SECTORS,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 	.shost_attrs		= stm_host_attrs,
 };
 
 static struct ata_port_operations stm_ops = {
-	.inherits		= &ata_sff_port_ops,
-
+	.port_disable		= ata_port_disable,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_noop_dev_select,
 	.check_atapi_dma	= stm_check_atapi_dma,
-	.qc_defer		= sata_pmp_qc_defer_cmd_switch,
+	.bmdma_setup		= stm_bmdma_setup,
+	.bmdma_start		= stm_bmdma_start,
+	.bmdma_stop		= stm_bmdma_stop,
+	.bmdma_status		= stm_bmdma_status,
 	.qc_prep		= stm_qc_prep,
-
-	.dev_config		= stm_dev_config,
-
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= stm_data_xfer,
 	.freeze			= stm_freeze,
 	.thaw			= stm_thaw,
-	.prereset		= stm_prereset,
-	.postreset		= stm_postreset,
-
-	.pmp_hardreset		= stm_pmp_hardreset,
-	.pmp_softreset		= stm_softreset,
-	.softreset		= stm_softreset,
-	.hardreset		= stm_sata_hardreset,
-	.error_handler		= sata_pmp_error_handler,
-
+	.error_handler		= stm_error_handler,
+	.post_internal_cmd	= stm_post_internal_cmd,
+	.irq_clear		= stm_irq_clear,
+	.irq_on			= ata_dummy_irq_on,
 	.scr_read		= stm_sata_scr_read,
 	.scr_write		= stm_sata_scr_write,
-
 	.port_start		= stm_port_start,
-
-	.sff_data_xfer		= stm_data_xfer,
-	.sff_irq_clear		= stm_irq_clear,
-
-	.bmdma_setup		= stm_bmdma_setup,
-	.bmdma_start		= stm_bmdma_start,
-	.bmdma_stop		= stm_bmdma_stop,
-	.bmdma_status		= stm_bmdma_status,
 };
 
 static const struct ata_port_info stm_port_info = {
 	.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
-			  ATA_FLAG_MMIO | ATA_FLAG_SATA_RESET | ATA_FLAG_PMP,
+			  ATA_FLAG_MMIO | ATA_FLAG_SATA_RESET,
 	.pio_mask	= 0x1f, /* pio0-4 */
 	.mwdma_mask	= 0x07, /* mwdma0-2 */
 	.udma_mask	= ATA_UDMA6,
 	.port_ops	= &stm_ops,
 };
 
-static int stm_sata_AHB_boot(struct device *dev)
+static unsigned char stm_readb(const volatile void __iomem *addr)
 {
-	struct stm_plat_sata_data *sata_private_info = dev->platform_data;
-	struct ata_host *host = dev_get_drvdata(dev);
-	struct ata_port *ap = host->ports[0];
-	void __iomem *mmio_base = ap->ioaddr.cmd_addr;
-
-	/* AHB bus wrapper setup */
-
-	/* SATA_AHB2STBUS_STBUS_OPC
-	 * 2:0  -- 100 = Store64/Load64
-	 * 4    -- 1   = Enable write posting
-	 * DMA Read, write posting always = 0
-	 * opcode = Load4 |Store 4
-	 */
-	writel(3, mmio_base + SATA_AHB2STBUS_STBUS_OPC);
-
-	/* SATA_AHB2STBUS_MESSAGE_SIZE_CONFIG
-	 * 3:0  -- 0111 = 128 Packets
-	 * 3:0  -- 0110 =  64 Packets
-	 * WAS: Message size = 64 packet when 6 now 3
-	 */
-	writel(3, mmio_base + SATA_AHB2STBUS_MESSAGE_SIZE_CONFIG);
-
-	/* SATA_AHB2STBUS_CHUNK_SIZE_CONFIG
-	 * 3:0  -- 0110 = 64 Packets
-	 * 3:0  -- 0001 =  2 Packets
-	 * WAS Chunk size = 2 packet when 1, now 0
-	 */
-	writel(2, mmio_base + SATA_AHB2STBUS_CHUNK_SIZE_CONFIG);
-
-	/* PC_GLUE_LOGIC
-	 * 7:0  -- 0xFF = Set as reset value, 256 STBus Clock Cycles
-	 * 8    -- 1  = Time out enabled
-	 * (has bit 8 moved to bit 16 on 7109 cut2?)
-	 * time out count = 0xa0(160 dec)
-	 * time out enable = 1
-	 */
-	if (sata_private_info->pc_glue_logic_init)
-		writel(sata_private_info->pc_glue_logic_init,
-		       mmio_base + SATA_PC_GLUE_LOGIC);
-
-	/* DMA controller set up */
+	return readl(addr);
+}
 
-	/* Enable DMA controller */
-	writel(DMAC_DmaCfgReg_DMA_EN, mmio_base + DMAC_DmaCfgReg);
+static unsigned short stm_readw(const volatile void __iomem *addr)
+{
+	return readl(addr);
+}
 
-	/* Clear initial Serror */
-	writel(-1, mmio_base + SATA_SCR1);
+static void stm_writeb(unsigned char b, volatile void __iomem *addr)
+{
+	writel(b, addr);
+}
 
-	/* Finished hardware set up */
-	return 0;
+static void stm_writew(unsigned short b, volatile void __iomem *addr)
+{
+	writel(b, addr);
 }
 
 static int __devinit stm_sata_probe(struct platform_device *pdev)
@@ -1206,11 +1017,6 @@
 
         host->private_data = hpriv;
 
-	hpriv->device_state = devm_stm_device_init(dev,
-		sata_private_info->device_config);
-	if (!hpriv->device_state)
-		return -EBUSY;
-
 	mem_res = platform_get_resource(pdev,IORESOURCE_MEM,0);
 	phys_base = mem_res->start;
 	phys_size = mem_res->end - mem_res->start + 1;
@@ -1240,9 +1046,6 @@
 	ap->ioaddr.ctl_addr		= mmio_base + SATA_CLR0;
 
 	hpriv->phy_init = sata_private_info->phy_init;
-	hpriv->oob_wa = sata_private_info->oob_wa;
-	hpriv->host_restart = sata_private_info->host_restart;
-	hpriv->port_num = sata_private_info->port_num;
 	hpriv->softsg = readl(mmio_base + DMAC_COMP_PARAMS_2) &
 		DMAC_COMP_PARAMS_2_CH0_HC_LLP;
 	//hpriv->softsg = 1;
@@ -1251,9 +1054,11 @@
 	       hpriv->softsg ? "soft" : "hard");
 
 	if (sata_private_info->only_32bit) {
-		printk(KERN_ERR DRV_NAME " hardware doesn't support "
-			"byte/long ops, giving up\n");
-		return -EINVAL;
+		printk(KERN_DEBUG DRV_NAME " forcing all byte/word ops to long\n");
+		stm_ops.readb = stm_readb;
+		stm_ops.readw = stm_readw;
+		stm_ops.writeb = stm_writeb;
+		stm_ops.writew = stm_writew;
 	}
 
 	sata_rev = readl(mmio_base + SATA_VERSIONR);
@@ -1266,18 +1071,47 @@
 	       (int)(dmac_rev >> 16) & 0xff,
 	       (int)(dmac_rev >>  8) & 0xff);
 
-	hpriv->miphy_dev = stm_miphy_claim(sata_private_info->miphy_num,
-			SATA_MODE, dev);
-	if (!hpriv->miphy_dev) {
-		printk(KERN_ERR DRV_NAME " Unable to claim MiPHY %d\n",
-			sata_private_info->miphy_num);
-		return -EBUSY;
-	}
+	/* AHB bus wrapper setup */
 
-	stm_sata_AHB_boot(dev);
+        // SATA_AHB2STBUS_STBUS_OPC
+        // 2:0  -- 100 = Store64/Load64
+        // 4    -- 1   = Enable write posting
+	// DMA Read, write posting always = 0
+	/* opcode = Load4 |Store 4*/
+	writel(3, mmio_base + SATA_AHB2STBUS_STBUS_OPC);
+
+        // SATA_AHB2STBUS_MESSAGE_SIZE_CONFIG
+        // 3:0  -- 0111 = 128 Packets
+        // 3:0  -- 0110 =  64 Packets
+	/* WAS: Message size = 64 packet when 6 now 3*/
+	writel(3, mmio_base + SATA_AHB2STBUS_MESSAGE_SIZE_CONFIG);
+
+        // SATA_AHB2STBUS_CHUNK_SIZE_CONFIG
+        // 3:0  -- 0110 = 64 Packets
+        // 3:0  -- 0001 =  2 Packets
+	/* WAS Chunk size = 2 packet when 1, now 0 */
+	writel(2, mmio_base + SATA_AHB2STBUS_CHUNK_SIZE_CONFIG);
+
+        // PC_GLUE_LOGIC
+        // 7:0  -- 0xFF = Set as reset value, 256 STBus Clock Cycles
+        // 8    -- 1  = Time out enabled
+	// (has bit 8 moved to bit 16 on 7109 cut2?)
+	/* time out count = 0xa0(160 dec)
+	 * time out enable = 1
+	 */
+	if (sata_private_info->pc_glue_logic_init)
+		writel(sata_private_info->pc_glue_logic_init,
+		       mmio_base + SATA_PC_GLUE_LOGIC);
 
-	/* Wait & timeout till we detect the disk */
-	stm_sata_do_comreset(mmio_base, hpriv);
+	/* DMA controller set up */
+
+	/* Enable DMA controller */
+	writel(DMAC_DmaCfgReg_DMA_EN, mmio_base + DMAC_DmaCfgReg);
+
+	/* Clear initial Serror */
+	writel(-1, mmio_base + SATA_SCR1);
+
+	/* Finished hardware set up */
 
 	/* Now, are we on one of the later SATA IP's, we have the DMA and
 	 * host controller interrupt lines separated out. So if we have two
@@ -1302,12 +1136,6 @@
 
 	if (ret && dma_irq > 0)
 		devm_free_irq(host->dev, dma_irq, host);
-	else {
-		/* by default the device is on */
-		pm_runtime_set_active(&pdev->dev);
-		pm_suspend_ignore_children(&pdev->dev, 1);
-		pm_runtime_enable(&pdev->dev);
-	}
 
 	return ret;
 
@@ -1315,167 +1143,39 @@
 
 static int stm_sata_remove(struct platform_device *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(&pdev->dev);
-	struct stm_host_priv *hpriv = host->private_data;
-
-	stm_miphy_release(hpriv->miphy_dev);
-	stm_device_power(hpriv->device_state,  stm_device_power_off);
-
 	return 0;
 }
 
 #ifdef CONFIG_PM
-static int stm_sata_suspend(struct device *dev)
-{
-	struct ata_host *host = dev_get_drvdata(dev);
-	struct stm_host_priv *hpriv = host->private_data;
-
-#ifdef CONFIG_PM_RUNTIME
-	if (dev->power.runtime_status != RPM_ACTIVE)
-		return 0; /* sata already suspended via runtime_suspend */
-#endif
-
-	stm_device_power(hpriv->device_state,  stm_device_power_off);
-
-	return 0;
-}
-
-static int stm_sata_resume(struct device *dev)
-{
-	struct ata_host *host = dev_get_drvdata(dev);
-	struct stm_host_priv *hpriv = host->private_data;
-
-#ifdef CONFIG_PM_RUNTIME
-	if (dev->power.runtime_status == RPM_SUSPENDED)
-		return 0; /* sata wants resume via runtime_resume... */
-#endif
-
-	stm_device_power(hpriv->device_state, stm_device_power_on);
-
-	return 0;
-}
-
-static int stm_sata_freeze(struct device *dev)
-{
-	struct ata_host *host = dev_get_drvdata(dev);
-	struct stm_host_priv *hpriv = host->private_data;
-
-#ifdef CONFIG_PM_RUNTIME
-	if (dev->power.runtime_status != RPM_ACTIVE)
-		return 0; /* sata already suspended via runtime_suspend */
-#endif
-
-	stm_device_power(hpriv->device_state,  stm_device_power_off);
-	stm_miphy_freeze(hpriv->miphy_dev);
-
-	return 0;
-}
-
-static int stm_sata_restore(struct device *dev)
+static int stm_sata_suspend(struct platform_device *pdev, pm_message_t state)
 {
-	struct ata_host *host = dev_get_drvdata(dev);
-	struct stm_host_priv *hpriv = host->private_data;
-	struct ata_port *port;
-	struct Scsi_Host *scsi_host;
-	unsigned int nr_port, id, lun, channel;
-
-#ifdef CONFIG_PM_RUNTIME
-	if (dev->power.runtime_status == RPM_SUSPENDED)
-		return 0; /* sata wants resume via runtime_resume... */
-#endif
-
-	stm_device_power(hpriv->device_state, stm_device_power_on);
-
-	stm_sata_AHB_boot(dev);
-
-	for (nr_port = 0; nr_port < host->n_ports; ++nr_port) {
-		port = host->ports[nr_port];
-		scsi_host = port->scsi_host;
-
-		for (id = 0; id < scsi_host->max_id; ++id)
-			for (lun = 0; lun < scsi_host->max_lun; ++lun)
-				for (channel = 0;
-				     channel < scsi_host->max_channel;
-				     ++channel)
-					scsi_host->transportt->user_scan(
-						scsi_host, channel, id, lun);
-	}
+	if (state.event == PM_EVENT_SUSPEND) {
+		platform_pm_pwdn_req(pdev, HOST_PM, 1);
+		platform_pm_pwdn_ack(pdev, HOST_PM, 1);
+		}
 	return 0;
 }
 
-static int stm_sata_thaw(struct device *dev)
+static int stm_sata_resume(struct platform_device *pdev)
 {
-	struct ata_host *host = dev_get_drvdata(dev);
-	struct stm_host_priv *hpriv = host->private_data;
-
-	stm_miphy_thaw(hpriv->miphy_dev);
-	stm_device_power(hpriv->device_state, stm_device_power_on);
-
+	platform_pm_pwdn_req(pdev, HOST_PM, 0);
+	platform_pm_pwdn_ack(pdev, HOST_PM, 0);
 	return 0;
 }
-
-#ifdef CONFIG_PM_RUNTIME
-static int stm_sata_runtime_suspend(struct device *dev)
-{
-	struct ata_host *host = dev_get_drvdata(dev);
-	struct stm_host_priv *hpriv = host->private_data;
-	unsigned int nr_port;
-
-	if (dev->power.runtime_status == RPM_SUSPENDED) {
-		pr_debug("%s already suspended\n", dev_name(dev));
-		return 0;
-	}
-
-	for (nr_port = 0; nr_port < host->n_ports; ++nr_port) {
-		struct ata_port *port = host->ports[nr_port];
-		struct Scsi_Host *scsi_host = port->scsi_host;
-		struct scsi_device *sdev, *next_sdev;
-
-		list_for_each_entry_safe(sdev, next_sdev,
-			&scsi_host->__devices, siblings)
-			/* suspend all the child devices */
-			scsi_remove_device(sdev);
-	}
-
-	stm_device_power(hpriv->device_state,  stm_device_power_off);
-	return 0;
-}
-
-static int stm_sata_runtime_resume(struct device *dev)
-{
-	if (dev->power.runtime_status == RPM_ACTIVE) {
-		pr_debug("%s already active\n", dev_name(dev));
-		return 0;
-	}
-
-	return stm_sata_restore(dev);
-}
-#else
-#define stm_sata_runtime_suspend	NULL
-#define stm_sata_runtime_resume		NULL
-#endif
-
-static struct dev_pm_ops stm_sata_pm = {
-	.suspend = stm_sata_suspend,  /* on standby/memstandby */
-	.resume = stm_sata_resume,    /* resume from standby/memstandby */
-	.freeze = stm_sata_freeze,
-	.thaw = stm_sata_thaw,
-	.restore = stm_sata_restore,
-	.runtime_suspend = stm_sata_runtime_suspend,
-	.runtime_resume = stm_sata_runtime_resume,
-};
 #else
-static struct dev_pm_ops stm_sata_pm;
+#define stm_sata_suspend	NULL
+#define stm_sata_resume		NULL
 #endif
 
 static struct platform_driver stm_sata_driver = {
 	.driver = {
 		.name = DRV_NAME,
 		.owner = THIS_MODULE,
-		.pm = &stm_sata_pm,
 	},
 	.probe = stm_sata_probe,
 	.remove = stm_sata_remove,
+	.suspend = stm_sata_suspend,
+	.resume = stm_sata_resume,
 };
 
 static int __init stm_sata_init(void)
diff -Nur linux-sh4/drivers/ata.org/sata_svw.c linux-sh4/drivers/ata/sata_svw.c
--- linux-sh4/drivers/ata.org/sata_svw.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_svw.c	2012-01-15 06:30:15.000000000 -0800
@@ -45,8 +45,6 @@
 #include <linux/interrupt.h>
 #include <linux/device.h>
 #include <scsi/scsi_host.h>
-#include <scsi/scsi_cmnd.h>
-#include <scsi/scsi.h>
 #include <linux/libata.h>
 
 #ifdef CONFIG_PPC_OF
@@ -61,7 +59,6 @@
 	/* ap->flags bits */
 	K2_FLAG_SATA_8_PORTS		= (1 << 24),
 	K2_FLAG_NO_ATAPI_DMA		= (1 << 25),
-	K2_FLAG_BAR_POS_3			= (1 << 26),
 
 	/* Taskfile registers offsets */
 	K2_SATA_TF_CMD_OFFSET		= 0x00,
@@ -91,10 +88,8 @@
 	/* Port stride */
 	K2_SATA_PORT_OFFSET		= 0x100,
 
-	chip_svw4			= 0,
-	chip_svw8			= 1,
-	chip_svw42			= 2,	/* bar 3 */
-	chip_svw43			= 3,	/* bar 5 */
+	board_svw4			= 0,
+	board_svw8			= 1,
 };
 
 static u8 k2_stat_check_status(struct ata_port *ap);
@@ -102,43 +97,26 @@
 
 static int k2_sata_check_atapi_dma(struct ata_queued_cmd *qc)
 {
-	u8 cmnd = qc->scsicmd->cmnd[0];
-
 	if (qc->ap->flags & K2_FLAG_NO_ATAPI_DMA)
 		return -1;	/* ATAPI DMA not supported */
-	else {
-		switch (cmnd) {
-		case READ_10:
-		case READ_12:
-		case READ_16:
-		case WRITE_10:
-		case WRITE_12:
-		case WRITE_16:
-			return 0;
-
-		default:
-			return -1;
-		}
 
-	}
+	return 0;
 }
 
-static int k2_sata_scr_read(struct ata_link *link,
-			    unsigned int sc_reg, u32 *val)
+static int k2_sata_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	*val = readl(link->ap->ioaddr.scr_addr + (sc_reg * 4));
+	*val = readl(ap->ioaddr.scr_addr + (sc_reg * 4));
 	return 0;
 }
 
 
-static int k2_sata_scr_write(struct ata_link *link,
-			     unsigned int sc_reg, u32 val)
+static int k2_sata_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	writel(val, link->ap->ioaddr.scr_addr + (sc_reg * 4));
+	writel(val, ap->ioaddr.scr_addr + (sc_reg * 4));
 	return 0;
 }
 
@@ -204,7 +182,7 @@
 		tf->hob_lbal = lbal >> 8;
 		tf->hob_lbam = lbam >> 8;
 		tf->hob_lbah = lbah >> 8;
-	}
+        }
 }
 
 /**
@@ -215,7 +193,7 @@
  *	spin_lock_irqsave(host lock)
  */
 
-static void k2_bmdma_setup_mmio(struct ata_queued_cmd *qc)
+static void k2_bmdma_setup_mmio (struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	unsigned int rw = (qc->tf.flags & ATA_TFLAG_WRITE);
@@ -235,7 +213,7 @@
 
 	/* issue r/w command if this is not a ATA DMA command*/
 	if (qc->tf.protocol != ATA_PROT_DMA)
-		ap->ops->sff_exec_command(ap, &qc->tf);
+		ap->ops->exec_command(ap, &qc->tf);
 }
 
 /**
@@ -246,7 +224,7 @@
  *	spin_lock_irqsave(host lock)
  */
 
-static void k2_bmdma_start_mmio(struct ata_queued_cmd *qc)
+static void k2_bmdma_start_mmio (struct ata_queued_cmd *qc)
 {
 	struct ata_port *ap = qc->ap;
 	void __iomem *mmio = ap->ioaddr.bmdma_addr;
@@ -255,37 +233,29 @@
 	/* start host DMA transaction */
 	dmactl = readb(mmio + ATA_DMA_CMD);
 	writeb(dmactl | ATA_DMA_START, mmio + ATA_DMA_CMD);
-	/* This works around possible data corruption.
-
-	   On certain SATA controllers that can be seen when the r/w
-	   command is given to the controller before the host DMA is
-	   started.
-
-	   On a Read command, the controller would initiate the
-	   command to the drive even before it sees the DMA
-	   start. When there are very fast drives connected to the
-	   controller, or when the data request hits in the drive
-	   cache, there is the possibility that the drive returns a
-	   part or all of the requested data to the controller before
-	   the DMA start is issued.  In this case, the controller
-	   would become confused as to what to do with the data.  In
-	   the worst case when all the data is returned back to the
-	   controller, the controller could hang. In other cases it
-	   could return partial data returning in data
-	   corruption. This problem has been seen in PPC systems and
-	   can also appear on an system with very fast disks, where
-	   the SATA controller is sitting behind a number of bridges,
-	   and hence there is significant latency between the r/w
-	   command and the start command. */
-	/* issue r/w command if the access is to ATA */
+	/* There is a race condition in certain SATA controllers that can
+	   be seen when the r/w command is given to the controller before the
+	   host DMA is started. On a Read command, the controller would initiate
+	   the command to the drive even before it sees the DMA start. When there
+	   are very fast drives connected to the controller, or when the data request
+	   hits in the drive cache, there is the possibility that the drive returns a part
+	   or all of the requested data to the controller before the DMA start is issued.
+	   In this case, the controller would become confused as to what to do with the data.
+	   In the worst case when all the data is returned back to the controller, the
+	   controller could hang. In other cases it could return partial data returning
+	   in data corruption. This problem has been seen in PPC systems and can also appear
+	   on an system with very fast disks, where the SATA controller is sitting behind a
+	   number of bridges, and hence there is significant latency between the r/w command
+	   and the start command. */
+	/* issue r/w command if the access is to ATA*/
 	if (qc->tf.protocol == ATA_PROT_DMA)
-		ap->ops->sff_exec_command(ap, &qc->tf);
+		ap->ops->exec_command(ap, &qc->tf);
 }
 
 
 static u8 k2_stat_check_status(struct ata_port *ap)
 {
-	return readl(ap->ioaddr.status_addr);
+       	return readl(ap->ioaddr.status_addr);
 }
 
 #ifdef CONFIG_PPC_OF
@@ -337,60 +307,71 @@
 
 
 static struct scsi_host_template k2_sata_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
 #ifdef CONFIG_PPC_OF
 	.proc_info		= k2_sata_proc_info,
 #endif
+	.bios_param		= ata_std_bios_param,
 };
 
 
-static struct ata_port_operations k2_sata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.sff_tf_load		= k2_sata_tf_load,
-	.sff_tf_read		= k2_sata_tf_read,
-	.sff_check_status	= k2_stat_check_status,
+static const struct ata_port_operations k2_sata_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= k2_sata_tf_load,
+	.tf_read		= k2_sata_tf_read,
+	.check_status		= k2_stat_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
 	.check_atapi_dma	= k2_sata_check_atapi_dma,
 	.bmdma_setup		= k2_bmdma_setup_mmio,
 	.bmdma_start		= k2_bmdma_start_mmio,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 	.scr_read		= k2_sata_scr_read,
 	.scr_write		= k2_sata_scr_write,
+	.port_start		= ata_port_start,
 };
 
 static const struct ata_port_info k2_port_info[] = {
-	/* chip_svw4 */
+	/* board_svw4 */
 	{
 		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
 				  ATA_FLAG_MMIO | K2_FLAG_NO_ATAPI_DMA,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,
+		.mwdma_mask	= 0x07,
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &k2_sata_ops,
 	},
-	/* chip_svw8 */
+	/* board_svw8 */
 	{
 		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
 				  ATA_FLAG_MMIO | K2_FLAG_NO_ATAPI_DMA |
 				  K2_FLAG_SATA_8_PORTS,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &k2_sata_ops,
-	},
-	/* chip_svw42 */
-	{
-		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
-				  ATA_FLAG_MMIO | K2_FLAG_BAR_POS_3,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
-		.udma_mask	= ATA_UDMA6,
-		.port_ops	= &k2_sata_ops,
-	},
-	/* chip_svw43 */
-	{
-		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
-				  ATA_FLAG_MMIO,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,
+		.mwdma_mask	= 0x07,
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &k2_sata_ops,
 	},
@@ -416,14 +397,14 @@
 }
 
 
-static int k2_sata_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
+static int k2_sata_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
 	const struct ata_port_info *ppi[] =
 		{ &k2_port_info[ent->driver_data], NULL };
 	struct ata_host *host;
 	void __iomem *mmio_base;
-	int n_ports, i, rc, bar_pos;
+	int n_ports, i, rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
@@ -437,9 +418,6 @@
 	if (!host)
 		return -ENOMEM;
 
-	bar_pos = 5;
-	if (ppi[0]->flags & K2_FLAG_BAR_POS_3)
-		bar_pos = 3;
 	/*
 	 * If this driver happens to only be useful on Apple's K2, then
 	 * we should check that here as it has a normal Serverworks ID
@@ -452,36 +430,24 @@
 	 * Check if we have resources mapped at all (second function may
 	 * have been disabled by firmware)
 	 */
-	if (pci_resource_len(pdev, bar_pos) == 0) {
-		/* In IDE mode we need to pin the device to ensure that
-			pcim_release does not clear the busmaster bit in config
-			space, clearing causes busmaster DMA to fail on
-			ports 3 & 4 */
-		pcim_pin_device(pdev);
+	if (pci_resource_len(pdev, 5) == 0)
 		return -ENODEV;
-	}
 
 	/* Request and iomap PCI regions */
-	rc = pcim_iomap_regions(pdev, 1 << bar_pos, DRV_NAME);
+	rc = pcim_iomap_regions(pdev, 1 << 5, DRV_NAME);
 	if (rc == -EBUSY)
 		pcim_pin_device(pdev);
 	if (rc)
 		return rc;
 	host->iomap = pcim_iomap_table(pdev);
-	mmio_base = host->iomap[bar_pos];
+	mmio_base = host->iomap[5];
 
 	/* different controllers have different number of ports - currently 4 or 8 */
 	/* All ports are on the same function. Multi-function device is no
 	 * longer available. This should not be seen in any system. */
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		unsigned int offset = i * K2_SATA_PORT_OFFSET;
-
-		k2_sata_setup_port(&ap->ioaddr, mmio_base + offset);
-
-		ata_port_pbar_desc(ap, 5, -1, "mmio");
-		ata_port_pbar_desc(ap, 5, offset, "port");
-	}
+	for (i = 0; i < host->n_ports; i++)
+		k2_sata_setup_port(&host->ports[i]->ioaddr,
+				   mmio_base + i * K2_SATA_PORT_OFFSET);
 
 	rc = pci_set_dma_mask(pdev, ATA_DMA_MASK);
 	if (rc)
@@ -502,8 +468,8 @@
 	writel(0x0, mmio_base + K2_SATA_SIM_OFFSET);
 
 	pci_set_master(pdev);
-	return ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &k2_sata_sht);
+	return ata_host_activate(host, pdev->irq, ata_interrupt, IRQF_SHARED,
+				 &k2_sata_sht);
 }
 
 /* 0x240 is device ID for Apple K2 device
@@ -513,13 +479,11 @@
  * controller
  * */
 static const struct pci_device_id k2_sata_pci_tbl[] = {
-	{ PCI_VDEVICE(SERVERWORKS, 0x0240), chip_svw4 },
-	{ PCI_VDEVICE(SERVERWORKS, 0x0241), chip_svw8 },
-	{ PCI_VDEVICE(SERVERWORKS, 0x0242), chip_svw4 },
-	{ PCI_VDEVICE(SERVERWORKS, 0x024a), chip_svw4 },
-	{ PCI_VDEVICE(SERVERWORKS, 0x024b), chip_svw4 },
-	{ PCI_VDEVICE(SERVERWORKS, 0x0410), chip_svw42 },
-	{ PCI_VDEVICE(SERVERWORKS, 0x0411), chip_svw43 },
+	{ PCI_VDEVICE(SERVERWORKS, 0x0240), board_svw4 },
+	{ PCI_VDEVICE(SERVERWORKS, 0x0241), board_svw4 },
+	{ PCI_VDEVICE(SERVERWORKS, 0x0242), board_svw8 },
+	{ PCI_VDEVICE(SERVERWORKS, 0x024a), board_svw4 },
+	{ PCI_VDEVICE(SERVERWORKS, 0x024b), board_svw4 },
 
 	{ }
 };
diff -Nur linux-sh4/drivers/ata.org/sata_sx4.c linux-sh4/drivers/ata/sata_sx4.c
--- linux-sh4/drivers/ata.org/sata_sx4.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_sx4.c	2012-01-15 06:30:15.000000000 -0800
@@ -62,13 +62,13 @@
 		submit ATA packet to hardware
 		hardware executes ATA WRITE command, w/ data in DIMM
 		hardware raises interrupt
-
+	
 	and each READ looks like this:
 
 		submit ATA packet to hardware
 		hardware executes ATA READ command, w/ data in DIMM
 		hardware raises interrupt
-
+	
 		submit HDMA packet to hardware
 		hardware copies data from DIMM to system memory
 		hardware raises interrupt
@@ -193,7 +193,6 @@
 					  PDC_TIMER_MASK_INT,
 };
 
-#define ECC_ERASE_BUF_SZ (128 * 1024)
 
 struct pdc_port_priv {
 	u8			dimm_buf[(ATA_PRD_SZ * ATA_MAX_PRD) + 512];
@@ -213,10 +212,9 @@
 };
 
 
-static int pdc_sata_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
-static void pdc_error_handler(struct ata_port *ap);
-static void pdc_freeze(struct ata_port *ap);
-static void pdc_thaw(struct ata_port *ap);
+static int pdc_sata_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
+static void pdc_eng_timeout(struct ata_port *ap);
+static void pdc_20621_phy_reset (struct ata_port *ap);
 static int pdc_port_start(struct ata_port *ap);
 static void pdc20621_qc_prep(struct ata_queued_cmd *qc);
 static void pdc_tf_load_mmio(struct ata_port *ap, const struct ata_taskfile *tf);
@@ -234,39 +232,43 @@
 static void pdc20621_put_to_dimm(struct ata_host *host,
 				 void *psource, u32 offset, u32 size);
 static void pdc20621_irq_clear(struct ata_port *ap);
-static unsigned int pdc20621_qc_issue(struct ata_queued_cmd *qc);
-static int pdc_softreset(struct ata_link *link, unsigned int *class,
-			 unsigned long deadline);
-static void pdc_post_internal_cmd(struct ata_queued_cmd *qc);
-static int pdc_check_atapi_dma(struct ata_queued_cmd *qc);
+static unsigned int pdc20621_qc_issue_prot(struct ata_queued_cmd *qc);
 
 
 static struct scsi_host_template pdc_sata_sht = {
-	ATA_BASE_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
 	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
 	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
-/* TODO: inherit from base port_ops after converting to new EH */
-static struct ata_port_operations pdc_20621_ops = {
-	.inherits		= &ata_sff_port_ops,
-
-	.check_atapi_dma	= pdc_check_atapi_dma,
+static const struct ata_port_operations pdc_20621_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= pdc_tf_load_mmio,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= pdc_exec_command_mmio,
+	.dev_select		= ata_std_dev_select,
+	.phy_reset		= pdc_20621_phy_reset,
 	.qc_prep		= pdc20621_qc_prep,
-	.qc_issue		= pdc20621_qc_issue,
-
-	.freeze			= pdc_freeze,
-	.thaw			= pdc_thaw,
-	.softreset		= pdc_softreset,
-	.error_handler		= pdc_error_handler,
-	.lost_interrupt		= ATA_OP_NULL,
-	.post_internal_cmd	= pdc_post_internal_cmd,
-
+	.qc_issue		= pdc20621_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+	.eng_timeout		= pdc_eng_timeout,
+	.irq_clear		= pdc20621_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 	.port_start		= pdc_port_start,
-
-	.sff_tf_load		= pdc_tf_load_mmio,
-	.sff_exec_command	= pdc_exec_command_mmio,
-	.sff_irq_clear		= pdc20621_irq_clear,
 };
 
 static const struct ata_port_info pdc_port_info[] = {
@@ -275,8 +277,8 @@
 		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
 				  ATA_FLAG_SRST | ATA_FLAG_MMIO |
 				  ATA_FLAG_NO_ATAPI | ATA_FLAG_PIO_POLLING,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f, /* pio0-4 */
+		.mwdma_mask	= 0x07, /* mwdma0-2 */
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &pdc_20621_ops,
 	},
@@ -320,13 +322,21 @@
 	return 0;
 }
 
+static void pdc_20621_phy_reset (struct ata_port *ap)
+{
+	VPRINTK("ENTER\n");
+        ap->cbl = ATA_CBL_SATA;
+        ata_port_probe(ap);
+        ata_bus_reset(ap);
+}
+
 static inline void pdc20621_ata_sg(struct ata_taskfile *tf, u8 *buf,
-				   unsigned int portno,
+				    	   unsigned int portno,
 					   unsigned int total_len)
 {
 	u32 addr;
 	unsigned int dw = PDC_DIMM_APKT_PRD >> 2;
-	__le32 *buf32 = (__le32 *) buf;
+	u32 *buf32 = (u32 *) buf;
 
 	/* output ATA packet S/G table */
 	addr = PDC_20621_DIMM_BASE + PDC_20621_DIMM_DATA +
@@ -343,12 +353,12 @@
 }
 
 static inline void pdc20621_host_sg(struct ata_taskfile *tf, u8 *buf,
-				    unsigned int portno,
+				    	    unsigned int portno,
 					    unsigned int total_len)
 {
 	u32 addr;
 	unsigned int dw = PDC_DIMM_HPKT_PRD >> 2;
-	__le32 *buf32 = (__le32 *) buf;
+	u32 *buf32 = (u32 *) buf;
 
 	/* output Host DMA packet S/G table */
 	addr = PDC_20621_DIMM_BASE + PDC_20621_DIMM_DATA +
@@ -369,7 +379,7 @@
 					    unsigned int portno)
 {
 	unsigned int i, dw;
-	__le32 *buf32 = (__le32 *) buf;
+	u32 *buf32 = (u32 *) buf;
 	u8 dev_reg;
 
 	unsigned int dimm_sg = PDC_20621_DIMM_BASE +
@@ -421,8 +431,7 @@
 				     unsigned int portno)
 {
 	unsigned int dw;
-	u32 tmp;
-	__le32 *buf32 = (__le32 *) buf;
+	u32 tmp, *buf32 = (u32 *) buf;
 
 	unsigned int host_sg = PDC_20621_DIMM_BASE +
 			       (PDC_DIMM_WINDOW_STEP * portno) +
@@ -466,8 +475,8 @@
 	void __iomem *mmio = ap->host->iomap[PDC_MMIO_BAR];
 	void __iomem *dimm_mmio = ap->host->iomap[PDC_DIMM_BAR];
 	unsigned int portno = ap->port_no;
-	unsigned int i, si, idx, total_len = 0, sgt_len;
-	__le32 *buf = (__le32 *) &pp->dimm_buf[PDC_DIMM_HEADER_SZ];
+	unsigned int i, idx, total_len = 0, sgt_len;
+	u32 *buf = (u32 *) &pp->dimm_buf[PDC_DIMM_HEADER_SZ];
 
 	WARN_ON(!(qc->flags & ATA_QCFLAG_DMAMAP));
 
@@ -480,7 +489,7 @@
 	 * Build S/G table
 	 */
 	idx = 0;
-	for_each_sg(qc->sg, sg, qc->n_elem, si) {
+	ata_for_each_sg(sg, qc) {
 		buf[idx++] = cpu_to_le32(sg_dma_address(sg));
 		buf[idx++] = cpu_to_le32(sg_dma_len(sg));
 		total_len += sg_dma_len(sg);
@@ -685,18 +694,15 @@
 	}
 }
 
-static unsigned int pdc20621_qc_issue(struct ata_queued_cmd *qc)
+static unsigned int pdc20621_qc_issue_prot(struct ata_queued_cmd *qc)
 {
 	switch (qc->tf.protocol) {
-	case ATA_PROT_NODATA:
-		if (qc->tf.flags & ATA_TFLAG_POLLING)
-			break;
-		/*FALLTHROUGH*/
 	case ATA_PROT_DMA:
+	case ATA_PROT_NODATA:
 		pdc20621_packet_start(qc);
 		return 0;
 
-	case ATAPI_PROT_DMA:
+	case ATA_PROT_ATAPI_DMA:
 		BUG();
 		break;
 
@@ -704,11 +710,11 @@
 		break;
 	}
 
-	return ata_sff_qc_issue(qc);
+	return ata_qc_issue_prot(qc);
 }
 
-static inline unsigned int pdc20621_host_intr(struct ata_port *ap,
-					  struct ata_queued_cmd *qc,
+static inline unsigned int pdc20621_host_intr( struct ata_port *ap,
+                                          struct ata_queued_cmd *qc,
 					  unsigned int doing_hdma,
 					  void __iomem *mmio)
 {
@@ -776,7 +782,7 @@
 	/* command completion, but no data xfer */
 	} else if (qc->tf.protocol == ATA_PROT_NODATA) {
 
-		status = ata_sff_busy_wait(ap, ATA_BUSY | ATA_DRQ, 1000);
+		status = ata_busy_wait(ap, ATA_BUSY | ATA_DRQ, 1000);
 		DPRINTK("BUS_NODATA (drv_stat 0x%X)\n", status);
 		qc->err_mask |= ac_err_mask(status);
 		ata_qc_complete(qc);
@@ -791,10 +797,15 @@
 
 static void pdc20621_irq_clear(struct ata_port *ap)
 {
-	ioread8(ap->ioaddr.status_addr);
+	struct ata_host *host = ap->host;
+	void __iomem *mmio = host->iomap[PDC_MMIO_BAR];
+
+	mmio += PDC_CHIP0_OFS;
+
+	readl(mmio + PDC_20621_SEQMASK);
 }
 
-static irqreturn_t pdc20621_interrupt(int irq, void *dev_instance)
+static irqreturn_t pdc20621_interrupt (int irq, void *dev_instance)
 {
 	struct ata_host *host = dev_instance;
 	struct ata_port *ap;
@@ -827,9 +838,9 @@
 		return IRQ_NONE;
 	}
 
-	spin_lock(&host->lock);
+        spin_lock(&host->lock);
 
-	for (i = 1; i < 9; i++) {
+        for (i = 1; i < 9; i++) {
 		port_no = i - 1;
 		if (port_no > 3)
 			port_no -= 4;
@@ -843,14 +854,14 @@
 		    !(ap->flags & ATA_FLAG_DISABLED)) {
 			struct ata_queued_cmd *qc;
 
-			qc = ata_qc_from_tag(ap, ap->link.active_tag);
+			qc = ata_qc_from_tag(ap, ap->active_tag);
 			if (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)))
 				handled += pdc20621_host_intr(ap, qc, (i > 4),
 							      mmio_base);
 		}
 	}
 
-	spin_unlock(&host->lock);
+        spin_unlock(&host->lock);
 
 	VPRINTK("mask == 0x%x\n", mask);
 
@@ -859,128 +870,55 @@
 	return IRQ_RETVAL(handled);
 }
 
-static void pdc_freeze(struct ata_port *ap)
+static void pdc_eng_timeout(struct ata_port *ap)
 {
-	void __iomem *mmio = ap->ioaddr.cmd_addr;
-	u32 tmp;
-
-	/* FIXME: if all 4 ATA engines are stopped, also stop HDMA engine */
-
-	tmp = readl(mmio + PDC_CTLSTAT);
-	tmp |= PDC_MASK_INT;
-	tmp &= ~PDC_DMA_ENABLE;
-	writel(tmp, mmio + PDC_CTLSTAT);
-	readl(mmio + PDC_CTLSTAT); /* flush */
-}
-
-static void pdc_thaw(struct ata_port *ap)
-{
-	void __iomem *mmio = ap->ioaddr.cmd_addr;
-	u32 tmp;
+	u8 drv_stat;
+	struct ata_host *host = ap->host;
+	struct ata_queued_cmd *qc;
+	unsigned long flags;
 
-	/* FIXME: start HDMA engine, if zero ATA engines running */
+	DPRINTK("ENTER\n");
 
-	/* clear IRQ */
-	ioread8(ap->ioaddr.status_addr);
+	spin_lock_irqsave(&host->lock, flags);
 
-	/* turn IRQ back on */
-	tmp = readl(mmio + PDC_CTLSTAT);
-	tmp &= ~PDC_MASK_INT;
-	writel(tmp, mmio + PDC_CTLSTAT);
-	readl(mmio + PDC_CTLSTAT); /* flush */
-}
+	qc = ata_qc_from_tag(ap, ap->active_tag);
 
-static void pdc_reset_port(struct ata_port *ap)
-{
-	void __iomem *mmio = ap->ioaddr.cmd_addr + PDC_CTLSTAT;
-	unsigned int i;
-	u32 tmp;
-
-	/* FIXME: handle HDMA copy engine */
+	switch (qc->tf.protocol) {
+	case ATA_PROT_DMA:
+	case ATA_PROT_NODATA:
+		ata_port_printk(ap, KERN_ERR, "command timeout\n");
+		qc->err_mask |= __ac_err_mask(ata_wait_idle(ap));
+		break;
 
-	for (i = 11; i > 0; i--) {
-		tmp = readl(mmio);
-		if (tmp & PDC_RESET)
-			break;
+	default:
+		drv_stat = ata_busy_wait(ap, ATA_BUSY | ATA_DRQ, 1000);
 
-		udelay(100);
+		ata_port_printk(ap, KERN_ERR,
+				"unknown timeout, cmd 0x%x stat 0x%x\n",
+				qc->tf.command, drv_stat);
 
-		tmp |= PDC_RESET;
-		writel(tmp, mmio);
+		qc->err_mask |= ac_err_mask(drv_stat);
+		break;
 	}
 
-	tmp &= ~PDC_RESET;
-	writel(tmp, mmio);
-	readl(mmio);	/* flush */
-}
-
-static int pdc_softreset(struct ata_link *link, unsigned int *class,
-			 unsigned long deadline)
-{
-	pdc_reset_port(link->ap);
-	return ata_sff_softreset(link, class, deadline);
-}
-
-static void pdc_error_handler(struct ata_port *ap)
-{
-	if (!(ap->pflags & ATA_PFLAG_FROZEN))
-		pdc_reset_port(ap);
-
-	ata_std_error_handler(ap);
-}
-
-static void pdc_post_internal_cmd(struct ata_queued_cmd *qc)
-{
-	struct ata_port *ap = qc->ap;
-
-	/* make DMA engine forget about the failed command */
-	if (qc->flags & ATA_QCFLAG_FAILED)
-		pdc_reset_port(ap);
-}
-
-static int pdc_check_atapi_dma(struct ata_queued_cmd *qc)
-{
-	u8 *scsicmd = qc->scsicmd->cmnd;
-	int pio = 1; /* atapi dma off by default */
-
-	/* Whitelist commands that may use DMA. */
-	switch (scsicmd[0]) {
-	case WRITE_12:
-	case WRITE_10:
-	case WRITE_6:
-	case READ_12:
-	case READ_10:
-	case READ_6:
-	case 0xad: /* READ_DVD_STRUCTURE */
-	case 0xbe: /* READ_CD */
-		pio = 0;
-	}
-	/* -45150 (FFFF4FA2) to -1 (FFFFFFFF) shall use PIO mode */
-	if (scsicmd[0] == WRITE_10) {
-		unsigned int lba =
-			(scsicmd[2] << 24) |
-			(scsicmd[3] << 16) |
-			(scsicmd[4] << 8) |
-			scsicmd[5];
-		if (lba >= 0xFFFF4FA2)
-			pio = 1;
-	}
-	return pio;
+	spin_unlock_irqrestore(&host->lock, flags);
+	ata_eh_qc_complete(qc);
+	DPRINTK("EXIT\n");
 }
 
 static void pdc_tf_load_mmio(struct ata_port *ap, const struct ata_taskfile *tf)
 {
-	WARN_ON(tf->protocol == ATA_PROT_DMA ||
-		tf->protocol == ATAPI_PROT_DMA);
-	ata_sff_tf_load(ap, tf);
+	WARN_ON (tf->protocol == ATA_PROT_DMA ||
+		 tf->protocol == ATA_PROT_NODATA);
+	ata_tf_load(ap, tf);
 }
 
 
 static void pdc_exec_command_mmio(struct ata_port *ap, const struct ata_taskfile *tf)
 {
-	WARN_ON(tf->protocol == ATA_PROT_DMA ||
-		tf->protocol == ATAPI_PROT_DMA);
-	ata_sff_exec_command(ap, tf);
+	WARN_ON (tf->protocol == ATA_PROT_DMA ||
+		 tf->protocol == ATA_PROT_NODATA);
+	ata_exec_command(ap, tf);
 }
 
 
@@ -1017,7 +955,7 @@
 	mmio += PDC_CHIP0_OFS;
 
 	page_mask = 0x00;
-	window_size = 0x2000 * 4; /* 32K byte uchar size */
+   	window_size = 0x2000 * 4; /* 32K byte uchar size */
 	idx = (u16) (offset / window_size);
 
 	writel(0x01, mmio + PDC_GENERAL_CTLR);
@@ -1043,7 +981,7 @@
 			      window_size / 4);
 		psource += window_size;
 		size -= window_size;
-		idx++;
+		idx ++;
 	}
 
 	if (size) {
@@ -1072,7 +1010,7 @@
 	mmio += PDC_CHIP0_OFS;
 
 	page_mask = 0x00;
-	window_size = 0x2000 * 4;       /* 32K byte uchar size */
+   	window_size = 0x2000 * 4;       /* 32K byte uchar size */
 	idx = (u16) (offset / window_size);
 
 	writel(((idx) << page_mask), mmio + PDC_DIMM_WINDOW_CTLR);
@@ -1095,7 +1033,7 @@
 		readl(mmio + PDC_GENERAL_CTLR);
 		psource += window_size;
 		size -= window_size;
-		idx++;
+		idx ++;
 	}
 
 	if (size) {
@@ -1114,7 +1052,7 @@
 	void __iomem *mmio = host->iomap[PDC_MMIO_BAR];
 	u32 i2creg  = 0;
 	u32 status;
-	u32 count = 0;
+	u32 count =0;
 
 	/* hard-code chip #0 */
 	mmio += PDC_CHIP0_OFS;
@@ -1146,21 +1084,21 @@
 
 static int pdc20621_detect_dimm(struct ata_host *host)
 {
-	u32 data = 0;
+	u32 data=0 ;
 	if (pdc20621_i2c_read(host, PDC_DIMM0_SPD_DEV_ADDRESS,
 			     PDC_DIMM_SPD_SYSTEM_FREQ, &data)) {
-		if (data == 100)
+   		if (data == 100)
 			return 100;
-	} else
+  	} else
 		return 0;
 
 	if (pdc20621_i2c_read(host, PDC_DIMM0_SPD_DEV_ADDRESS, 9, &data)) {
-		if (data <= 0x75)
+		if(data <= 0x75)
 			return 133;
-	} else
+   	} else
 		return 0;
 
-	return 0;
+   	return 0;
 }
 
 
@@ -1168,8 +1106,8 @@
 {
 	u32 spd0[50];
 	u32 data = 0;
-	int size, i;
-	u8 bdimmsize;
+   	int size, i;
+   	u8 bdimmsize;
 	void __iomem *mmio = host->iomap[PDC_MMIO_BAR];
 	static const struct {
 		unsigned int reg;
@@ -1192,40 +1130,40 @@
 	/* hard-code chip #0 */
 	mmio += PDC_CHIP0_OFS;
 
-	for (i = 0; i < ARRAY_SIZE(pdc_i2c_read_data); i++)
+	for(i=0; i<ARRAY_SIZE(pdc_i2c_read_data); i++)
 		pdc20621_i2c_read(host, PDC_DIMM0_SPD_DEV_ADDRESS,
 				  pdc_i2c_read_data[i].reg,
 				  &spd0[pdc_i2c_read_data[i].ofs]);
 
-	data |= (spd0[4] - 8) | ((spd0[21] != 0) << 3) | ((spd0[3]-11) << 4);
-	data |= ((spd0[17] / 4) << 6) | ((spd0[5] / 2) << 7) |
+   	data |= (spd0[4] - 8) | ((spd0[21] != 0) << 3) | ((spd0[3]-11) << 4);
+   	data |= ((spd0[17] / 4) << 6) | ((spd0[5] / 2) << 7) |
 		((((spd0[27] + 9) / 10) - 1) << 8) ;
-	data |= (((((spd0[29] > spd0[28])
+   	data |= (((((spd0[29] > spd0[28])
 		    ? spd0[29] : spd0[28]) + 9) / 10) - 1) << 10;
-	data |= ((spd0[30] - spd0[29] + 9) / 10 - 2) << 12;
+   	data |= ((spd0[30] - spd0[29] + 9) / 10 - 2) << 12;
 
-	if (spd0[18] & 0x08)
+   	if (spd0[18] & 0x08)
 		data |= ((0x03) << 14);
-	else if (spd0[18] & 0x04)
+   	else if (spd0[18] & 0x04)
 		data |= ((0x02) << 14);
-	else if (spd0[18] & 0x01)
+   	else if (spd0[18] & 0x01)
 		data |= ((0x01) << 14);
-	else
+   	else
 		data |= (0 << 14);
 
-	/*
+  	/*
 	   Calculate the size of bDIMMSize (power of 2) and
 	   merge the DIMM size by program start/end address.
 	*/
 
-	bdimmsize = spd0[4] + (spd0[5] / 2) + spd0[3] + (spd0[17] / 2) + 3;
-	size = (1 << bdimmsize) >> 20;	/* size = xxx(MB) */
-	data |= (((size / 16) - 1) << 16);
-	data |= (0 << 23);
+   	bdimmsize = spd0[4] + (spd0[5] / 2) + spd0[3] + (spd0[17] / 2) + 3;
+   	size = (1 << bdimmsize) >> 20;	/* size = xxx(MB) */
+   	data |= (((size / 16) - 1) << 16);
+   	data |= (0 << 23);
 	data |= 8;
-	writel(data, mmio + PDC_DIMM0_CONTROL);
+   	writel(data, mmio + PDC_DIMM0_CONTROL);
 	readl(mmio + PDC_DIMM0_CONTROL);
-	return size;
+   	return size;
 }
 
 
@@ -1236,9 +1174,9 @@
 	void __iomem *mmio = host->iomap[PDC_MMIO_BAR];
 
 	/* hard-code chip #0 */
-	mmio += PDC_CHIP0_OFS;
+   	mmio += PDC_CHIP0_OFS;
 
-	/*
+   	/*
 	  Set To Default : DIMM Module Global Control Register (0x022259F1)
 	  DIMM Arbitration Disable (bit 20)
 	  DIMM Data/Control Output Driving Selection (bit12 - bit15)
@@ -1257,39 +1195,40 @@
 		writel(data, mmio + PDC_SDRAM_CONTROL);
 		readl(mmio + PDC_SDRAM_CONTROL);
 		printk(KERN_ERR "Local DIMM ECC Enabled\n");
-	}
+   	}
 
-	/* DIMM Initialization Select/Enable (bit 18/19) */
-	data &= (~(1<<18));
-	data |= (1<<19);
-	writel(data, mmio + PDC_SDRAM_CONTROL);
+   	/* DIMM Initialization Select/Enable (bit 18/19) */
+   	data &= (~(1<<18));
+   	data |= (1<<19);
+   	writel(data, mmio + PDC_SDRAM_CONTROL);
 
-	error = 1;
-	for (i = 1; i <= 10; i++) {   /* polling ~5 secs */
+   	error = 1;
+   	for (i = 1; i <= 10; i++) {   /* polling ~5 secs */
 		data = readl(mmio + PDC_SDRAM_CONTROL);
 		if (!(data & (1<<19))) {
-			error = 0;
-			break;
+	   		error = 0;
+	   		break;
 		}
 		msleep(i*100);
-	}
-	return error;
+   	}
+   	return error;
 }
 
 
 static unsigned int pdc20621_dimm_init(struct ata_host *host)
 {
 	int speed, size, length;
-	u32 addr, spd0, pci_status;
-	u32 time_period = 0;
-	u32 tcount = 0;
-	u32 ticks = 0;
-	u32 clock = 0;
-	u32 fparam = 0;
+	u32 addr,spd0,pci_status;
+	u32 tmp=0;
+	u32 time_period=0;
+	u32 tcount=0;
+	u32 ticks=0;
+	u32 clock=0;
+	u32 fparam=0;
 	void __iomem *mmio = host->iomap[PDC_MMIO_BAR];
 
 	/* hard-code chip #0 */
-	mmio += PDC_CHIP0_OFS;
+   	mmio += PDC_CHIP0_OFS;
 
 	/* Initialize PLL based upon PCI Bus Frequency */
 
@@ -1317,7 +1256,7 @@
 	   If SX4 is on PCI-X bus, after 3 seconds, the timer counter
 	   register should be >= (0xffffffff - 3x10^8).
 	*/
-	if (tcount >= PCI_X_TCOUNT) {
+	if(tcount >= PCI_X_TCOUNT) {
 		ticks = (time_period - tcount);
 		VPRINTK("Num counters 0x%x (%d)\n", ticks, ticks);
 
@@ -1348,43 +1287,41 @@
 	if (!(speed = pdc20621_detect_dimm(host))) {
 		printk(KERN_ERR "Detect Local DIMM Fail\n");
 		return 1;	/* DIMM error */
-	}
-	VPRINTK("Local DIMM Speed = %d\n", speed);
+   	}
+   	VPRINTK("Local DIMM Speed = %d\n", speed);
 
-	/* Programming DIMM0 Module Control Register (index_CID0:80h) */
+   	/* Programming DIMM0 Module Control Register (index_CID0:80h) */
 	size = pdc20621_prog_dimm0(host);
-	VPRINTK("Local DIMM Size = %dMB\n", size);
+   	VPRINTK("Local DIMM Size = %dMB\n",size);
 
-	/* Programming DIMM Module Global Control Register (index_CID0:88h) */
+   	/* Programming DIMM Module Global Control Register (index_CID0:88h) */
 	if (pdc20621_prog_dimm_global(host)) {
 		printk(KERN_ERR "Programming DIMM Module Global Control Register Fail\n");
 		return 1;
-	}
+   	}
 
 #ifdef ATA_VERBOSE_DEBUG
 	{
-		u8 test_parttern1[40] =
-			{0x55,0xAA,'P','r','o','m','i','s','e',' ',
-			'N','o','t',' ','Y','e','t',' ',
-			'D','e','f','i','n','e','d',' ',
-			'1','.','1','0',
-			'9','8','0','3','1','6','1','2',0,0};
+		u8 test_parttern1[40] = {0x55,0xAA,'P','r','o','m','i','s','e',' ',
+  				'N','o','t',' ','Y','e','t',' ','D','e','f','i','n','e','d',' ',
+ 				 '1','.','1','0',
+  				'9','8','0','3','1','6','1','2',0,0};
 		u8 test_parttern2[40] = {0};
 
-		pdc20621_put_to_dimm(host, test_parttern2, 0x10040, 40);
-		pdc20621_put_to_dimm(host, test_parttern2, 0x40, 40);
+		pdc20621_put_to_dimm(host, (void *) test_parttern2, 0x10040, 40);
+		pdc20621_put_to_dimm(host, (void *) test_parttern2, 0x40, 40);
 
-		pdc20621_put_to_dimm(host, test_parttern1, 0x10040, 40);
-		pdc20621_get_from_dimm(host, test_parttern2, 0x40, 40);
+		pdc20621_put_to_dimm(host, (void *) test_parttern1, 0x10040, 40);
+		pdc20621_get_from_dimm(host, (void *) test_parttern2, 0x40, 40);
 		printk(KERN_ERR "%x, %x, %s\n", test_parttern2[0],
 		       test_parttern2[1], &(test_parttern2[2]));
-		pdc20621_get_from_dimm(host, test_parttern2, 0x10040,
+		pdc20621_get_from_dimm(host, (void *) test_parttern2, 0x10040,
 				       40);
 		printk(KERN_ERR "%x, %x, %s\n", test_parttern2[0],
 		       test_parttern2[1], &(test_parttern2[2]));
 
-		pdc20621_put_to_dimm(host, test_parttern1, 0x40, 40);
-		pdc20621_get_from_dimm(host, test_parttern2, 0x40, 40);
+		pdc20621_put_to_dimm(host, (void *) test_parttern1, 0x40, 40);
+		pdc20621_get_from_dimm(host, (void *) test_parttern2, 0x40, 40);
 		printk(KERN_ERR "%x, %x, %s\n", test_parttern2[0],
 		       test_parttern2[1], &(test_parttern2[2]));
 	}
@@ -1395,17 +1332,14 @@
 	pdc20621_i2c_read(host, PDC_DIMM0_SPD_DEV_ADDRESS,
 			  PDC_DIMM_SPD_TYPE, &spd0);
 	if (spd0 == 0x02) {
-		void *buf;
 		VPRINTK("Start ECC initialization\n");
 		addr = 0;
 		length = size * 1024 * 1024;
-		buf = kzalloc(ECC_ERASE_BUF_SZ, GFP_KERNEL);
 		while (addr < length) {
-			pdc20621_put_to_dimm(host, buf, addr,
-					     ECC_ERASE_BUF_SZ);
-			addr += ECC_ERASE_BUF_SZ;
+			pdc20621_put_to_dimm(host, (void *) &tmp, addr,
+					     sizeof(u32));
+			addr += sizeof(u32);
 		}
-		kfree(buf);
 		VPRINTK("Finish ECC initialization\n");
 	}
 	return 0;
@@ -1443,15 +1377,15 @@
 	readl(mmio + PDC_HDMA_CTLSTAT);		/* flush */
 }
 
-static int pdc_sata_init_one(struct pci_dev *pdev,
-			     const struct pci_device_id *ent)
+static int pdc_sata_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
 	const struct ata_port_info *ppi[] =
 		{ &pdc_port_info[ent->driver_data], NULL };
 	struct ata_host *host;
+	void __iomem *base;
 	struct pdc_host_priv *hpriv;
-	int i, rc;
+	int rc;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
@@ -1477,17 +1411,11 @@
 		return rc;
 	host->iomap = pcim_iomap_table(pdev);
 
-	for (i = 0; i < 4; i++) {
-		struct ata_port *ap = host->ports[i];
-		void __iomem *base = host->iomap[PDC_MMIO_BAR] + PDC_CHIP0_OFS;
-		unsigned int offset = 0x200 + i * 0x80;
-
-		pdc_sata_setup_port(&ap->ioaddr, base + offset);
-
-		ata_port_pbar_desc(ap, PDC_MMIO_BAR, -1, "mmio");
-		ata_port_pbar_desc(ap, PDC_DIMM_BAR, -1, "dimm");
-		ata_port_pbar_desc(ap, PDC_MMIO_BAR, offset, "port");
-	}
+	base = host->iomap[PDC_MMIO_BAR] + PDC_CHIP0_OFS;
+	pdc_sata_setup_port(&host->ports[0]->ioaddr, base + 0x200);
+	pdc_sata_setup_port(&host->ports[1]->ioaddr, base + 0x280);
+	pdc_sata_setup_port(&host->ports[2]->ioaddr, base + 0x300);
+	pdc_sata_setup_port(&host->ports[3]->ioaddr, base + 0x380);
 
 	/* configure and activate */
 	rc = pci_set_dma_mask(pdev, ATA_DMA_MASK);
diff -Nur linux-sh4/drivers/ata.org/sata_uli.c linux-sh4/drivers/ata/sata_uli.c
--- linux-sh4/drivers/ata.org/sata_uli.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_uli.c	2012-01-15 06:30:15.000000000 -0800
@@ -56,9 +56,9 @@
 	unsigned int		scr_cfg_addr[uli_max_ports];
 };
 
-static int uli_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
-static int uli_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val);
-static int uli_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val);
+static int uli_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
+static int uli_scr_read (struct ata_port *ap, unsigned int sc_reg, u32 *val);
+static int uli_scr_write (struct ata_port *ap, unsigned int sc_reg, u32 val);
 
 static const struct pci_device_id uli_pci_tbl[] = {
 	{ PCI_VDEVICE(AL, 0x5289), uli_5289 },
@@ -76,20 +76,59 @@
 };
 
 static struct scsi_host_template uli_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
+};
+
+static const struct ata_port_operations uli_ops = {
+	.port_disable		= ata_port_disable,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.bmdma_setup            = ata_bmdma_setup,
+	.bmdma_start            = ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 
-static struct ata_port_operations uli_ops = {
-	.inherits		= &ata_bmdma_port_ops,
 	.scr_read		= uli_scr_read,
 	.scr_write		= uli_scr_write,
-	.hardreset		= ATA_OP_NULL,
+
+	.port_start		= ata_port_start,
 };
 
 static const struct ata_port_info uli_port_info = {
 	.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
 			  ATA_FLAG_IGN_SIMPLEX,
-	.pio_mask       = ATA_PIO4,
+	.pio_mask       = 0x1f,		/* pio0-4 */
 	.udma_mask      = ATA_UDMA6,
 	.port_ops       = &uli_ops,
 };
@@ -107,43 +146,43 @@
 	return hpriv->scr_cfg_addr[ap->port_no] + (4 * sc_reg);
 }
 
-static u32 uli_scr_cfg_read(struct ata_link *link, unsigned int sc_reg)
+static u32 uli_scr_cfg_read (struct ata_port *ap, unsigned int sc_reg)
 {
-	struct pci_dev *pdev = to_pci_dev(link->ap->host->dev);
-	unsigned int cfg_addr = get_scr_cfg_addr(link->ap, sc_reg);
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	unsigned int cfg_addr = get_scr_cfg_addr(ap, sc_reg);
 	u32 val;
 
 	pci_read_config_dword(pdev, cfg_addr, &val);
 	return val;
 }
 
-static void uli_scr_cfg_write(struct ata_link *link, unsigned int scr, u32 val)
+static void uli_scr_cfg_write (struct ata_port *ap, unsigned int scr, u32 val)
 {
-	struct pci_dev *pdev = to_pci_dev(link->ap->host->dev);
-	unsigned int cfg_addr = get_scr_cfg_addr(link->ap, scr);
+	struct pci_dev *pdev = to_pci_dev(ap->host->dev);
+	unsigned int cfg_addr = get_scr_cfg_addr(ap, scr);
 
 	pci_write_config_dword(pdev, cfg_addr, val);
 }
 
-static int uli_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)
+static int uli_scr_read (struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
 
-	*val = uli_scr_cfg_read(link, sc_reg);
+	*val = uli_scr_cfg_read(ap, sc_reg);
 	return 0;
 }
 
-static int uli_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)
+static int uli_scr_write (struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
-	if (sc_reg > SCR_CONTROL) //SCR_CONTROL=2, SCR_ERROR=1, SCR_STATUS=0
+	if (sc_reg > SCR_CONTROL)	//SCR_CONTROL=2, SCR_ERROR=1, SCR_STATUS=0
 		return -EINVAL;
 
-	uli_scr_cfg_write(link, sc_reg, val);
+	uli_scr_cfg_write(ap, sc_reg, val);
 	return 0;
 }
 
-static int uli_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
+static int uli_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
 	const struct ata_port_info *ppi[] = { &uli_port_info, NULL };
@@ -176,11 +215,11 @@
 	host->private_data = hpriv;
 
 	/* the first two ports are standard SFF */
-	rc = ata_pci_sff_init_host(host);
+	rc = ata_pci_init_sff_host(host);
 	if (rc)
 		return rc;
 
-	rc = ata_pci_bmdma_init(host);
+	rc = ata_pci_init_bmdma(host);
 	if (rc)
 		return rc;
 
@@ -201,13 +240,7 @@
 			((unsigned long)iomap[1] | ATA_PCI_CTL_OFS) + 4;
 		ioaddr->bmdma_addr = iomap[4] + 16;
 		hpriv->scr_cfg_addr[2] = ULI5287_BASE + ULI5287_OFFS*4;
-		ata_sff_std_ports(ioaddr);
-
-		ata_port_desc(host->ports[2],
-			"cmd 0x%llx ctl 0x%llx bmdma 0x%llx",
-			(unsigned long long)pci_resource_start(pdev, 0) + 8,
-			((unsigned long long)pci_resource_start(pdev, 1) | ATA_PCI_CTL_OFS) + 4,
-			(unsigned long long)pci_resource_start(pdev, 4) + 16);
+		ata_std_ports(ioaddr);
 
 		ioaddr = &host->ports[3]->ioaddr;
 		ioaddr->cmd_addr = iomap[2] + 8;
@@ -216,14 +249,7 @@
 			((unsigned long)iomap[3] | ATA_PCI_CTL_OFS) + 4;
 		ioaddr->bmdma_addr = iomap[4] + 24;
 		hpriv->scr_cfg_addr[3] = ULI5287_BASE + ULI5287_OFFS*5;
-		ata_sff_std_ports(ioaddr);
-
-		ata_port_desc(host->ports[2],
-			"cmd 0x%llx ctl 0x%llx bmdma 0x%llx",
-			(unsigned long long)pci_resource_start(pdev, 2) + 9,
-			((unsigned long long)pci_resource_start(pdev, 3) | ATA_PCI_CTL_OFS) + 4,
-			(unsigned long long)pci_resource_start(pdev, 4) + 24);
-
+		ata_std_ports(ioaddr);
 		break;
 
 	case uli_5289:
@@ -243,8 +269,8 @@
 
 	pci_set_master(pdev);
 	pci_intx(pdev, 1);
-	return ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &uli_sht);
+	return ata_host_activate(host, pdev->irq, ata_interrupt, IRQF_SHARED,
+				 &uli_sht);
 }
 
 static int __init uli_init(void)
diff -Nur linux-sh4/drivers/ata.org/sata_via.c linux-sh4/drivers/ata/sata_via.c
--- linux-sh4/drivers/ata.org/sata_via.c	2012-03-10 00:25:13.000000000 -0800
+++ linux-sh4/drivers/ata/sata_via.c	2012-01-15 06:30:15.000000000 -0800
@@ -3,7 +3,7 @@
  *
  *  Maintained by:  Jeff Garzik <jgarzik@pobox.com>
  * 		   Please ALWAYS copy linux-ide@vger.kernel.org
- *		   on emails.
+ 		   on emails.
  *
  *  Copyright 2003-2004 Red Hat, Inc.  All rights reserved.
  *  Copyright 2003-2004 Jeff Garzik
@@ -30,6 +30,8 @@
  *  Hardware documentation available under NDA.
  *
  *
+ *  To-do list:
+ *  - VT6421 PATA support
  *
  */
 
@@ -40,28 +42,22 @@
 #include <linux/blkdev.h>
 #include <linux/delay.h>
 #include <linux/device.h>
-#include <scsi/scsi.h>
-#include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_host.h>
 #include <linux/libata.h>
 
 #define DRV_NAME	"sata_via"
-#define DRV_VERSION	"2.4"
+#define DRV_VERSION	"2.3"
 
-/*
- * vt8251 is different from other sata controllers of VIA.  It has two
- * channels, each channel has both Master and Slave slot.
- */
 enum board_ids_enum {
 	vt6420,
 	vt6421,
-	vt8251,
 };
 
 enum {
 	SATA_CHAN_ENAB		= 0x40, /* SATA channel enable */
 	SATA_INT_GATE		= 0x41, /* SATA interrupt gating */
 	SATA_NATIVE_MODE	= 0x42, /* Native mode enable */
+	SATA_PATA_SHARING	= 0x49, /* PATA/SATA sharing func ctrl */
 	PATA_UDMA_TIMING	= 0xB3, /* PATA timing for DMA/ cable detect */
 	PATA_PIO_TIMING		= 0xAB, /* PATA timing register */
 
@@ -72,30 +68,26 @@
 	NATIVE_MODE_ALL		= (1 << 7) | (1 << 6) | (1 << 5) | (1 << 4),
 
 	SATA_EXT_PHY		= (1 << 6), /* 0==use PATA, 1==ext phy */
+	SATA_2DEV		= (1 << 5), /* SATA is master/slave */
 };
 
-static int svia_init_one(struct pci_dev *pdev, const struct pci_device_id *ent);
-static int svia_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val);
-static int svia_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val);
-static int vt8251_scr_read(struct ata_link *link, unsigned int scr, u32 *val);
-static int vt8251_scr_write(struct ata_link *link, unsigned int scr, u32 val);
-static void svia_tf_load(struct ata_port *ap, const struct ata_taskfile *tf);
+static int svia_init_one (struct pci_dev *pdev, const struct pci_device_id *ent);
+static int svia_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val);
+static int svia_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val);
 static void svia_noop_freeze(struct ata_port *ap);
-static int vt6420_prereset(struct ata_link *link, unsigned long deadline);
-static void vt6420_bmdma_start(struct ata_queued_cmd *qc);
+static void vt6420_error_handler(struct ata_port *ap);
 static int vt6421_pata_cable_detect(struct ata_port *ap);
 static void vt6421_set_pio_mode(struct ata_port *ap, struct ata_device *adev);
 static void vt6421_set_dma_mode(struct ata_port *ap, struct ata_device *adev);
 
 static const struct pci_device_id svia_pci_tbl[] = {
 	{ PCI_VDEVICE(VIA, 0x5337), vt6420 },
-	{ PCI_VDEVICE(VIA, 0x0591), vt6420 }, /* 2 sata chnls (Master) */
-	{ PCI_VDEVICE(VIA, 0x3149), vt6420 }, /* 2 sata chnls (Master) */
-	{ PCI_VDEVICE(VIA, 0x3249), vt6421 }, /* 2 sata chnls, 1 pata chnl */
+	{ PCI_VDEVICE(VIA, 0x0591), vt6420 },
+	{ PCI_VDEVICE(VIA, 0x3149), vt6420 },
+	{ PCI_VDEVICE(VIA, 0x3249), vt6421 },
+	{ PCI_VDEVICE(VIA, 0x5287), vt6420 },
 	{ PCI_VDEVICE(VIA, 0x5372), vt6420 },
 	{ PCI_VDEVICE(VIA, 0x7372), vt6420 },
-	{ PCI_VDEVICE(VIA, 0x5287), vt8251 }, /* 2 sata chnls (Master/Slave) */
-	{ PCI_VDEVICE(VIA, 0x9000), vt8251 },
 
 	{ }	/* terminate list */
 };
@@ -112,208 +104,179 @@
 };
 
 static struct scsi_host_template svia_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
-};
-
-static struct ata_port_operations svia_base_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	.sff_tf_load		= svia_tf_load,
-};
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
+};
+
+static const struct ata_port_operations vt6420_sata_ops = {
+	.port_disable		= ata_port_disable,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.bmdma_setup            = ata_bmdma_setup,
+	.bmdma_start            = ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
 
-static struct ata_port_operations vt6420_sata_ops = {
-	.inherits		= &svia_base_ops,
 	.freeze			= svia_noop_freeze,
-	.prereset		= vt6420_prereset,
-	.bmdma_start		= vt6420_bmdma_start,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= vt6420_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
 };
 
-static struct ata_port_operations vt6421_pata_ops = {
-	.inherits		= &svia_base_ops,
-	.cable_detect		= vt6421_pata_cable_detect,
+static const struct ata_port_operations vt6421_pata_ops = {
+	.port_disable		= ata_port_disable,
+
 	.set_piomode		= vt6421_set_pio_mode,
 	.set_dmamode		= vt6421_set_dma_mode,
-};
 
-static struct ata_port_operations vt6421_sata_ops = {
-	.inherits		= &svia_base_ops,
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.bmdma_setup            = ata_bmdma_setup,
+	.bmdma_start            = ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= vt6421_pata_cable_detect,
+
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
+	.port_start		= ata_port_start,
+};
+
+static const struct ata_port_operations vt6421_sata_ops = {
+	.port_disable		= ata_port_disable,
+
+	.tf_load		= ata_tf_load,
+	.tf_read		= ata_tf_read,
+	.check_status		= ata_check_status,
+	.exec_command		= ata_exec_command,
+	.dev_select		= ata_std_dev_select,
+
+	.bmdma_setup            = ata_bmdma_setup,
+	.bmdma_start            = ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
+
+	.freeze			= ata_bmdma_freeze,
+	.thaw			= ata_bmdma_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.cable_detect		= ata_cable_sata,
+
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
+
 	.scr_read		= svia_scr_read,
 	.scr_write		= svia_scr_write,
-};
 
-static struct ata_port_operations vt8251_ops = {
-	.inherits		= &svia_base_ops,
-	.hardreset		= sata_std_hardreset,
-	.scr_read		= vt8251_scr_read,
-	.scr_write		= vt8251_scr_write,
+	.port_start		= ata_port_start,
 };
 
 static const struct ata_port_info vt6420_port_info = {
 	.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY,
-	.pio_mask	= ATA_PIO4,
-	.mwdma_mask	= ATA_MWDMA2,
+	.pio_mask	= 0x1f,
+	.mwdma_mask	= 0x07,
 	.udma_mask	= ATA_UDMA6,
 	.port_ops	= &vt6420_sata_ops,
 };
 
 static struct ata_port_info vt6421_sport_info = {
 	.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY,
-	.pio_mask	= ATA_PIO4,
-	.mwdma_mask	= ATA_MWDMA2,
+	.pio_mask	= 0x1f,
+	.mwdma_mask	= 0x07,
 	.udma_mask	= ATA_UDMA6,
 	.port_ops	= &vt6421_sata_ops,
 };
 
 static struct ata_port_info vt6421_pport_info = {
 	.flags		= ATA_FLAG_SLAVE_POSS | ATA_FLAG_NO_LEGACY,
-	.pio_mask	= ATA_PIO4,
-	/* No MWDMA */
+	.pio_mask	= 0x1f,
+	.mwdma_mask	= 0,
 	.udma_mask	= ATA_UDMA6,
 	.port_ops	= &vt6421_pata_ops,
 };
 
-static struct ata_port_info vt8251_port_info = {
-	.flags		= ATA_FLAG_SATA | ATA_FLAG_SLAVE_POSS |
-			  ATA_FLAG_NO_LEGACY,
-	.pio_mask	= ATA_PIO4,
-	.mwdma_mask	= ATA_MWDMA2,
-	.udma_mask	= ATA_UDMA6,
-	.port_ops	= &vt8251_ops,
-};
-
 MODULE_AUTHOR("Jeff Garzik");
 MODULE_DESCRIPTION("SCSI low-level driver for VIA SATA controllers");
 MODULE_LICENSE("GPL");
 MODULE_DEVICE_TABLE(pci, svia_pci_tbl);
 MODULE_VERSION(DRV_VERSION);
 
-static int svia_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)
+static int svia_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	*val = ioread32(link->ap->ioaddr.scr_addr + (4 * sc_reg));
+	*val = ioread32(ap->ioaddr.scr_addr + (4 * sc_reg));
 	return 0;
 }
 
-static int svia_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)
+static int svia_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	iowrite32(val, link->ap->ioaddr.scr_addr + (4 * sc_reg));
+	iowrite32(val, ap->ioaddr.scr_addr + (4 * sc_reg));
 	return 0;
 }
 
-static int vt8251_scr_read(struct ata_link *link, unsigned int scr, u32 *val)
-{
-	static const u8 ipm_tbl[] = { 1, 2, 6, 0 };
-	struct pci_dev *pdev = to_pci_dev(link->ap->host->dev);
-	int slot = 2 * link->ap->port_no + link->pmp;
-	u32 v = 0;
-	u8 raw;
-
-	switch (scr) {
-	case SCR_STATUS:
-		pci_read_config_byte(pdev, 0xA0 + slot, &raw);
-
-		/* read the DET field, bit0 and 1 of the config byte */
-		v |= raw & 0x03;
-
-		/* read the SPD field, bit4 of the configure byte */
-		if (raw & (1 << 4))
-			v |= 0x02 << 4;
-		else
-			v |= 0x01 << 4;
-
-		/* read the IPM field, bit2 and 3 of the config byte */
-		v |= ipm_tbl[(raw >> 2) & 0x3];
-		break;
-
-	case SCR_ERROR:
-		/* devices other than 5287 uses 0xA8 as base */
-		WARN_ON(pdev->device != 0x5287);
-		pci_read_config_dword(pdev, 0xB0 + slot * 4, &v);
-		break;
-
-	case SCR_CONTROL:
-		pci_read_config_byte(pdev, 0xA4 + slot, &raw);
-
-		/* read the DET field, bit0 and bit1 */
-		v |= ((raw & 0x02) << 1) | (raw & 0x01);
-
-		/* read the IPM field, bit2 and bit3 */
-		v |= ((raw >> 2) & 0x03) << 8;
-		break;
-
-	default:
-		return -EINVAL;
-	}
-
-	*val = v;
-	return 0;
-}
-
-static int vt8251_scr_write(struct ata_link *link, unsigned int scr, u32 val)
-{
-	struct pci_dev *pdev = to_pci_dev(link->ap->host->dev);
-	int slot = 2 * link->ap->port_no + link->pmp;
-	u32 v = 0;
-
-	switch (scr) {
-	case SCR_ERROR:
-		/* devices other than 5287 uses 0xA8 as base */
-		WARN_ON(pdev->device != 0x5287);
-		pci_write_config_dword(pdev, 0xB0 + slot * 4, val);
-		return 0;
-
-	case SCR_CONTROL:
-		/* set the DET field */
-		v |= ((val & 0x4) >> 1) | (val & 0x1);
-
-		/* set the IPM field */
-		v |= ((val >> 8) & 0x3) << 2;
-
-		pci_write_config_byte(pdev, 0xA4 + slot, v);
-		return 0;
-
-	default:
-		return -EINVAL;
-	}
-}
-
-/**
- *	svia_tf_load - send taskfile registers to host controller
- *	@ap: Port to which output is sent
- *	@tf: ATA taskfile register set
- *
- *	Outputs ATA taskfile to standard ATA host controller.
- *
- *	This is to fix the internal bug of via chipsets, which will
- *	reset the device register after changing the IEN bit on ctl
- *	register.
- */
-static void svia_tf_load(struct ata_port *ap, const struct ata_taskfile *tf)
-{
-	struct ata_taskfile ttf;
-
-	if (tf->ctl != ap->last_ctl)  {
-		ttf = *tf;
-		ttf.flags |= ATA_TFLAG_DEVICE;
-		tf = &ttf;
-	}
-	ata_sff_tf_load(ap, tf);
-}
-
 static void svia_noop_freeze(struct ata_port *ap)
 {
 	/* Some VIA controllers choke if ATA_NIEN is manipulated in
 	 * certain way.  Leave it alone and just clear pending IRQ.
 	 */
-	ap->ops->sff_check_status(ap);
-	ata_sff_irq_clear(ap);
+	ata_chk_status(ap);
+	ata_bmdma_irq_clear(ap);
 }
 
 /**
  *	vt6420_prereset - prereset for vt6420
- *	@link: target ATA link
+ *	@ap: target ATA port
  *	@deadline: deadline jiffies for the operation
  *
  *	SCR registers on vt6420 are pieces of shit and may hang the
@@ -331,10 +294,9 @@
  *	RETURNS:
  *	0 on success, -errno otherwise.
  */
-static int vt6420_prereset(struct ata_link *link, unsigned long deadline)
+static int vt6420_prereset(struct ata_port *ap, unsigned long deadline)
 {
-	struct ata_port *ap = link->ap;
-	struct ata_eh_context *ehc = &ap->link.eh_context;
+	struct ata_eh_context *ehc = &ap->eh_context;
 	unsigned long timeout = jiffies + (HZ * 5);
 	u32 sstatus, scontrol;
 	int online;
@@ -344,20 +306,20 @@
 		goto skip_scr;
 
 	/* Resume phy.  This is the old SATA resume sequence */
-	svia_scr_write(link, SCR_CONTROL, 0x300);
-	svia_scr_read(link, SCR_CONTROL, &scontrol); /* flush */
+	svia_scr_write(ap, SCR_CONTROL, 0x300);
+	svia_scr_read(ap, SCR_CONTROL, &scontrol); /* flush */
 
 	/* wait for phy to become ready, if necessary */
 	do {
 		msleep(200);
-		svia_scr_read(link, SCR_STATUS, &sstatus);
+		svia_scr_read(ap, SCR_STATUS, &sstatus);
 		if ((sstatus & 0xf) != 1)
 			break;
 	} while (time_before(jiffies, timeout));
 
 	/* open code sata_print_link_status() */
-	svia_scr_read(link, SCR_STATUS, &sstatus);
-	svia_scr_read(link, SCR_CONTROL, &scontrol);
+	svia_scr_read(ap, SCR_STATUS, &sstatus);
+	svia_scr_read(ap, SCR_CONTROL, &scontrol);
 
 	online = (sstatus & 0xf) == 0x3;
 
@@ -366,30 +328,25 @@
 			online ? "up" : "down", sstatus, scontrol);
 
 	/* SStatus is read one more time */
-	svia_scr_read(link, SCR_STATUS, &sstatus);
+	svia_scr_read(ap, SCR_STATUS, &sstatus);
 
 	if (!online) {
 		/* tell EH to bail */
-		ehc->i.action &= ~ATA_EH_RESET;
+		ehc->i.action &= ~ATA_EH_RESET_MASK;
 		return 0;
 	}
 
  skip_scr:
 	/* wait for !BSY */
-	ata_sff_wait_ready(link, deadline);
+	ata_wait_ready(ap, deadline);
 
 	return 0;
 }
 
-static void vt6420_bmdma_start(struct ata_queued_cmd *qc)
+static void vt6420_error_handler(struct ata_port *ap)
 {
-	struct ata_port *ap = qc->ap;
-	if ((qc->tf.command == ATA_CMD_PACKET) &&
-	    (qc->scsicmd->sc_data_direction == DMA_TO_DEVICE)) {
-		/* Prevents corruption on some ATAPI burners */
-		ata_sff_pause(ap);
-	}
-	ata_bmdma_start(qc);
+	return ata_bmdma_drive_eh(ap, vt6420_prereset, ata_std_softreset,
+				  NULL, ata_std_postreset);
 }
 
 static int vt6421_pata_cable_detect(struct ata_port *ap)
@@ -425,12 +382,12 @@
 	16, 16, 16, 16, 32, 128
 };
 
-static void __iomem *svia_scr_addr(void __iomem *addr, unsigned int port)
+static void __iomem * svia_scr_addr(void __iomem *addr, unsigned int port)
 {
 	return addr + (port * 128);
 }
 
-static void __iomem *vt6421_scr_addr(void __iomem *addr, unsigned int port)
+static void __iomem * vt6421_scr_addr(void __iomem *addr, unsigned int port)
 {
 	return addr + (port * 64);
 }
@@ -449,10 +406,7 @@
 	ioaddr->bmdma_addr = bmdma_addr;
 	ioaddr->scr_addr = vt6421_scr_addr(iomap[5], ap->port_no);
 
-	ata_sff_std_ports(ioaddr);
-
-	ata_port_pbar_desc(ap, ap->port_no, -1, "port");
-	ata_port_pbar_desc(ap, 4, ap->port_no * 8, "bmdma");
+	ata_std_ports(ioaddr);
 }
 
 static int vt6420_prepare_host(struct pci_dev *pdev, struct ata_host **r_host)
@@ -461,7 +415,7 @@
 	struct ata_host *host;
 	int rc;
 
-	rc = ata_pci_sff_prepare_host(pdev, ppi, &host);
+	rc = ata_pci_prepare_sff_host(pdev, ppi, &host);
 	if (rc)
 		return rc;
 	*r_host = host;
@@ -512,30 +466,6 @@
 	return 0;
 }
 
-static int vt8251_prepare_host(struct pci_dev *pdev, struct ata_host **r_host)
-{
-	const struct ata_port_info *ppi[] = { &vt8251_port_info, NULL };
-	struct ata_host *host;
-	int i, rc;
-
-	rc = ata_pci_sff_prepare_host(pdev, ppi, &host);
-	if (rc)
-		return rc;
-	*r_host = host;
-
-	rc = pcim_iomap_regions(pdev, 1 << 5, DRV_NAME);
-	if (rc) {
-		dev_printk(KERN_ERR, &pdev->dev, "failed to iomap PCI BAR 5\n");
-		return rc;
-	}
-
-	/* 8251 hosts four sata ports as M/S of the two channels */
-	for (i = 0; i < host->n_ports; i++)
-		ata_slave_link_init(host->ports[i]);
-
-	return 0;
-}
-
 static void svia_configure(struct pci_dev *pdev)
 {
 	u8 tmp8;
@@ -549,7 +479,7 @@
 	if ((tmp8 & ALL_PORTS) != ALL_PORTS) {
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "enabling SATA channels (0x%x)\n",
-			   (int) tmp8);
+		           (int) tmp8);
 		tmp8 |= ALL_PORTS;
 		pci_write_config_byte(pdev, SATA_CHAN_ENAB, tmp8);
 	}
@@ -559,7 +489,7 @@
 	if ((tmp8 & ALL_PORTS) != ALL_PORTS) {
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "enabling SATA channel interrupts (0x%x)\n",
-			   (int) tmp8);
+		           (int) tmp8);
 		tmp8 |= ALL_PORTS;
 		pci_write_config_byte(pdev, SATA_INT_GATE, tmp8);
 	}
@@ -569,33 +499,21 @@
 	if ((tmp8 & NATIVE_MODE_ALL) != NATIVE_MODE_ALL) {
 		dev_printk(KERN_DEBUG, &pdev->dev,
 			   "enabling SATA channel native mode (0x%x)\n",
-			   (int) tmp8);
+		           (int) tmp8);
 		tmp8 |= NATIVE_MODE_ALL;
 		pci_write_config_byte(pdev, SATA_NATIVE_MODE, tmp8);
 	}
-
-	/*
-	 * vt6421 has problems talking to some drives.  The following
-	 * is the magic fix from Joseph Chan <JosephChan@via.com.tw>.
-	 * Please add proper documentation if possible.
-	 *
-	 * https://bugzilla.kernel.org/show_bug.cgi?id=15173
-	 */
-	if (pdev->device == 0x3249) {
-		pci_read_config_byte(pdev, 0x52, &tmp8);
-		tmp8 |= 1 << 2;
-		pci_write_config_byte(pdev, 0x52, tmp8);
-	}
 }
 
-static int svia_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)
+static int svia_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static int printed_version;
 	unsigned int i;
 	int rc;
-	struct ata_host *host = NULL;
+	struct ata_host *host;
 	int board_id = (int) ent->driver_data;
-	const unsigned *bar_sizes;
+	const int *bar_sizes;
+	u8 tmp8;
 
 	if (!printed_version++)
 		dev_printk(KERN_DEBUG, &pdev->dev, "version " DRV_VERSION "\n");
@@ -604,10 +522,19 @@
 	if (rc)
 		return rc;
 
-	if (board_id == vt6421)
-		bar_sizes = &vt6421_bar_sizes[0];
-	else
+	if (board_id == vt6420) {
+		pci_read_config_byte(pdev, SATA_PATA_SHARING, &tmp8);
+		if (tmp8 & SATA_2DEV) {
+			dev_printk(KERN_ERR, &pdev->dev,
+				   "SATA master/slave not supported (0x%x)\n",
+		       		   (int) tmp8);
+			return -EIO;
+		}
+
 		bar_sizes = &svia_bar_sizes[0];
+	} else {
+		bar_sizes = &vt6421_bar_sizes[0];
+	}
 
 	for (i = 0; i < ARRAY_SIZE(svia_bar_sizes); i++)
 		if ((pci_resource_start(pdev, i) == 0) ||
@@ -615,32 +542,23 @@
 			dev_printk(KERN_ERR, &pdev->dev,
 				"invalid PCI BAR %u (sz 0x%llx, val 0x%llx)\n",
 				i,
-				(unsigned long long)pci_resource_start(pdev, i),
-				(unsigned long long)pci_resource_len(pdev, i));
+			        (unsigned long long)pci_resource_start(pdev, i),
+			        (unsigned long long)pci_resource_len(pdev, i));
 			return -ENODEV;
 		}
 
-	switch (board_id) {
-	case vt6420:
+	if (board_id == vt6420)
 		rc = vt6420_prepare_host(pdev, &host);
-		break;
-	case vt6421:
+	else
 		rc = vt6421_prepare_host(pdev, &host);
-		break;
-	case vt8251:
-		rc = vt8251_prepare_host(pdev, &host);
-		break;
-	default:
-		rc = -EINVAL;
-	}
 	if (rc)
 		return rc;
 
 	svia_configure(pdev);
 
 	pci_set_master(pdev);
-	return ata_host_activate(host, pdev->irq, ata_sff_interrupt,
-				 IRQF_SHARED, &svia_sht);
+	return ata_host_activate(host, pdev->irq, ata_interrupt, IRQF_SHARED,
+				 &svia_sht);
 }
 
 static int __init svia_init(void)
diff -Nur linux-sh4/drivers/ata.org/sata_vsc.c linux-sh4/drivers/ata/sata_vsc.c
--- linux-sh4/drivers/ata.org/sata_vsc.c	2009-12-02 19:51:21.000000000 -0800
+++ linux-sh4/drivers/ata/sata_vsc.c	2012-01-15 06:30:15.000000000 -0800
@@ -98,22 +98,20 @@
 			      VSC_SATA_INT_PHY_CHANGE),
 };
 
-static int vsc_sata_scr_read(struct ata_link *link,
-			     unsigned int sc_reg, u32 *val)
+static int vsc_sata_scr_read(struct ata_port *ap, unsigned int sc_reg, u32 *val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	*val = readl(link->ap->ioaddr.scr_addr + (sc_reg * 4));
+	*val = readl(ap->ioaddr.scr_addr + (sc_reg * 4));
 	return 0;
 }
 
 
-static int vsc_sata_scr_write(struct ata_link *link,
-			      unsigned int sc_reg, u32 val)
+static int vsc_sata_scr_write(struct ata_port *ap, unsigned int sc_reg, u32 val)
 {
 	if (sc_reg > SCR_CONTROL)
 		return -EINVAL;
-	writel(val, link->ap->ioaddr.scr_addr + (sc_reg * 4));
+	writel(val, ap->ioaddr.scr_addr + (sc_reg * 4));
 	return 0;
 }
 
@@ -164,8 +162,7 @@
 	/*
 	 * The only thing the ctl register is used for is SRST.
 	 * That is not enabled or disabled via tf_load.
-	 * However, if ATA_NIEN is changed, then we need to change
-	 * the interrupt register.
+	 * However, if ATA_NIEN is changed, then we need to change the interrupt register.
 	 */
 	if ((tf->ctl & ATA_NIEN) != (ap->last_ctl & ATA_NIEN)) {
 		ap->last_ctl = tf->ctl;
@@ -202,7 +199,7 @@
 	struct ata_ioports *ioaddr = &ap->ioaddr;
 	u16 nsect, lbal, lbam, lbah, feature;
 
-	tf->command = ata_sff_check_status(ap);
+	tf->command = ata_check_status(ap);
 	tf->device = readw(ioaddr->device_addr);
 	feature = readw(ioaddr->error_addr);
 	nsect = readw(ioaddr->nsect_addr);
@@ -222,7 +219,7 @@
 		tf->hob_lbal = lbal >> 8;
 		tf->hob_lbam = lbam >> 8;
 		tf->hob_lbah = lbah >> 8;
-	}
+        }
 }
 
 static inline void vsc_error_intr(u8 port_status, struct ata_port *ap)
@@ -243,9 +240,9 @@
 		return;
 	}
 
-	qc = ata_qc_from_tag(ap, ap->link.active_tag);
+	qc = ata_qc_from_tag(ap, ap->active_tag);
 	if (qc && likely(!(qc->tf.flags & ATA_TFLAG_POLLING)))
-		handled = ata_sff_host_intr(ap, qc);
+		handled = ata_host_intr(ap, qc);
 
 	/* We received an interrupt during a polled command,
 	 * or some other spurious condition.  Interrupt reporting
@@ -253,16 +250,15 @@
 	 * simply clear the interrupt
 	 */
 	if (unlikely(!handled))
-		ap->ops->sff_check_status(ap);
+		ata_chk_status(ap);
 }
 
 /*
  * vsc_sata_interrupt
  *
- * Read the interrupt register and process for the devices that have
- * them pending.
+ * Read the interrupt register and process for the devices that have them pending.
  */
-static irqreturn_t vsc_sata_interrupt(int irq, void *dev_instance)
+static irqreturn_t vsc_sata_interrupt (int irq, void *dev_instance)
 {
 	struct ata_host *host = dev_instance;
 	unsigned int i;
@@ -291,7 +287,7 @@
 				handled++;
 			} else
 				dev_printk(KERN_ERR, host->dev,
-					"interrupt from disabled port %d\n", i);
+					": interrupt from disabled port %d\n", i);
 		}
 	}
 
@@ -302,21 +298,48 @@
 
 
 static struct scsi_host_template vsc_sata_sht = {
-	ATA_BMDMA_SHT(DRV_NAME),
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
 };
 
 
-static struct ata_port_operations vsc_sata_ops = {
-	.inherits		= &ata_bmdma_port_ops,
-	/* The IRQ handling is not quite standard SFF behaviour so we
-	   cannot use the default lost interrupt handler */
-	.lost_interrupt		= ATA_OP_NULL,
-	.sff_tf_load		= vsc_sata_tf_load,
-	.sff_tf_read		= vsc_sata_tf_read,
+static const struct ata_port_operations vsc_sata_ops = {
+	.port_disable		= ata_port_disable,
+	.tf_load		= vsc_sata_tf_load,
+	.tf_read		= vsc_sata_tf_read,
+	.exec_command		= ata_exec_command,
+	.check_status		= ata_check_status,
+	.dev_select		= ata_std_dev_select,
+	.bmdma_setup            = ata_bmdma_setup,
+	.bmdma_start            = ata_bmdma_start,
+	.bmdma_stop		= ata_bmdma_stop,
+	.bmdma_status		= ata_bmdma_status,
+	.qc_prep		= ata_qc_prep,
+	.qc_issue		= ata_qc_issue_prot,
+	.data_xfer		= ata_data_xfer,
 	.freeze			= vsc_freeze,
 	.thaw			= vsc_thaw,
+	.error_handler		= ata_bmdma_error_handler,
+	.post_internal_cmd	= ata_bmdma_post_internal_cmd,
+	.irq_clear		= ata_bmdma_irq_clear,
+	.irq_on			= ata_irq_on,
+	.irq_ack		= ata_irq_ack,
 	.scr_read		= vsc_sata_scr_read,
 	.scr_write		= vsc_sata_scr_write,
+	.port_start		= ata_port_start,
 };
 
 static void __devinit vsc_sata_setup_port(struct ata_ioports *port,
@@ -342,14 +365,13 @@
 }
 
 
-static int __devinit vsc_sata_init_one(struct pci_dev *pdev,
-				       const struct pci_device_id *ent)
+static int __devinit vsc_sata_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	static const struct ata_port_info pi = {
 		.flags		= ATA_FLAG_SATA | ATA_FLAG_NO_LEGACY |
 				  ATA_FLAG_MMIO,
-		.pio_mask	= ATA_PIO4,
-		.mwdma_mask	= ATA_MWDMA2,
+		.pio_mask	= 0x1f,
+		.mwdma_mask	= 0x07,
 		.udma_mask	= ATA_UDMA6,
 		.port_ops	= &vsc_sata_ops,
 	};
@@ -386,23 +408,17 @@
 
 	mmio_base = host->iomap[VSC_MMIO_BAR];
 
-	for (i = 0; i < host->n_ports; i++) {
-		struct ata_port *ap = host->ports[i];
-		unsigned int offset = (i + 1) * VSC_SATA_PORT_OFFSET;
-
-		vsc_sata_setup_port(&ap->ioaddr, mmio_base + offset);
-
-		ata_port_pbar_desc(ap, VSC_MMIO_BAR, -1, "mmio");
-		ata_port_pbar_desc(ap, VSC_MMIO_BAR, offset, "port");
-	}
+	for (i = 0; i < host->n_ports; i++)
+		vsc_sata_setup_port(&host->ports[i]->ioaddr,
+				    mmio_base + (i + 1) * VSC_SATA_PORT_OFFSET);
 
 	/*
 	 * Use 32 bit DMA mask, because 64 bit address support is poor.
 	 */
-	rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
+	rc = pci_set_dma_mask(pdev, DMA_32BIT_MASK);
 	if (rc)
 		return rc;
-	rc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+	rc = pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK);
 	if (rc)
 		return rc;
 
